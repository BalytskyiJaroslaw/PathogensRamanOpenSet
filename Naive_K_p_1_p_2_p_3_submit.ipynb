{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BalytskyiJaroslaw/PathogensRamanOpenSet/blob/main/Naive_K_p_1_p_2_p_3_submit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6MZtHw8cizd"
      },
      "source": [
        "# Naive thresholding, $\\mathcal{K} = p_1+p_2+p_3$, $\\mathcal{I}$ = $∅$, $\\mathcal{N}$ = $∅$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlQ76qXvX-xJ"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "from pandas import read_csv\n",
        "\n",
        "from keras.layers import Lambda, Multiply\n",
        "import csv\n",
        "import pprint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "import keras\n",
        "#from keras.utils import to_categorical\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "#from keras.optimizers import SGD\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#from keras.optimizers import SGD\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import gspread\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import pywt\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "from time import time\n",
        "t00 = time()\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling1D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjMmDBRYc2nm"
      },
      "source": [
        "# Initializing TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEBeC3Gfc8Jg"
      },
      "outputs": [],
      "source": [
        "# Initialize the TPU and spread the computations across the 8 cores\n",
        "import tensorflow as tf\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "tf.config.list_logical_devices('TPU')\n",
        "#print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoXfC8vkdHIQ"
      },
      "source": [
        "# Uploading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEFKstcxdGnO",
        "outputId": "6964252c-f77f-4bca-9e46-53a040cc6173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyFU_ZXCgHGG"
      },
      "source": [
        "# Reference dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2X6lpq-dOSV"
      },
      "outputs": [],
      "source": [
        "# Reference data\n",
        "data_X_reference = np.load(\"/content/gdrive/MyDrive/Stanford_data/X_reference.npy\")\n",
        "# Test data\n",
        "data_X_test = np.load(\"/content/gdrive/MyDrive/Stanford_data/X_test.npy\")\n",
        "\n",
        "data_y_reference = np.load(\"/content/gdrive/MyDrive/Stanford_data/y_reference.npy\")\n",
        "# Test labels\n",
        "data_y_test = np.load(\"/content/gdrive/MyDrive/Stanford_data/y_test.npy\")\n",
        "\n",
        "data_y_reference_int = []\n",
        "\n",
        "for i in range(data_y_reference.shape[0]):\n",
        "  data_y_reference_int.append(int(data_y_reference[i]))\n",
        "\n",
        "data_y_test_int = []\n",
        "\n",
        "for i in range(data_y_test.shape[0]):\n",
        "  data_y_test_int.append(int(data_y_test[i]))\n",
        "\n",
        "train_label = tf.keras.utils.to_categorical(data_y_reference_int)\n",
        "test_label = tf.keras.utils.to_categorical(data_y_test_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpn4ERtzdVkk"
      },
      "source": [
        "# The case of $\\mathcal{K} = p_1+p_2+p_3$, corresponds to the known training reference indices: 10000 - 14000, 18000 - 38000, 42000 - 50000,52000 - 60000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ76u-x7di-7",
        "outputId": "92978890-8c49-4c92-c21f-35483cb2592f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the known data, reference: (40000, 1000)\n",
            "Shape of the known labels, reference: (40000, 20)\n"
          ]
        }
      ],
      "source": [
        "indices = [slice(10000, 14000),slice(18000, 38000),slice(42000, 50000),slice(52000, 60000)]\n",
        "\n",
        "Known_data_X_reference = np.concatenate([data_X_reference[idx, :] for idx in indices], axis=0)\n",
        "\n",
        "Known_data_X_train_label_int = []\n",
        "\n",
        "for i in range(2000*20):\n",
        "  Known_data_X_train_label_int.append(int(data_y_reference[i]))\n",
        "\n",
        "Known_data_X_train_label = tf.keras.utils.to_categorical(Known_data_X_train_label_int)\n",
        "print(\"Shape of the known data, reference:\", Known_data_X_reference.shape)\n",
        "print(\"Shape of the known labels, reference:\", Known_data_X_train_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZzs-rpIfJ9f"
      },
      "source": [
        "# Known data indices, testing dataset. Indices = 500-700, 900-1900, 2100 -2500,2600 - 3000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1a48lk8djF5",
        "outputId": "f2aa0c86-b30c-4856-9faa-788c4cda4176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the known data, test: (2000, 1000)\n",
            "Shape of the known labels, test: (2000, 20)\n"
          ]
        }
      ],
      "source": [
        "indices = [slice(500, 700),slice(900, 1900),slice(2100, 2500),slice(2600, 3000)]\n",
        "\n",
        "Known_data_X_test = np.concatenate([data_X_test[idx, :] for idx in indices], axis=0)\n",
        "\n",
        "Known_data_X_test_label_int = []\n",
        "\n",
        "for i in range(100*20):\n",
        "  Known_data_X_test_label_int.append(int(data_y_test[i]))\n",
        "\n",
        "Known_data_X_test_label = tf.keras.utils.to_categorical(Known_data_X_test_label_int)\n",
        "print(\"Shape of the known data, test:\", Known_data_X_test.shape)\n",
        "print(\"Shape of the known labels, test:\", Known_data_X_test_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKGM50gJn43Q"
      },
      "source": [
        "# Never seen before, $\\mathcal{N} = p_4$, test: 0 - 500, 700 - 900, 1900 - 2100, 2500 - 2600.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RedGonT-oENJ",
        "outputId": "38518fbc-8456-48ef-c478-45ab37766191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the Neverseen data, test: (1000, 1000)\n",
            "Shape of the Neverseen labels, test: (1000, 10)\n"
          ]
        }
      ],
      "source": [
        "indices = [slice(0, 500),slice(700, 900),slice(1900, 2100),slice(2500, 2600)]\n",
        "NeverSeen_data_X_test = np.concatenate([data_X_test[idx, :] for idx in indices], axis=0)\n",
        "\n",
        "NeverSeen_data_X_test_label_int = []\n",
        "\n",
        "for i in range(100*10):\n",
        "  NeverSeen_data_X_test_label_int.append(int(data_y_test[i]))\n",
        "\n",
        "NeverSeen_data_X_test_label = tf.keras.utils.to_categorical(NeverSeen_data_X_test_label_int)\n",
        "print(\"Shape of the Neverseen data, test:\", NeverSeen_data_X_test.shape)\n",
        "print(\"Shape of the Neverseen labels, test:\", NeverSeen_data_X_test_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TM7Jf_ugOVY"
      },
      "source": [
        "# Finetuning dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33-QtJx0djIS"
      },
      "outputs": [],
      "source": [
        "# Finetuning\n",
        "data_X_finetune = np.load(\"/content/gdrive/MyDrive/Stanford_data/X_finetune.npy\")\n",
        "# Test data\n",
        "data_X_test = np.load(\"/content/gdrive/MyDrive/Stanford_data/X_test.npy\")\n",
        "\n",
        "data_y_finetune = np.load(\"/content/gdrive/MyDrive/Stanford_data/y_finetune.npy\")\n",
        "# Test labels\n",
        "data_y_test = np.load(\"/content/gdrive/MyDrive/Stanford_data/y_test.npy\")\n",
        "\n",
        "data_y_finetune_int = []\n",
        "\n",
        "for i in range(data_y_finetune.shape[0]):\n",
        "  data_y_finetune_int.append(int(data_y_finetune[i]))\n",
        "\n",
        "data_y_test_int = []\n",
        "\n",
        "for i in range(data_y_test.shape[0]):\n",
        "  data_y_test_int.append(int(data_y_test[i]))\n",
        "\n",
        "train_label = tf.keras.utils.to_categorical(data_y_finetune_int)\n",
        "test_label = tf.keras.utils.to_categorical(data_y_test_int)\n",
        "\n",
        "#data_X_finetune, train_label = shuffle(data_X_finetune, train_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQhOuowIgkWf"
      },
      "source": [
        "# Known data for finetuning. Finetuning indices = 500 - 700, 900 - 1900, 2100 - 2500, 2600 - 3000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHDu8argdnn",
        "outputId": "0033964f-2e02-48e9-dcbe-016c465577aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the known data, finetune: (2000, 1000)\n",
            "Shape of the known labels, finetune: (2000, 20)\n"
          ]
        }
      ],
      "source": [
        "indices = [slice(500, 700),slice(900, 1900),slice(2100, 2500),slice(2600, 3000)]\n",
        "\n",
        "Known_data_X_finetune = np.concatenate([data_X_finetune[idx, :] for idx in indices], axis=0)\n",
        "\n",
        "Known_data_X_finetune_label_int = []\n",
        "\n",
        "for i in range(100*20):\n",
        "  Known_data_X_finetune_label_int.append(int(data_y_finetune[i]))\n",
        "\n",
        "Known_data_X_finetune_label = tf.keras.utils.to_categorical(Known_data_X_finetune_label_int)\n",
        "\n",
        "print(\"Shape of the known data, finetune:\", Known_data_X_finetune.shape)\n",
        "print(\"Shape of the known labels, finetune:\", Known_data_X_finetune_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkB5irz-g4nT"
      },
      "source": [
        "# Initializing the our NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va3BhxK3gdh9"
      },
      "outputs": [],
      "source": [
        "# Create a checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from numpy import interp\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "#from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score, roc_curve, plot_roc_curve\n",
        "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, BatchNormalization, Activation, add\n",
        "from keras.layers import Conv2D, MaxPooling2D, Reshape, Flatten, Dense, GlobalAveragePooling1D, GlobalMaxPooling1D, Multiply, Conv1DTranspose, LeakyReLU, Dropout\n",
        "from keras.models import Model, model_from_json\n",
        "#from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "sns.set_theme(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFBxaPt1hDQQ",
        "outputId": "c30cd165-e3f9-40f3-c64e-eff830b7978e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"ResNet29\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1000, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " zero_padding1d (ZeroPaddin  (None, 1006, 1)              0         ['input_1[0][0]']             \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " Convolution1 (Conv1D)       (None, 500, 64)              512       ['zero_padding1d[0][0]']      \n",
            "                                                                                                  \n",
            " BatchNormStage1 (BatchNorm  (None, 500, 64)              256       ['Convolution1[0][0]']        \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 500, 64)              0         ['BatchNormStage1[0][0]']     \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 249, 64)              0         ['activation[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 249, 64)              12352     ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 249, 64)              256       ['conv1d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 249, 64)              0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 249, 64)              12352     ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 249, 64)              256       ['conv1d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 249, 64)              0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " res2a_branch (Conv1D)       (None, 249, 256)             49408     ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 249, 256)             16640     ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 249, 256)             1024      ['res2a_branch[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 249, 256)             1024      ['conv1d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 249, 256)             0         ['batch_normalization_2[0][0]'\n",
            "                                                                    , 'batch_normalization_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 249, 256)             0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 249, 64)              16448     ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 249, 64)              256       ['conv1d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 249, 64)              0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 249, 64)              12352     ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 249, 64)              256       ['conv1d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 249, 64)              0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 249, 256)             16640     ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 249, 256)             1024      ['conv1d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 249, 256)             0         ['batch_normalization_6[0][0]'\n",
            "                                                                    , 'activation_3[0][0]']       \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 249, 256)             0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 125, 128)             98432     ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 125, 128)             512       ['conv1d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 125, 128)             0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 125, 128)             49280     ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 125, 128)             512       ['conv1d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 125, 128)             0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " res3a_branch (Conv1D)       (None, 125, 512)             197120    ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)           (None, 125, 512)             131584    ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 125, 512)             2048      ['res3a_branch[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 125, 512)             2048      ['conv1d_8[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 125, 512)             0         ['batch_normalization_9[0][0]'\n",
            "                                                                    , 'batch_normalization_10[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 125, 512)             0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)           (None, 125, 128)             65664     ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 125, 128)             512       ['conv1d_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 125, 128)             0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)          (None, 125, 128)             49280     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 125, 128)             512       ['conv1d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 125, 128)             0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)          (None, 125, 512)             66048     ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 125, 512)             2048      ['conv1d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 125, 512)             0         ['batch_normalization_13[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 125, 512)             0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)          (None, 63, 256)              393472    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 63, 256)              1024      ['conv1d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 63, 256)              0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)          (None, 63, 256)              196864    ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 63, 256)              1024      ['conv1d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 63, 256)              0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " res4a_branch (Conv1D)       (None, 63, 1024)             787456    ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)          (None, 63, 1024)             525312    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 63, 1024)             4096      ['res4a_branch[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 63, 1024)             4096      ['conv1d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 63, 1024)             0         ['batch_normalization_16[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 63, 1024)             0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)          (None, 63, 256)              262400    ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 63, 256)              1024      ['conv1d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 63, 256)              0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)          (None, 63, 256)              196864    ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 63, 256)              1024      ['conv1d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 63, 256)              0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)          (None, 63, 1024)             263168    ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 63, 1024)             4096      ['conv1d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 63, 1024)             0         ['batch_normalization_20[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 63, 1024)             0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)          (None, 32, 256)              786688    ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 32, 256)              1024      ['conv1d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 32, 256)              0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)          (None, 32, 256)              196864    ['activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 32, 256)              1024      ['conv1d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 32, 256)              0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " res5a_branch (Conv1D)       (None, 32, 2048)             1574912   ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)          (None, 32, 2048)             2099200   ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 32, 2048)             8192      ['res5a_branch[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 32, 2048)             8192      ['conv1d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 32, 2048)             0         ['batch_normalization_23[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 32, 2048)             0         ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)          (None, 32, 256)              524544    ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 32, 256)              1024      ['conv1d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 32, 256)              0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)          (None, 32, 256)              196864    ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 32, 256)              1024      ['conv1d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 32, 256)              0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)          (None, 32, 2048)             526336    ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 32, 2048)             8192      ['conv1d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 32, 2048)             0         ['batch_normalization_27[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 32, 2048)             0         ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 2048)                 0         ['activation_24[0][0]']       \n",
            " GlobalAveragePooling1D)                                                                          \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1, 2048)              0         ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1, 128)               262272    ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1, 2048)              264192    ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 32, 2048)             0         ['activation_24[0][0]',       \n",
            "                                                                     'dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_transpose (Conv1DTr  (None, 64, 64)               393280    ['multiply[0][0]']            \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 64, 64)               256       ['conv1d_transpose[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)     (None, 64, 64)               0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 4096)                 0         ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 4096)                 0         ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 20)                   81940     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10384596 (39.61 MB)\n",
            "Trainable params: 10326868 (39.39 MB)\n",
            "Non-trainable params: 57728 (225.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "NoF = 64  # Number of filters in the first convolutional layer\n",
        "SE_RATIO = 16  # Squeeze-and-Excitation ratio\n",
        "\n",
        "nb_classes = 20\n",
        "\n",
        "\n",
        "initializer = tf.keras.initializers.GlorotUniform(seed=0)\n",
        "initializer2 = tf.keras.initializers.HeUniform(seed=0)\n",
        "\n",
        "def squeeze_excitation_block(X, ratio=16):\n",
        "    num_channels = X.shape[-1]\n",
        "    se = tf.keras.layers.GlobalAveragePooling1D()(X)\n",
        "    se = tf.keras.layers.Reshape((1, num_channels))(se)\n",
        "    se = tf.keras.layers.Dense(num_channels // ratio, activation='relu', kernel_initializer=initializer)(se)\n",
        "    se = tf.keras.layers.Dense(num_channels, activation='sigmoid', kernel_initializer=initializer)(se)\n",
        "    return tf.keras.layers.Multiply()([X, se])\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "initializer = tf.keras.initializers.GlorotUniform(seed=0)\n",
        "initializer2 = tf.keras.initializers.HeUniform(seed=0)\n",
        "Stride=1\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "\n",
        "  #defining name basis\n",
        "  ConvNameBase = 'res' + str(stage) + block + '_branch'\n",
        "  BatchNormBase = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "  #retrieve filters\n",
        "  F1,F2,F3 = filters\n",
        "\n",
        "  #save the input value. You'll need this later to add back the main path\n",
        "  x_shortcut = X\n",
        "\n",
        "  ### First component of the main path ###\n",
        "  X = tf.keras.layers.Conv1D(filters=F1, kernel_size=1, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer#, name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  ### Second component of main path ###\n",
        "  X = tf.keras.layers.Conv1D(filters=F2, kernel_size=f, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer, #name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  #Third Component of main path\n",
        "  X = tf.keras.layers.Conv1D(filters=F3, kernel_size=1, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer#,name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "\n",
        "  #Final step: add shortcut to the main path, and pass it through ReLU activation\n",
        "  X = tf.keras.layers.Add()([X, x_shortcut])\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  return X\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "\n",
        "  #Defining name bases\n",
        "  ConvNameBase = 'res' + str(stage) + block + '_branch'\n",
        "  BatchNormBase = 'res' + str(stage) + block + '_branch'\n",
        "\n",
        "  #retrive n_filters\n",
        "  F1, F2, F3 = filters\n",
        "\n",
        "  #Save the input value\n",
        "  x_shortcut = X\n",
        "\n",
        "  #First component of the main path\n",
        "  X = tf.keras.layers.Conv1D(F1, strides=s, kernel_size=f, kernel_initializer=initializer,\n",
        "             padding='same'#, name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  #Second Component of main path\n",
        "  X = tf.keras.layers.Conv1D(filters=F2, kernel_size=f, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer#, name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  #Third component of main path\n",
        "  X = tf.keras.layers.Conv1D(filters=F3, kernel_size=f, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer, name=ConvNameBase)(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "  )(X)\n",
        "\n",
        "  ###### SHORTCUT PATH ######\n",
        "  x_shortcut = tf.keras.layers.Conv1D(filters = F3, kernel_size=1, strides=s,\n",
        "                      padding='same', #name=ConvNameBase,\n",
        "                      kernel_initializer=initializer)(x_shortcut)\n",
        "  x_shortcut = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                                  )(x_shortcut)\n",
        "\n",
        "  #Add shortcut to main path and pass in through ReLU activation\n",
        "  X = tf.keras.layers.Add()([X, x_shortcut])\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  return X\n",
        "\n",
        "def create_model():\n",
        "    input_shape = (1000, 1)\n",
        "\n",
        "    x_input = tf.keras.layers.Input(input_shape)\n",
        "    X = tf.keras.layers.ZeroPadding1D(padding=3)(x_input)\n",
        "\n",
        "    X = tf.keras.layers.Conv1D(NoF, kernel_size=7, strides=2, name='Convolution1',\n",
        "                               kernel_initializer=initializer)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(name=\"BatchNormStage1\")(X)\n",
        "    X = tf.keras.layers.Activation('relu')(X)\n",
        "    X = tf.keras.layers.MaxPooling1D(3, strides=2)(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[NoF, NoF, NoF * 4], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [NoF, NoF, NoF * 4], stage=2, block='b')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[NoF * 2, NoF * 2, NoF * 8], stage=3, block='a')\n",
        "    X = identity_block(X, 3, [NoF * 2, NoF * 2, NoF * 8], stage=3, block='b')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[NoF * 4, NoF * 4, NoF * 16], stage=4, block='a')\n",
        "    X = identity_block(X, 3, [NoF * 4, NoF * 4, NoF * 16], stage=4, block='b')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[NoF * 4, NoF * 4, NoF * 32], stage=5, block='a')\n",
        "    X = identity_block(X, f=3, filters=[NoF * 4, NoF * 4, NoF * 32], stage=5, block='b')\n",
        "\n",
        "    #  Applying SE mechanism before transposed convolutional layers\n",
        "    X = squeeze_excitation_block(X)\n",
        "\n",
        "    #  Adding transposed convolutional layers\n",
        "    X = Conv1DTranspose(filters=NoF, kernel_size=3, strides=2, padding='same', kernel_initializer=initializer)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,)(X)\n",
        "    X = LeakyReLU(alpha=0.2)(X)\n",
        "\n",
        "    X = Flatten()(X)\n",
        "\n",
        "    #  Adding dropout regularization\n",
        "    X = Dropout(0.5)(X)\n",
        "\n",
        "    X = Dense(nb_classes, activation='softmax', kernel_initializer=initializer)(X)\n",
        "\n",
        "    res_net = models.Model(inputs=x_input, outputs=X, name='ResNet29')\n",
        "\n",
        "    return res_net\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMeFr8POhDR8",
        "outputId": "2327a28e-3517-4d57-da5f-c8b55c86aa88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6242 - accuracy: 0.4898\n",
            "Epoch 1: val_loss improved from inf to 0.44566, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 58s 34ms/step - loss: 1.6242 - accuracy: 0.4898 - val_loss: 0.4457 - val_accuracy: 0.8794\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.8188\n",
            "Epoch 2: val_loss improved from 0.44566 to 0.23230, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.5373 - accuracy: 0.8188 - val_loss: 0.2323 - val_accuracy: 0.9317\n",
            "Epoch 3/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3664 - accuracy: 0.8745\n",
            "Epoch 3: val_loss improved from 0.23230 to 0.18128, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3662 - accuracy: 0.8746 - val_loss: 0.1813 - val_accuracy: 0.9429\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.9015\n",
            "Epoch 4: val_loss improved from 0.18128 to 0.16317, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2887 - accuracy: 0.9016 - val_loss: 0.1632 - val_accuracy: 0.9477\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9139\n",
            "Epoch 5: val_loss improved from 0.16317 to 0.14849, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2514 - accuracy: 0.9139 - val_loss: 0.1485 - val_accuracy: 0.9505\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.9226\n",
            "Epoch 6: val_loss improved from 0.14849 to 0.14295, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2220 - accuracy: 0.9226 - val_loss: 0.1430 - val_accuracy: 0.9550\n",
            "Epoch 7/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9308\n",
            "Epoch 7: val_loss improved from 0.14295 to 0.12446, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2033 - accuracy: 0.9308 - val_loss: 0.1245 - val_accuracy: 0.9597\n",
            "Epoch 8/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1865 - accuracy: 0.9364\n",
            "Epoch 8: val_loss improved from 0.12446 to 0.11802, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1863 - accuracy: 0.9365 - val_loss: 0.1180 - val_accuracy: 0.9604\n",
            "Epoch 9/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9397\n",
            "Epoch 9: val_loss did not improve from 0.11802\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1760 - accuracy: 0.9396 - val_loss: 0.1183 - val_accuracy: 0.9610\n",
            "Epoch 10/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9437\n",
            "Epoch 10: val_loss improved from 0.11802 to 0.10539, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1627 - accuracy: 0.9437 - val_loss: 0.1054 - val_accuracy: 0.9645\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.9485\n",
            "Epoch 11: val_loss improved from 0.10539 to 0.10474, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1512 - accuracy: 0.9485 - val_loss: 0.1047 - val_accuracy: 0.9657\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1475 - accuracy: 0.9491\n",
            "Epoch 12: val_loss did not improve from 0.10474\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1476 - accuracy: 0.9490 - val_loss: 0.1137 - val_accuracy: 0.9609\n",
            "Epoch 13/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1386 - accuracy: 0.9517\n",
            "Epoch 13: val_loss did not improve from 0.10474\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1385 - accuracy: 0.9517 - val_loss: 0.1081 - val_accuracy: 0.9631\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9554\n",
            "Epoch 14: val_loss improved from 0.10474 to 0.10354, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1307 - accuracy: 0.9554 - val_loss: 0.1035 - val_accuracy: 0.9668\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1270 - accuracy: 0.9559\n",
            "Epoch 15: val_loss improved from 0.10354 to 0.10039, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1270 - accuracy: 0.9559 - val_loss: 0.1004 - val_accuracy: 0.9660\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9584\n",
            "Epoch 16: val_loss improved from 0.10039 to 0.09735, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1178 - accuracy: 0.9584 - val_loss: 0.0974 - val_accuracy: 0.9674\n",
            "Epoch 17/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.9583\n",
            "Epoch 17: val_loss did not improve from 0.09735\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1178 - accuracy: 0.9583 - val_loss: 0.0984 - val_accuracy: 0.9690\n",
            "Epoch 18/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9604\n",
            "Epoch 18: val_loss did not improve from 0.09735\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1117 - accuracy: 0.9604 - val_loss: 0.1006 - val_accuracy: 0.9630\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9613\n",
            "Epoch 19: val_loss did not improve from 0.09735\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1095 - accuracy: 0.9613 - val_loss: 0.0981 - val_accuracy: 0.9689\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9637\n",
            "Epoch 20: val_loss did not improve from 0.09735\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1015 - accuracy: 0.9637 - val_loss: 0.1104 - val_accuracy: 0.9616\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9659\n",
            "Epoch 21: val_loss did not improve from 0.09735\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0984 - accuracy: 0.9659 - val_loss: 0.0984 - val_accuracy: 0.9679\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9652\n",
            "Epoch 22: val_loss improved from 0.09735 to 0.09583, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0972 - accuracy: 0.9652 - val_loss: 0.0958 - val_accuracy: 0.9697\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9673\n",
            "Epoch 23: val_loss did not improve from 0.09583\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0932 - accuracy: 0.9672 - val_loss: 0.0989 - val_accuracy: 0.9665\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9675\n",
            "Epoch 24: val_loss did not improve from 0.09583\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0911 - accuracy: 0.9675 - val_loss: 0.0973 - val_accuracy: 0.9688\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 0.9700\n",
            "Epoch 25: val_loss improved from 0.09583 to 0.09334, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0855 - accuracy: 0.9701 - val_loss: 0.0933 - val_accuracy: 0.9680\n",
            "Epoch 26/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9698\n",
            "Epoch 26: val_loss did not improve from 0.09334\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0833 - accuracy: 0.9697 - val_loss: 0.1068 - val_accuracy: 0.9639\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9707\n",
            "Epoch 27: val_loss improved from 0.09334 to 0.09235, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0807 - accuracy: 0.9707 - val_loss: 0.0923 - val_accuracy: 0.9682\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9732\n",
            "Epoch 28: val_loss did not improve from 0.09235\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0758 - accuracy: 0.9732 - val_loss: 0.0938 - val_accuracy: 0.9696\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9731\n",
            "Epoch 29: val_loss did not improve from 0.09235\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0767 - accuracy: 0.9731 - val_loss: 0.0986 - val_accuracy: 0.9659\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9740\n",
            "Epoch 30: val_loss improved from 0.09235 to 0.09006, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0721 - accuracy: 0.9740 - val_loss: 0.0901 - val_accuracy: 0.9700\n",
            "Epoch 31/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9747\n",
            "Epoch 31: val_loss did not improve from 0.09006\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0710 - accuracy: 0.9747 - val_loss: 0.0934 - val_accuracy: 0.9678\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9757\n",
            "Epoch 32: val_loss improved from 0.09006 to 0.08815, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0691 - accuracy: 0.9757 - val_loss: 0.0882 - val_accuracy: 0.9701\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9752\n",
            "Epoch 33: val_loss did not improve from 0.08815\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0682 - accuracy: 0.9752 - val_loss: 0.0951 - val_accuracy: 0.9670\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.9768\n",
            "Epoch 34: val_loss improved from 0.08815 to 0.08784, saving model to /content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0636 - accuracy: 0.9768 - val_loss: 0.0878 - val_accuracy: 0.9706\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9765\n",
            "Epoch 35: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0618 - accuracy: 0.9765 - val_loss: 0.0921 - val_accuracy: 0.9695\n",
            "Epoch 36/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9777\n",
            "Epoch 36: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0608 - accuracy: 0.9777 - val_loss: 0.0898 - val_accuracy: 0.9697\n",
            "Epoch 37/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9789\n",
            "Epoch 37: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0593 - accuracy: 0.9790 - val_loss: 0.1023 - val_accuracy: 0.9664\n",
            "Epoch 38/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 0.9796\n",
            "Epoch 38: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0565 - accuracy: 0.9796 - val_loss: 0.0981 - val_accuracy: 0.9706\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0575 - accuracy: 0.9792\n",
            "Epoch 39: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 0.0925 - val_accuracy: 0.9696\n",
            "Epoch 40/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9814\n",
            "Epoch 40: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0512 - accuracy: 0.9813 - val_loss: 0.0936 - val_accuracy: 0.9700\n",
            "Epoch 41/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9812\n",
            "Epoch 41: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0506 - accuracy: 0.9812 - val_loss: 0.0949 - val_accuracy: 0.9684\n",
            "Epoch 42/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9811\n",
            "Epoch 42: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.0990 - val_accuracy: 0.9680\n",
            "Epoch 43/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9824\n",
            "Epoch 43: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0481 - accuracy: 0.9824 - val_loss: 0.0976 - val_accuracy: 0.9660\n",
            "Epoch 44/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9835\n",
            "Epoch 44: val_loss did not improve from 0.08784\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0457 - accuracy: 0.9835 - val_loss: 0.0967 - val_accuracy: 0.9697\n",
            "63/63 [==============================] - 8s 47ms/step - loss: 3.5115 - accuracy: 0.5720\n",
            "Test accuracy, 01_SJ11: 0.5720000267028809\n",
            "Epoch 1/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 1.6293 - accuracy: 0.4915\n",
            "Epoch 1: val_loss improved from inf to 0.40258, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 59s 33ms/step - loss: 1.6274 - accuracy: 0.4920 - val_loss: 0.4026 - val_accuracy: 0.9044\n",
            "Epoch 2/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.5349 - accuracy: 0.8186\n",
            "Epoch 2: val_loss improved from 0.40258 to 0.22482, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5349 - accuracy: 0.8187 - val_loss: 0.2248 - val_accuracy: 0.9321\n",
            "Epoch 3/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.3582 - accuracy: 0.8759\n",
            "Epoch 3: val_loss improved from 0.22482 to 0.19486, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3583 - accuracy: 0.8758 - val_loss: 0.1949 - val_accuracy: 0.9391\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2947 - accuracy: 0.8985\n",
            "Epoch 4: val_loss improved from 0.19486 to 0.15910, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2947 - accuracy: 0.8985 - val_loss: 0.1591 - val_accuracy: 0.9492\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2510 - accuracy: 0.9136\n",
            "Epoch 5: val_loss improved from 0.15910 to 0.14528, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2508 - accuracy: 0.9137 - val_loss: 0.1453 - val_accuracy: 0.9519\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2223 - accuracy: 0.9238\n",
            "Epoch 6: val_loss improved from 0.14528 to 0.13326, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.2223 - accuracy: 0.9237 - val_loss: 0.1333 - val_accuracy: 0.9561\n",
            "Epoch 7/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9309\n",
            "Epoch 7: val_loss did not improve from 0.13326\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2024 - accuracy: 0.9309 - val_loss: 0.1454 - val_accuracy: 0.9504\n",
            "Epoch 8/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1866 - accuracy: 0.9359\n",
            "Epoch 8: val_loss improved from 0.13326 to 0.13070, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1866 - accuracy: 0.9359 - val_loss: 0.1307 - val_accuracy: 0.9570\n",
            "Epoch 9/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9397\n",
            "Epoch 9: val_loss improved from 0.13070 to 0.12145, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1750 - accuracy: 0.9397 - val_loss: 0.1215 - val_accuracy: 0.9600\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.9435\n",
            "Epoch 10: val_loss improved from 0.12145 to 0.11645, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1661 - accuracy: 0.9435 - val_loss: 0.1165 - val_accuracy: 0.9619\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9476\n",
            "Epoch 11: val_loss improved from 0.11645 to 0.10785, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1570 - accuracy: 0.9476 - val_loss: 0.1079 - val_accuracy: 0.9631\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9493\n",
            "Epoch 12: val_loss improved from 0.10785 to 0.10573, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1442 - accuracy: 0.9493 - val_loss: 0.1057 - val_accuracy: 0.9635\n",
            "Epoch 13/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9520\n",
            "Epoch 13: val_loss improved from 0.10573 to 0.10236, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1415 - accuracy: 0.9519 - val_loss: 0.1024 - val_accuracy: 0.9654\n",
            "Epoch 14/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9550\n",
            "Epoch 14: val_loss did not improve from 0.10236\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1302 - accuracy: 0.9550 - val_loss: 0.1080 - val_accuracy: 0.9629\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9562\n",
            "Epoch 15: val_loss did not improve from 0.10236\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1265 - accuracy: 0.9562 - val_loss: 0.1114 - val_accuracy: 0.9625\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9576\n",
            "Epoch 16: val_loss improved from 0.10236 to 0.09878, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1216 - accuracy: 0.9576 - val_loss: 0.0988 - val_accuracy: 0.9663\n",
            "Epoch 17/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.9596\n",
            "Epoch 17: val_loss improved from 0.09878 to 0.09781, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1170 - accuracy: 0.9597 - val_loss: 0.0978 - val_accuracy: 0.9668\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9603\n",
            "Epoch 18: val_loss did not improve from 0.09781\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1127 - accuracy: 0.9603 - val_loss: 0.0986 - val_accuracy: 0.9655\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9609\n",
            "Epoch 19: val_loss did not improve from 0.09781\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1087 - accuracy: 0.9609 - val_loss: 0.1111 - val_accuracy: 0.9636\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1044 - accuracy: 0.9633\n",
            "Epoch 20: val_loss improved from 0.09781 to 0.09150, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1044 - accuracy: 0.9633 - val_loss: 0.0915 - val_accuracy: 0.9689\n",
            "Epoch 21/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9644\n",
            "Epoch 21: val_loss did not improve from 0.09150\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1016 - accuracy: 0.9645 - val_loss: 0.1110 - val_accuracy: 0.9625\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9665\n",
            "Epoch 22: val_loss did not improve from 0.09150\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0946 - accuracy: 0.9665 - val_loss: 0.0969 - val_accuracy: 0.9665\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9672\n",
            "Epoch 23: val_loss did not improve from 0.09150\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0930 - accuracy: 0.9672 - val_loss: 0.1027 - val_accuracy: 0.9664\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9689\n",
            "Epoch 24: val_loss improved from 0.09150 to 0.08932, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0879 - accuracy: 0.9689 - val_loss: 0.0893 - val_accuracy: 0.9691\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9690\n",
            "Epoch 25: val_loss improved from 0.08932 to 0.08719, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0864 - accuracy: 0.9691 - val_loss: 0.0872 - val_accuracy: 0.9691\n",
            "Epoch 26/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9691\n",
            "Epoch 26: val_loss did not improve from 0.08719\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0852 - accuracy: 0.9691 - val_loss: 0.1041 - val_accuracy: 0.9659\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9711\n",
            "Epoch 27: val_loss did not improve from 0.08719\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0815 - accuracy: 0.9711 - val_loss: 0.0873 - val_accuracy: 0.9712\n",
            "Epoch 28/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9720\n",
            "Epoch 28: val_loss did not improve from 0.08719\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0773 - accuracy: 0.9720 - val_loss: 0.0913 - val_accuracy: 0.9672\n",
            "Epoch 29/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9730\n",
            "Epoch 29: val_loss did not improve from 0.08719\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0757 - accuracy: 0.9731 - val_loss: 0.0909 - val_accuracy: 0.9682\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9729\n",
            "Epoch 30: val_loss did not improve from 0.08719\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0750 - accuracy: 0.9729 - val_loss: 0.0924 - val_accuracy: 0.9686\n",
            "Epoch 31/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9733\n",
            "Epoch 31: val_loss did not improve from 0.08719\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0733 - accuracy: 0.9733 - val_loss: 0.0931 - val_accuracy: 0.9685\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9751\n",
            "Epoch 32: val_loss improved from 0.08719 to 0.08699, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0701 - accuracy: 0.9751 - val_loss: 0.0870 - val_accuracy: 0.9720\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9766\n",
            "Epoch 33: val_loss did not improve from 0.08699\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0676 - accuracy: 0.9766 - val_loss: 0.0949 - val_accuracy: 0.9651\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9776\n",
            "Epoch 34: val_loss did not improve from 0.08699\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0638 - accuracy: 0.9776 - val_loss: 0.0873 - val_accuracy: 0.9710\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9773\n",
            "Epoch 35: val_loss did not improve from 0.08699\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0619 - accuracy: 0.9773 - val_loss: 0.1004 - val_accuracy: 0.9675\n",
            "Epoch 36/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 0.9774\n",
            "Epoch 36: val_loss did not improve from 0.08699\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0617 - accuracy: 0.9773 - val_loss: 0.0945 - val_accuracy: 0.9679\n",
            "Epoch 37/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9788\n",
            "Epoch 37: val_loss did not improve from 0.08699\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0594 - accuracy: 0.9788 - val_loss: 0.0985 - val_accuracy: 0.9672\n",
            "Epoch 38/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9799\n",
            "Epoch 38: val_loss did not improve from 0.08699\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0566 - accuracy: 0.9799 - val_loss: 0.0957 - val_accuracy: 0.9674\n",
            "Epoch 39/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 0.9807\n",
            "Epoch 39: val_loss improved from 0.08699 to 0.08454, saving model to /content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0549 - accuracy: 0.9807 - val_loss: 0.0845 - val_accuracy: 0.9728\n",
            "Epoch 40/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9804\n",
            "Epoch 40: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0548 - accuracy: 0.9804 - val_loss: 0.0956 - val_accuracy: 0.9688\n",
            "Epoch 41/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9815\n",
            "Epoch 41: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0505 - accuracy: 0.9815 - val_loss: 0.0932 - val_accuracy: 0.9680\n",
            "Epoch 42/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9816\n",
            "Epoch 42: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0508 - accuracy: 0.9816 - val_loss: 0.0892 - val_accuracy: 0.9691\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9822\n",
            "Epoch 43: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0494 - accuracy: 0.9822 - val_loss: 0.0918 - val_accuracy: 0.9703\n",
            "Epoch 44/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9823\n",
            "Epoch 44: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0471 - accuracy: 0.9823 - val_loss: 0.1114 - val_accuracy: 0.9641\n",
            "Epoch 45/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0438 - accuracy: 0.9840\n",
            "Epoch 45: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0438 - accuracy: 0.9840 - val_loss: 0.0928 - val_accuracy: 0.9719\n",
            "Epoch 46/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9827\n",
            "Epoch 46: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0456 - accuracy: 0.9827 - val_loss: 0.0983 - val_accuracy: 0.9678\n",
            "Epoch 47/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9846\n",
            "Epoch 47: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0438 - accuracy: 0.9846 - val_loss: 0.0907 - val_accuracy: 0.9707\n",
            "Epoch 48/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9843\n",
            "Epoch 48: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0420 - accuracy: 0.9843 - val_loss: 0.0980 - val_accuracy: 0.9676\n",
            "Epoch 49/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9865\n",
            "Epoch 49: val_loss did not improve from 0.08454\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0382 - accuracy: 0.9865 - val_loss: 0.0984 - val_accuracy: 0.9686\n",
            "63/63 [==============================] - 7s 47ms/step - loss: 4.1938 - accuracy: 0.5105\n",
            "Test accuracy, 02_SJ11: 0.5105000138282776\n",
            "Epoch 1/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.6165 - accuracy: 0.4937\n",
            "Epoch 1: val_loss improved from inf to 0.45670, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 60s 34ms/step - loss: 1.6156 - accuracy: 0.4940 - val_loss: 0.4567 - val_accuracy: 0.8845\n",
            "Epoch 2/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.5227 - accuracy: 0.8221\n",
            "Epoch 2: val_loss improved from 0.45670 to 0.24582, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5223 - accuracy: 0.8223 - val_loss: 0.2458 - val_accuracy: 0.9287\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.8759\n",
            "Epoch 3: val_loss improved from 0.24582 to 0.20011, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3635 - accuracy: 0.8759 - val_loss: 0.2001 - val_accuracy: 0.9362\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2914 - accuracy: 0.9010\n",
            "Epoch 4: val_loss improved from 0.20011 to 0.18254, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2914 - accuracy: 0.9010 - val_loss: 0.1825 - val_accuracy: 0.9401\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2522 - accuracy: 0.9129\n",
            "Epoch 5: val_loss improved from 0.18254 to 0.15374, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2524 - accuracy: 0.9129 - val_loss: 0.1537 - val_accuracy: 0.9506\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9253\n",
            "Epoch 6: val_loss improved from 0.15374 to 0.14656, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 32ms/step - loss: 0.2218 - accuracy: 0.9253 - val_loss: 0.1466 - val_accuracy: 0.9504\n",
            "Epoch 7/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9315\n",
            "Epoch 7: val_loss improved from 0.14656 to 0.13552, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1997 - accuracy: 0.9314 - val_loss: 0.1355 - val_accuracy: 0.9561\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.9373\n",
            "Epoch 8: val_loss improved from 0.13552 to 0.12680, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1853 - accuracy: 0.9373 - val_loss: 0.1268 - val_accuracy: 0.9588\n",
            "Epoch 9/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1730 - accuracy: 0.9393\n",
            "Epoch 9: val_loss did not improve from 0.12680\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1730 - accuracy: 0.9393 - val_loss: 0.1329 - val_accuracy: 0.9545\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9447\n",
            "Epoch 10: val_loss did not improve from 0.12680\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1605 - accuracy: 0.9447 - val_loss: 0.1275 - val_accuracy: 0.9586\n",
            "Epoch 11/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1500 - accuracy: 0.9484\n",
            "Epoch 11: val_loss improved from 0.12680 to 0.11864, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1500 - accuracy: 0.9484 - val_loss: 0.1186 - val_accuracy: 0.9599\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1421 - accuracy: 0.9520\n",
            "Epoch 12: val_loss did not improve from 0.11864\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1421 - accuracy: 0.9520 - val_loss: 0.1188 - val_accuracy: 0.9594\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9519\n",
            "Epoch 13: val_loss improved from 0.11864 to 0.11397, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1385 - accuracy: 0.9519 - val_loss: 0.1140 - val_accuracy: 0.9631\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9544\n",
            "Epoch 14: val_loss did not improve from 0.11397\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1287 - accuracy: 0.9543 - val_loss: 0.1142 - val_accuracy: 0.9607\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9563\n",
            "Epoch 15: val_loss did not improve from 0.11397\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1277 - accuracy: 0.9563 - val_loss: 0.1167 - val_accuracy: 0.9607\n",
            "Epoch 16/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9584\n",
            "Epoch 16: val_loss improved from 0.11397 to 0.10739, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1178 - accuracy: 0.9585 - val_loss: 0.1074 - val_accuracy: 0.9615\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9588\n",
            "Epoch 17: val_loss did not improve from 0.10739\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1195 - accuracy: 0.9588 - val_loss: 0.1197 - val_accuracy: 0.9579\n",
            "Epoch 18/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9622\n",
            "Epoch 18: val_loss improved from 0.10739 to 0.10475, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1092 - accuracy: 0.9622 - val_loss: 0.1048 - val_accuracy: 0.9641\n",
            "Epoch 19/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9624\n",
            "Epoch 19: val_loss improved from 0.10475 to 0.10155, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1068 - accuracy: 0.9624 - val_loss: 0.1016 - val_accuracy: 0.9636\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9638\n",
            "Epoch 20: val_loss improved from 0.10155 to 0.09826, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1045 - accuracy: 0.9638 - val_loss: 0.0983 - val_accuracy: 0.9647\n",
            "Epoch 21/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9647\n",
            "Epoch 21: val_loss did not improve from 0.09826\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0974 - accuracy: 0.9646 - val_loss: 0.1000 - val_accuracy: 0.9636\n",
            "Epoch 22/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9670\n",
            "Epoch 22: val_loss did not improve from 0.09826\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0938 - accuracy: 0.9671 - val_loss: 0.1055 - val_accuracy: 0.9631\n",
            "Epoch 23/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0922 - accuracy: 0.9678\n",
            "Epoch 23: val_loss improved from 0.09826 to 0.09708, saving model to /content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0923 - accuracy: 0.9678 - val_loss: 0.0971 - val_accuracy: 0.9641\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9687\n",
            "Epoch 24: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0869 - accuracy: 0.9687 - val_loss: 0.1049 - val_accuracy: 0.9613\n",
            "Epoch 25/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0849 - accuracy: 0.9690\n",
            "Epoch 25: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0847 - accuracy: 0.9691 - val_loss: 0.1100 - val_accuracy: 0.9596\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9699\n",
            "Epoch 26: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0845 - accuracy: 0.9699 - val_loss: 0.0980 - val_accuracy: 0.9661\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9721\n",
            "Epoch 27: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0778 - accuracy: 0.9721 - val_loss: 0.1012 - val_accuracy: 0.9629\n",
            "Epoch 28/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9732\n",
            "Epoch 28: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0768 - accuracy: 0.9732 - val_loss: 0.1150 - val_accuracy: 0.9606\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9737\n",
            "Epoch 29: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0742 - accuracy: 0.9737 - val_loss: 0.1089 - val_accuracy: 0.9615\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9735\n",
            "Epoch 30: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0734 - accuracy: 0.9735 - val_loss: 0.0984 - val_accuracy: 0.9641\n",
            "Epoch 31/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9747\n",
            "Epoch 31: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0709 - accuracy: 0.9747 - val_loss: 0.0991 - val_accuracy: 0.9636\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9759\n",
            "Epoch 32: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0679 - accuracy: 0.9759 - val_loss: 0.0979 - val_accuracy: 0.9646\n",
            "Epoch 33/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0649 - accuracy: 0.9767\n",
            "Epoch 33: val_loss did not improve from 0.09708\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0650 - accuracy: 0.9766 - val_loss: 0.1059 - val_accuracy: 0.9631\n",
            "63/63 [==============================] - 8s 49ms/step - loss: 2.8399 - accuracy: 0.5715\n",
            "Test accuracy, 03_SJ11: 0.5715000033378601\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6159 - accuracy: 0.4963\n",
            "Epoch 1: val_loss improved from inf to 0.42630, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 63s 35ms/step - loss: 1.6159 - accuracy: 0.4963 - val_loss: 0.4263 - val_accuracy: 0.8831\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.8227\n",
            "Epoch 2: val_loss improved from 0.42630 to 0.26757, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5280 - accuracy: 0.8227 - val_loss: 0.2676 - val_accuracy: 0.9162\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8751\n",
            "Epoch 3: val_loss improved from 0.26757 to 0.20740, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3658 - accuracy: 0.8751 - val_loss: 0.2074 - val_accuracy: 0.9345\n",
            "Epoch 4/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2953 - accuracy: 0.8987\n",
            "Epoch 4: val_loss improved from 0.20740 to 0.15369, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.2952 - accuracy: 0.8988 - val_loss: 0.1537 - val_accuracy: 0.9531\n",
            "Epoch 5/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2513 - accuracy: 0.9148\n",
            "Epoch 5: val_loss did not improve from 0.15369\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2511 - accuracy: 0.9148 - val_loss: 0.1557 - val_accuracy: 0.9505\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.9209\n",
            "Epoch 6: val_loss improved from 0.15369 to 0.14365, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2307 - accuracy: 0.9209 - val_loss: 0.1437 - val_accuracy: 0.9520\n",
            "Epoch 7/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2046 - accuracy: 0.9310\n",
            "Epoch 7: val_loss improved from 0.14365 to 0.12447, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.2045 - accuracy: 0.9311 - val_loss: 0.1245 - val_accuracy: 0.9604\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9346\n",
            "Epoch 8: val_loss did not improve from 0.12447\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1903 - accuracy: 0.9346 - val_loss: 0.1269 - val_accuracy: 0.9607\n",
            "Epoch 9/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9405\n",
            "Epoch 9: val_loss improved from 0.12447 to 0.11898, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1720 - accuracy: 0.9405 - val_loss: 0.1190 - val_accuracy: 0.9613\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9432\n",
            "Epoch 10: val_loss improved from 0.11898 to 0.11259, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1647 - accuracy: 0.9432 - val_loss: 0.1126 - val_accuracy: 0.9635\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9456\n",
            "Epoch 11: val_loss did not improve from 0.11259\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1534 - accuracy: 0.9456 - val_loss: 0.1131 - val_accuracy: 0.9624\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9485\n",
            "Epoch 12: val_loss improved from 0.11259 to 0.10634, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1518 - accuracy: 0.9485 - val_loss: 0.1063 - val_accuracy: 0.9649\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.9523\n",
            "Epoch 13: val_loss did not improve from 0.10634\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1398 - accuracy: 0.9523 - val_loss: 0.1098 - val_accuracy: 0.9634\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 0.9534\n",
            "Epoch 14: val_loss did not improve from 0.10634\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1340 - accuracy: 0.9533 - val_loss: 0.1255 - val_accuracy: 0.9550\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1257 - accuracy: 0.9580\n",
            "Epoch 15: val_loss improved from 0.10634 to 0.10144, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1257 - accuracy: 0.9580 - val_loss: 0.1014 - val_accuracy: 0.9653\n",
            "Epoch 16/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.9576\n",
            "Epoch 16: val_loss improved from 0.10144 to 0.09435, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1230 - accuracy: 0.9576 - val_loss: 0.0943 - val_accuracy: 0.9680\n",
            "Epoch 17/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9592\n",
            "Epoch 17: val_loss did not improve from 0.09435\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1182 - accuracy: 0.9593 - val_loss: 0.1081 - val_accuracy: 0.9628\n",
            "Epoch 18/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9619\n",
            "Epoch 18: val_loss improved from 0.09435 to 0.09308, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1104 - accuracy: 0.9619 - val_loss: 0.0931 - val_accuracy: 0.9681\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1086 - accuracy: 0.9615\n",
            "Epoch 19: val_loss did not improve from 0.09308\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1086 - accuracy: 0.9615 - val_loss: 0.0947 - val_accuracy: 0.9696\n",
            "Epoch 20/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.9628\n",
            "Epoch 20: val_loss improved from 0.09308 to 0.09246, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1041 - accuracy: 0.9628 - val_loss: 0.0925 - val_accuracy: 0.9705\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9657\n",
            "Epoch 21: val_loss did not improve from 0.09246\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0978 - accuracy: 0.9657 - val_loss: 0.0996 - val_accuracy: 0.9655\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9672\n",
            "Epoch 22: val_loss did not improve from 0.09246\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0962 - accuracy: 0.9671 - val_loss: 0.0939 - val_accuracy: 0.9686\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9670\n",
            "Epoch 23: val_loss did not improve from 0.09246\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0939 - accuracy: 0.9670 - val_loss: 0.0964 - val_accuracy: 0.9681\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9672\n",
            "Epoch 24: val_loss did not improve from 0.09246\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0909 - accuracy: 0.9672 - val_loss: 0.0976 - val_accuracy: 0.9654\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9688\n",
            "Epoch 25: val_loss improved from 0.09246 to 0.08804, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0884 - accuracy: 0.9688 - val_loss: 0.0880 - val_accuracy: 0.9710\n",
            "Epoch 26/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9706\n",
            "Epoch 26: val_loss did not improve from 0.08804\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0851 - accuracy: 0.9707 - val_loss: 0.1054 - val_accuracy: 0.9617\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9706\n",
            "Epoch 27: val_loss did not improve from 0.08804\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0823 - accuracy: 0.9706 - val_loss: 0.0916 - val_accuracy: 0.9685\n",
            "Epoch 28/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 0.9716\n",
            "Epoch 28: val_loss did not improve from 0.08804\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0784 - accuracy: 0.9716 - val_loss: 0.0904 - val_accuracy: 0.9685\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9727\n",
            "Epoch 29: val_loss improved from 0.08804 to 0.08382, saving model to /content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0762 - accuracy: 0.9727 - val_loss: 0.0838 - val_accuracy: 0.9739\n",
            "Epoch 30/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9735\n",
            "Epoch 30: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0740 - accuracy: 0.9735 - val_loss: 0.0877 - val_accuracy: 0.9720\n",
            "Epoch 31/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0706 - accuracy: 0.9747\n",
            "Epoch 31: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0706 - accuracy: 0.9747 - val_loss: 0.0864 - val_accuracy: 0.9716\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9749\n",
            "Epoch 32: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0682 - accuracy: 0.9749 - val_loss: 0.0943 - val_accuracy: 0.9694\n",
            "Epoch 33/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9753\n",
            "Epoch 33: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0681 - accuracy: 0.9753 - val_loss: 0.0954 - val_accuracy: 0.9680\n",
            "Epoch 34/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0668 - accuracy: 0.9759\n",
            "Epoch 34: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0668 - accuracy: 0.9759 - val_loss: 0.0910 - val_accuracy: 0.9709\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9784\n",
            "Epoch 35: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0614 - accuracy: 0.9784 - val_loss: 0.1021 - val_accuracy: 0.9671\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9777\n",
            "Epoch 36: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0610 - accuracy: 0.9777 - val_loss: 0.0894 - val_accuracy: 0.9693\n",
            "Epoch 37/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9777\n",
            "Epoch 37: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0605 - accuracy: 0.9777 - val_loss: 0.0888 - val_accuracy: 0.9701\n",
            "Epoch 38/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9788\n",
            "Epoch 38: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0568 - accuracy: 0.9788 - val_loss: 0.0908 - val_accuracy: 0.9700\n",
            "Epoch 39/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9794\n",
            "Epoch 39: val_loss did not improve from 0.08382\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0581 - accuracy: 0.9793 - val_loss: 0.0883 - val_accuracy: 0.9722\n",
            "63/63 [==============================] - 8s 48ms/step - loss: 3.2688 - accuracy: 0.5545\n",
            "Test accuracy, 04_SJ11: 0.5544999837875366\n",
            "Epoch 1/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.6174 - accuracy: 0.4935\n",
            "Epoch 1: val_loss improved from inf to 0.42869, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 58s 34ms/step - loss: 1.6166 - accuracy: 0.4937 - val_loss: 0.4287 - val_accuracy: 0.8979\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.8189\n",
            "Epoch 2: val_loss improved from 0.42869 to 0.24351, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.5304 - accuracy: 0.8189 - val_loss: 0.2435 - val_accuracy: 0.9264\n",
            "Epoch 3/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.3593 - accuracy: 0.8768\n",
            "Epoch 3: val_loss improved from 0.24351 to 0.18518, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.3592 - accuracy: 0.8768 - val_loss: 0.1852 - val_accuracy: 0.9415\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8973\n",
            "Epoch 4: val_loss improved from 0.18518 to 0.16632, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3001 - accuracy: 0.8973 - val_loss: 0.1663 - val_accuracy: 0.9476\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.9108\n",
            "Epoch 5: val_loss improved from 0.16632 to 0.15694, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2574 - accuracy: 0.9107 - val_loss: 0.1569 - val_accuracy: 0.9516\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2237 - accuracy: 0.9254\n",
            "Epoch 6: val_loss improved from 0.15694 to 0.14426, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2236 - accuracy: 0.9253 - val_loss: 0.1443 - val_accuracy: 0.9505\n",
            "Epoch 7/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9294\n",
            "Epoch 7: val_loss improved from 0.14426 to 0.13597, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.2058 - accuracy: 0.9294 - val_loss: 0.1360 - val_accuracy: 0.9561\n",
            "Epoch 8/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9364\n",
            "Epoch 8: val_loss improved from 0.13597 to 0.12119, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.1861 - accuracy: 0.9363 - val_loss: 0.1212 - val_accuracy: 0.9600\n",
            "Epoch 9/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9417\n",
            "Epoch 9: val_loss improved from 0.12119 to 0.10958, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1733 - accuracy: 0.9417 - val_loss: 0.1096 - val_accuracy: 0.9621\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9423\n",
            "Epoch 10: val_loss did not improve from 0.10958\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1641 - accuracy: 0.9423 - val_loss: 0.1167 - val_accuracy: 0.9615\n",
            "Epoch 11/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9456\n",
            "Epoch 11: val_loss did not improve from 0.10958\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1548 - accuracy: 0.9456 - val_loss: 0.1130 - val_accuracy: 0.9613\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1485 - accuracy: 0.9488\n",
            "Epoch 12: val_loss did not improve from 0.10958\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1484 - accuracy: 0.9489 - val_loss: 0.1159 - val_accuracy: 0.9599\n",
            "Epoch 13/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1402 - accuracy: 0.9511\n",
            "Epoch 13: val_loss improved from 0.10958 to 0.10590, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1402 - accuracy: 0.9511 - val_loss: 0.1059 - val_accuracy: 0.9635\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1321 - accuracy: 0.9531\n",
            "Epoch 14: val_loss improved from 0.10590 to 0.09909, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1320 - accuracy: 0.9532 - val_loss: 0.0991 - val_accuracy: 0.9672\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9563\n",
            "Epoch 15: val_loss improved from 0.09909 to 0.09802, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1238 - accuracy: 0.9563 - val_loss: 0.0980 - val_accuracy: 0.9674\n",
            "Epoch 16/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9576\n",
            "Epoch 16: val_loss did not improve from 0.09802\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1216 - accuracy: 0.9577 - val_loss: 0.1046 - val_accuracy: 0.9634\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9604\n",
            "Epoch 17: val_loss did not improve from 0.09802\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1138 - accuracy: 0.9604 - val_loss: 0.1018 - val_accuracy: 0.9650\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.9607\n",
            "Epoch 18: val_loss did not improve from 0.09802\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1109 - accuracy: 0.9607 - val_loss: 0.0983 - val_accuracy: 0.9668\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9638\n",
            "Epoch 19: val_loss improved from 0.09802 to 0.09072, saving model to /content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1054 - accuracy: 0.9638 - val_loss: 0.0907 - val_accuracy: 0.9701\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9646\n",
            "Epoch 20: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1017 - accuracy: 0.9646 - val_loss: 0.0981 - val_accuracy: 0.9670\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9648\n",
            "Epoch 21: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0982 - accuracy: 0.9648 - val_loss: 0.1084 - val_accuracy: 0.9638\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9666\n",
            "Epoch 22: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0938 - accuracy: 0.9666 - val_loss: 0.1067 - val_accuracy: 0.9631\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9674\n",
            "Epoch 23: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0938 - accuracy: 0.9674 - val_loss: 0.0988 - val_accuracy: 0.9649\n",
            "Epoch 24/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0911 - accuracy: 0.9666\n",
            "Epoch 24: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0911 - accuracy: 0.9666 - val_loss: 0.1002 - val_accuracy: 0.9674\n",
            "Epoch 25/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0876 - accuracy: 0.9700\n",
            "Epoch 25: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0874 - accuracy: 0.9700 - val_loss: 0.0938 - val_accuracy: 0.9674\n",
            "Epoch 26/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 0.9694\n",
            "Epoch 26: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0845 - accuracy: 0.9694 - val_loss: 0.0972 - val_accuracy: 0.9665\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9726\n",
            "Epoch 27: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0796 - accuracy: 0.9726 - val_loss: 0.0955 - val_accuracy: 0.9663\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9715\n",
            "Epoch 28: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0793 - accuracy: 0.9715 - val_loss: 0.0979 - val_accuracy: 0.9663\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9740\n",
            "Epoch 29: val_loss did not improve from 0.09072\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0745 - accuracy: 0.9740 - val_loss: 0.0932 - val_accuracy: 0.9679\n",
            "63/63 [==============================] - 8s 49ms/step - loss: 2.7894 - accuracy: 0.5685\n",
            "Test accuracy, 05_SJ11: 0.5684999823570251\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6167 - accuracy: 0.4944\n",
            "Epoch 1: val_loss improved from inf to 0.42831, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 62s 34ms/step - loss: 1.6167 - accuracy: 0.4944 - val_loss: 0.4283 - val_accuracy: 0.8939\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.8179\n",
            "Epoch 2: val_loss improved from 0.42831 to 0.25643, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.5320 - accuracy: 0.8179 - val_loss: 0.2564 - val_accuracy: 0.9180\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.3663 - accuracy: 0.8742\n",
            "Epoch 3: val_loss improved from 0.25643 to 0.19924, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3663 - accuracy: 0.8742 - val_loss: 0.1992 - val_accuracy: 0.9391\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2986 - accuracy: 0.8970\n",
            "Epoch 4: val_loss improved from 0.19924 to 0.19027, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2986 - accuracy: 0.8970 - val_loss: 0.1903 - val_accuracy: 0.9373\n",
            "Epoch 5/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2530 - accuracy: 0.9147\n",
            "Epoch 5: val_loss improved from 0.19027 to 0.15037, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2530 - accuracy: 0.9146 - val_loss: 0.1504 - val_accuracy: 0.9474\n",
            "Epoch 6/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2248 - accuracy: 0.9237\n",
            "Epoch 6: val_loss improved from 0.15037 to 0.13519, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2249 - accuracy: 0.9237 - val_loss: 0.1352 - val_accuracy: 0.9534\n",
            "Epoch 7/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9298\n",
            "Epoch 7: val_loss did not improve from 0.13519\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2045 - accuracy: 0.9298 - val_loss: 0.1422 - val_accuracy: 0.9525\n",
            "Epoch 8/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9381\n",
            "Epoch 8: val_loss improved from 0.13519 to 0.12494, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1832 - accuracy: 0.9381 - val_loss: 0.1249 - val_accuracy: 0.9555\n",
            "Epoch 9/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.9389\n",
            "Epoch 9: val_loss improved from 0.12494 to 0.12400, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1725 - accuracy: 0.9389 - val_loss: 0.1240 - val_accuracy: 0.9584\n",
            "Epoch 10/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9435\n",
            "Epoch 10: val_loss improved from 0.12400 to 0.11803, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1623 - accuracy: 0.9435 - val_loss: 0.1180 - val_accuracy: 0.9589\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9482\n",
            "Epoch 11: val_loss improved from 0.11803 to 0.11207, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1508 - accuracy: 0.9482 - val_loss: 0.1121 - val_accuracy: 0.9616\n",
            "Epoch 12/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.9497\n",
            "Epoch 12: val_loss did not improve from 0.11207\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1452 - accuracy: 0.9498 - val_loss: 0.1229 - val_accuracy: 0.9581\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9522\n",
            "Epoch 13: val_loss improved from 0.11207 to 0.10629, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1379 - accuracy: 0.9522 - val_loss: 0.1063 - val_accuracy: 0.9635\n",
            "Epoch 14/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.9545\n",
            "Epoch 14: val_loss improved from 0.10629 to 0.10516, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1311 - accuracy: 0.9545 - val_loss: 0.1052 - val_accuracy: 0.9628\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9542\n",
            "Epoch 15: val_loss did not improve from 0.10516\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1288 - accuracy: 0.9542 - val_loss: 0.1053 - val_accuracy: 0.9624\n",
            "Epoch 16/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.9578\n",
            "Epoch 16: val_loss improved from 0.10516 to 0.09969, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1179 - accuracy: 0.9579 - val_loss: 0.0997 - val_accuracy: 0.9653\n",
            "Epoch 17/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9595\n",
            "Epoch 17: val_loss improved from 0.09969 to 0.09508, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1164 - accuracy: 0.9595 - val_loss: 0.0951 - val_accuracy: 0.9663\n",
            "Epoch 18/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9609\n",
            "Epoch 18: val_loss did not improve from 0.09508\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1084 - accuracy: 0.9610 - val_loss: 0.0955 - val_accuracy: 0.9670\n",
            "Epoch 19/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9634\n",
            "Epoch 19: val_loss improved from 0.09508 to 0.09388, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1063 - accuracy: 0.9634 - val_loss: 0.0939 - val_accuracy: 0.9686\n",
            "Epoch 20/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9634\n",
            "Epoch 20: val_loss improved from 0.09388 to 0.08891, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1029 - accuracy: 0.9633 - val_loss: 0.0889 - val_accuracy: 0.9695\n",
            "Epoch 21/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9650\n",
            "Epoch 21: val_loss did not improve from 0.08891\n",
            "1000/1000 [==============================] - 29s 28ms/step - loss: 0.0989 - accuracy: 0.9649 - val_loss: 0.0978 - val_accuracy: 0.9675\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9662\n",
            "Epoch 22: val_loss did not improve from 0.08891\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0933 - accuracy: 0.9662 - val_loss: 0.0927 - val_accuracy: 0.9680\n",
            "Epoch 23/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9667\n",
            "Epoch 23: val_loss did not improve from 0.08891\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0929 - accuracy: 0.9667 - val_loss: 0.0960 - val_accuracy: 0.9674\n",
            "Epoch 24/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9682\n",
            "Epoch 24: val_loss did not improve from 0.08891\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0906 - accuracy: 0.9682 - val_loss: 0.1001 - val_accuracy: 0.9655\n",
            "Epoch 25/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9704\n",
            "Epoch 25: val_loss did not improve from 0.08891\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0844 - accuracy: 0.9704 - val_loss: 0.0914 - val_accuracy: 0.9688\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9706\n",
            "Epoch 26: val_loss did not improve from 0.08891\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0846 - accuracy: 0.9706 - val_loss: 0.0965 - val_accuracy: 0.9674\n",
            "Epoch 27/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 0.9721\n",
            "Epoch 27: val_loss improved from 0.08891 to 0.08705, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0782 - accuracy: 0.9721 - val_loss: 0.0870 - val_accuracy: 0.9707\n",
            "Epoch 28/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 0.9715\n",
            "Epoch 28: val_loss did not improve from 0.08705\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0794 - accuracy: 0.9715 - val_loss: 0.0906 - val_accuracy: 0.9681\n",
            "Epoch 29/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9739\n",
            "Epoch 29: val_loss did not improve from 0.08705\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0754 - accuracy: 0.9739 - val_loss: 0.0903 - val_accuracy: 0.9674\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9743\n",
            "Epoch 30: val_loss did not improve from 0.08705\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0727 - accuracy: 0.9743 - val_loss: 0.0903 - val_accuracy: 0.9696\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9752\n",
            "Epoch 31: val_loss did not improve from 0.08705\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0711 - accuracy: 0.9752 - val_loss: 0.0952 - val_accuracy: 0.9663\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9746\n",
            "Epoch 32: val_loss did not improve from 0.08705\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0703 - accuracy: 0.9746 - val_loss: 0.0920 - val_accuracy: 0.9685\n",
            "Epoch 33/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9754\n",
            "Epoch 33: val_loss did not improve from 0.08705\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0668 - accuracy: 0.9754 - val_loss: 0.1000 - val_accuracy: 0.9656\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9767\n",
            "Epoch 34: val_loss improved from 0.08705 to 0.08691, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0646 - accuracy: 0.9767 - val_loss: 0.0869 - val_accuracy: 0.9696\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0622 - accuracy: 0.9773\n",
            "Epoch 35: val_loss did not improve from 0.08691\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0623 - accuracy: 0.9772 - val_loss: 0.0989 - val_accuracy: 0.9676\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9778\n",
            "Epoch 36: val_loss did not improve from 0.08691\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0609 - accuracy: 0.9778 - val_loss: 0.0987 - val_accuracy: 0.9680\n",
            "Epoch 37/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9791\n",
            "Epoch 37: val_loss did not improve from 0.08691\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0586 - accuracy: 0.9791 - val_loss: 0.0962 - val_accuracy: 0.9679\n",
            "Epoch 38/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9799\n",
            "Epoch 38: val_loss did not improve from 0.08691\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0565 - accuracy: 0.9798 - val_loss: 0.0939 - val_accuracy: 0.9674\n",
            "Epoch 39/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9800\n",
            "Epoch 39: val_loss did not improve from 0.08691\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.0979 - val_accuracy: 0.9672\n",
            "Epoch 40/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9817\n",
            "Epoch 40: val_loss did not improve from 0.08691\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0514 - accuracy: 0.9817 - val_loss: 0.0959 - val_accuracy: 0.9684\n",
            "Epoch 41/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0546 - accuracy: 0.9799\n",
            "Epoch 41: val_loss did not improve from 0.08691\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0546 - accuracy: 0.9798 - val_loss: 0.0953 - val_accuracy: 0.9685\n",
            "Epoch 42/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9821\n",
            "Epoch 42: val_loss improved from 0.08691 to 0.08548, saving model to /content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.0855 - val_accuracy: 0.9716\n",
            "Epoch 43/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9829\n",
            "Epoch 43: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0473 - accuracy: 0.9829 - val_loss: 0.0952 - val_accuracy: 0.9703\n",
            "Epoch 44/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9837\n",
            "Epoch 44: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0456 - accuracy: 0.9837 - val_loss: 0.0946 - val_accuracy: 0.9697\n",
            "Epoch 45/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9826\n",
            "Epoch 45: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0460 - accuracy: 0.9826 - val_loss: 0.0973 - val_accuracy: 0.9682\n",
            "Epoch 46/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9849\n",
            "Epoch 46: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0432 - accuracy: 0.9849 - val_loss: 0.0936 - val_accuracy: 0.9696\n",
            "Epoch 47/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9846\n",
            "Epoch 47: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0413 - accuracy: 0.9846 - val_loss: 0.0951 - val_accuracy: 0.9710\n",
            "Epoch 48/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9858\n",
            "Epoch 48: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0390 - accuracy: 0.9858 - val_loss: 0.0949 - val_accuracy: 0.9703\n",
            "Epoch 49/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9857\n",
            "Epoch 49: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 0.0963 - val_accuracy: 0.9689\n",
            "Epoch 50/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9873\n",
            "Epoch 50: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0358 - accuracy: 0.9873 - val_loss: 0.1072 - val_accuracy: 0.9672\n",
            "Epoch 51/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9863\n",
            "Epoch 51: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0367 - accuracy: 0.9863 - val_loss: 0.0949 - val_accuracy: 0.9703\n",
            "Epoch 52/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9868\n",
            "Epoch 52: val_loss did not improve from 0.08548\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.0970 - val_accuracy: 0.9707\n",
            "63/63 [==============================] - 7s 47ms/step - loss: 4.1011 - accuracy: 0.5575\n",
            "Test accuracy, 06_SJ11: 0.5575000047683716\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6287 - accuracy: 0.4948\n",
            "Epoch 1: val_loss improved from inf to 0.46000, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 59s 34ms/step - loss: 1.6287 - accuracy: 0.4948 - val_loss: 0.4600 - val_accuracy: 0.8831\n",
            "Epoch 2/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.8172\n",
            "Epoch 2: val_loss improved from 0.46000 to 0.24221, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5380 - accuracy: 0.8172 - val_loss: 0.2422 - val_accuracy: 0.9346\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8748\n",
            "Epoch 3: val_loss improved from 0.24221 to 0.19264, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3623 - accuracy: 0.8748 - val_loss: 0.1926 - val_accuracy: 0.9369\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2955 - accuracy: 0.9008\n",
            "Epoch 4: val_loss improved from 0.19264 to 0.15184, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2953 - accuracy: 0.9009 - val_loss: 0.1518 - val_accuracy: 0.9516\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.9134\n",
            "Epoch 5: val_loss improved from 0.15184 to 0.13999, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2535 - accuracy: 0.9134 - val_loss: 0.1400 - val_accuracy: 0.9542\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2249 - accuracy: 0.9214\n",
            "Epoch 6: val_loss improved from 0.13999 to 0.12925, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2250 - accuracy: 0.9214 - val_loss: 0.1293 - val_accuracy: 0.9574\n",
            "Epoch 7/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.9298\n",
            "Epoch 7: val_loss improved from 0.12925 to 0.12550, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2066 - accuracy: 0.9298 - val_loss: 0.1255 - val_accuracy: 0.9578\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9355\n",
            "Epoch 8: val_loss improved from 0.12550 to 0.11395, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 32ms/step - loss: 0.1880 - accuracy: 0.9355 - val_loss: 0.1139 - val_accuracy: 0.9630\n",
            "Epoch 9/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1745 - accuracy: 0.9403\n",
            "Epoch 9: val_loss improved from 0.11395 to 0.11366, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1746 - accuracy: 0.9403 - val_loss: 0.1137 - val_accuracy: 0.9634\n",
            "Epoch 10/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1673 - accuracy: 0.9410\n",
            "Epoch 10: val_loss improved from 0.11366 to 0.10341, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1672 - accuracy: 0.9410 - val_loss: 0.1034 - val_accuracy: 0.9664\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9459\n",
            "Epoch 11: val_loss did not improve from 0.10341\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1556 - accuracy: 0.9459 - val_loss: 0.1101 - val_accuracy: 0.9624\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9504\n",
            "Epoch 12: val_loss did not improve from 0.10341\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1439 - accuracy: 0.9504 - val_loss: 0.1040 - val_accuracy: 0.9641\n",
            "Epoch 13/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1404 - accuracy: 0.9517\n",
            "Epoch 13: val_loss improved from 0.10341 to 0.10227, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1404 - accuracy: 0.9517 - val_loss: 0.1023 - val_accuracy: 0.9668\n",
            "Epoch 14/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.9545\n",
            "Epoch 14: val_loss improved from 0.10227 to 0.10039, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1311 - accuracy: 0.9545 - val_loss: 0.1004 - val_accuracy: 0.9672\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1283 - accuracy: 0.9555\n",
            "Epoch 15: val_loss did not improve from 0.10039\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1285 - accuracy: 0.9555 - val_loss: 0.1022 - val_accuracy: 0.9650\n",
            "Epoch 16/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1239 - accuracy: 0.9567\n",
            "Epoch 16: val_loss improved from 0.10039 to 0.09235, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1238 - accuracy: 0.9567 - val_loss: 0.0923 - val_accuracy: 0.9670\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9579\n",
            "Epoch 17: val_loss did not improve from 0.09235\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1204 - accuracy: 0.9579 - val_loss: 0.0965 - val_accuracy: 0.9679\n",
            "Epoch 18/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9609\n",
            "Epoch 18: val_loss did not improve from 0.09235\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1118 - accuracy: 0.9610 - val_loss: 0.0954 - val_accuracy: 0.9682\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1095 - accuracy: 0.9621\n",
            "Epoch 19: val_loss did not improve from 0.09235\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1094 - accuracy: 0.9622 - val_loss: 0.0963 - val_accuracy: 0.9672\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.9626\n",
            "Epoch 20: val_loss improved from 0.09235 to 0.08849, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1042 - accuracy: 0.9625 - val_loss: 0.0885 - val_accuracy: 0.9686\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9663\n",
            "Epoch 21: val_loss did not improve from 0.08849\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0976 - accuracy: 0.9663 - val_loss: 0.0891 - val_accuracy: 0.9693\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9657\n",
            "Epoch 22: val_loss did not improve from 0.08849\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0985 - accuracy: 0.9657 - val_loss: 0.0948 - val_accuracy: 0.9674\n",
            "Epoch 23/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9660\n",
            "Epoch 23: val_loss did not improve from 0.08849\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0933 - accuracy: 0.9661 - val_loss: 0.1101 - val_accuracy: 0.9634\n",
            "Epoch 24/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9687\n",
            "Epoch 24: val_loss improved from 0.08849 to 0.08441, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0935 - accuracy: 0.9687 - val_loss: 0.0844 - val_accuracy: 0.9703\n",
            "Epoch 25/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.9702\n",
            "Epoch 25: val_loss did not improve from 0.08441\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0856 - accuracy: 0.9702 - val_loss: 0.0939 - val_accuracy: 0.9691\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9696\n",
            "Epoch 26: val_loss did not improve from 0.08441\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0867 - accuracy: 0.9696 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
            "Epoch 27/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.9709\n",
            "Epoch 27: val_loss did not improve from 0.08441\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0815 - accuracy: 0.9709 - val_loss: 0.0870 - val_accuracy: 0.9703\n",
            "Epoch 28/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 0.9725\n",
            "Epoch 28: val_loss did not improve from 0.08441\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0794 - accuracy: 0.9725 - val_loss: 0.0958 - val_accuracy: 0.9671\n",
            "Epoch 29/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0784 - accuracy: 0.9722\n",
            "Epoch 29: val_loss improved from 0.08441 to 0.08058, saving model to /content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0784 - accuracy: 0.9722 - val_loss: 0.0806 - val_accuracy: 0.9726\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 0.9734\n",
            "Epoch 30: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 29s 30ms/step - loss: 0.0745 - accuracy: 0.9734 - val_loss: 0.0832 - val_accuracy: 0.9725\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9749\n",
            "Epoch 31: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0692 - accuracy: 0.9749 - val_loss: 0.0818 - val_accuracy: 0.9721\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9755\n",
            "Epoch 32: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0691 - accuracy: 0.9755 - val_loss: 0.0871 - val_accuracy: 0.9709\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9770\n",
            "Epoch 33: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0665 - accuracy: 0.9770 - val_loss: 0.0955 - val_accuracy: 0.9676\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9768\n",
            "Epoch 34: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0661 - accuracy: 0.9768 - val_loss: 0.0813 - val_accuracy: 0.9725\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9773\n",
            "Epoch 35: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0631 - accuracy: 0.9773 - val_loss: 0.0812 - val_accuracy: 0.9716\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9788\n",
            "Epoch 36: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.0860 - val_accuracy: 0.9709\n",
            "Epoch 37/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9788\n",
            "Epoch 37: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0583 - accuracy: 0.9788 - val_loss: 0.0860 - val_accuracy: 0.9712\n",
            "Epoch 38/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9793\n",
            "Epoch 38: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0555 - accuracy: 0.9793 - val_loss: 0.0865 - val_accuracy: 0.9699\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9803\n",
            "Epoch 39: val_loss did not improve from 0.08058\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0541 - accuracy: 0.9803 - val_loss: 0.0870 - val_accuracy: 0.9705\n",
            "63/63 [==============================] - 8s 49ms/step - loss: 3.5102 - accuracy: 0.5490\n",
            "Test accuracy, 07_SJ11: 0.5490000247955322\n",
            "Epoch 1/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 1.6178 - accuracy: 0.4920\n",
            "Epoch 1: val_loss improved from inf to 0.41572, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 59s 32ms/step - loss: 1.6155 - accuracy: 0.4928 - val_loss: 0.4157 - val_accuracy: 0.8934\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.8235\n",
            "Epoch 2: val_loss improved from 0.41572 to 0.22427, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.5291 - accuracy: 0.8235 - val_loss: 0.2243 - val_accuracy: 0.9377\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8765\n",
            "Epoch 3: val_loss improved from 0.22427 to 0.16652, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3605 - accuracy: 0.8765 - val_loss: 0.1665 - val_accuracy: 0.9474\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.8981\n",
            "Epoch 4: val_loss improved from 0.16652 to 0.15049, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2930 - accuracy: 0.8982 - val_loss: 0.1505 - val_accuracy: 0.9515\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9119\n",
            "Epoch 5: val_loss improved from 0.15049 to 0.13241, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2520 - accuracy: 0.9119 - val_loss: 0.1324 - val_accuracy: 0.9565\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2252 - accuracy: 0.9215\n",
            "Epoch 6: val_loss did not improve from 0.13241\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2251 - accuracy: 0.9215 - val_loss: 0.1353 - val_accuracy: 0.9564\n",
            "Epoch 7/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.9301\n",
            "Epoch 7: val_loss improved from 0.13241 to 0.11258, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2054 - accuracy: 0.9301 - val_loss: 0.1126 - val_accuracy: 0.9629\n",
            "Epoch 8/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1869 - accuracy: 0.9367\n",
            "Epoch 8: val_loss did not improve from 0.11258\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1869 - accuracy: 0.9367 - val_loss: 0.1287 - val_accuracy: 0.9580\n",
            "Epoch 9/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9387\n",
            "Epoch 9: val_loss did not improve from 0.11258\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1760 - accuracy: 0.9386 - val_loss: 0.1219 - val_accuracy: 0.9606\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.9418\n",
            "Epoch 10: val_loss improved from 0.11258 to 0.10436, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1667 - accuracy: 0.9418 - val_loss: 0.1044 - val_accuracy: 0.9659\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9481\n",
            "Epoch 11: val_loss improved from 0.10436 to 0.09953, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1530 - accuracy: 0.9481 - val_loss: 0.0995 - val_accuracy: 0.9670\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9500\n",
            "Epoch 12: val_loss did not improve from 0.09953\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1449 - accuracy: 0.9500 - val_loss: 0.1094 - val_accuracy: 0.9630\n",
            "Epoch 13/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1400 - accuracy: 0.9515\n",
            "Epoch 13: val_loss did not improve from 0.09953\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1398 - accuracy: 0.9516 - val_loss: 0.1093 - val_accuracy: 0.9634\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9539\n",
            "Epoch 14: val_loss did not improve from 0.09953\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1344 - accuracy: 0.9539 - val_loss: 0.1052 - val_accuracy: 0.9644\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9543\n",
            "Epoch 15: val_loss improved from 0.09953 to 0.09165, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1283 - accuracy: 0.9543 - val_loss: 0.0916 - val_accuracy: 0.9690\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.9577\n",
            "Epoch 16: val_loss did not improve from 0.09165\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1201 - accuracy: 0.9577 - val_loss: 0.0997 - val_accuracy: 0.9659\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9590\n",
            "Epoch 17: val_loss did not improve from 0.09165\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1172 - accuracy: 0.9590 - val_loss: 0.1005 - val_accuracy: 0.9653\n",
            "Epoch 18/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9588\n",
            "Epoch 18: val_loss did not improve from 0.09165\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1148 - accuracy: 0.9589 - val_loss: 0.0932 - val_accuracy: 0.9676\n",
            "Epoch 19/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9624\n",
            "Epoch 19: val_loss improved from 0.09165 to 0.09066, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1068 - accuracy: 0.9624 - val_loss: 0.0907 - val_accuracy: 0.9695\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1041 - accuracy: 0.9637\n",
            "Epoch 20: val_loss did not improve from 0.09066\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1041 - accuracy: 0.9636 - val_loss: 0.1022 - val_accuracy: 0.9641\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9625\n",
            "Epoch 21: val_loss improved from 0.09066 to 0.08976, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1025 - accuracy: 0.9625 - val_loss: 0.0898 - val_accuracy: 0.9700\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9657\n",
            "Epoch 22: val_loss did not improve from 0.08976\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0973 - accuracy: 0.9657 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 23/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9669\n",
            "Epoch 23: val_loss did not improve from 0.08976\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0943 - accuracy: 0.9668 - val_loss: 0.1002 - val_accuracy: 0.9659\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9693\n",
            "Epoch 24: val_loss improved from 0.08976 to 0.08951, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0895 - accuracy: 0.9693 - val_loss: 0.0895 - val_accuracy: 0.9672\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9692\n",
            "Epoch 25: val_loss improved from 0.08951 to 0.08827, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0860 - accuracy: 0.9692 - val_loss: 0.0883 - val_accuracy: 0.9689\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9703\n",
            "Epoch 26: val_loss improved from 0.08827 to 0.08601, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0832 - accuracy: 0.9703 - val_loss: 0.0860 - val_accuracy: 0.9704\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9710\n",
            "Epoch 27: val_loss did not improve from 0.08601\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0818 - accuracy: 0.9710 - val_loss: 0.0899 - val_accuracy: 0.9704\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.9711\n",
            "Epoch 28: val_loss did not improve from 0.08601\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0808 - accuracy: 0.9711 - val_loss: 0.0885 - val_accuracy: 0.9693\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9728\n",
            "Epoch 29: val_loss did not improve from 0.08601\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0758 - accuracy: 0.9728 - val_loss: 0.0949 - val_accuracy: 0.9684\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9745\n",
            "Epoch 30: val_loss did not improve from 0.08601\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0720 - accuracy: 0.9745 - val_loss: 0.0874 - val_accuracy: 0.9710\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9744\n",
            "Epoch 31: val_loss did not improve from 0.08601\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0716 - accuracy: 0.9744 - val_loss: 0.0905 - val_accuracy: 0.9705\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9748\n",
            "Epoch 32: val_loss did not improve from 0.08601\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0694 - accuracy: 0.9747 - val_loss: 0.0921 - val_accuracy: 0.9681\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9744\n",
            "Epoch 33: val_loss improved from 0.08601 to 0.08550, saving model to /content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0691 - accuracy: 0.9744 - val_loss: 0.0855 - val_accuracy: 0.9700\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9774\n",
            "Epoch 34: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0642 - accuracy: 0.9774 - val_loss: 0.0942 - val_accuracy: 0.9668\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9771\n",
            "Epoch 35: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0628 - accuracy: 0.9771 - val_loss: 0.0881 - val_accuracy: 0.9721\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9773\n",
            "Epoch 36: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0607 - accuracy: 0.9773 - val_loss: 0.0889 - val_accuracy: 0.9700\n",
            "Epoch 37/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9788\n",
            "Epoch 37: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0584 - accuracy: 0.9788 - val_loss: 0.0898 - val_accuracy: 0.9696\n",
            "Epoch 38/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 0.9798\n",
            "Epoch 38: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0582 - accuracy: 0.9798 - val_loss: 0.0887 - val_accuracy: 0.9710\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9797\n",
            "Epoch 39: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0557 - accuracy: 0.9797 - val_loss: 0.0898 - val_accuracy: 0.9682\n",
            "Epoch 40/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9798\n",
            "Epoch 40: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0545 - accuracy: 0.9797 - val_loss: 0.0925 - val_accuracy: 0.9697\n",
            "Epoch 41/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9814\n",
            "Epoch 41: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0535 - accuracy: 0.9814 - val_loss: 0.0946 - val_accuracy: 0.9680\n",
            "Epoch 42/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9803\n",
            "Epoch 42: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0533 - accuracy: 0.9803 - val_loss: 0.0880 - val_accuracy: 0.9705\n",
            "Epoch 43/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9817\n",
            "Epoch 43: val_loss did not improve from 0.08550\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0503 - accuracy: 0.9817 - val_loss: 0.0941 - val_accuracy: 0.9705\n",
            "63/63 [==============================] - 8s 54ms/step - loss: 4.0571 - accuracy: 0.5215\n",
            "Test accuracy, 08_SJ11: 0.5214999914169312\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6309 - accuracy: 0.4933\n",
            "Epoch 1: val_loss improved from inf to 0.41919, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 61s 34ms/step - loss: 1.6309 - accuracy: 0.4933 - val_loss: 0.4192 - val_accuracy: 0.8966\n",
            "Epoch 2/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.5431 - accuracy: 0.8159\n",
            "Epoch 2: val_loss improved from 0.41919 to 0.23395, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.5426 - accuracy: 0.8161 - val_loss: 0.2339 - val_accuracy: 0.9341\n",
            "Epoch 3/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8708\n",
            "Epoch 3: val_loss improved from 0.23395 to 0.17474, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3738 - accuracy: 0.8708 - val_loss: 0.1747 - val_accuracy: 0.9465\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.8971\n",
            "Epoch 4: val_loss improved from 0.17474 to 0.15181, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3009 - accuracy: 0.8971 - val_loss: 0.1518 - val_accuracy: 0.9544\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2528 - accuracy: 0.9134\n",
            "Epoch 5: val_loss improved from 0.15181 to 0.14059, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2526 - accuracy: 0.9134 - val_loss: 0.1406 - val_accuracy: 0.9530\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9214\n",
            "Epoch 6: val_loss improved from 0.14059 to 0.12724, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2299 - accuracy: 0.9214 - val_loss: 0.1272 - val_accuracy: 0.9597\n",
            "Epoch 7/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9289\n",
            "Epoch 7: val_loss improved from 0.12724 to 0.12427, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2094 - accuracy: 0.9289 - val_loss: 0.1243 - val_accuracy: 0.9599\n",
            "Epoch 8/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1926 - accuracy: 0.9343\n",
            "Epoch 8: val_loss improved from 0.12427 to 0.10901, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1924 - accuracy: 0.9344 - val_loss: 0.1090 - val_accuracy: 0.9654\n",
            "Epoch 9/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9389\n",
            "Epoch 9: val_loss did not improve from 0.10901\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1778 - accuracy: 0.9389 - val_loss: 0.1099 - val_accuracy: 0.9634\n",
            "Epoch 10/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9422\n",
            "Epoch 10: val_loss improved from 0.10901 to 0.10038, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1670 - accuracy: 0.9421 - val_loss: 0.1004 - val_accuracy: 0.9684\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9472\n",
            "Epoch 11: val_loss did not improve from 0.10038\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1547 - accuracy: 0.9472 - val_loss: 0.1009 - val_accuracy: 0.9650\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1447 - accuracy: 0.9492\n",
            "Epoch 12: val_loss did not improve from 0.10038\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1445 - accuracy: 0.9492 - val_loss: 0.1042 - val_accuracy: 0.9651\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.9515\n",
            "Epoch 13: val_loss improved from 0.10038 to 0.09638, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1435 - accuracy: 0.9515 - val_loss: 0.0964 - val_accuracy: 0.9671\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9526\n",
            "Epoch 14: val_loss improved from 0.09638 to 0.09136, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1375 - accuracy: 0.9526 - val_loss: 0.0914 - val_accuracy: 0.9680\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9560\n",
            "Epoch 15: val_loss improved from 0.09136 to 0.08902, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1281 - accuracy: 0.9561 - val_loss: 0.0890 - val_accuracy: 0.9694\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9576\n",
            "Epoch 16: val_loss improved from 0.08902 to 0.08631, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1206 - accuracy: 0.9576 - val_loss: 0.0863 - val_accuracy: 0.9718\n",
            "Epoch 17/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9585\n",
            "Epoch 17: val_loss did not improve from 0.08631\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1178 - accuracy: 0.9586 - val_loss: 0.0865 - val_accuracy: 0.9728\n",
            "Epoch 18/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9596\n",
            "Epoch 18: val_loss improved from 0.08631 to 0.08456, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1132 - accuracy: 0.9596 - val_loss: 0.0846 - val_accuracy: 0.9721\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9600\n",
            "Epoch 19: val_loss did not improve from 0.08456\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1105 - accuracy: 0.9599 - val_loss: 0.0853 - val_accuracy: 0.9705\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9633\n",
            "Epoch 20: val_loss did not improve from 0.08456\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1044 - accuracy: 0.9632 - val_loss: 0.0924 - val_accuracy: 0.9679\n",
            "Epoch 21/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 0.9628\n",
            "Epoch 21: val_loss improved from 0.08456 to 0.08080, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1051 - accuracy: 0.9628 - val_loss: 0.0808 - val_accuracy: 0.9730\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9647\n",
            "Epoch 22: val_loss did not improve from 0.08080\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0992 - accuracy: 0.9647 - val_loss: 0.0885 - val_accuracy: 0.9682\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9661\n",
            "Epoch 23: val_loss did not improve from 0.08080\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0955 - accuracy: 0.9661 - val_loss: 0.0922 - val_accuracy: 0.9686\n",
            "Epoch 24/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9677\n",
            "Epoch 24: val_loss did not improve from 0.08080\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0927 - accuracy: 0.9677 - val_loss: 0.0929 - val_accuracy: 0.9675\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0923 - accuracy: 0.9675\n",
            "Epoch 25: val_loss did not improve from 0.08080\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0923 - accuracy: 0.9675 - val_loss: 0.0845 - val_accuracy: 0.9715\n",
            "Epoch 26/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 0.9705\n",
            "Epoch 26: val_loss did not improve from 0.08080\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0838 - accuracy: 0.9705 - val_loss: 0.0887 - val_accuracy: 0.9699\n",
            "Epoch 27/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9707\n",
            "Epoch 27: val_loss did not improve from 0.08080\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0823 - accuracy: 0.9707 - val_loss: 0.0868 - val_accuracy: 0.9704\n",
            "Epoch 28/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9705\n",
            "Epoch 28: val_loss did not improve from 0.08080\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0804 - accuracy: 0.9705 - val_loss: 0.1043 - val_accuracy: 0.9639\n",
            "Epoch 29/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9713\n",
            "Epoch 29: val_loss improved from 0.08080 to 0.07869, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0803 - accuracy: 0.9712 - val_loss: 0.0787 - val_accuracy: 0.9728\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 0.9722\n",
            "Epoch 30: val_loss improved from 0.07869 to 0.07692, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0782 - accuracy: 0.9722 - val_loss: 0.0769 - val_accuracy: 0.9732\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0727 - accuracy: 0.9729\n",
            "Epoch 31: val_loss did not improve from 0.07692\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0727 - accuracy: 0.9728 - val_loss: 0.0800 - val_accuracy: 0.9721\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9744\n",
            "Epoch 32: val_loss did not improve from 0.07692\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0696 - accuracy: 0.9744 - val_loss: 0.0822 - val_accuracy: 0.9710\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9749\n",
            "Epoch 33: val_loss improved from 0.07692 to 0.07465, saving model to /content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0692 - accuracy: 0.9749 - val_loss: 0.0746 - val_accuracy: 0.9760\n",
            "Epoch 34/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9766\n",
            "Epoch 34: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0649 - accuracy: 0.9766 - val_loss: 0.0783 - val_accuracy: 0.9731\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 0.9762\n",
            "Epoch 35: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0665 - accuracy: 0.9762 - val_loss: 0.0849 - val_accuracy: 0.9701\n",
            "Epoch 36/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0622 - accuracy: 0.9777\n",
            "Epoch 36: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0623 - accuracy: 0.9777 - val_loss: 0.0796 - val_accuracy: 0.9725\n",
            "Epoch 37/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9784\n",
            "Epoch 37: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0609 - accuracy: 0.9784 - val_loss: 0.0908 - val_accuracy: 0.9706\n",
            "Epoch 38/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9789\n",
            "Epoch 38: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0590 - accuracy: 0.9789 - val_loss: 0.0827 - val_accuracy: 0.9722\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9795\n",
            "Epoch 39: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0566 - accuracy: 0.9795 - val_loss: 0.0798 - val_accuracy: 0.9753\n",
            "Epoch 40/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0571 - accuracy: 0.9793\n",
            "Epoch 40: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0571 - accuracy: 0.9793 - val_loss: 0.0822 - val_accuracy: 0.9737\n",
            "Epoch 41/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9803\n",
            "Epoch 41: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 0.0808 - val_accuracy: 0.9735\n",
            "Epoch 42/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.9812\n",
            "Epoch 42: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0794 - val_accuracy: 0.9721\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9807\n",
            "Epoch 43: val_loss did not improve from 0.07465\n",
            "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0519 - accuracy: 0.9807 - val_loss: 0.0876 - val_accuracy: 0.9696\n",
            "63/63 [==============================] - 7s 48ms/step - loss: 3.7011 - accuracy: 0.5215\n",
            "Test accuracy, 09_SJ11: 0.5214999914169312\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6323 - accuracy: 0.4912\n",
            "Epoch 1: val_loss improved from inf to 0.47060, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 59s 32ms/step - loss: 1.6323 - accuracy: 0.4912 - val_loss: 0.4706 - val_accuracy: 0.8622\n",
            "Epoch 2/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.5370 - accuracy: 0.8183\n",
            "Epoch 2: val_loss improved from 0.47060 to 0.24502, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.5368 - accuracy: 0.8183 - val_loss: 0.2450 - val_accuracy: 0.9271\n",
            "Epoch 3/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3661 - accuracy: 0.8757\n",
            "Epoch 3: val_loss improved from 0.24502 to 0.18793, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3662 - accuracy: 0.8756 - val_loss: 0.1879 - val_accuracy: 0.9409\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2916 - accuracy: 0.9002\n",
            "Epoch 4: val_loss improved from 0.18793 to 0.15902, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2918 - accuracy: 0.9002 - val_loss: 0.1590 - val_accuracy: 0.9491\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2541 - accuracy: 0.9129\n",
            "Epoch 5: val_loss improved from 0.15902 to 0.14746, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2540 - accuracy: 0.9130 - val_loss: 0.1475 - val_accuracy: 0.9526\n",
            "Epoch 6/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2237 - accuracy: 0.9230\n",
            "Epoch 6: val_loss did not improve from 0.14746\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2239 - accuracy: 0.9230 - val_loss: 0.1754 - val_accuracy: 0.9389\n",
            "Epoch 7/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.9308\n",
            "Epoch 7: val_loss improved from 0.14746 to 0.12126, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2044 - accuracy: 0.9308 - val_loss: 0.1213 - val_accuracy: 0.9625\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9351\n",
            "Epoch 8: val_loss improved from 0.12126 to 0.11264, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1898 - accuracy: 0.9351 - val_loss: 0.1126 - val_accuracy: 0.9644\n",
            "Epoch 9/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9393\n",
            "Epoch 9: val_loss did not improve from 0.11264\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1768 - accuracy: 0.9392 - val_loss: 0.1194 - val_accuracy: 0.9615\n",
            "Epoch 10/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1628 - accuracy: 0.9432\n",
            "Epoch 10: val_loss improved from 0.11264 to 0.10424, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1628 - accuracy: 0.9432 - val_loss: 0.1042 - val_accuracy: 0.9639\n",
            "Epoch 11/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 0.9481\n",
            "Epoch 11: val_loss did not improve from 0.10424\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1530 - accuracy: 0.9481 - val_loss: 0.1129 - val_accuracy: 0.9619\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1487 - accuracy: 0.9494\n",
            "Epoch 12: val_loss did not improve from 0.10424\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1486 - accuracy: 0.9494 - val_loss: 0.1122 - val_accuracy: 0.9624\n",
            "Epoch 13/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9513\n",
            "Epoch 13: val_loss did not improve from 0.10424\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1406 - accuracy: 0.9513 - val_loss: 0.1112 - val_accuracy: 0.9607\n",
            "Epoch 14/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9544\n",
            "Epoch 14: val_loss did not improve from 0.10424\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1320 - accuracy: 0.9544 - val_loss: 0.1120 - val_accuracy: 0.9613\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1290 - accuracy: 0.9550\n",
            "Epoch 15: val_loss improved from 0.10424 to 0.10297, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1289 - accuracy: 0.9550 - val_loss: 0.1030 - val_accuracy: 0.9635\n",
            "Epoch 16/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9567\n",
            "Epoch 16: val_loss improved from 0.10297 to 0.08934, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1233 - accuracy: 0.9567 - val_loss: 0.0893 - val_accuracy: 0.9691\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9586\n",
            "Epoch 17: val_loss did not improve from 0.08934\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1181 - accuracy: 0.9586 - val_loss: 0.0980 - val_accuracy: 0.9657\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9604\n",
            "Epoch 18: val_loss did not improve from 0.08934\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1117 - accuracy: 0.9604 - val_loss: 0.0924 - val_accuracy: 0.9694\n",
            "Epoch 19/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9631\n",
            "Epoch 19: val_loss did not improve from 0.08934\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1069 - accuracy: 0.9631 - val_loss: 0.0896 - val_accuracy: 0.9694\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9638\n",
            "Epoch 20: val_loss did not improve from 0.08934\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1048 - accuracy: 0.9638 - val_loss: 0.1016 - val_accuracy: 0.9646\n",
            "Epoch 21/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1019 - accuracy: 0.9648\n",
            "Epoch 21: val_loss did not improve from 0.08934\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1022 - accuracy: 0.9647 - val_loss: 0.1001 - val_accuracy: 0.9661\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.9658\n",
            "Epoch 22: val_loss improved from 0.08934 to 0.08837, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0984 - accuracy: 0.9658 - val_loss: 0.0884 - val_accuracy: 0.9695\n",
            "Epoch 23/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9667\n",
            "Epoch 23: val_loss improved from 0.08837 to 0.08617, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0947 - accuracy: 0.9667 - val_loss: 0.0862 - val_accuracy: 0.9712\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9671\n",
            "Epoch 24: val_loss did not improve from 0.08617\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0917 - accuracy: 0.9671 - val_loss: 0.0872 - val_accuracy: 0.9684\n",
            "Epoch 25/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9695\n",
            "Epoch 25: val_loss did not improve from 0.08617\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0872 - accuracy: 0.9694 - val_loss: 0.0928 - val_accuracy: 0.9675\n",
            "Epoch 26/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9715\n",
            "Epoch 26: val_loss improved from 0.08617 to 0.08313, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0819 - accuracy: 0.9715 - val_loss: 0.0831 - val_accuracy: 0.9716\n",
            "Epoch 27/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0831 - accuracy: 0.9710\n",
            "Epoch 27: val_loss did not improve from 0.08313\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0831 - accuracy: 0.9710 - val_loss: 0.0868 - val_accuracy: 0.9696\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9712\n",
            "Epoch 28: val_loss did not improve from 0.08313\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0815 - accuracy: 0.9712 - val_loss: 0.0837 - val_accuracy: 0.9707\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9738\n",
            "Epoch 29: val_loss did not improve from 0.08313\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0738 - accuracy: 0.9738 - val_loss: 0.0871 - val_accuracy: 0.9691\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9737\n",
            "Epoch 30: val_loss did not improve from 0.08313\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0743 - accuracy: 0.9737 - val_loss: 0.1049 - val_accuracy: 0.9657\n",
            "Epoch 31/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9752\n",
            "Epoch 31: val_loss did not improve from 0.08313\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0715 - accuracy: 0.9752 - val_loss: 0.0934 - val_accuracy: 0.9685\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9755\n",
            "Epoch 32: val_loss did not improve from 0.08313\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0668 - accuracy: 0.9755 - val_loss: 0.0913 - val_accuracy: 0.9691\n",
            "Epoch 33/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9762\n",
            "Epoch 33: val_loss did not improve from 0.08313\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0651 - accuracy: 0.9762 - val_loss: 0.0866 - val_accuracy: 0.9704\n",
            "Epoch 34/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9756\n",
            "Epoch 34: val_loss improved from 0.08313 to 0.08136, saving model to /content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0665 - accuracy: 0.9757 - val_loss: 0.0814 - val_accuracy: 0.9710\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9785\n",
            "Epoch 35: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0613 - accuracy: 0.9785 - val_loss: 0.0879 - val_accuracy: 0.9700\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9773\n",
            "Epoch 36: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0612 - accuracy: 0.9773 - val_loss: 0.0846 - val_accuracy: 0.9712\n",
            "Epoch 37/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9787\n",
            "Epoch 37: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0601 - accuracy: 0.9787 - val_loss: 0.0869 - val_accuracy: 0.9704\n",
            "Epoch 38/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9794\n",
            "Epoch 38: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0572 - accuracy: 0.9794 - val_loss: 0.0842 - val_accuracy: 0.9712\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9810\n",
            "Epoch 39: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.1010 - val_accuracy: 0.9672\n",
            "Epoch 40/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9804\n",
            "Epoch 40: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 0.0917 - val_accuracy: 0.9699\n",
            "Epoch 41/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9815\n",
            "Epoch 41: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0524 - accuracy: 0.9815 - val_loss: 0.0872 - val_accuracy: 0.9700\n",
            "Epoch 42/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9812\n",
            "Epoch 42: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0514 - accuracy: 0.9812 - val_loss: 0.0884 - val_accuracy: 0.9695\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.9816\n",
            "Epoch 43: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0493 - accuracy: 0.9816 - val_loss: 0.0866 - val_accuracy: 0.9715\n",
            "Epoch 44/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9830\n",
            "Epoch 44: val_loss did not improve from 0.08136\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0474 - accuracy: 0.9830 - val_loss: 0.0875 - val_accuracy: 0.9711\n",
            "63/63 [==============================] - 7s 47ms/step - loss: 3.6241 - accuracy: 0.5570\n",
            "Test accuracy, 10_SJ11: 0.5569999814033508\n",
            "Epoch 1/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.6231 - accuracy: 0.4938\n",
            "Epoch 1: val_loss improved from inf to 0.46154, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 60s 33ms/step - loss: 1.6223 - accuracy: 0.4941 - val_loss: 0.4615 - val_accuracy: 0.8729\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5344 - accuracy: 0.8190\n",
            "Epoch 2: val_loss improved from 0.46154 to 0.24484, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.5344 - accuracy: 0.8190 - val_loss: 0.2448 - val_accuracy: 0.9296\n",
            "Epoch 3/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8728\n",
            "Epoch 3: val_loss improved from 0.24484 to 0.18418, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3698 - accuracy: 0.8729 - val_loss: 0.1842 - val_accuracy: 0.9400\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2969 - accuracy: 0.8972\n",
            "Epoch 4: val_loss improved from 0.18418 to 0.15054, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2970 - accuracy: 0.8972 - val_loss: 0.1505 - val_accuracy: 0.9526\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.9121\n",
            "Epoch 5: val_loss improved from 0.15054 to 0.14242, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2571 - accuracy: 0.9121 - val_loss: 0.1424 - val_accuracy: 0.9556\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9243\n",
            "Epoch 6: val_loss improved from 0.14242 to 0.13380, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2225 - accuracy: 0.9243 - val_loss: 0.1338 - val_accuracy: 0.9550\n",
            "Epoch 7/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2089 - accuracy: 0.9282\n",
            "Epoch 7: val_loss improved from 0.13380 to 0.13026, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 30ms/step - loss: 0.2089 - accuracy: 0.9282 - val_loss: 0.1303 - val_accuracy: 0.9546\n",
            "Epoch 8/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9364\n",
            "Epoch 8: val_loss improved from 0.13026 to 0.11850, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1888 - accuracy: 0.9363 - val_loss: 0.1185 - val_accuracy: 0.9617\n",
            "Epoch 9/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1731 - accuracy: 0.9408\n",
            "Epoch 9: val_loss improved from 0.11850 to 0.10978, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1729 - accuracy: 0.9409 - val_loss: 0.1098 - val_accuracy: 0.9609\n",
            "Epoch 10/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9426\n",
            "Epoch 10: val_loss improved from 0.10978 to 0.10758, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1645 - accuracy: 0.9426 - val_loss: 0.1076 - val_accuracy: 0.9638\n",
            "Epoch 11/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1561 - accuracy: 0.9460\n",
            "Epoch 11: val_loss did not improve from 0.10758\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1559 - accuracy: 0.9461 - val_loss: 0.1165 - val_accuracy: 0.9600\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9486\n",
            "Epoch 12: val_loss improved from 0.10758 to 0.09779, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1465 - accuracy: 0.9486 - val_loss: 0.0978 - val_accuracy: 0.9679\n",
            "Epoch 13/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1386 - accuracy: 0.9515\n",
            "Epoch 13: val_loss did not improve from 0.09779\n",
            "1000/1000 [==============================] - 28s 27ms/step - loss: 0.1385 - accuracy: 0.9515 - val_loss: 0.1015 - val_accuracy: 0.9626\n",
            "Epoch 14/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9537\n",
            "Epoch 14: val_loss did not improve from 0.09779\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1311 - accuracy: 0.9536 - val_loss: 0.1009 - val_accuracy: 0.9643\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9534\n",
            "Epoch 15: val_loss did not improve from 0.09779\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1303 - accuracy: 0.9534 - val_loss: 0.0982 - val_accuracy: 0.9671\n",
            "Epoch 16/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1212 - accuracy: 0.9584\n",
            "Epoch 16: val_loss did not improve from 0.09779\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1211 - accuracy: 0.9584 - val_loss: 0.1003 - val_accuracy: 0.9655\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9586\n",
            "Epoch 17: val_loss did not improve from 0.09779\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1161 - accuracy: 0.9586 - val_loss: 0.0997 - val_accuracy: 0.9654\n",
            "Epoch 18/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9614\n",
            "Epoch 18: val_loss did not improve from 0.09779\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1110 - accuracy: 0.9614 - val_loss: 0.0982 - val_accuracy: 0.9660\n",
            "Epoch 19/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.9626\n",
            "Epoch 19: val_loss did not improve from 0.09779\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1066 - accuracy: 0.9626 - val_loss: 0.1016 - val_accuracy: 0.9629\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 0.9640\n",
            "Epoch 20: val_loss improved from 0.09779 to 0.09136, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1015 - accuracy: 0.9640 - val_loss: 0.0914 - val_accuracy: 0.9681\n",
            "Epoch 21/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9653\n",
            "Epoch 21: val_loss did not improve from 0.09136\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0988 - accuracy: 0.9652 - val_loss: 0.1086 - val_accuracy: 0.9634\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9662\n",
            "Epoch 22: val_loss improved from 0.09136 to 0.08955, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0955 - accuracy: 0.9663 - val_loss: 0.0895 - val_accuracy: 0.9684\n",
            "Epoch 23/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9668\n",
            "Epoch 23: val_loss did not improve from 0.08955\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0932 - accuracy: 0.9668 - val_loss: 0.0915 - val_accuracy: 0.9672\n",
            "Epoch 24/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9688\n",
            "Epoch 24: val_loss did not improve from 0.08955\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0897 - accuracy: 0.9688 - val_loss: 0.0951 - val_accuracy: 0.9661\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9692\n",
            "Epoch 25: val_loss did not improve from 0.08955\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0865 - accuracy: 0.9692 - val_loss: 0.0956 - val_accuracy: 0.9684\n",
            "Epoch 26/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9693\n",
            "Epoch 26: val_loss did not improve from 0.08955\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0852 - accuracy: 0.9693 - val_loss: 0.0922 - val_accuracy: 0.9694\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9714\n",
            "Epoch 27: val_loss did not improve from 0.08955\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0806 - accuracy: 0.9714 - val_loss: 0.0918 - val_accuracy: 0.9675\n",
            "Epoch 28/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9719\n",
            "Epoch 28: val_loss improved from 0.08955 to 0.08725, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 0.0873 - val_accuracy: 0.9686\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9729\n",
            "Epoch 29: val_loss did not improve from 0.08725\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0770 - accuracy: 0.9729 - val_loss: 0.0917 - val_accuracy: 0.9680\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9743\n",
            "Epoch 30: val_loss improved from 0.08725 to 0.08709, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0723 - accuracy: 0.9742 - val_loss: 0.0871 - val_accuracy: 0.9699\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9737\n",
            "Epoch 31: val_loss did not improve from 0.08709\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0723 - accuracy: 0.9737 - val_loss: 0.0904 - val_accuracy: 0.9680\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9772\n",
            "Epoch 32: val_loss did not improve from 0.08709\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0662 - accuracy: 0.9772 - val_loss: 0.1079 - val_accuracy: 0.9643\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9757\n",
            "Epoch 33: val_loss did not improve from 0.08709\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0663 - accuracy: 0.9757 - val_loss: 0.0900 - val_accuracy: 0.9679\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9768\n",
            "Epoch 34: val_loss did not improve from 0.08709\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0639 - accuracy: 0.9768 - val_loss: 0.0894 - val_accuracy: 0.9691\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9780\n",
            "Epoch 35: val_loss did not improve from 0.08709\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0605 - accuracy: 0.9780 - val_loss: 0.0916 - val_accuracy: 0.9676\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9788\n",
            "Epoch 36: val_loss improved from 0.08709 to 0.08582, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0591 - accuracy: 0.9788 - val_loss: 0.0858 - val_accuracy: 0.9699\n",
            "Epoch 37/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9787\n",
            "Epoch 37: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0569 - accuracy: 0.9787 - val_loss: 0.0911 - val_accuracy: 0.9678\n",
            "Epoch 38/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9795\n",
            "Epoch 38: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0564 - accuracy: 0.9794 - val_loss: 0.0977 - val_accuracy: 0.9690\n",
            "Epoch 39/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0560 - accuracy: 0.9795\n",
            "Epoch 39: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0560 - accuracy: 0.9795 - val_loss: 0.0938 - val_accuracy: 0.9681\n",
            "Epoch 40/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9802\n",
            "Epoch 40: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0540 - accuracy: 0.9802 - val_loss: 0.0913 - val_accuracy: 0.9695\n",
            "Epoch 41/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9813\n",
            "Epoch 41: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.0906 - val_accuracy: 0.9689\n",
            "Epoch 42/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9830\n",
            "Epoch 42: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0483 - accuracy: 0.9830 - val_loss: 0.0982 - val_accuracy: 0.9688\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9828\n",
            "Epoch 43: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.1000 - val_accuracy: 0.9651\n",
            "Epoch 44/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9835\n",
            "Epoch 44: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0462 - accuracy: 0.9835 - val_loss: 0.0913 - val_accuracy: 0.9697\n",
            "Epoch 45/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9838\n",
            "Epoch 45: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0450 - accuracy: 0.9838 - val_loss: 0.0998 - val_accuracy: 0.9664\n",
            "Epoch 46/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9843\n",
            "Epoch 46: val_loss did not improve from 0.08582\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0429 - accuracy: 0.9843 - val_loss: 0.0953 - val_accuracy: 0.9691\n",
            "63/63 [==============================] - 7s 46ms/step - loss: 3.8551 - accuracy: 0.5250\n",
            "Test accuracy, 11_SJ11: 0.5249999761581421\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6246 - accuracy: 0.4924\n",
            "Epoch 1: val_loss improved from inf to 0.45056, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 60s 33ms/step - loss: 1.6246 - accuracy: 0.4924 - val_loss: 0.4506 - val_accuracy: 0.8920\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.8180\n",
            "Epoch 2: val_loss improved from 0.45056 to 0.24201, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5317 - accuracy: 0.8180 - val_loss: 0.2420 - val_accuracy: 0.9266\n",
            "Epoch 3/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.8761\n",
            "Epoch 3: val_loss improved from 0.24201 to 0.18762, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3664 - accuracy: 0.8761 - val_loss: 0.1876 - val_accuracy: 0.9439\n",
            "Epoch 4/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.8987\n",
            "Epoch 4: val_loss improved from 0.18762 to 0.16074, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2941 - accuracy: 0.8988 - val_loss: 0.1607 - val_accuracy: 0.9499\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.9124\n",
            "Epoch 5: val_loss improved from 0.16074 to 0.14259, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2547 - accuracy: 0.9124 - val_loss: 0.1426 - val_accuracy: 0.9557\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.9220\n",
            "Epoch 6: val_loss improved from 0.14259 to 0.14046, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2273 - accuracy: 0.9220 - val_loss: 0.1405 - val_accuracy: 0.9550\n",
            "Epoch 7/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2043 - accuracy: 0.9294\n",
            "Epoch 7: val_loss improved from 0.14046 to 0.12502, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2042 - accuracy: 0.9294 - val_loss: 0.1250 - val_accuracy: 0.9592\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.9342\n",
            "Epoch 8: val_loss improved from 0.12502 to 0.12196, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1900 - accuracy: 0.9342 - val_loss: 0.1220 - val_accuracy: 0.9600\n",
            "Epoch 9/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9385\n",
            "Epoch 9: val_loss improved from 0.12196 to 0.11043, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1803 - accuracy: 0.9385 - val_loss: 0.1104 - val_accuracy: 0.9651\n",
            "Epoch 10/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1643 - accuracy: 0.9441\n",
            "Epoch 10: val_loss improved from 0.11043 to 0.10643, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1643 - accuracy: 0.9440 - val_loss: 0.1064 - val_accuracy: 0.9664\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.9450\n",
            "Epoch 11: val_loss did not improve from 0.10643\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1562 - accuracy: 0.9450 - val_loss: 0.1087 - val_accuracy: 0.9628\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9489\n",
            "Epoch 12: val_loss improved from 0.10643 to 0.10198, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1470 - accuracy: 0.9489 - val_loss: 0.1020 - val_accuracy: 0.9672\n",
            "Epoch 13/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1422 - accuracy: 0.9502\n",
            "Epoch 13: val_loss improved from 0.10198 to 0.09772, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1421 - accuracy: 0.9502 - val_loss: 0.0977 - val_accuracy: 0.9684\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 0.9530\n",
            "Epoch 14: val_loss improved from 0.09772 to 0.09710, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1354 - accuracy: 0.9530 - val_loss: 0.0971 - val_accuracy: 0.9685\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9568\n",
            "Epoch 15: val_loss improved from 0.09710 to 0.09240, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1255 - accuracy: 0.9567 - val_loss: 0.0924 - val_accuracy: 0.9679\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9573\n",
            "Epoch 16: val_loss did not improve from 0.09240\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1234 - accuracy: 0.9572 - val_loss: 0.1011 - val_accuracy: 0.9649\n",
            "Epoch 17/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9602\n",
            "Epoch 17: val_loss improved from 0.09240 to 0.09146, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1157 - accuracy: 0.9602 - val_loss: 0.0915 - val_accuracy: 0.9691\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9585\n",
            "Epoch 18: val_loss improved from 0.09146 to 0.08875, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1154 - accuracy: 0.9585 - val_loss: 0.0888 - val_accuracy: 0.9704\n",
            "Epoch 19/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.9618\n",
            "Epoch 19: val_loss did not improve from 0.08875\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1088 - accuracy: 0.9618 - val_loss: 0.0906 - val_accuracy: 0.9694\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9621\n",
            "Epoch 20: val_loss did not improve from 0.08875\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1057 - accuracy: 0.9622 - val_loss: 0.0942 - val_accuracy: 0.9678\n",
            "Epoch 21/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9656\n",
            "Epoch 21: val_loss improved from 0.08875 to 0.08745, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0997 - accuracy: 0.9656 - val_loss: 0.0875 - val_accuracy: 0.9712\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9655\n",
            "Epoch 22: val_loss did not improve from 0.08745\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0963 - accuracy: 0.9655 - val_loss: 0.0915 - val_accuracy: 0.9697\n",
            "Epoch 23/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9658\n",
            "Epoch 23: val_loss did not improve from 0.08745\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0941 - accuracy: 0.9659 - val_loss: 0.0889 - val_accuracy: 0.9719\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9670\n",
            "Epoch 24: val_loss did not improve from 0.08745\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0916 - accuracy: 0.9670 - val_loss: 0.0929 - val_accuracy: 0.9685\n",
            "Epoch 25/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9681\n",
            "Epoch 25: val_loss improved from 0.08745 to 0.08493, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0873 - accuracy: 0.9681 - val_loss: 0.0849 - val_accuracy: 0.9714\n",
            "Epoch 26/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9695\n",
            "Epoch 26: val_loss improved from 0.08493 to 0.08290, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0873 - accuracy: 0.9696 - val_loss: 0.0829 - val_accuracy: 0.9714\n",
            "Epoch 27/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0820 - accuracy: 0.9715\n",
            "Epoch 27: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0819 - accuracy: 0.9716 - val_loss: 0.0853 - val_accuracy: 0.9721\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9707\n",
            "Epoch 28: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0812 - accuracy: 0.9707 - val_loss: 0.0911 - val_accuracy: 0.9701\n",
            "Epoch 29/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9725\n",
            "Epoch 29: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0747 - accuracy: 0.9725 - val_loss: 0.0888 - val_accuracy: 0.9709\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9741\n",
            "Epoch 30: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0710 - accuracy: 0.9741 - val_loss: 0.0869 - val_accuracy: 0.9700\n",
            "Epoch 31/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9743\n",
            "Epoch 31: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0706 - accuracy: 0.9743 - val_loss: 0.0931 - val_accuracy: 0.9689\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9743\n",
            "Epoch 32: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0700 - accuracy: 0.9744 - val_loss: 0.0975 - val_accuracy: 0.9688\n",
            "Epoch 33/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9757\n",
            "Epoch 33: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0660 - accuracy: 0.9757 - val_loss: 0.0999 - val_accuracy: 0.9672\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9769\n",
            "Epoch 34: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 28s 27ms/step - loss: 0.0632 - accuracy: 0.9769 - val_loss: 0.0887 - val_accuracy: 0.9704\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9764\n",
            "Epoch 35: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0640 - accuracy: 0.9764 - val_loss: 0.1015 - val_accuracy: 0.9675\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9771\n",
            "Epoch 36: val_loss did not improve from 0.08290\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0608 - accuracy: 0.9771 - val_loss: 0.0914 - val_accuracy: 0.9704\n",
            "63/63 [==============================] - 7s 46ms/step - loss: 3.6913 - accuracy: 0.5265\n",
            "Test accuracy, 12_SJ11: 0.5264999866485596\n",
            "Epoch 1/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.6141 - accuracy: 0.4969\n",
            "Epoch 1: val_loss improved from inf to 0.43984, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 56s 32ms/step - loss: 1.6133 - accuracy: 0.4971 - val_loss: 0.4398 - val_accuracy: 0.9022\n",
            "Epoch 2/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.5326 - accuracy: 0.8194\n",
            "Epoch 2: val_loss improved from 0.43984 to 0.25691, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5326 - accuracy: 0.8193 - val_loss: 0.2569 - val_accuracy: 0.9225\n",
            "Epoch 3/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.8747\n",
            "Epoch 3: val_loss improved from 0.25691 to 0.18824, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3672 - accuracy: 0.8747 - val_loss: 0.1882 - val_accuracy: 0.9445\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3012 - accuracy: 0.8978\n",
            "Epoch 4: val_loss improved from 0.18824 to 0.15425, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3010 - accuracy: 0.8979 - val_loss: 0.1543 - val_accuracy: 0.9500\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2524 - accuracy: 0.9127\n",
            "Epoch 5: val_loss improved from 0.15425 to 0.13538, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2524 - accuracy: 0.9127 - val_loss: 0.1354 - val_accuracy: 0.9599\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9219\n",
            "Epoch 6: val_loss did not improve from 0.13538\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2270 - accuracy: 0.9219 - val_loss: 0.1495 - val_accuracy: 0.9500\n",
            "Epoch 7/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.9317\n",
            "Epoch 7: val_loss improved from 0.13538 to 0.11771, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2036 - accuracy: 0.9316 - val_loss: 0.1177 - val_accuracy: 0.9620\n",
            "Epoch 8/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9337\n",
            "Epoch 8: val_loss improved from 0.11771 to 0.11260, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1899 - accuracy: 0.9337 - val_loss: 0.1126 - val_accuracy: 0.9617\n",
            "Epoch 9/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9387\n",
            "Epoch 9: val_loss did not improve from 0.11260\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1767 - accuracy: 0.9387 - val_loss: 0.1168 - val_accuracy: 0.9631\n",
            "Epoch 10/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9416\n",
            "Epoch 10: val_loss improved from 0.11260 to 0.10981, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1649 - accuracy: 0.9415 - val_loss: 0.1098 - val_accuracy: 0.9628\n",
            "Epoch 11/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9464\n",
            "Epoch 11: val_loss improved from 0.10981 to 0.10581, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1554 - accuracy: 0.9464 - val_loss: 0.1058 - val_accuracy: 0.9655\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9487\n",
            "Epoch 12: val_loss improved from 0.10581 to 0.09739, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1507 - accuracy: 0.9487 - val_loss: 0.0974 - val_accuracy: 0.9693\n",
            "Epoch 13/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1382 - accuracy: 0.9521\n",
            "Epoch 13: val_loss did not improve from 0.09739\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1381 - accuracy: 0.9521 - val_loss: 0.1008 - val_accuracy: 0.9679\n",
            "Epoch 14/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9515\n",
            "Epoch 14: val_loss improved from 0.09739 to 0.09579, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1358 - accuracy: 0.9515 - val_loss: 0.0958 - val_accuracy: 0.9671\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9547\n",
            "Epoch 15: val_loss improved from 0.09579 to 0.09043, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1293 - accuracy: 0.9547 - val_loss: 0.0904 - val_accuracy: 0.9697\n",
            "Epoch 16/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.9558\n",
            "Epoch 16: val_loss improved from 0.09043 to 0.08988, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1236 - accuracy: 0.9558 - val_loss: 0.0899 - val_accuracy: 0.9701\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9570\n",
            "Epoch 17: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1190 - accuracy: 0.9570 - val_loss: 0.0927 - val_accuracy: 0.9684\n",
            "Epoch 18/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.9603\n",
            "Epoch 18: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1124 - accuracy: 0.9604 - val_loss: 0.1020 - val_accuracy: 0.9651\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9614\n",
            "Epoch 19: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1100 - accuracy: 0.9615 - val_loss: 0.0903 - val_accuracy: 0.9693\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9635\n",
            "Epoch 20: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1036 - accuracy: 0.9635 - val_loss: 0.0908 - val_accuracy: 0.9693\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9647\n",
            "Epoch 21: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1030 - accuracy: 0.9647 - val_loss: 0.0977 - val_accuracy: 0.9655\n",
            "Epoch 22/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9652\n",
            "Epoch 22: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0992 - accuracy: 0.9652 - val_loss: 0.0902 - val_accuracy: 0.9712\n",
            "Epoch 23/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9670\n",
            "Epoch 23: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0945 - accuracy: 0.9670 - val_loss: 0.0971 - val_accuracy: 0.9682\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9680\n",
            "Epoch 24: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0895 - accuracy: 0.9680 - val_loss: 0.0917 - val_accuracy: 0.9690\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9685\n",
            "Epoch 25: val_loss did not improve from 0.08988\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0871 - accuracy: 0.9685 - val_loss: 0.0909 - val_accuracy: 0.9678\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9690\n",
            "Epoch 26: val_loss improved from 0.08988 to 0.08559, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0865 - accuracy: 0.9690 - val_loss: 0.0856 - val_accuracy: 0.9697\n",
            "Epoch 27/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 0.9710\n",
            "Epoch 27: val_loss did not improve from 0.08559\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0817 - accuracy: 0.9710 - val_loss: 0.0876 - val_accuracy: 0.9707\n",
            "Epoch 28/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9715\n",
            "Epoch 28: val_loss did not improve from 0.08559\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0798 - accuracy: 0.9713 - val_loss: 0.0880 - val_accuracy: 0.9720\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9732\n",
            "Epoch 29: val_loss did not improve from 0.08559\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0755 - accuracy: 0.9732 - val_loss: 0.0945 - val_accuracy: 0.9671\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9725\n",
            "Epoch 30: val_loss improved from 0.08559 to 0.08463, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0754 - accuracy: 0.9725 - val_loss: 0.0846 - val_accuracy: 0.9724\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9745\n",
            "Epoch 31: val_loss did not improve from 0.08463\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0715 - accuracy: 0.9745 - val_loss: 0.0906 - val_accuracy: 0.9709\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9742\n",
            "Epoch 32: val_loss improved from 0.08463 to 0.08229, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0722 - accuracy: 0.9742 - val_loss: 0.0823 - val_accuracy: 0.9729\n",
            "Epoch 33/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9760\n",
            "Epoch 33: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0668 - accuracy: 0.9760 - val_loss: 0.0850 - val_accuracy: 0.9710\n",
            "Epoch 34/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9773\n",
            "Epoch 34: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0651 - accuracy: 0.9773 - val_loss: 0.0890 - val_accuracy: 0.9700\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9771\n",
            "Epoch 35: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0638 - accuracy: 0.9771 - val_loss: 0.1023 - val_accuracy: 0.9659\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9783\n",
            "Epoch 36: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0606 - accuracy: 0.9783 - val_loss: 0.0844 - val_accuracy: 0.9718\n",
            "Epoch 37/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9795\n",
            "Epoch 37: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0592 - accuracy: 0.9795 - val_loss: 0.0958 - val_accuracy: 0.9681\n",
            "Epoch 38/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9786\n",
            "Epoch 38: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0590 - accuracy: 0.9786 - val_loss: 0.0853 - val_accuracy: 0.9707\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9798\n",
            "Epoch 39: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0561 - accuracy: 0.9798 - val_loss: 0.0831 - val_accuracy: 0.9719\n",
            "Epoch 40/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9803\n",
            "Epoch 40: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0552 - accuracy: 0.9803 - val_loss: 0.0943 - val_accuracy: 0.9681\n",
            "Epoch 41/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9816\n",
            "Epoch 41: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.0850 - val_accuracy: 0.9725\n",
            "Epoch 42/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9820\n",
            "Epoch 42: val_loss did not improve from 0.08229\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 0.0850 - val_accuracy: 0.9725\n",
            "63/63 [==============================] - 8s 48ms/step - loss: 3.5371 - accuracy: 0.5485\n",
            "Test accuracy, 13_SJ11: 0.5485000014305115\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6244 - accuracy: 0.4934\n",
            "Epoch 1: val_loss improved from inf to 0.46854, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 60s 33ms/step - loss: 1.6244 - accuracy: 0.4934 - val_loss: 0.4685 - val_accuracy: 0.8546\n",
            "Epoch 2/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.8193\n",
            "Epoch 2: val_loss improved from 0.46854 to 0.25144, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5338 - accuracy: 0.8193 - val_loss: 0.2514 - val_accuracy: 0.9264\n",
            "Epoch 3/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.8761\n",
            "Epoch 3: val_loss improved from 0.25144 to 0.19131, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3641 - accuracy: 0.8761 - val_loss: 0.1913 - val_accuracy: 0.9433\n",
            "Epoch 4/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2959 - accuracy: 0.8994\n",
            "Epoch 4: val_loss improved from 0.19131 to 0.16222, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2956 - accuracy: 0.8994 - val_loss: 0.1622 - val_accuracy: 0.9520\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2539 - accuracy: 0.9135\n",
            "Epoch 5: val_loss improved from 0.16222 to 0.14919, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2539 - accuracy: 0.9136 - val_loss: 0.1492 - val_accuracy: 0.9531\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2288 - accuracy: 0.9212\n",
            "Epoch 6: val_loss improved from 0.14919 to 0.13751, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.2287 - accuracy: 0.9213 - val_loss: 0.1375 - val_accuracy: 0.9570\n",
            "Epoch 7/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9316\n",
            "Epoch 7: val_loss improved from 0.13751 to 0.12748, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1995 - accuracy: 0.9315 - val_loss: 0.1275 - val_accuracy: 0.9604\n",
            "Epoch 8/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1847 - accuracy: 0.9369\n",
            "Epoch 8: val_loss did not improve from 0.12748\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1846 - accuracy: 0.9370 - val_loss: 0.1296 - val_accuracy: 0.9584\n",
            "Epoch 9/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9404\n",
            "Epoch 9: val_loss improved from 0.12748 to 0.11497, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1756 - accuracy: 0.9404 - val_loss: 0.1150 - val_accuracy: 0.9615\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9435\n",
            "Epoch 10: val_loss improved from 0.11497 to 0.10997, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1633 - accuracy: 0.9435 - val_loss: 0.1100 - val_accuracy: 0.9655\n",
            "Epoch 11/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9471\n",
            "Epoch 11: val_loss did not improve from 0.10997\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1537 - accuracy: 0.9472 - val_loss: 0.1142 - val_accuracy: 0.9626\n",
            "Epoch 12/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9521\n",
            "Epoch 12: val_loss improved from 0.10997 to 0.10173, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1414 - accuracy: 0.9521 - val_loss: 0.1017 - val_accuracy: 0.9678\n",
            "Epoch 13/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9516\n",
            "Epoch 13: val_loss did not improve from 0.10173\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1373 - accuracy: 0.9516 - val_loss: 0.1214 - val_accuracy: 0.9599\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9539\n",
            "Epoch 14: val_loss did not improve from 0.10173\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1316 - accuracy: 0.9539 - val_loss: 0.1046 - val_accuracy: 0.9644\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9552\n",
            "Epoch 15: val_loss did not improve from 0.10173\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1265 - accuracy: 0.9552 - val_loss: 0.1027 - val_accuracy: 0.9654\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9574\n",
            "Epoch 16: val_loss improved from 0.10173 to 0.09741, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1187 - accuracy: 0.9574 - val_loss: 0.0974 - val_accuracy: 0.9681\n",
            "Epoch 17/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.9580\n",
            "Epoch 17: val_loss did not improve from 0.09741\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1163 - accuracy: 0.9580 - val_loss: 0.1149 - val_accuracy: 0.9605\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9614\n",
            "Epoch 18: val_loss did not improve from 0.09741\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1116 - accuracy: 0.9614 - val_loss: 0.1110 - val_accuracy: 0.9630\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.9625\n",
            "Epoch 19: val_loss improved from 0.09741 to 0.09143, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1069 - accuracy: 0.9625 - val_loss: 0.0914 - val_accuracy: 0.9690\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1034 - accuracy: 0.9639\n",
            "Epoch 20: val_loss did not improve from 0.09143\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1033 - accuracy: 0.9640 - val_loss: 0.0921 - val_accuracy: 0.9693\n",
            "Epoch 21/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0989 - accuracy: 0.9654\n",
            "Epoch 21: val_loss improved from 0.09143 to 0.09064, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0992 - accuracy: 0.9653 - val_loss: 0.0906 - val_accuracy: 0.9705\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0950 - accuracy: 0.9662\n",
            "Epoch 22: val_loss did not improve from 0.09064\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0949 - accuracy: 0.9662 - val_loss: 0.0938 - val_accuracy: 0.9701\n",
            "Epoch 23/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 0.9672\n",
            "Epoch 23: val_loss did not improve from 0.09064\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0916 - accuracy: 0.9673 - val_loss: 0.1016 - val_accuracy: 0.9660\n",
            "Epoch 24/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9672\n",
            "Epoch 24: val_loss did not improve from 0.09064\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0903 - accuracy: 0.9672 - val_loss: 0.0933 - val_accuracy: 0.9684\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9697\n",
            "Epoch 25: val_loss did not improve from 0.09064\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0871 - accuracy: 0.9697 - val_loss: 0.0913 - val_accuracy: 0.9690\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9710\n",
            "Epoch 26: val_loss did not improve from 0.09064\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0828 - accuracy: 0.9710 - val_loss: 0.0919 - val_accuracy: 0.9690\n",
            "Epoch 27/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0775 - accuracy: 0.9721\n",
            "Epoch 27: val_loss did not improve from 0.09064\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0774 - accuracy: 0.9721 - val_loss: 0.0981 - val_accuracy: 0.9670\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9723\n",
            "Epoch 28: val_loss did not improve from 0.09064\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0787 - accuracy: 0.9723 - val_loss: 0.1044 - val_accuracy: 0.9657\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9732\n",
            "Epoch 29: val_loss improved from 0.09064 to 0.08783, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0753 - accuracy: 0.9732 - val_loss: 0.0878 - val_accuracy: 0.9710\n",
            "Epoch 30/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9736\n",
            "Epoch 30: val_loss improved from 0.08783 to 0.08607, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0736 - accuracy: 0.9736 - val_loss: 0.0861 - val_accuracy: 0.9712\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9748\n",
            "Epoch 31: val_loss did not improve from 0.08607\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0713 - accuracy: 0.9749 - val_loss: 0.1088 - val_accuracy: 0.9631\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9760\n",
            "Epoch 32: val_loss improved from 0.08607 to 0.08593, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0672 - accuracy: 0.9760 - val_loss: 0.0859 - val_accuracy: 0.9709\n",
            "Epoch 33/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9774\n",
            "Epoch 33: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 0.0914 - val_accuracy: 0.9690\n",
            "Epoch 34/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9772\n",
            "Epoch 34: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0625 - accuracy: 0.9772 - val_loss: 0.0980 - val_accuracy: 0.9684\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9777\n",
            "Epoch 35: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0620 - accuracy: 0.9778 - val_loss: 0.0920 - val_accuracy: 0.9691\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9798\n",
            "Epoch 36: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0566 - accuracy: 0.9797 - val_loss: 0.0883 - val_accuracy: 0.9710\n",
            "Epoch 37/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9793\n",
            "Epoch 37: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0585 - accuracy: 0.9793 - val_loss: 0.0959 - val_accuracy: 0.9700\n",
            "Epoch 38/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0545 - accuracy: 0.9801\n",
            "Epoch 38: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0544 - accuracy: 0.9801 - val_loss: 0.1017 - val_accuracy: 0.9675\n",
            "Epoch 39/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9808\n",
            "Epoch 39: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0542 - accuracy: 0.9808 - val_loss: 0.0920 - val_accuracy: 0.9689\n",
            "Epoch 40/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9809\n",
            "Epoch 40: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0519 - accuracy: 0.9808 - val_loss: 0.0950 - val_accuracy: 0.9695\n",
            "Epoch 41/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9813\n",
            "Epoch 41: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0519 - accuracy: 0.9813 - val_loss: 0.0915 - val_accuracy: 0.9699\n",
            "Epoch 42/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9833\n",
            "Epoch 42: val_loss did not improve from 0.08593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0480 - accuracy: 0.9833 - val_loss: 0.0936 - val_accuracy: 0.9719\n",
            "63/63 [==============================] - 7s 48ms/step - loss: 4.1336 - accuracy: 0.5535\n",
            "Test accuracy, 14_SJ11: 0.5534999966621399\n",
            "Epoch 1/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.6252 - accuracy: 0.4901\n",
            "Epoch 1: val_loss improved from inf to 0.44580, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 60s 32ms/step - loss: 1.6252 - accuracy: 0.4901 - val_loss: 0.4458 - val_accuracy: 0.8910\n",
            "Epoch 2/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.8212\n",
            "Epoch 2: val_loss improved from 0.44580 to 0.26140, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.5286 - accuracy: 0.8212 - val_loss: 0.2614 - val_accuracy: 0.9197\n",
            "Epoch 3/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.3650 - accuracy: 0.8737\n",
            "Epoch 3: val_loss improved from 0.26140 to 0.19485, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3646 - accuracy: 0.8738 - val_loss: 0.1948 - val_accuracy: 0.9409\n",
            "Epoch 4/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.9004\n",
            "Epoch 4: val_loss improved from 0.19485 to 0.16308, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2942 - accuracy: 0.9003 - val_loss: 0.1631 - val_accuracy: 0.9475\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2562 - accuracy: 0.9117\n",
            "Epoch 5: val_loss improved from 0.16308 to 0.15052, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2563 - accuracy: 0.9117 - val_loss: 0.1505 - val_accuracy: 0.9529\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.9223\n",
            "Epoch 6: val_loss improved from 0.15052 to 0.14445, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2237 - accuracy: 0.9222 - val_loss: 0.1445 - val_accuracy: 0.9521\n",
            "Epoch 7/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9273\n",
            "Epoch 7: val_loss improved from 0.14445 to 0.13871, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2064 - accuracy: 0.9273 - val_loss: 0.1387 - val_accuracy: 0.9560\n",
            "Epoch 8/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9348\n",
            "Epoch 8: val_loss improved from 0.13871 to 0.12908, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1884 - accuracy: 0.9348 - val_loss: 0.1291 - val_accuracy: 0.9569\n",
            "Epoch 9/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1770 - accuracy: 0.9393\n",
            "Epoch 9: val_loss did not improve from 0.12908\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1772 - accuracy: 0.9392 - val_loss: 0.1301 - val_accuracy: 0.9569\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9417\n",
            "Epoch 10: val_loss improved from 0.12908 to 0.11489, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1655 - accuracy: 0.9417 - val_loss: 0.1149 - val_accuracy: 0.9617\n",
            "Epoch 11/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9473\n",
            "Epoch 11: val_loss improved from 0.11489 to 0.10997, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1524 - accuracy: 0.9473 - val_loss: 0.1100 - val_accuracy: 0.9653\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.9474\n",
            "Epoch 12: val_loss improved from 0.10997 to 0.10462, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1480 - accuracy: 0.9474 - val_loss: 0.1046 - val_accuracy: 0.9649\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9517\n",
            "Epoch 13: val_loss improved from 0.10462 to 0.10430, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1419 - accuracy: 0.9517 - val_loss: 0.1043 - val_accuracy: 0.9666\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1308 - accuracy: 0.9549\n",
            "Epoch 14: val_loss did not improve from 0.10430\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1307 - accuracy: 0.9549 - val_loss: 0.1098 - val_accuracy: 0.9639\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.9549\n",
            "Epoch 15: val_loss did not improve from 0.10430\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1285 - accuracy: 0.9549 - val_loss: 0.1111 - val_accuracy: 0.9656\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9581\n",
            "Epoch 16: val_loss improved from 0.10430 to 0.10428, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1193 - accuracy: 0.9581 - val_loss: 0.1043 - val_accuracy: 0.9655\n",
            "Epoch 17/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.9591\n",
            "Epoch 17: val_loss improved from 0.10428 to 0.09593, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1162 - accuracy: 0.9591 - val_loss: 0.0959 - val_accuracy: 0.9686\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9599\n",
            "Epoch 18: val_loss did not improve from 0.09593\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1133 - accuracy: 0.9599 - val_loss: 0.0984 - val_accuracy: 0.9671\n",
            "Epoch 19/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9622\n",
            "Epoch 19: val_loss did not improve from 0.09593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1104 - accuracy: 0.9622 - val_loss: 0.1001 - val_accuracy: 0.9666\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9645\n",
            "Epoch 20: val_loss did not improve from 0.09593\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1027 - accuracy: 0.9645 - val_loss: 0.1023 - val_accuracy: 0.9643\n",
            "Epoch 21/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9651\n",
            "Epoch 21: val_loss did not improve from 0.09593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0984 - accuracy: 0.9651 - val_loss: 0.1003 - val_accuracy: 0.9661\n",
            "Epoch 22/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9676\n",
            "Epoch 22: val_loss did not improve from 0.09593\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0943 - accuracy: 0.9675 - val_loss: 0.0986 - val_accuracy: 0.9651\n",
            "Epoch 23/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9662\n",
            "Epoch 23: val_loss improved from 0.09593 to 0.09384, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0939 - accuracy: 0.9661 - val_loss: 0.0938 - val_accuracy: 0.9679\n",
            "Epoch 24/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9681\n",
            "Epoch 24: val_loss did not improve from 0.09384\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0903 - accuracy: 0.9680 - val_loss: 0.0955 - val_accuracy: 0.9669\n",
            "Epoch 25/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 0.9694\n",
            "Epoch 25: val_loss did not improve from 0.09384\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0892 - accuracy: 0.9694 - val_loss: 0.1000 - val_accuracy: 0.9664\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9692\n",
            "Epoch 26: val_loss did not improve from 0.09384\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0849 - accuracy: 0.9692 - val_loss: 0.1000 - val_accuracy: 0.9664\n",
            "Epoch 27/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9712\n",
            "Epoch 27: val_loss improved from 0.09384 to 0.09375, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0797 - accuracy: 0.9712 - val_loss: 0.0937 - val_accuracy: 0.9668\n",
            "Epoch 28/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0780 - accuracy: 0.9725\n",
            "Epoch 28: val_loss did not improve from 0.09375\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0780 - accuracy: 0.9725 - val_loss: 0.1051 - val_accuracy: 0.9638\n",
            "Epoch 29/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9733\n",
            "Epoch 29: val_loss did not improve from 0.09375\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0742 - accuracy: 0.9733 - val_loss: 0.0975 - val_accuracy: 0.9675\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0726 - accuracy: 0.9742\n",
            "Epoch 30: val_loss did not improve from 0.09375\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0727 - accuracy: 0.9742 - val_loss: 0.0983 - val_accuracy: 0.9680\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9753\n",
            "Epoch 31: val_loss did not improve from 0.09375\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0700 - accuracy: 0.9753 - val_loss: 0.0967 - val_accuracy: 0.9674\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9747\n",
            "Epoch 32: val_loss did not improve from 0.09375\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0707 - accuracy: 0.9747 - val_loss: 0.0966 - val_accuracy: 0.9678\n",
            "Epoch 33/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0667 - accuracy: 0.9763\n",
            "Epoch 33: val_loss improved from 0.09375 to 0.09260, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0667 - accuracy: 0.9763 - val_loss: 0.0926 - val_accuracy: 0.9682\n",
            "Epoch 34/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9766\n",
            "Epoch 34: val_loss improved from 0.09260 to 0.09158, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0663 - accuracy: 0.9766 - val_loss: 0.0916 - val_accuracy: 0.9696\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9779\n",
            "Epoch 35: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0621 - accuracy: 0.9778 - val_loss: 0.0991 - val_accuracy: 0.9647\n",
            "Epoch 36/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0631 - accuracy: 0.9774\n",
            "Epoch 36: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0631 - accuracy: 0.9774 - val_loss: 0.0983 - val_accuracy: 0.9684\n",
            "Epoch 37/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9789\n",
            "Epoch 37: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0589 - accuracy: 0.9789 - val_loss: 0.0917 - val_accuracy: 0.9706\n",
            "Epoch 38/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9791\n",
            "Epoch 38: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0583 - accuracy: 0.9791 - val_loss: 0.0925 - val_accuracy: 0.9694\n",
            "Epoch 39/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9796\n",
            "Epoch 39: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0578 - accuracy: 0.9796 - val_loss: 0.0927 - val_accuracy: 0.9699\n",
            "Epoch 40/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.9801\n",
            "Epoch 40: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0535 - accuracy: 0.9801 - val_loss: 0.0916 - val_accuracy: 0.9700\n",
            "Epoch 41/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9810\n",
            "Epoch 41: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 27s 26ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0932 - val_accuracy: 0.9704\n",
            "Epoch 42/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9827\n",
            "Epoch 42: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0493 - accuracy: 0.9827 - val_loss: 0.1132 - val_accuracy: 0.9620\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9823\n",
            "Epoch 43: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0472 - accuracy: 0.9822 - val_loss: 0.1042 - val_accuracy: 0.9689\n",
            "Epoch 44/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9837\n",
            "Epoch 44: val_loss did not improve from 0.09158\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0472 - accuracy: 0.9837 - val_loss: 0.1001 - val_accuracy: 0.9656\n",
            "63/63 [==============================] - 8s 47ms/step - loss: 4.3003 - accuracy: 0.5100\n",
            "Test accuracy, 15_SJ11: 0.5099999904632568\n",
            "Epoch 1/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 1.6290 - accuracy: 0.4897\n",
            "Epoch 1: val_loss improved from inf to 0.42420, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 59s 33ms/step - loss: 1.6273 - accuracy: 0.4902 - val_loss: 0.4242 - val_accuracy: 0.8986\n",
            "Epoch 2/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.5323 - accuracy: 0.8180\n",
            "Epoch 2: val_loss improved from 0.42420 to 0.23253, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.5321 - accuracy: 0.8180 - val_loss: 0.2325 - val_accuracy: 0.9266\n",
            "Epoch 3/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3705 - accuracy: 0.8727\n",
            "Epoch 3: val_loss improved from 0.23253 to 0.23244, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3704 - accuracy: 0.8727 - val_loss: 0.2324 - val_accuracy: 0.9233\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2999 - accuracy: 0.8979\n",
            "Epoch 4: val_loss improved from 0.23244 to 0.16556, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3000 - accuracy: 0.8979 - val_loss: 0.1656 - val_accuracy: 0.9456\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9139\n",
            "Epoch 5: val_loss improved from 0.16556 to 0.14141, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2481 - accuracy: 0.9139 - val_loss: 0.1414 - val_accuracy: 0.9534\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2273 - accuracy: 0.9228\n",
            "Epoch 6: val_loss improved from 0.14141 to 0.13706, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2273 - accuracy: 0.9228 - val_loss: 0.1371 - val_accuracy: 0.9550\n",
            "Epoch 7/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.9293\n",
            "Epoch 7: val_loss improved from 0.13706 to 0.13580, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2050 - accuracy: 0.9293 - val_loss: 0.1358 - val_accuracy: 0.9524\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9339\n",
            "Epoch 8: val_loss improved from 0.13580 to 0.12194, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1910 - accuracy: 0.9339 - val_loss: 0.1219 - val_accuracy: 0.9601\n",
            "Epoch 9/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.9393\n",
            "Epoch 9: val_loss improved from 0.12194 to 0.11721, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1771 - accuracy: 0.9393 - val_loss: 0.1172 - val_accuracy: 0.9591\n",
            "Epoch 10/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1661 - accuracy: 0.9422\n",
            "Epoch 10: val_loss improved from 0.11721 to 0.11278, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1660 - accuracy: 0.9423 - val_loss: 0.1128 - val_accuracy: 0.9628\n",
            "Epoch 11/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9460\n",
            "Epoch 11: val_loss did not improve from 0.11278\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1555 - accuracy: 0.9460 - val_loss: 0.1138 - val_accuracy: 0.9605\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9478\n",
            "Epoch 12: val_loss improved from 0.11278 to 0.10973, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1488 - accuracy: 0.9478 - val_loss: 0.1097 - val_accuracy: 0.9635\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9515\n",
            "Epoch 13: val_loss improved from 0.10973 to 0.10114, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1405 - accuracy: 0.9515 - val_loss: 0.1011 - val_accuracy: 0.9622\n",
            "Epoch 14/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 0.9530\n",
            "Epoch 14: val_loss did not improve from 0.10114\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1347 - accuracy: 0.9529 - val_loss: 0.1066 - val_accuracy: 0.9636\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9552\n",
            "Epoch 15: val_loss did not improve from 0.10114\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1304 - accuracy: 0.9552 - val_loss: 0.1088 - val_accuracy: 0.9604\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9563\n",
            "Epoch 16: val_loss did not improve from 0.10114\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1235 - accuracy: 0.9563 - val_loss: 0.1131 - val_accuracy: 0.9603\n",
            "Epoch 17/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9599\n",
            "Epoch 17: val_loss improved from 0.10114 to 0.09247, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1168 - accuracy: 0.9599 - val_loss: 0.0925 - val_accuracy: 0.9659\n",
            "Epoch 18/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1162 - accuracy: 0.9592\n",
            "Epoch 18: val_loss did not improve from 0.09247\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1164 - accuracy: 0.9591 - val_loss: 0.0967 - val_accuracy: 0.9656\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9611\n",
            "Epoch 19: val_loss improved from 0.09247 to 0.09084, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1098 - accuracy: 0.9611 - val_loss: 0.0908 - val_accuracy: 0.9682\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9645\n",
            "Epoch 20: val_loss did not improve from 0.09084\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1033 - accuracy: 0.9644 - val_loss: 0.0922 - val_accuracy: 0.9679\n",
            "Epoch 21/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9628\n",
            "Epoch 21: val_loss improved from 0.09084 to 0.08969, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1059 - accuracy: 0.9628 - val_loss: 0.0897 - val_accuracy: 0.9675\n",
            "Epoch 22/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9657\n",
            "Epoch 22: val_loss improved from 0.08969 to 0.08824, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0984 - accuracy: 0.9656 - val_loss: 0.0882 - val_accuracy: 0.9690\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9667\n",
            "Epoch 23: val_loss did not improve from 0.08824\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0940 - accuracy: 0.9667 - val_loss: 0.0946 - val_accuracy: 0.9660\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9670\n",
            "Epoch 24: val_loss did not improve from 0.08824\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0917 - accuracy: 0.9670 - val_loss: 0.0976 - val_accuracy: 0.9634\n",
            "Epoch 25/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9683\n",
            "Epoch 25: val_loss did not improve from 0.08824\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0878 - accuracy: 0.9683 - val_loss: 0.0896 - val_accuracy: 0.9685\n",
            "Epoch 26/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 0.9698\n",
            "Epoch 26: val_loss improved from 0.08824 to 0.08601, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0845 - accuracy: 0.9697 - val_loss: 0.0860 - val_accuracy: 0.9688\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9710\n",
            "Epoch 27: val_loss did not improve from 0.08601\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0820 - accuracy: 0.9710 - val_loss: 0.0946 - val_accuracy: 0.9674\n",
            "Epoch 28/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9716\n",
            "Epoch 28: val_loss improved from 0.08601 to 0.08135, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0809 - accuracy: 0.9716 - val_loss: 0.0814 - val_accuracy: 0.9709\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9723\n",
            "Epoch 29: val_loss did not improve from 0.08135\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0755 - accuracy: 0.9723 - val_loss: 0.0887 - val_accuracy: 0.9690\n",
            "Epoch 30/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9737\n",
            "Epoch 30: val_loss improved from 0.08135 to 0.08009, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0754 - accuracy: 0.9737 - val_loss: 0.0801 - val_accuracy: 0.9718\n",
            "Epoch 31/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9738\n",
            "Epoch 31: val_loss did not improve from 0.08009\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0748 - accuracy: 0.9738 - val_loss: 0.0875 - val_accuracy: 0.9675\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9733\n",
            "Epoch 32: val_loss did not improve from 0.08009\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0733 - accuracy: 0.9734 - val_loss: 0.0872 - val_accuracy: 0.9685\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9766\n",
            "Epoch 33: val_loss did not improve from 0.08009\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0667 - accuracy: 0.9766 - val_loss: 0.0859 - val_accuracy: 0.9691\n",
            "Epoch 34/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9772\n",
            "Epoch 34: val_loss improved from 0.08009 to 0.07895, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0649 - accuracy: 0.9772 - val_loss: 0.0790 - val_accuracy: 0.9710\n",
            "Epoch 35/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9782\n",
            "Epoch 35: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0635 - accuracy: 0.9782 - val_loss: 0.0860 - val_accuracy: 0.9710\n",
            "Epoch 36/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9769\n",
            "Epoch 36: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0638 - accuracy: 0.9769 - val_loss: 0.0845 - val_accuracy: 0.9697\n",
            "Epoch 37/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9792\n",
            "Epoch 37: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0602 - accuracy: 0.9791 - val_loss: 0.0907 - val_accuracy: 0.9669\n",
            "Epoch 38/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9792\n",
            "Epoch 38: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0584 - accuracy: 0.9792 - val_loss: 0.0936 - val_accuracy: 0.9671\n",
            "Epoch 39/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 0.9784\n",
            "Epoch 39: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0582 - accuracy: 0.9784 - val_loss: 0.0923 - val_accuracy: 0.9686\n",
            "Epoch 40/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9799\n",
            "Epoch 40: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0548 - accuracy: 0.9799 - val_loss: 0.0807 - val_accuracy: 0.9705\n",
            "Epoch 41/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9809\n",
            "Epoch 41: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0520 - accuracy: 0.9809 - val_loss: 0.0842 - val_accuracy: 0.9697\n",
            "Epoch 42/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9813\n",
            "Epoch 42: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 28s 27ms/step - loss: 0.0512 - accuracy: 0.9813 - val_loss: 0.0937 - val_accuracy: 0.9680\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9823\n",
            "Epoch 43: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.0891 - val_accuracy: 0.9705\n",
            "Epoch 44/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9826\n",
            "Epoch 44: val_loss did not improve from 0.07895\n",
            "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0493 - accuracy: 0.9826 - val_loss: 0.0842 - val_accuracy: 0.9707\n",
            "63/63 [==============================] - 8s 45ms/step - loss: 3.7423 - accuracy: 0.5420\n",
            "Test accuracy, 16_SJ11: 0.5419999957084656\n",
            "Epoch 1/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.6067 - accuracy: 0.4957\n",
            "Epoch 1: val_loss improved from inf to 0.44377, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 60s 32ms/step - loss: 1.6061 - accuracy: 0.4960 - val_loss: 0.4438 - val_accuracy: 0.8790\n",
            "Epoch 2/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.8180\n",
            "Epoch 2: val_loss improved from 0.44377 to 0.23863, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5339 - accuracy: 0.8182 - val_loss: 0.2386 - val_accuracy: 0.9325\n",
            "Epoch 3/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.3647 - accuracy: 0.8747\n",
            "Epoch 3: val_loss improved from 0.23863 to 0.17826, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3645 - accuracy: 0.8748 - val_loss: 0.1783 - val_accuracy: 0.9484\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.8991\n",
            "Epoch 4: val_loss improved from 0.17826 to 0.15872, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2964 - accuracy: 0.8991 - val_loss: 0.1587 - val_accuracy: 0.9498\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.9124\n",
            "Epoch 5: val_loss did not improve from 0.15872\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2555 - accuracy: 0.9124 - val_loss: 0.1600 - val_accuracy: 0.9475\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.9238\n",
            "Epoch 6: val_loss improved from 0.15872 to 0.12825, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2270 - accuracy: 0.9237 - val_loss: 0.1282 - val_accuracy: 0.9606\n",
            "Epoch 7/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.9286\n",
            "Epoch 7: val_loss improved from 0.12825 to 0.12476, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2067 - accuracy: 0.9287 - val_loss: 0.1248 - val_accuracy: 0.9592\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9356\n",
            "Epoch 8: val_loss did not improve from 0.12476\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1881 - accuracy: 0.9356 - val_loss: 0.1335 - val_accuracy: 0.9544\n",
            "Epoch 9/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9396\n",
            "Epoch 9: val_loss improved from 0.12476 to 0.10831, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1754 - accuracy: 0.9396 - val_loss: 0.1083 - val_accuracy: 0.9631\n",
            "Epoch 10/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 0.9434\n",
            "Epoch 10: val_loss did not improve from 0.10831\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1614 - accuracy: 0.9434 - val_loss: 0.1102 - val_accuracy: 0.9640\n",
            "Epoch 11/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9466\n",
            "Epoch 11: val_loss did not improve from 0.10831\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1549 - accuracy: 0.9466 - val_loss: 0.1122 - val_accuracy: 0.9630\n",
            "Epoch 12/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9482\n",
            "Epoch 12: val_loss did not improve from 0.10831\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1499 - accuracy: 0.9482 - val_loss: 0.1135 - val_accuracy: 0.9621\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.9514\n",
            "Epoch 13: val_loss improved from 0.10831 to 0.09815, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1415 - accuracy: 0.9514 - val_loss: 0.0981 - val_accuracy: 0.9661\n",
            "Epoch 14/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9523\n",
            "Epoch 14: val_loss improved from 0.09815 to 0.09783, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1341 - accuracy: 0.9523 - val_loss: 0.0978 - val_accuracy: 0.9679\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.9543\n",
            "Epoch 15: val_loss did not improve from 0.09783\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1296 - accuracy: 0.9542 - val_loss: 0.0986 - val_accuracy: 0.9646\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.9572\n",
            "Epoch 16: val_loss improved from 0.09783 to 0.09273, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1241 - accuracy: 0.9572 - val_loss: 0.0927 - val_accuracy: 0.9690\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9600\n",
            "Epoch 17: val_loss did not improve from 0.09273\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1158 - accuracy: 0.9600 - val_loss: 0.0973 - val_accuracy: 0.9653\n",
            "Epoch 18/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9597\n",
            "Epoch 18: val_loss did not improve from 0.09273\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1150 - accuracy: 0.9597 - val_loss: 0.0963 - val_accuracy: 0.9670\n",
            "Epoch 19/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.9623\n",
            "Epoch 19: val_loss did not improve from 0.09273\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1073 - accuracy: 0.9622 - val_loss: 0.0995 - val_accuracy: 0.9681\n",
            "Epoch 20/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9626\n",
            "Epoch 20: val_loss improved from 0.09273 to 0.08508, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1080 - accuracy: 0.9626 - val_loss: 0.0851 - val_accuracy: 0.9712\n",
            "Epoch 21/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1019 - accuracy: 0.9631\n",
            "Epoch 21: val_loss did not improve from 0.08508\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 0.0881 - val_accuracy: 0.9707\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9650\n",
            "Epoch 22: val_loss did not improve from 0.08508\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0994 - accuracy: 0.9650 - val_loss: 0.0878 - val_accuracy: 0.9706\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9661\n",
            "Epoch 23: val_loss did not improve from 0.08508\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0954 - accuracy: 0.9661 - val_loss: 0.0860 - val_accuracy: 0.9710\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9675\n",
            "Epoch 24: val_loss did not improve from 0.08508\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0905 - accuracy: 0.9675 - val_loss: 0.0872 - val_accuracy: 0.9686\n",
            "Epoch 25/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 0.9684\n",
            "Epoch 25: val_loss improved from 0.08508 to 0.08168, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0863 - accuracy: 0.9684 - val_loss: 0.0817 - val_accuracy: 0.9722\n",
            "Epoch 26/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9698\n",
            "Epoch 26: val_loss did not improve from 0.08168\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0851 - accuracy: 0.9698 - val_loss: 0.0849 - val_accuracy: 0.9696\n",
            "Epoch 27/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9713\n",
            "Epoch 27: val_loss did not improve from 0.08168\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0837 - accuracy: 0.9712 - val_loss: 0.0833 - val_accuracy: 0.9715\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9708\n",
            "Epoch 28: val_loss did not improve from 0.08168\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0818 - accuracy: 0.9708 - val_loss: 0.0839 - val_accuracy: 0.9711\n",
            "Epoch 29/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9737\n",
            "Epoch 29: val_loss did not improve from 0.08168\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0752 - accuracy: 0.9737 - val_loss: 0.0873 - val_accuracy: 0.9697\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9734\n",
            "Epoch 30: val_loss did not improve from 0.08168\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0751 - accuracy: 0.9734 - val_loss: 0.0831 - val_accuracy: 0.9716\n",
            "Epoch 31/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0706 - accuracy: 0.9746\n",
            "Epoch 31: val_loss did not improve from 0.08168\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0706 - accuracy: 0.9745 - val_loss: 0.0897 - val_accuracy: 0.9695\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9740\n",
            "Epoch 32: val_loss did not improve from 0.08168\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 0.0827 - val_accuracy: 0.9734\n",
            "Epoch 33/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9764\n",
            "Epoch 33: val_loss improved from 0.08168 to 0.07870, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0675 - accuracy: 0.9763 - val_loss: 0.0787 - val_accuracy: 0.9734\n",
            "Epoch 34/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9760\n",
            "Epoch 34: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0655 - accuracy: 0.9760 - val_loss: 0.0857 - val_accuracy: 0.9729\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9766\n",
            "Epoch 35: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0652 - accuracy: 0.9766 - val_loss: 0.0834 - val_accuracy: 0.9718\n",
            "Epoch 36/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9789\n",
            "Epoch 36: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0592 - accuracy: 0.9789 - val_loss: 0.0837 - val_accuracy: 0.9730\n",
            "Epoch 37/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9781\n",
            "Epoch 37: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0602 - accuracy: 0.9781 - val_loss: 0.0829 - val_accuracy: 0.9707\n",
            "Epoch 38/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9794\n",
            "Epoch 38: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0563 - accuracy: 0.9794 - val_loss: 0.0877 - val_accuracy: 0.9712\n",
            "Epoch 39/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 0.9795\n",
            "Epoch 39: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0571 - accuracy: 0.9795 - val_loss: 0.0875 - val_accuracy: 0.9716\n",
            "Epoch 40/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9811\n",
            "Epoch 40: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0535 - accuracy: 0.9812 - val_loss: 0.0822 - val_accuracy: 0.9728\n",
            "Epoch 41/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9818\n",
            "Epoch 41: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0518 - accuracy: 0.9819 - val_loss: 0.0892 - val_accuracy: 0.9710\n",
            "Epoch 42/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9809\n",
            "Epoch 42: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0501 - accuracy: 0.9810 - val_loss: 0.0908 - val_accuracy: 0.9701\n",
            "Epoch 43/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9824\n",
            "Epoch 43: val_loss did not improve from 0.07870\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0482 - accuracy: 0.9824 - val_loss: 0.0904 - val_accuracy: 0.9699\n",
            "63/63 [==============================] - 7s 47ms/step - loss: 4.1810 - accuracy: 0.5290\n",
            "Test accuracy, 17_SJ11: 0.5289999842643738\n",
            "Epoch 1/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 1.6269 - accuracy: 0.4902\n",
            "Epoch 1: val_loss improved from inf to 0.47904, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 60s 33ms/step - loss: 1.6250 - accuracy: 0.4908 - val_loss: 0.4790 - val_accuracy: 0.8680\n",
            "Epoch 2/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5371 - accuracy: 0.8188\n",
            "Epoch 2: val_loss improved from 0.47904 to 0.25461, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.5371 - accuracy: 0.8188 - val_loss: 0.2546 - val_accuracy: 0.9244\n",
            "Epoch 3/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3681 - accuracy: 0.8753\n",
            "Epoch 3: val_loss improved from 0.25461 to 0.18028, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3683 - accuracy: 0.8753 - val_loss: 0.1803 - val_accuracy: 0.9467\n",
            "Epoch 4/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.8971\n",
            "Epoch 4: val_loss improved from 0.18028 to 0.15101, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 30ms/step - loss: 0.2993 - accuracy: 0.8971 - val_loss: 0.1510 - val_accuracy: 0.9534\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2561 - accuracy: 0.9129\n",
            "Epoch 5: val_loss did not improve from 0.15101\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.2561 - accuracy: 0.9129 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9224\n",
            "Epoch 6: val_loss improved from 0.15101 to 0.14279, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2257 - accuracy: 0.9224 - val_loss: 0.1428 - val_accuracy: 0.9507\n",
            "Epoch 7/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.9298\n",
            "Epoch 7: val_loss improved from 0.14279 to 0.12191, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2027 - accuracy: 0.9298 - val_loss: 0.1219 - val_accuracy: 0.9586\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9345\n",
            "Epoch 8: val_loss improved from 0.12191 to 0.12095, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1864 - accuracy: 0.9345 - val_loss: 0.1209 - val_accuracy: 0.9611\n",
            "Epoch 9/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9390\n",
            "Epoch 9: val_loss improved from 0.12095 to 0.11918, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1732 - accuracy: 0.9391 - val_loss: 0.1192 - val_accuracy: 0.9595\n",
            "Epoch 10/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9420\n",
            "Epoch 10: val_loss improved from 0.11918 to 0.11286, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1660 - accuracy: 0.9420 - val_loss: 0.1129 - val_accuracy: 0.9629\n",
            "Epoch 11/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1543 - accuracy: 0.9470\n",
            "Epoch 11: val_loss improved from 0.11286 to 0.10733, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1543 - accuracy: 0.9470 - val_loss: 0.1073 - val_accuracy: 0.9634\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9497\n",
            "Epoch 12: val_loss improved from 0.10733 to 0.10685, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1466 - accuracy: 0.9497 - val_loss: 0.1068 - val_accuracy: 0.9640\n",
            "Epoch 13/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9511\n",
            "Epoch 13: val_loss did not improve from 0.10685\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1435 - accuracy: 0.9511 - val_loss: 0.1155 - val_accuracy: 0.9591\n",
            "Epoch 14/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.9561\n",
            "Epoch 14: val_loss improved from 0.10685 to 0.10614, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1305 - accuracy: 0.9561 - val_loss: 0.1061 - val_accuracy: 0.9639\n",
            "Epoch 15/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.9551\n",
            "Epoch 15: val_loss improved from 0.10614 to 0.10106, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1261 - accuracy: 0.9551 - val_loss: 0.1011 - val_accuracy: 0.9659\n",
            "Epoch 16/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1199 - accuracy: 0.9579\n",
            "Epoch 16: val_loss improved from 0.10106 to 0.09571, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1200 - accuracy: 0.9579 - val_loss: 0.0957 - val_accuracy: 0.9688\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9580\n",
            "Epoch 17: val_loss did not improve from 0.09571\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1184 - accuracy: 0.9580 - val_loss: 0.1041 - val_accuracy: 0.9645\n",
            "Epoch 18/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9600\n",
            "Epoch 18: val_loss did not improve from 0.09571\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1129 - accuracy: 0.9600 - val_loss: 0.0981 - val_accuracy: 0.9670\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9606\n",
            "Epoch 19: val_loss did not improve from 0.09571\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1092 - accuracy: 0.9607 - val_loss: 0.1008 - val_accuracy: 0.9649\n",
            "Epoch 20/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 0.9641\n",
            "Epoch 20: val_loss did not improve from 0.09571\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1023 - accuracy: 0.9641 - val_loss: 0.1066 - val_accuracy: 0.9641\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9648\n",
            "Epoch 21: val_loss improved from 0.09571 to 0.09428, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0996 - accuracy: 0.9647 - val_loss: 0.0943 - val_accuracy: 0.9678\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9664\n",
            "Epoch 22: val_loss did not improve from 0.09428\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0962 - accuracy: 0.9664 - val_loss: 0.0965 - val_accuracy: 0.9679\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9659\n",
            "Epoch 23: val_loss did not improve from 0.09428\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0931 - accuracy: 0.9659 - val_loss: 0.1007 - val_accuracy: 0.9670\n",
            "Epoch 24/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 0.9673\n",
            "Epoch 24: val_loss improved from 0.09428 to 0.09011, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0909 - accuracy: 0.9673 - val_loss: 0.0901 - val_accuracy: 0.9716\n",
            "Epoch 25/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 0.9690\n",
            "Epoch 25: val_loss did not improve from 0.09011\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0864 - accuracy: 0.9689 - val_loss: 0.0952 - val_accuracy: 0.9678\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9706\n",
            "Epoch 26: val_loss improved from 0.09011 to 0.08866, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0842 - accuracy: 0.9706 - val_loss: 0.0887 - val_accuracy: 0.9706\n",
            "Epoch 27/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9702\n",
            "Epoch 27: val_loss did not improve from 0.08866\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0824 - accuracy: 0.9702 - val_loss: 0.0936 - val_accuracy: 0.9672\n",
            "Epoch 28/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9716\n",
            "Epoch 28: val_loss did not improve from 0.08866\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0795 - accuracy: 0.9716 - val_loss: 0.0911 - val_accuracy: 0.9706\n",
            "Epoch 29/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9725\n",
            "Epoch 29: val_loss improved from 0.08866 to 0.08809, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0772 - accuracy: 0.9726 - val_loss: 0.0881 - val_accuracy: 0.9720\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0741 - accuracy: 0.9737\n",
            "Epoch 30: val_loss did not improve from 0.08809\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0740 - accuracy: 0.9737 - val_loss: 0.0910 - val_accuracy: 0.9715\n",
            "Epoch 31/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9752\n",
            "Epoch 31: val_loss did not improve from 0.08809\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0704 - accuracy: 0.9752 - val_loss: 0.0956 - val_accuracy: 0.9694\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9741\n",
            "Epoch 32: val_loss did not improve from 0.08809\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0700 - accuracy: 0.9741 - val_loss: 0.0903 - val_accuracy: 0.9715\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9766\n",
            "Epoch 33: val_loss did not improve from 0.08809\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0672 - accuracy: 0.9766 - val_loss: 0.0893 - val_accuracy: 0.9712\n",
            "Epoch 34/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9774\n",
            "Epoch 34: val_loss did not improve from 0.08809\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0634 - accuracy: 0.9774 - val_loss: 0.0955 - val_accuracy: 0.9703\n",
            "Epoch 35/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 0.9772\n",
            "Epoch 35: val_loss improved from 0.08809 to 0.08680, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0622 - accuracy: 0.9772 - val_loss: 0.0868 - val_accuracy: 0.9720\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9784\n",
            "Epoch 36: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0598 - accuracy: 0.9784 - val_loss: 0.0885 - val_accuracy: 0.9699\n",
            "Epoch 37/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9792\n",
            "Epoch 37: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0592 - accuracy: 0.9792 - val_loss: 0.0933 - val_accuracy: 0.9695\n",
            "Epoch 38/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9800\n",
            "Epoch 38: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0567 - accuracy: 0.9800 - val_loss: 0.1024 - val_accuracy: 0.9664\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9801\n",
            "Epoch 39: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0565 - accuracy: 0.9801 - val_loss: 0.0974 - val_accuracy: 0.9697\n",
            "Epoch 40/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9801\n",
            "Epoch 40: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0551 - accuracy: 0.9801 - val_loss: 0.0907 - val_accuracy: 0.9712\n",
            "Epoch 41/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9821\n",
            "Epoch 41: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0506 - accuracy: 0.9822 - val_loss: 0.0875 - val_accuracy: 0.9725\n",
            "Epoch 42/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9806\n",
            "Epoch 42: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0519 - accuracy: 0.9806 - val_loss: 0.0984 - val_accuracy: 0.9691\n",
            "Epoch 43/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9823\n",
            "Epoch 43: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0488 - accuracy: 0.9823 - val_loss: 0.0936 - val_accuracy: 0.9704\n",
            "Epoch 44/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9826\n",
            "Epoch 44: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0464 - accuracy: 0.9827 - val_loss: 0.1016 - val_accuracy: 0.9703\n",
            "Epoch 45/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9832\n",
            "Epoch 45: val_loss did not improve from 0.08680\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0463 - accuracy: 0.9832 - val_loss: 0.1011 - val_accuracy: 0.9700\n",
            "63/63 [==============================] - 7s 47ms/step - loss: 4.2218 - accuracy: 0.5235\n",
            "Test accuracy, 18_SJ11: 0.5235000252723694\n",
            "Epoch 1/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.6215 - accuracy: 0.4950\n",
            "Epoch 1: val_loss improved from inf to 0.49222, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 61s 33ms/step - loss: 1.6208 - accuracy: 0.4952 - val_loss: 0.4922 - val_accuracy: 0.8750\n",
            "Epoch 2/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.5405 - accuracy: 0.8151\n",
            "Epoch 2: val_loss improved from 0.49222 to 0.24737, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5406 - accuracy: 0.8150 - val_loss: 0.2474 - val_accuracy: 0.9264\n",
            "Epoch 3/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.3673 - accuracy: 0.8741\n",
            "Epoch 3: val_loss improved from 0.24737 to 0.18513, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3673 - accuracy: 0.8740 - val_loss: 0.1851 - val_accuracy: 0.9417\n",
            "Epoch 4/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.8991\n",
            "Epoch 4: val_loss improved from 0.18513 to 0.17844, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2950 - accuracy: 0.8991 - val_loss: 0.1784 - val_accuracy: 0.9456\n",
            "Epoch 5/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.9131\n",
            "Epoch 5: val_loss improved from 0.17844 to 0.14003, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2502 - accuracy: 0.9131 - val_loss: 0.1400 - val_accuracy: 0.9556\n",
            "Epoch 6/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2280 - accuracy: 0.9215\n",
            "Epoch 6: val_loss did not improve from 0.14003\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2281 - accuracy: 0.9214 - val_loss: 0.1486 - val_accuracy: 0.9491\n",
            "Epoch 7/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1992 - accuracy: 0.9306\n",
            "Epoch 7: val_loss improved from 0.14003 to 0.13310, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1992 - accuracy: 0.9307 - val_loss: 0.1331 - val_accuracy: 0.9530\n",
            "Epoch 8/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.9379\n",
            "Epoch 8: val_loss improved from 0.13310 to 0.12403, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1817 - accuracy: 0.9379 - val_loss: 0.1240 - val_accuracy: 0.9599\n",
            "Epoch 9/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.9377\n",
            "Epoch 9: val_loss improved from 0.12403 to 0.10960, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1799 - accuracy: 0.9377 - val_loss: 0.1096 - val_accuracy: 0.9639\n",
            "Epoch 10/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9447\n",
            "Epoch 10: val_loss improved from 0.10960 to 0.10612, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1625 - accuracy: 0.9448 - val_loss: 0.1061 - val_accuracy: 0.9636\n",
            "Epoch 11/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1523 - accuracy: 0.9484\n",
            "Epoch 11: val_loss improved from 0.10612 to 0.10415, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1522 - accuracy: 0.9484 - val_loss: 0.1041 - val_accuracy: 0.9640\n",
            "Epoch 12/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.9489\n",
            "Epoch 12: val_loss did not improve from 0.10415\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1462 - accuracy: 0.9489 - val_loss: 0.1259 - val_accuracy: 0.9575\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9548\n",
            "Epoch 13: val_loss did not improve from 0.10415\n",
            "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1342 - accuracy: 0.9548 - val_loss: 0.1142 - val_accuracy: 0.9601\n",
            "Epoch 14/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9553\n",
            "Epoch 14: val_loss improved from 0.10415 to 0.10320, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1271 - accuracy: 0.9553 - val_loss: 0.1032 - val_accuracy: 0.9640\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9553\n",
            "Epoch 15: val_loss improved from 0.10320 to 0.09764, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1257 - accuracy: 0.9553 - val_loss: 0.0976 - val_accuracy: 0.9660\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.9578\n",
            "Epoch 16: val_loss did not improve from 0.09764\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1208 - accuracy: 0.9578 - val_loss: 0.1193 - val_accuracy: 0.9567\n",
            "Epoch 17/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.9586\n",
            "Epoch 17: val_loss improved from 0.09764 to 0.09731, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1177 - accuracy: 0.9586 - val_loss: 0.0973 - val_accuracy: 0.9643\n",
            "Epoch 18/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.9610\n",
            "Epoch 18: val_loss improved from 0.09731 to 0.09135, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1131 - accuracy: 0.9610 - val_loss: 0.0913 - val_accuracy: 0.9693\n",
            "Epoch 19/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 0.9622\n",
            "Epoch 19: val_loss improved from 0.09135 to 0.09098, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1071 - accuracy: 0.9622 - val_loss: 0.0910 - val_accuracy: 0.9681\n",
            "Epoch 20/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9635\n",
            "Epoch 20: val_loss did not improve from 0.09098\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1018 - accuracy: 0.9635 - val_loss: 0.1368 - val_accuracy: 0.9510\n",
            "Epoch 21/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9657\n",
            "Epoch 21: val_loss improved from 0.09098 to 0.08999, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0979 - accuracy: 0.9657 - val_loss: 0.0900 - val_accuracy: 0.9680\n",
            "Epoch 22/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9666\n",
            "Epoch 22: val_loss did not improve from 0.08999\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0951 - accuracy: 0.9666 - val_loss: 0.0916 - val_accuracy: 0.9671\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9679\n",
            "Epoch 23: val_loss did not improve from 0.08999\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0929 - accuracy: 0.9679 - val_loss: 0.0983 - val_accuracy: 0.9621\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9697\n",
            "Epoch 24: val_loss did not improve from 0.08999\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0893 - accuracy: 0.9697 - val_loss: 0.0942 - val_accuracy: 0.9655\n",
            "Epoch 25/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9682\n",
            "Epoch 25: val_loss did not improve from 0.08999\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0865 - accuracy: 0.9682 - val_loss: 0.0912 - val_accuracy: 0.9681\n",
            "Epoch 26/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9704\n",
            "Epoch 26: val_loss did not improve from 0.08999\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0829 - accuracy: 0.9704 - val_loss: 0.0934 - val_accuracy: 0.9670\n",
            "Epoch 27/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9709\n",
            "Epoch 27: val_loss did not improve from 0.08999\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0803 - accuracy: 0.9709 - val_loss: 0.0961 - val_accuracy: 0.9655\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9712\n",
            "Epoch 28: val_loss improved from 0.08999 to 0.08990, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0790 - accuracy: 0.9712 - val_loss: 0.0899 - val_accuracy: 0.9688\n",
            "Epoch 29/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9741\n",
            "Epoch 29: val_loss did not improve from 0.08990\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0737 - accuracy: 0.9740 - val_loss: 0.0908 - val_accuracy: 0.9684\n",
            "Epoch 30/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.9731\n",
            "Epoch 30: val_loss did not improve from 0.08990\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0755 - accuracy: 0.9731 - val_loss: 0.0926 - val_accuracy: 0.9674\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9749\n",
            "Epoch 31: val_loss improved from 0.08990 to 0.08981, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0705 - accuracy: 0.9749 - val_loss: 0.0898 - val_accuracy: 0.9688\n",
            "Epoch 32/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9765\n",
            "Epoch 32: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0669 - accuracy: 0.9765 - val_loss: 0.1026 - val_accuracy: 0.9635\n",
            "Epoch 33/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9766\n",
            "Epoch 33: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0645 - accuracy: 0.9766 - val_loss: 0.0963 - val_accuracy: 0.9669\n",
            "Epoch 34/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9770\n",
            "Epoch 34: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0663 - accuracy: 0.9771 - val_loss: 0.0942 - val_accuracy: 0.9674\n",
            "Epoch 35/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9769\n",
            "Epoch 35: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0629 - accuracy: 0.9769 - val_loss: 0.0935 - val_accuracy: 0.9682\n",
            "Epoch 36/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9778\n",
            "Epoch 36: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0607 - accuracy: 0.9778 - val_loss: 0.0950 - val_accuracy: 0.9669\n",
            "Epoch 37/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9791\n",
            "Epoch 37: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0555 - accuracy: 0.9791 - val_loss: 0.0934 - val_accuracy: 0.9676\n",
            "Epoch 38/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9811\n",
            "Epoch 38: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0543 - accuracy: 0.9812 - val_loss: 0.0934 - val_accuracy: 0.9704\n",
            "Epoch 39/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9798\n",
            "Epoch 39: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0537 - accuracy: 0.9797 - val_loss: 0.0932 - val_accuracy: 0.9703\n",
            "Epoch 40/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9807\n",
            "Epoch 40: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0517 - accuracy: 0.9808 - val_loss: 0.0910 - val_accuracy: 0.9694\n",
            "Epoch 41/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9822\n",
            "Epoch 41: val_loss did not improve from 0.08981\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0491 - accuracy: 0.9822 - val_loss: 0.1170 - val_accuracy: 0.9631\n",
            "63/63 [==============================] - 7s 46ms/step - loss: 3.1670 - accuracy: 0.5760\n",
            "Test accuracy, 19_SJ11: 0.5759999752044678\n",
            "Epoch 1/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 1.6344 - accuracy: 0.4867\n",
            "Epoch 1: val_loss improved from inf to 0.45658, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 60s 34ms/step - loss: 1.6340 - accuracy: 0.4869 - val_loss: 0.4566 - val_accuracy: 0.8731\n",
            "Epoch 2/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.5357 - accuracy: 0.8174\n",
            "Epoch 2: val_loss improved from 0.45658 to 0.24316, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.5358 - accuracy: 0.8174 - val_loss: 0.2432 - val_accuracy: 0.9306\n",
            "Epoch 3/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.3651 - accuracy: 0.8760\n",
            "Epoch 3: val_loss improved from 0.24316 to 0.20379, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3652 - accuracy: 0.8759 - val_loss: 0.2038 - val_accuracy: 0.9341\n",
            "Epoch 4/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.2906 - accuracy: 0.9002\n",
            "Epoch 4: val_loss improved from 0.20379 to 0.17176, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2904 - accuracy: 0.9003 - val_loss: 0.1718 - val_accuracy: 0.9441\n",
            "Epoch 5/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9141\n",
            "Epoch 5: val_loss improved from 0.17176 to 0.15058, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2508 - accuracy: 0.9141 - val_loss: 0.1506 - val_accuracy: 0.9551\n",
            "Epoch 6/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9213\n",
            "Epoch 6: val_loss improved from 0.15058 to 0.13351, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2228 - accuracy: 0.9213 - val_loss: 0.1335 - val_accuracy: 0.9597\n",
            "Epoch 7/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.9296\n",
            "Epoch 7: val_loss did not improve from 0.13351\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2031 - accuracy: 0.9295 - val_loss: 0.1345 - val_accuracy: 0.9566\n",
            "Epoch 8/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1871 - accuracy: 0.9363\n",
            "Epoch 8: val_loss improved from 0.13351 to 0.12325, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1870 - accuracy: 0.9363 - val_loss: 0.1232 - val_accuracy: 0.9572\n",
            "Epoch 9/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1722 - accuracy: 0.9409\n",
            "Epoch 9: val_loss improved from 0.12325 to 0.11356, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1721 - accuracy: 0.9410 - val_loss: 0.1136 - val_accuracy: 0.9643\n",
            "Epoch 10/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9428\n",
            "Epoch 10: val_loss improved from 0.11356 to 0.11287, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1643 - accuracy: 0.9429 - val_loss: 0.1129 - val_accuracy: 0.9614\n",
            "Epoch 11/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1561 - accuracy: 0.9459\n",
            "Epoch 11: val_loss improved from 0.11287 to 0.10710, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1560 - accuracy: 0.9459 - val_loss: 0.1071 - val_accuracy: 0.9670\n",
            "Epoch 12/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9487\n",
            "Epoch 12: val_loss did not improve from 0.10710\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1475 - accuracy: 0.9488 - val_loss: 0.1110 - val_accuracy: 0.9643\n",
            "Epoch 13/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9509\n",
            "Epoch 13: val_loss did not improve from 0.10710\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1419 - accuracy: 0.9509 - val_loss: 0.1090 - val_accuracy: 0.9639\n",
            "Epoch 14/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1323 - accuracy: 0.9534\n",
            "Epoch 14: val_loss improved from 0.10710 to 0.10184, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1323 - accuracy: 0.9534 - val_loss: 0.1018 - val_accuracy: 0.9665\n",
            "Epoch 15/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9571\n",
            "Epoch 15: val_loss improved from 0.10184 to 0.10182, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.1258 - accuracy: 0.9571 - val_loss: 0.1018 - val_accuracy: 0.9665\n",
            "Epoch 16/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9574\n",
            "Epoch 16: val_loss improved from 0.10182 to 0.10113, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1195 - accuracy: 0.9574 - val_loss: 0.1011 - val_accuracy: 0.9680\n",
            "Epoch 17/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9598\n",
            "Epoch 17: val_loss did not improve from 0.10113\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1158 - accuracy: 0.9597 - val_loss: 0.1016 - val_accuracy: 0.9671\n",
            "Epoch 18/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9601\n",
            "Epoch 18: val_loss did not improve from 0.10113\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1134 - accuracy: 0.9602 - val_loss: 0.1021 - val_accuracy: 0.9651\n",
            "Epoch 19/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.1068 - accuracy: 0.9618\n",
            "Epoch 19: val_loss did not improve from 0.10113\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.1067 - accuracy: 0.9618 - val_loss: 0.1023 - val_accuracy: 0.9651\n",
            "Epoch 20/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.1017 - accuracy: 0.9641\n",
            "Epoch 20: val_loss did not improve from 0.10113\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1016 - accuracy: 0.9641 - val_loss: 0.1011 - val_accuracy: 0.9672\n",
            "Epoch 21/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9651\n",
            "Epoch 21: val_loss improved from 0.10113 to 0.09473, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0980 - accuracy: 0.9651 - val_loss: 0.0947 - val_accuracy: 0.9688\n",
            "Epoch 22/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9657\n",
            "Epoch 22: val_loss improved from 0.09473 to 0.09355, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0949 - accuracy: 0.9657 - val_loss: 0.0936 - val_accuracy: 0.9699\n",
            "Epoch 23/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9669\n",
            "Epoch 23: val_loss did not improve from 0.09355\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0927 - accuracy: 0.9669 - val_loss: 0.0949 - val_accuracy: 0.9701\n",
            "Epoch 24/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9680\n",
            "Epoch 24: val_loss did not improve from 0.09355\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0878 - accuracy: 0.9680 - val_loss: 0.0947 - val_accuracy: 0.9686\n",
            "Epoch 25/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9706\n",
            "Epoch 25: val_loss improved from 0.09355 to 0.09245, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0853 - accuracy: 0.9706 - val_loss: 0.0925 - val_accuracy: 0.9694\n",
            "Epoch 26/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9711\n",
            "Epoch 26: val_loss did not improve from 0.09245\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0808 - accuracy: 0.9711 - val_loss: 0.1049 - val_accuracy: 0.9664\n",
            "Epoch 27/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9714\n",
            "Epoch 27: val_loss did not improve from 0.09245\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0795 - accuracy: 0.9714 - val_loss: 0.0965 - val_accuracy: 0.9691\n",
            "Epoch 28/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9726\n",
            "Epoch 28: val_loss did not improve from 0.09245\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0771 - accuracy: 0.9726 - val_loss: 0.0968 - val_accuracy: 0.9670\n",
            "Epoch 29/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9727\n",
            "Epoch 29: val_loss improved from 0.09245 to 0.08869, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0762 - accuracy: 0.9727 - val_loss: 0.0887 - val_accuracy: 0.9704\n",
            "Epoch 30/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9735\n",
            "Epoch 30: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.0737 - accuracy: 0.9735 - val_loss: 0.0962 - val_accuracy: 0.9703\n",
            "Epoch 31/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9747\n",
            "Epoch 31: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0704 - accuracy: 0.9747 - val_loss: 0.0960 - val_accuracy: 0.9693\n",
            "Epoch 32/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0677 - accuracy: 0.9756\n",
            "Epoch 32: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0677 - accuracy: 0.9756 - val_loss: 0.0970 - val_accuracy: 0.9674\n",
            "Epoch 33/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9768\n",
            "Epoch 33: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0652 - accuracy: 0.9768 - val_loss: 0.0952 - val_accuracy: 0.9696\n",
            "Epoch 34/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9778\n",
            "Epoch 34: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0631 - accuracy: 0.9778 - val_loss: 0.1040 - val_accuracy: 0.9654\n",
            "Epoch 35/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9775\n",
            "Epoch 35: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0631 - accuracy: 0.9775 - val_loss: 0.0921 - val_accuracy: 0.9714\n",
            "Epoch 36/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9792\n",
            "Epoch 36: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0563 - accuracy: 0.9792 - val_loss: 0.1002 - val_accuracy: 0.9684\n",
            "Epoch 37/200\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9801\n",
            "Epoch 37: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 0.0936 - val_accuracy: 0.9719\n",
            "Epoch 38/200\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9809\n",
            "Epoch 38: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0544 - accuracy: 0.9808 - val_loss: 0.1014 - val_accuracy: 0.9695\n",
            "Epoch 39/200\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9796\n",
            "Epoch 39: val_loss did not improve from 0.08869\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0577 - accuracy: 0.9796 - val_loss: 0.1068 - val_accuracy: 0.9674\n",
            "63/63 [==============================] - 7s 47ms/step - loss: 3.1518 - accuracy: 0.5745\n",
            "Test accuracy, 20_SJ11: 0.5745000243186951\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  res_net = create_model()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=res_net)\n",
        "  callbacks = [EarlyStopping(monitor='val_loss', patience=10, mode='min'), ModelCheckpoint('/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
        "  res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "  Known_data_X_reference, Known_data_X_train_label = shuffle(Known_data_X_reference, Known_data_X_train_label)\n",
        "\n",
        "  history = res_net.fit(Known_data_X_reference, Known_data_X_train_label, epochs=200, batch_size=32, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)\n",
        "\n",
        "  test_loss, test_acc = res_net.evaluate(Known_data_X_test, Known_data_X_test_label)\n",
        "\n",
        "  print('Test accuracy, 01_SJ11:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlX_NfqohDTs",
        "outputId": "dd007213-7cd8-4047-8a34-77a26af295d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 83s 1s/step - loss: 3.2255 - accuracy: 0.5460\n",
            "Test accuracy, 01 run: 0.5460000038146973\n",
            "63/63 [==============================] - 85s 1s/step - loss: 3.3154 - accuracy: 0.5585\n",
            "Test accuracy, 02 run: 0.5584999918937683\n",
            "63/63 [==============================] - 50s 764ms/step - loss: 2.7449 - accuracy: 0.5390\n",
            "Test accuracy, 03 run: 0.5389999747276306\n",
            "63/63 [==============================] - 51s 761ms/step - loss: 3.0738 - accuracy: 0.5415\n",
            "Test accuracy, 04 run: 0.5414999723434448\n",
            "63/63 [==============================] - 55s 837ms/step - loss: 2.4547 - accuracy: 0.5805\n",
            "Test accuracy, 05 run: 0.5805000066757202\n",
            "63/63 [==============================] - 54s 822ms/step - loss: 3.2694 - accuracy: 0.5540\n",
            "Test accuracy, 06 run: 0.5540000200271606\n",
            "63/63 [==============================] - 54s 830ms/step - loss: 3.2156 - accuracy: 0.5460\n",
            "Test accuracy, 07 run: 0.5460000038146973\n",
            "63/63 [==============================] - 55s 797ms/step - loss: 3.4278 - accuracy: 0.5200\n",
            "Test accuracy, 08 run: 0.5199999809265137\n",
            "63/63 [==============================] - 53s 783ms/step - loss: 2.9415 - accuracy: 0.5635\n",
            "Test accuracy, 09 run: 0.5634999871253967\n",
            "63/63 [==============================] - 52s 800ms/step - loss: 3.2795 - accuracy: 0.5450\n",
            "Test accuracy, 10 run: 0.5450000166893005\n",
            "63/63 [==============================] - 50s 757ms/step - loss: 3.2111 - accuracy: 0.5610\n",
            "Test accuracy, 11 run: 0.5609999895095825\n",
            "63/63 [==============================] - 53s 792ms/step - loss: 2.7591 - accuracy: 0.5370\n",
            "Test accuracy, 12 run: 0.5370000004768372\n",
            "63/63 [==============================] - 55s 827ms/step - loss: 2.8052 - accuracy: 0.5715\n",
            "Test accuracy, 13 run: 0.5715000033378601\n",
            "63/63 [==============================] - 52s 795ms/step - loss: 3.4658 - accuracy: 0.5180\n",
            "Test accuracy, 14 run: 0.5180000066757202\n",
            "63/63 [==============================] - 50s 765ms/step - loss: 3.5318 - accuracy: 0.5495\n",
            "Test accuracy, 15 run: 0.5494999885559082\n",
            "63/63 [==============================] - 56s 824ms/step - loss: 3.3594 - accuracy: 0.5270\n",
            "Test accuracy, 16 run: 0.5270000100135803\n",
            "63/63 [==============================] - 52s 759ms/step - loss: 2.8980 - accuracy: 0.5445\n",
            "Test accuracy, 17 run: 0.5444999933242798\n",
            "63/63 [==============================] - 58s 893ms/step - loss: 3.0668 - accuracy: 0.5550\n",
            "Test accuracy, 18 run: 0.5550000071525574\n",
            "63/63 [==============================] - 50s 761ms/step - loss: 3.4744 - accuracy: 0.5330\n",
            "Test accuracy, 19 run: 0.5329999923706055\n",
            "63/63 [==============================] - 55s 850ms/step - loss: 3.0972 - accuracy: 0.5320\n",
            "Test accuracy, 20 run: 0.5320000052452087\n"
          ]
        }
      ],
      "source": [
        "# Now run and see the models with the best validation accuracy\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 01 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 02 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 03 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 04 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 05 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 06 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 07 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 08 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 09 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 10 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 11 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 12 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 13 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 14 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 15 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 16 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 17 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 18 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 19 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 20 run:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzqOXpJUhDVE",
        "outputId": "f4f7b1f6-13c4-4896-e47c-35514c998e3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 63/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9319\n",
            "Epoch 63: val_loss improved from 0.24420 to 0.24392, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 114ms/step - loss: 0.2082 - accuracy: 0.9319 - val_loss: 0.2439 - val_accuracy: 0.9100\n",
            "Epoch 64/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9319\n",
            "Epoch 64: val_loss did not improve from 0.24392\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.2049 - accuracy: 0.9319 - val_loss: 0.2466 - val_accuracy: 0.9125\n",
            "Epoch 65/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.9306\n",
            "Epoch 65: val_loss did not improve from 0.24392\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.2066 - accuracy: 0.9306 - val_loss: 0.2442 - val_accuracy: 0.9150\n",
            "Epoch 66/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.9311\n",
            "Epoch 66: val_loss improved from 0.24392 to 0.23930, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 127ms/step - loss: 0.1957 - accuracy: 0.9306 - val_loss: 0.2393 - val_accuracy: 0.9150\n",
            "Epoch 67/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 0.9324\n",
            "Epoch 67: val_loss improved from 0.23930 to 0.23685, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 114ms/step - loss: 0.1836 - accuracy: 0.9331 - val_loss: 0.2368 - val_accuracy: 0.9125\n",
            "Epoch 68/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2009 - accuracy: 0.9287\n",
            "Epoch 68: val_loss did not improve from 0.23685\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.2009 - accuracy: 0.9287 - val_loss: 0.2372 - val_accuracy: 0.9175\n",
            "Epoch 69/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1809 - accuracy: 0.9426\n",
            "Epoch 69: val_loss improved from 0.23685 to 0.23652, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 100ms/step - loss: 0.1818 - accuracy: 0.9425 - val_loss: 0.2365 - val_accuracy: 0.9150\n",
            "Epoch 70/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9356\n",
            "Epoch 70: val_loss did not improve from 0.23652\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 0.1850 - accuracy: 0.9356 - val_loss: 0.2368 - val_accuracy: 0.9125\n",
            "Epoch 71/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9381\n",
            "Epoch 71: val_loss improved from 0.23652 to 0.22971, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 108ms/step - loss: 0.1833 - accuracy: 0.9381 - val_loss: 0.2297 - val_accuracy: 0.9150\n",
            "Epoch 72/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1874 - accuracy: 0.9381\n",
            "Epoch 72: val_loss improved from 0.22971 to 0.22831, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 99ms/step - loss: 0.1857 - accuracy: 0.9388 - val_loss: 0.2283 - val_accuracy: 0.9125\n",
            "Epoch 73/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1683 - accuracy: 0.9490\n",
            "Epoch 73: val_loss did not improve from 0.22831\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.1674 - accuracy: 0.9494 - val_loss: 0.2318 - val_accuracy: 0.9100\n",
            "Epoch 74/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1789 - accuracy: 0.9337\n",
            "Epoch 74: val_loss did not improve from 0.22831\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.1784 - accuracy: 0.9344 - val_loss: 0.2293 - val_accuracy: 0.9150\n",
            "Epoch 75/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.9450\n",
            "Epoch 75: val_loss improved from 0.22831 to 0.22181, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 112ms/step - loss: 0.1583 - accuracy: 0.9450 - val_loss: 0.2218 - val_accuracy: 0.9200\n",
            "Epoch 76/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9522\n",
            "Epoch 76: val_loss did not improve from 0.22181\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.1566 - accuracy: 0.9513 - val_loss: 0.2286 - val_accuracy: 0.9150\n",
            "Epoch 77/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1597 - accuracy: 0.9444\n",
            "Epoch 77: val_loss did not improve from 0.22181\n",
            "50/50 [==============================] - 3s 63ms/step - loss: 0.1597 - accuracy: 0.9444 - val_loss: 0.2257 - val_accuracy: 0.9150\n",
            "Epoch 78/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9337\n",
            "Epoch 78: val_loss did not improve from 0.22181\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.1715 - accuracy: 0.9337 - val_loss: 0.2280 - val_accuracy: 0.9125\n",
            "Epoch 79/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9425\n",
            "Epoch 79: val_loss did not improve from 0.22181\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.1685 - accuracy: 0.9425 - val_loss: 0.2278 - val_accuracy: 0.9125\n",
            "Epoch 80/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9413\n",
            "Epoch 80: val_loss did not improve from 0.22181\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 0.1574 - accuracy: 0.9425 - val_loss: 0.2274 - val_accuracy: 0.9125\n",
            "Epoch 81/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9387\n",
            "Epoch 81: val_loss did not improve from 0.22181\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.1650 - accuracy: 0.9388 - val_loss: 0.2226 - val_accuracy: 0.9125\n",
            "Epoch 82/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9437\n",
            "Epoch 82: val_loss did not improve from 0.22181\n",
            "50/50 [==============================] - 3s 54ms/step - loss: 0.1584 - accuracy: 0.9438 - val_loss: 0.2257 - val_accuracy: 0.9175\n",
            "Epoch 83/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9556\n",
            "Epoch 83: val_loss did not improve from 0.22181\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1441 - accuracy: 0.9556 - val_loss: 0.2229 - val_accuracy: 0.9150\n",
            "Epoch 84/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.9437\n",
            "Epoch 84: val_loss improved from 0.22181 to 0.21886, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 107ms/step - loss: 0.1583 - accuracy: 0.9438 - val_loss: 0.2189 - val_accuracy: 0.9175\n",
            "Epoch 85/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9512\n",
            "Epoch 85: val_loss did not improve from 0.21886\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.1442 - accuracy: 0.9513 - val_loss: 0.2216 - val_accuracy: 0.9125\n",
            "Epoch 86/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1469 - accuracy: 0.9531\n",
            "Epoch 86: val_loss improved from 0.21886 to 0.21684, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.1445 - accuracy: 0.9544 - val_loss: 0.2168 - val_accuracy: 0.9250\n",
            "Epoch 87/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1410 - accuracy: 0.9544\n",
            "Epoch 87: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1386 - accuracy: 0.9556 - val_loss: 0.2235 - val_accuracy: 0.9150\n",
            "Epoch 88/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1515 - accuracy: 0.9469\n",
            "Epoch 88: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1515 - accuracy: 0.9469 - val_loss: 0.2206 - val_accuracy: 0.9150\n",
            "Epoch 89/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1245 - accuracy: 0.9577\n",
            "Epoch 89: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1252 - accuracy: 0.9575 - val_loss: 0.2216 - val_accuracy: 0.9150\n",
            "Epoch 90/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1362 - accuracy: 0.9577\n",
            "Epoch 90: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.1331 - accuracy: 0.9594 - val_loss: 0.2226 - val_accuracy: 0.9100\n",
            "Epoch 91/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1424 - accuracy: 0.9505\n",
            "Epoch 91: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.1422 - accuracy: 0.9488 - val_loss: 0.2200 - val_accuracy: 0.9150\n",
            "Epoch 92/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1288 - accuracy: 0.9590\n",
            "Epoch 92: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.1268 - accuracy: 0.9594 - val_loss: 0.2179 - val_accuracy: 0.9175\n",
            "Epoch 93/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.9566\n",
            "Epoch 93: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1306 - accuracy: 0.9569 - val_loss: 0.2169 - val_accuracy: 0.9200\n",
            "Epoch 94/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1468 - accuracy: 0.9525\n",
            "Epoch 94: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1468 - accuracy: 0.9525 - val_loss: 0.2190 - val_accuracy: 0.9175\n",
            "Epoch 95/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1317 - accuracy: 0.9583\n",
            "Epoch 95: val_loss did not improve from 0.21684\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1306 - accuracy: 0.9594 - val_loss: 0.2178 - val_accuracy: 0.9200\n",
            "Epoch 96/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1424 - accuracy: 0.9522\n",
            "Epoch 96: val_loss improved from 0.21684 to 0.21351, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 111ms/step - loss: 0.1408 - accuracy: 0.9531 - val_loss: 0.2135 - val_accuracy: 0.9225\n",
            "Epoch 97/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1234 - accuracy: 0.9564\n",
            "Epoch 97: val_loss did not improve from 0.21351\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.1240 - accuracy: 0.9569 - val_loss: 0.2147 - val_accuracy: 0.9225\n",
            "Epoch 98/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1308 - accuracy: 0.9557\n",
            "Epoch 98: val_loss did not improve from 0.21351\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1296 - accuracy: 0.9563 - val_loss: 0.2155 - val_accuracy: 0.9175\n",
            "Epoch 99/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.9522\n",
            "Epoch 99: val_loss did not improve from 0.21351\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1347 - accuracy: 0.9531 - val_loss: 0.2167 - val_accuracy: 0.9175\n",
            "Epoch 100/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9600\n",
            "Epoch 100: val_loss did not improve from 0.21351\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1280 - accuracy: 0.9600 - val_loss: 0.2184 - val_accuracy: 0.9150\n",
            "Epoch 101/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9556\n",
            "Epoch 101: val_loss did not improve from 0.21351\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.1139 - accuracy: 0.9556 - val_loss: 0.2146 - val_accuracy: 0.9200\n",
            "Epoch 102/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1194 - accuracy: 0.9570\n",
            "Epoch 102: val_loss did not improve from 0.21351\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 0.1192 - accuracy: 0.9569 - val_loss: 0.2157 - val_accuracy: 0.9225\n",
            "Epoch 103/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1162 - accuracy: 0.9585\n",
            "Epoch 103: val_loss improved from 0.21351 to 0.21276, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.1198 - accuracy: 0.9581 - val_loss: 0.2128 - val_accuracy: 0.9250\n",
            "Epoch 104/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9587\n",
            "Epoch 104: val_loss did not improve from 0.21276\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 0.1290 - accuracy: 0.9588 - val_loss: 0.2162 - val_accuracy: 0.9200\n",
            "Epoch 105/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9625\n",
            "Epoch 105: val_loss did not improve from 0.21276\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1127 - accuracy: 0.9625 - val_loss: 0.2174 - val_accuracy: 0.9200\n",
            "Epoch 106/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1070 - accuracy: 0.9681\n",
            "Epoch 106: val_loss did not improve from 0.21276\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.1067 - accuracy: 0.9681 - val_loss: 0.2129 - val_accuracy: 0.9225\n",
            "Epoch 107/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9573\n",
            "Epoch 107: val_loss improved from 0.21276 to 0.21123, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.1156 - accuracy: 0.9569 - val_loss: 0.2112 - val_accuracy: 0.9200\n",
            "Epoch 108/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9624\n",
            "Epoch 108: val_loss did not improve from 0.21123\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0982 - accuracy: 0.9631 - val_loss: 0.2122 - val_accuracy: 0.9250\n",
            "Epoch 109/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.9649\n",
            "Epoch 109: val_loss improved from 0.21123 to 0.20944, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1042 - accuracy: 0.9650 - val_loss: 0.2094 - val_accuracy: 0.9325\n",
            "Epoch 110/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9719\n",
            "Epoch 110: val_loss did not improve from 0.20944\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0980 - accuracy: 0.9719 - val_loss: 0.2141 - val_accuracy: 0.9300\n",
            "Epoch 111/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9625\n",
            "Epoch 111: val_loss did not improve from 0.20944\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1114 - accuracy: 0.9625 - val_loss: 0.2156 - val_accuracy: 0.9225\n",
            "Epoch 112/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1106 - accuracy: 0.9635\n",
            "Epoch 112: val_loss did not improve from 0.20944\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.1094 - accuracy: 0.9631 - val_loss: 0.2136 - val_accuracy: 0.9250\n",
            "Epoch 113/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9606\n",
            "Epoch 113: val_loss improved from 0.20944 to 0.20897, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.1138 - accuracy: 0.9606 - val_loss: 0.2090 - val_accuracy: 0.9275\n",
            "Epoch 114/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0991 - accuracy: 0.9655\n",
            "Epoch 114: val_loss did not improve from 0.20897\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0976 - accuracy: 0.9663 - val_loss: 0.2116 - val_accuracy: 0.9300\n",
            "Epoch 115/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9600\n",
            "Epoch 115: val_loss did not improve from 0.20897\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.1105 - accuracy: 0.9600 - val_loss: 0.2114 - val_accuracy: 0.9275\n",
            "Epoch 116/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9732\n",
            "Epoch 116: val_loss did not improve from 0.20897\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0889 - accuracy: 0.9737 - val_loss: 0.2122 - val_accuracy: 0.9250\n",
            "Epoch 117/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0852 - accuracy: 0.9753\n",
            "Epoch 117: val_loss improved from 0.20897 to 0.20750, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 99ms/step - loss: 0.0854 - accuracy: 0.9744 - val_loss: 0.2075 - val_accuracy: 0.9300\n",
            "Epoch 118/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1031 - accuracy: 0.9635\n",
            "Epoch 118: val_loss did not improve from 0.20750\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1042 - accuracy: 0.9625 - val_loss: 0.2115 - val_accuracy: 0.9300\n",
            "Epoch 119/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9739\n",
            "Epoch 119: val_loss did not improve from 0.20750\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0859 - accuracy: 0.9744 - val_loss: 0.2116 - val_accuracy: 0.9275\n",
            "Epoch 120/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 0.9617\n",
            "Epoch 120: val_loss did not improve from 0.20750\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1018 - accuracy: 0.9625 - val_loss: 0.2133 - val_accuracy: 0.9275\n",
            "Epoch 121/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 0.9668\n",
            "Epoch 121: val_loss did not improve from 0.20750\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0967 - accuracy: 0.9669 - val_loss: 0.2098 - val_accuracy: 0.9325\n",
            "Epoch 122/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9731\n",
            "Epoch 122: val_loss did not improve from 0.20750\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0827 - accuracy: 0.9731 - val_loss: 0.2127 - val_accuracy: 0.9250\n",
            "Epoch 123/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9688\n",
            "Epoch 123: val_loss did not improve from 0.20750\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0820 - accuracy: 0.9688 - val_loss: 0.2080 - val_accuracy: 0.9325\n",
            "Epoch 124/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9719\n",
            "Epoch 124: val_loss did not improve from 0.20750\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0835 - accuracy: 0.9725 - val_loss: 0.2092 - val_accuracy: 0.9300\n",
            "Epoch 125/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9732\n",
            "Epoch 125: val_loss improved from 0.20750 to 0.20667, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 0.0840 - accuracy: 0.9737 - val_loss: 0.2067 - val_accuracy: 0.9300\n",
            "Epoch 126/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9681\n",
            "Epoch 126: val_loss improved from 0.20667 to 0.20633, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.0839 - accuracy: 0.9688 - val_loss: 0.2063 - val_accuracy: 0.9275\n",
            "Epoch 127/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0753 - accuracy: 0.9727\n",
            "Epoch 127: val_loss improved from 0.20633 to 0.20566, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.0759 - accuracy: 0.9731 - val_loss: 0.2057 - val_accuracy: 0.9300\n",
            "Epoch 128/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0674 - accuracy: 0.9772\n",
            "Epoch 128: val_loss did not improve from 0.20566\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.2102 - val_accuracy: 0.9250\n",
            "Epoch 129/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9688\n",
            "Epoch 129: val_loss did not improve from 0.20566\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0842 - accuracy: 0.9688 - val_loss: 0.2113 - val_accuracy: 0.9325\n",
            "Epoch 130/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 0.9751\n",
            "Epoch 130: val_loss improved from 0.20566 to 0.20435, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.0748 - accuracy: 0.9750 - val_loss: 0.2043 - val_accuracy: 0.9325\n",
            "Epoch 131/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9731\n",
            "Epoch 131: val_loss did not improve from 0.20435\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0854 - accuracy: 0.9731 - val_loss: 0.2052 - val_accuracy: 0.9325\n",
            "Epoch 132/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9726\n",
            "Epoch 132: val_loss did not improve from 0.20435\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0708 - accuracy: 0.9731 - val_loss: 0.2072 - val_accuracy: 0.9350\n",
            "Epoch 133/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0794 - accuracy: 0.9720\n",
            "Epoch 133: val_loss improved from 0.20435 to 0.20394, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0783 - accuracy: 0.9719 - val_loss: 0.2039 - val_accuracy: 0.9350\n",
            "Epoch 134/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9787\n",
            "Epoch 134: val_loss did not improve from 0.20394\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0678 - accuracy: 0.9787 - val_loss: 0.2078 - val_accuracy: 0.9325\n",
            "Epoch 135/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9694\n",
            "Epoch 135: val_loss did not improve from 0.20394\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0874 - accuracy: 0.9694 - val_loss: 0.2082 - val_accuracy: 0.9275\n",
            "Epoch 136/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9770\n",
            "Epoch 136: val_loss did not improve from 0.20394\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0677 - accuracy: 0.9775 - val_loss: 0.2083 - val_accuracy: 0.9350\n",
            "Epoch 137/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9751\n",
            "Epoch 137: val_loss improved from 0.20394 to 0.20225, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 124ms/step - loss: 0.0841 - accuracy: 0.9744 - val_loss: 0.2023 - val_accuracy: 0.9350\n",
            "Epoch 138/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9712\n",
            "Epoch 138: val_loss improved from 0.20225 to 0.20108, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 99ms/step - loss: 0.0764 - accuracy: 0.9712 - val_loss: 0.2011 - val_accuracy: 0.9325\n",
            "Epoch 139/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9775\n",
            "Epoch 139: val_loss did not improve from 0.20108\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0702 - accuracy: 0.9775 - val_loss: 0.2040 - val_accuracy: 0.9300\n",
            "Epoch 140/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9787\n",
            "Epoch 140: val_loss did not improve from 0.20108\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0704 - accuracy: 0.9787 - val_loss: 0.2040 - val_accuracy: 0.9325\n",
            "Epoch 141/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0709 - accuracy: 0.9733\n",
            "Epoch 141: val_loss did not improve from 0.20108\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0693 - accuracy: 0.9744 - val_loss: 0.2024 - val_accuracy: 0.9325\n",
            "Epoch 142/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9831\n",
            "Epoch 142: val_loss did not improve from 0.20108\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 0.0564 - accuracy: 0.9831 - val_loss: 0.2031 - val_accuracy: 0.9375\n",
            "Epoch 143/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9725\n",
            "Epoch 143: val_loss did not improve from 0.20108\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0763 - accuracy: 0.9725 - val_loss: 0.2022 - val_accuracy: 0.9350\n",
            "Epoch 144/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9794\n",
            "Epoch 144: val_loss did not improve from 0.20108\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0644 - accuracy: 0.9794 - val_loss: 0.2069 - val_accuracy: 0.9350\n",
            "Epoch 145/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0670 - accuracy: 0.9766\n",
            "Epoch 145: val_loss improved from 0.20108 to 0.19929, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.0668 - accuracy: 0.9769 - val_loss: 0.1993 - val_accuracy: 0.9375\n",
            "Epoch 146/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.9750\n",
            "Epoch 146: val_loss did not improve from 0.19929\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0657 - accuracy: 0.9750 - val_loss: 0.2029 - val_accuracy: 0.9350\n",
            "Epoch 147/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9775\n",
            "Epoch 147: val_loss improved from 0.19929 to 0.19907, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 95ms/step - loss: 0.0745 - accuracy: 0.9775 - val_loss: 0.1991 - val_accuracy: 0.9350\n",
            "Epoch 148/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9756\n",
            "Epoch 148: val_loss did not improve from 0.19907\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0648 - accuracy: 0.9756 - val_loss: 0.2044 - val_accuracy: 0.9350\n",
            "Epoch 149/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0593 - accuracy: 0.9798\n",
            "Epoch 149: val_loss improved from 0.19907 to 0.19867, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0610 - accuracy: 0.9787 - val_loss: 0.1987 - val_accuracy: 0.9375\n",
            "Epoch 150/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9802\n",
            "Epoch 150: val_loss did not improve from 0.19867\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0593 - accuracy: 0.9794 - val_loss: 0.1988 - val_accuracy: 0.9400\n",
            "Epoch 151/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0654 - accuracy: 0.9772\n",
            "Epoch 151: val_loss improved from 0.19867 to 0.19810, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 99ms/step - loss: 0.0689 - accuracy: 0.9756 - val_loss: 0.1981 - val_accuracy: 0.9350\n",
            "Epoch 152/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9787\n",
            "Epoch 152: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0583 - accuracy: 0.9787 - val_loss: 0.2052 - val_accuracy: 0.9350\n",
            "Epoch 153/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9812\n",
            "Epoch 153: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0587 - accuracy: 0.9812 - val_loss: 0.2004 - val_accuracy: 0.9375\n",
            "Epoch 154/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9841\n",
            "Epoch 154: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.2004 - val_accuracy: 0.9350\n",
            "Epoch 155/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 0.9777\n",
            "Epoch 155: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0560 - accuracy: 0.9775 - val_loss: 0.2069 - val_accuracy: 0.9275\n",
            "Epoch 156/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0521 - accuracy: 0.9831\n",
            "Epoch 156: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 0.1991 - val_accuracy: 0.9375\n",
            "Epoch 157/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9828\n",
            "Epoch 157: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.2010 - val_accuracy: 0.9350\n",
            "Epoch 158/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0487 - accuracy: 0.9876\n",
            "Epoch 158: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0508 - accuracy: 0.9869 - val_loss: 0.2036 - val_accuracy: 0.9350\n",
            "Epoch 159/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0568 - accuracy: 0.9811\n",
            "Epoch 159: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0557 - accuracy: 0.9812 - val_loss: 0.2043 - val_accuracy: 0.9350\n",
            "Epoch 160/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0612 - accuracy: 0.9802\n",
            "Epoch 160: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0607 - accuracy: 0.9806 - val_loss: 0.2058 - val_accuracy: 0.9350\n",
            "Epoch 161/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0518 - accuracy: 0.9850\n",
            "Epoch 161: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.2062 - val_accuracy: 0.9325\n",
            "Epoch 162/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9860\n",
            "Epoch 162: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0553 - accuracy: 0.9856 - val_loss: 0.2035 - val_accuracy: 0.9325\n",
            "Epoch 163/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9790\n",
            "Epoch 163: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 3s 64ms/step - loss: 0.0529 - accuracy: 0.9794 - val_loss: 0.2048 - val_accuracy: 0.9325\n",
            "Epoch 164/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0471 - accuracy: 0.9876\n",
            "Epoch 164: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.0483 - accuracy: 0.9862 - val_loss: 0.2054 - val_accuracy: 0.9350\n",
            "Epoch 165/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9844\n",
            "Epoch 165: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0508 - accuracy: 0.9844 - val_loss: 0.2037 - val_accuracy: 0.9325\n",
            "Epoch 166/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9837\n",
            "Epoch 166: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 0.2046 - val_accuracy: 0.9400\n",
            "Epoch 167/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9850\n",
            "Epoch 167: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0460 - accuracy: 0.9850 - val_loss: 0.2064 - val_accuracy: 0.9375\n",
            "Epoch 168/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9815\n",
            "Epoch 168: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 0.2099 - val_accuracy: 0.9375\n",
            "Epoch 169/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9894\n",
            "Epoch 169: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0389 - accuracy: 0.9894 - val_loss: 0.2085 - val_accuracy: 0.9400\n",
            "Epoch 170/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9815\n",
            "Epoch 170: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0500 - accuracy: 0.9812 - val_loss: 0.2062 - val_accuracy: 0.9375\n",
            "Epoch 171/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0431 - accuracy: 0.9844\n",
            "Epoch 171: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0423 - accuracy: 0.9850 - val_loss: 0.2051 - val_accuracy: 0.9375\n",
            "Epoch 172/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9821\n",
            "Epoch 172: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0465 - accuracy: 0.9819 - val_loss: 0.2027 - val_accuracy: 0.9350\n",
            "Epoch 173/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9831\n",
            "Epoch 173: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0505 - accuracy: 0.9831 - val_loss: 0.2028 - val_accuracy: 0.9375\n",
            "Epoch 174/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9837\n",
            "Epoch 174: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0449 - accuracy: 0.9837 - val_loss: 0.2026 - val_accuracy: 0.9400\n",
            "Epoch 175/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9866\n",
            "Epoch 175: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.2067 - val_accuracy: 0.9375\n",
            "Epoch 176/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9906\n",
            "Epoch 176: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0371 - accuracy: 0.9906 - val_loss: 0.2076 - val_accuracy: 0.9375\n",
            "Epoch 177/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9862\n",
            "Epoch 177: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0441 - accuracy: 0.9862 - val_loss: 0.2059 - val_accuracy: 0.9350\n",
            "Epoch 178/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9885\n",
            "Epoch 178: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.2062 - val_accuracy: 0.9425\n",
            "Epoch 179/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9850\n",
            "Epoch 179: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0463 - accuracy: 0.9850 - val_loss: 0.2021 - val_accuracy: 0.9425\n",
            "Epoch 180/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9847\n",
            "Epoch 180: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 0.2028 - val_accuracy: 0.9450\n",
            "Epoch 181/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9819\n",
            "Epoch 181: val_loss did not improve from 0.19810\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0536 - accuracy: 0.9819 - val_loss: 0.2055 - val_accuracy: 0.9375\n",
            "63/63 [==============================] - 2s 18ms/step - loss: 0.4415 - accuracy: 0.8865\n",
            "Test accuracy, 15 run, after finetuning: 0.8865000009536743\n",
            "Epoch 1/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 2.6065 - accuracy: 0.6059\n",
            "Epoch 1: val_loss improved from inf to 2.11190, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 33s 207ms/step - loss: 2.5905 - accuracy: 0.6050 - val_loss: 2.1119 - val_accuracy: 0.6325\n",
            "Epoch 2/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.6556 - accuracy: 0.6696\n",
            "Epoch 2: val_loss improved from 2.11190 to 1.49249, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 1.6482 - accuracy: 0.6694 - val_loss: 1.4925 - val_accuracy: 0.6925\n",
            "Epoch 3/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 1.3093 - accuracy: 0.6875\n",
            "Epoch 3: val_loss improved from 1.49249 to 1.18043, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.2885 - accuracy: 0.6888 - val_loss: 1.1804 - val_accuracy: 0.7200\n",
            "Epoch 4/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0720 - accuracy: 0.7100\n",
            "Epoch 4: val_loss improved from 1.18043 to 0.99522, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 1.0720 - accuracy: 0.7100 - val_loss: 0.9952 - val_accuracy: 0.7350\n",
            "Epoch 5/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9313 - accuracy: 0.7400\n",
            "Epoch 5: val_loss improved from 0.99522 to 0.87107, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.9313 - accuracy: 0.7400 - val_loss: 0.8711 - val_accuracy: 0.7575\n",
            "Epoch 6/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8430 - accuracy: 0.7519\n",
            "Epoch 6: val_loss improved from 0.87107 to 0.78905, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.8430 - accuracy: 0.7519 - val_loss: 0.7890 - val_accuracy: 0.7650\n",
            "Epoch 7/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.7808 - accuracy: 0.7546\n",
            "Epoch 7: val_loss improved from 0.78905 to 0.73439, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.7756 - accuracy: 0.7563 - val_loss: 0.7344 - val_accuracy: 0.7750\n",
            "Epoch 8/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7505 - accuracy: 0.7606\n",
            "Epoch 8: val_loss improved from 0.73439 to 0.69060, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.7505 - accuracy: 0.7606 - val_loss: 0.6906 - val_accuracy: 0.7750\n",
            "Epoch 9/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6802 - accuracy: 0.7730\n",
            "Epoch 9: val_loss improved from 0.69060 to 0.65384, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.6745 - accuracy: 0.7738 - val_loss: 0.6538 - val_accuracy: 0.8025\n",
            "Epoch 10/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6814 - accuracy: 0.7698\n",
            "Epoch 10: val_loss improved from 0.65384 to 0.63012, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.6801 - accuracy: 0.7700 - val_loss: 0.6301 - val_accuracy: 0.8025\n",
            "Epoch 11/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.6314 - accuracy: 0.7910\n",
            "Epoch 11: val_loss improved from 0.63012 to 0.60156, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.6295 - accuracy: 0.7906 - val_loss: 0.6016 - val_accuracy: 0.8150\n",
            "Epoch 12/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.6057 - accuracy: 0.8053\n",
            "Epoch 12: val_loss improved from 0.60156 to 0.59048, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.6047 - accuracy: 0.8062 - val_loss: 0.5905 - val_accuracy: 0.8075\n",
            "Epoch 13/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6239 - accuracy: 0.7985\n",
            "Epoch 13: val_loss improved from 0.59048 to 0.57302, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.6231 - accuracy: 0.7975 - val_loss: 0.5730 - val_accuracy: 0.8225\n",
            "Epoch 14/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5721 - accuracy: 0.8112\n",
            "Epoch 14: val_loss improved from 0.57302 to 0.55491, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.5699 - accuracy: 0.8112 - val_loss: 0.5549 - val_accuracy: 0.8325\n",
            "Epoch 15/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5721 - accuracy: 0.8132\n",
            "Epoch 15: val_loss improved from 0.55491 to 0.53977, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.5737 - accuracy: 0.8119 - val_loss: 0.5398 - val_accuracy: 0.8350\n",
            "Epoch 16/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5766 - accuracy: 0.8195\n",
            "Epoch 16: val_loss improved from 0.53977 to 0.52866, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.5740 - accuracy: 0.8213 - val_loss: 0.5287 - val_accuracy: 0.8400\n",
            "Epoch 17/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5389 - accuracy: 0.8203\n",
            "Epoch 17: val_loss improved from 0.52866 to 0.51479, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 0.5400 - accuracy: 0.8206 - val_loss: 0.5148 - val_accuracy: 0.8400\n",
            "Epoch 18/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.8375\n",
            "Epoch 18: val_loss improved from 0.51479 to 0.50055, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 8s 155ms/step - loss: 0.5010 - accuracy: 0.8375 - val_loss: 0.5006 - val_accuracy: 0.8450\n",
            "Epoch 19/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4973 - accuracy: 0.8359\n",
            "Epoch 19: val_loss improved from 0.50055 to 0.48194, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.4929 - accuracy: 0.8381 - val_loss: 0.4819 - val_accuracy: 0.8475\n",
            "Epoch 20/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.8304\n",
            "Epoch 20: val_loss improved from 0.48194 to 0.47591, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.4933 - accuracy: 0.8325 - val_loss: 0.4759 - val_accuracy: 0.8475\n",
            "Epoch 21/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4573 - accuracy: 0.8469\n",
            "Epoch 21: val_loss improved from 0.47591 to 0.46309, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.4583 - accuracy: 0.8469 - val_loss: 0.4631 - val_accuracy: 0.8550\n",
            "Epoch 22/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4406 - accuracy: 0.8527\n",
            "Epoch 22: val_loss improved from 0.46309 to 0.45672, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.4406 - accuracy: 0.8519 - val_loss: 0.4567 - val_accuracy: 0.8550\n",
            "Epoch 23/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.8519\n",
            "Epoch 23: val_loss improved from 0.45672 to 0.44981, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.4404 - accuracy: 0.8519 - val_loss: 0.4498 - val_accuracy: 0.8575\n",
            "Epoch 24/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4196 - accuracy: 0.8503\n",
            "Epoch 24: val_loss improved from 0.44981 to 0.44073, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.4163 - accuracy: 0.8512 - val_loss: 0.4407 - val_accuracy: 0.8650\n",
            "Epoch 25/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4437 - accuracy: 0.8450\n",
            "Epoch 25: val_loss improved from 0.44073 to 0.43690, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.4437 - accuracy: 0.8450 - val_loss: 0.4369 - val_accuracy: 0.8650\n",
            "Epoch 26/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4271 - accuracy: 0.8559\n",
            "Epoch 26: val_loss improved from 0.43690 to 0.42599, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.4228 - accuracy: 0.8581 - val_loss: 0.4260 - val_accuracy: 0.8700\n",
            "Epoch 27/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4185 - accuracy: 0.8548\n",
            "Epoch 27: val_loss improved from 0.42599 to 0.41276, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.4238 - accuracy: 0.8550 - val_loss: 0.4128 - val_accuracy: 0.8750\n",
            "Epoch 28/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3817 - accuracy: 0.8744\n",
            "Epoch 28: val_loss improved from 0.41276 to 0.40425, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.3825 - accuracy: 0.8744 - val_loss: 0.4043 - val_accuracy: 0.8775\n",
            "Epoch 29/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3986 - accuracy: 0.8610\n",
            "Epoch 29: val_loss improved from 0.40425 to 0.40404, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.4026 - accuracy: 0.8594 - val_loss: 0.4040 - val_accuracy: 0.8750\n",
            "Epoch 30/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3746 - accuracy: 0.8673\n",
            "Epoch 30: val_loss improved from 0.40404 to 0.39605, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.3807 - accuracy: 0.8662 - val_loss: 0.3961 - val_accuracy: 0.8725\n",
            "Epoch 31/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3858 - accuracy: 0.8661\n",
            "Epoch 31: val_loss improved from 0.39605 to 0.38945, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3852 - accuracy: 0.8669 - val_loss: 0.3894 - val_accuracy: 0.8775\n",
            "Epoch 32/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8699\n",
            "Epoch 32: val_loss improved from 0.38945 to 0.38231, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.3818 - accuracy: 0.8694 - val_loss: 0.3823 - val_accuracy: 0.8825\n",
            "Epoch 33/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3629 - accuracy: 0.8802\n",
            "Epoch 33: val_loss did not improve from 0.38231\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.3625 - accuracy: 0.8819 - val_loss: 0.3827 - val_accuracy: 0.8800\n",
            "Epoch 34/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3595 - accuracy: 0.8744\n",
            "Epoch 34: val_loss improved from 0.38231 to 0.37014, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.3571 - accuracy: 0.8750 - val_loss: 0.3701 - val_accuracy: 0.8850\n",
            "Epoch 35/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.8858\n",
            "Epoch 35: val_loss improved from 0.37014 to 0.36724, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3434 - accuracy: 0.8844 - val_loss: 0.3672 - val_accuracy: 0.8850\n",
            "Epoch 36/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3516 - accuracy: 0.8795\n",
            "Epoch 36: val_loss improved from 0.36724 to 0.36106, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.3554 - accuracy: 0.8781 - val_loss: 0.3611 - val_accuracy: 0.8875\n",
            "Epoch 37/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.8881\n",
            "Epoch 37: val_loss improved from 0.36106 to 0.35312, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.3325 - accuracy: 0.8881 - val_loss: 0.3531 - val_accuracy: 0.8900\n",
            "Epoch 38/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.8858\n",
            "Epoch 38: val_loss improved from 0.35312 to 0.34931, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3273 - accuracy: 0.8856 - val_loss: 0.3493 - val_accuracy: 0.8950\n",
            "Epoch 39/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3206 - accuracy: 0.8948\n",
            "Epoch 39: val_loss improved from 0.34931 to 0.34166, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.3223 - accuracy: 0.8938 - val_loss: 0.3417 - val_accuracy: 0.8925\n",
            "Epoch 40/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3056 - accuracy: 0.8954\n",
            "Epoch 40: val_loss did not improve from 0.34166\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.3087 - accuracy: 0.8950 - val_loss: 0.3477 - val_accuracy: 0.8925\n",
            "Epoch 41/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8931\n",
            "Epoch 41: val_loss did not improve from 0.34166\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.3068 - accuracy: 0.8931 - val_loss: 0.3419 - val_accuracy: 0.8925\n",
            "Epoch 42/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.9011\n",
            "Epoch 42: val_loss improved from 0.34166 to 0.33444, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2872 - accuracy: 0.9025 - val_loss: 0.3344 - val_accuracy: 0.8950\n",
            "Epoch 43/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.8884\n",
            "Epoch 43: val_loss did not improve from 0.33444\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.3235 - accuracy: 0.8888 - val_loss: 0.3348 - val_accuracy: 0.8950\n",
            "Epoch 44/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.9005\n",
            "Epoch 44: val_loss improved from 0.33444 to 0.32874, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2686 - accuracy: 0.9006 - val_loss: 0.3287 - val_accuracy: 0.8975\n",
            "Epoch 45/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3037 - accuracy: 0.8980\n",
            "Epoch 45: val_loss improved from 0.32874 to 0.32259, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.3009 - accuracy: 0.8981 - val_loss: 0.3226 - val_accuracy: 0.9025\n",
            "Epoch 46/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9126\n",
            "Epoch 46: val_loss improved from 0.32259 to 0.31727, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.2664 - accuracy: 0.9119 - val_loss: 0.3173 - val_accuracy: 0.9025\n",
            "Epoch 47/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.9043\n",
            "Epoch 47: val_loss did not improve from 0.31727\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.2763 - accuracy: 0.9050 - val_loss: 0.3183 - val_accuracy: 0.9025\n",
            "Epoch 48/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2503 - accuracy: 0.9165\n",
            "Epoch 48: val_loss did not improve from 0.31727\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.2520 - accuracy: 0.9162 - val_loss: 0.3186 - val_accuracy: 0.9050\n",
            "Epoch 49/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9145\n",
            "Epoch 49: val_loss improved from 0.31727 to 0.31372, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.2508 - accuracy: 0.9150 - val_loss: 0.3137 - val_accuracy: 0.9075\n",
            "Epoch 50/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2695 - accuracy: 0.9018\n",
            "Epoch 50: val_loss improved from 0.31372 to 0.30507, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.2698 - accuracy: 0.9013 - val_loss: 0.3051 - val_accuracy: 0.9125\n",
            "Epoch 51/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.9171\n",
            "Epoch 51: val_loss did not improve from 0.30507\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.2541 - accuracy: 0.9169 - val_loss: 0.3061 - val_accuracy: 0.9125\n",
            "Epoch 52/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2409 - accuracy: 0.9186\n",
            "Epoch 52: val_loss improved from 0.30507 to 0.30240, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2448 - accuracy: 0.9162 - val_loss: 0.3024 - val_accuracy: 0.9125\n",
            "Epoch 53/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2554 - accuracy: 0.9049\n",
            "Epoch 53: val_loss improved from 0.30240 to 0.29960, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.2509 - accuracy: 0.9069 - val_loss: 0.2996 - val_accuracy: 0.9100\n",
            "Epoch 54/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.9190\n",
            "Epoch 54: val_loss improved from 0.29960 to 0.29559, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.2430 - accuracy: 0.9181 - val_loss: 0.2956 - val_accuracy: 0.9175\n",
            "Epoch 55/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9216\n",
            "Epoch 55: val_loss did not improve from 0.29559\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.2315 - accuracy: 0.9206 - val_loss: 0.2972 - val_accuracy: 0.9150\n",
            "Epoch 56/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9260\n",
            "Epoch 56: val_loss improved from 0.29559 to 0.29009, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2162 - accuracy: 0.9262 - val_loss: 0.2901 - val_accuracy: 0.9150\n",
            "Epoch 57/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.9158\n",
            "Epoch 57: val_loss improved from 0.29009 to 0.28993, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.2366 - accuracy: 0.9150 - val_loss: 0.2899 - val_accuracy: 0.9225\n",
            "Epoch 58/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2373 - accuracy: 0.9222\n",
            "Epoch 58: val_loss did not improve from 0.28993\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2352 - accuracy: 0.9231 - val_loss: 0.2942 - val_accuracy: 0.9175\n",
            "Epoch 59/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2300 - accuracy: 0.9203\n",
            "Epoch 59: val_loss did not improve from 0.28993\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.2262 - accuracy: 0.9219 - val_loss: 0.2938 - val_accuracy: 0.9175\n",
            "Epoch 60/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2338 - accuracy: 0.9158\n",
            "Epoch 60: val_loss improved from 0.28993 to 0.28216, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2338 - accuracy: 0.9156 - val_loss: 0.2822 - val_accuracy: 0.9225\n",
            "Epoch 61/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2286 - accuracy: 0.9258\n",
            "Epoch 61: val_loss improved from 0.28216 to 0.28103, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2258 - accuracy: 0.9269 - val_loss: 0.2810 - val_accuracy: 0.9175\n",
            "Epoch 62/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2142 - accuracy: 0.9311\n",
            "Epoch 62: val_loss did not improve from 0.28103\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.2149 - accuracy: 0.9312 - val_loss: 0.2821 - val_accuracy: 0.9200\n",
            "Epoch 63/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9362\n",
            "Epoch 63: val_loss improved from 0.28103 to 0.27650, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.1949 - accuracy: 0.9337 - val_loss: 0.2765 - val_accuracy: 0.9225\n",
            "Epoch 64/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2117 - accuracy: 0.9251\n",
            "Epoch 64: val_loss improved from 0.27650 to 0.27514, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2109 - accuracy: 0.9244 - val_loss: 0.2751 - val_accuracy: 0.9225\n",
            "Epoch 65/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2000 - accuracy: 0.9324\n",
            "Epoch 65: val_loss did not improve from 0.27514\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.2011 - accuracy: 0.9319 - val_loss: 0.2807 - val_accuracy: 0.9250\n",
            "Epoch 66/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9254\n",
            "Epoch 66: val_loss did not improve from 0.27514\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.2035 - accuracy: 0.9250 - val_loss: 0.2769 - val_accuracy: 0.9225\n",
            "Epoch 67/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2009 - accuracy: 0.9343\n",
            "Epoch 67: val_loss improved from 0.27514 to 0.26716, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.2000 - accuracy: 0.9344 - val_loss: 0.2672 - val_accuracy: 0.9200\n",
            "Epoch 68/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9381\n",
            "Epoch 68: val_loss did not improve from 0.26716\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1932 - accuracy: 0.9381 - val_loss: 0.2693 - val_accuracy: 0.9200\n",
            "Epoch 69/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.9337\n",
            "Epoch 69: val_loss did not improve from 0.26716\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1989 - accuracy: 0.9337 - val_loss: 0.2739 - val_accuracy: 0.9200\n",
            "Epoch 70/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1936 - accuracy: 0.9292\n",
            "Epoch 70: val_loss improved from 0.26716 to 0.26487, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1969 - accuracy: 0.9281 - val_loss: 0.2649 - val_accuracy: 0.9225\n",
            "Epoch 71/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1810 - accuracy: 0.9471\n",
            "Epoch 71: val_loss did not improve from 0.26487\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1813 - accuracy: 0.9456 - val_loss: 0.2654 - val_accuracy: 0.9200\n",
            "Epoch 72/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9407\n",
            "Epoch 72: val_loss improved from 0.26487 to 0.26337, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1871 - accuracy: 0.9413 - val_loss: 0.2634 - val_accuracy: 0.9175\n",
            "Epoch 73/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1821 - accuracy: 0.9342\n",
            "Epoch 73: val_loss improved from 0.26337 to 0.26103, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 90ms/step - loss: 0.1803 - accuracy: 0.9344 - val_loss: 0.2610 - val_accuracy: 0.9200\n",
            "Epoch 74/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1626 - accuracy: 0.9538\n",
            "Epoch 74: val_loss improved from 0.26103 to 0.25869, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1602 - accuracy: 0.9544 - val_loss: 0.2587 - val_accuracy: 0.9250\n",
            "Epoch 75/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1837 - accuracy: 0.9401\n",
            "Epoch 75: val_loss improved from 0.25869 to 0.25351, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1839 - accuracy: 0.9388 - val_loss: 0.2535 - val_accuracy: 0.9250\n",
            "Epoch 76/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.9369\n",
            "Epoch 76: val_loss did not improve from 0.25351\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1862 - accuracy: 0.9369 - val_loss: 0.2640 - val_accuracy: 0.9200\n",
            "Epoch 77/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1679 - accuracy: 0.9395\n",
            "Epoch 77: val_loss did not improve from 0.25351\n",
            "50/50 [==============================] - 3s 53ms/step - loss: 0.1694 - accuracy: 0.9394 - val_loss: 0.2573 - val_accuracy: 0.9200\n",
            "Epoch 78/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9452\n",
            "Epoch 78: val_loss improved from 0.25351 to 0.24977, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.1612 - accuracy: 0.9456 - val_loss: 0.2498 - val_accuracy: 0.9250\n",
            "Epoch 79/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9349\n",
            "Epoch 79: val_loss improved from 0.24977 to 0.24947, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1811 - accuracy: 0.9344 - val_loss: 0.2495 - val_accuracy: 0.9200\n",
            "Epoch 80/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9483\n",
            "Epoch 80: val_loss did not improve from 0.24947\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1576 - accuracy: 0.9488 - val_loss: 0.2525 - val_accuracy: 0.9200\n",
            "Epoch 81/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.9534\n",
            "Epoch 81: val_loss improved from 0.24947 to 0.24640, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1543 - accuracy: 0.9531 - val_loss: 0.2464 - val_accuracy: 0.9225\n",
            "Epoch 82/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1666 - accuracy: 0.9490\n",
            "Epoch 82: val_loss did not improve from 0.24640\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1642 - accuracy: 0.9500 - val_loss: 0.2576 - val_accuracy: 0.9225\n",
            "Epoch 83/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9445\n",
            "Epoch 83: val_loss did not improve from 0.24640\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1504 - accuracy: 0.9456 - val_loss: 0.2513 - val_accuracy: 0.9200\n",
            "Epoch 84/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9439\n",
            "Epoch 84: val_loss did not improve from 0.24640\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1632 - accuracy: 0.9438 - val_loss: 0.2502 - val_accuracy: 0.9225\n",
            "Epoch 85/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9471\n",
            "Epoch 85: val_loss did not improve from 0.24640\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1507 - accuracy: 0.9481 - val_loss: 0.2483 - val_accuracy: 0.9200\n",
            "Epoch 86/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9477\n",
            "Epoch 86: val_loss did not improve from 0.24640\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1527 - accuracy: 0.9475 - val_loss: 0.2467 - val_accuracy: 0.9250\n",
            "Epoch 87/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 0.9509\n",
            "Epoch 87: val_loss did not improve from 0.24640\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.1507 - accuracy: 0.9513 - val_loss: 0.2486 - val_accuracy: 0.9200\n",
            "Epoch 88/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9522\n",
            "Epoch 88: val_loss did not improve from 0.24640\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1446 - accuracy: 0.9519 - val_loss: 0.2469 - val_accuracy: 0.9275\n",
            "Epoch 89/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1487 - accuracy: 0.9499\n",
            "Epoch 89: val_loss improved from 0.24640 to 0.24461, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.1514 - accuracy: 0.9488 - val_loss: 0.2446 - val_accuracy: 0.9225\n",
            "Epoch 90/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9471\n",
            "Epoch 90: val_loss did not improve from 0.24461\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1473 - accuracy: 0.9463 - val_loss: 0.2453 - val_accuracy: 0.9225\n",
            "Epoch 91/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9445\n",
            "Epoch 91: val_loss did not improve from 0.24461\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1528 - accuracy: 0.9431 - val_loss: 0.2473 - val_accuracy: 0.9225\n",
            "Epoch 92/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1439 - accuracy: 0.9503\n",
            "Epoch 92: val_loss improved from 0.24461 to 0.23708, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1464 - accuracy: 0.9488 - val_loss: 0.2371 - val_accuracy: 0.9250\n",
            "Epoch 93/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9515\n",
            "Epoch 93: val_loss did not improve from 0.23708\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1327 - accuracy: 0.9519 - val_loss: 0.2380 - val_accuracy: 0.9275\n",
            "Epoch 94/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1421 - accuracy: 0.9544\n",
            "Epoch 94: val_loss did not improve from 0.23708\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.1419 - accuracy: 0.9538 - val_loss: 0.2398 - val_accuracy: 0.9250\n",
            "Epoch 95/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9611\n",
            "Epoch 95: val_loss did not improve from 0.23708\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.1180 - accuracy: 0.9619 - val_loss: 0.2391 - val_accuracy: 0.9275\n",
            "Epoch 96/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9506\n",
            "Epoch 96: val_loss improved from 0.23708 to 0.23591, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.1395 - accuracy: 0.9506 - val_loss: 0.2359 - val_accuracy: 0.9275\n",
            "Epoch 97/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 0.9573\n",
            "Epoch 97: val_loss did not improve from 0.23591\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1228 - accuracy: 0.9581 - val_loss: 0.2421 - val_accuracy: 0.9250\n",
            "Epoch 98/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1119 - accuracy: 0.9656\n",
            "Epoch 98: val_loss did not improve from 0.23591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1123 - accuracy: 0.9650 - val_loss: 0.2384 - val_accuracy: 0.9275\n",
            "Epoch 99/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1232 - accuracy: 0.9590\n",
            "Epoch 99: val_loss did not improve from 0.23591\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1209 - accuracy: 0.9594 - val_loss: 0.2392 - val_accuracy: 0.9250\n",
            "Epoch 100/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1381 - accuracy: 0.9585\n",
            "Epoch 100: val_loss did not improve from 0.23591\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1393 - accuracy: 0.9575 - val_loss: 0.2425 - val_accuracy: 0.9275\n",
            "Epoch 101/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9585\n",
            "Epoch 101: val_loss improved from 0.23591 to 0.23429, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 99ms/step - loss: 0.1211 - accuracy: 0.9581 - val_loss: 0.2343 - val_accuracy: 0.9250\n",
            "Epoch 102/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9644\n",
            "Epoch 102: val_loss did not improve from 0.23429\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1224 - accuracy: 0.9644 - val_loss: 0.2428 - val_accuracy: 0.9275\n",
            "Epoch 103/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1253 - accuracy: 0.9579\n",
            "Epoch 103: val_loss did not improve from 0.23429\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1258 - accuracy: 0.9581 - val_loss: 0.2385 - val_accuracy: 0.9275\n",
            "Epoch 104/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9573\n",
            "Epoch 104: val_loss did not improve from 0.23429\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1204 - accuracy: 0.9581 - val_loss: 0.2390 - val_accuracy: 0.9275\n",
            "Epoch 105/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 0.9579\n",
            "Epoch 105: val_loss improved from 0.23429 to 0.23337, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.1240 - accuracy: 0.9588 - val_loss: 0.2334 - val_accuracy: 0.9300\n",
            "Epoch 106/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1206 - accuracy: 0.9617\n",
            "Epoch 106: val_loss improved from 0.23337 to 0.22881, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1211 - accuracy: 0.9606 - val_loss: 0.2288 - val_accuracy: 0.9300\n",
            "Epoch 107/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9617\n",
            "Epoch 107: val_loss did not improve from 0.22881\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1087 - accuracy: 0.9619 - val_loss: 0.2363 - val_accuracy: 0.9275\n",
            "Epoch 108/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9547\n",
            "Epoch 108: val_loss did not improve from 0.22881\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1248 - accuracy: 0.9550 - val_loss: 0.2419 - val_accuracy: 0.9250\n",
            "Epoch 109/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1073 - accuracy: 0.9629\n",
            "Epoch 109: val_loss did not improve from 0.22881\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1073 - accuracy: 0.9631 - val_loss: 0.2325 - val_accuracy: 0.9275\n",
            "Epoch 110/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1130 - accuracy: 0.9598\n",
            "Epoch 110: val_loss did not improve from 0.22881\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.1121 - accuracy: 0.9600 - val_loss: 0.2360 - val_accuracy: 0.9250\n",
            "Epoch 111/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9585\n",
            "Epoch 111: val_loss improved from 0.22881 to 0.22557, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.1151 - accuracy: 0.9581 - val_loss: 0.2256 - val_accuracy: 0.9325\n",
            "Epoch 112/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9662\n",
            "Epoch 112: val_loss did not improve from 0.22557\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0949 - accuracy: 0.9644 - val_loss: 0.2282 - val_accuracy: 0.9350\n",
            "Epoch 113/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9560\n",
            "Epoch 113: val_loss did not improve from 0.22557\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1122 - accuracy: 0.9569 - val_loss: 0.2268 - val_accuracy: 0.9275\n",
            "Epoch 114/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9611\n",
            "Epoch 114: val_loss did not improve from 0.22557\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1151 - accuracy: 0.9600 - val_loss: 0.2328 - val_accuracy: 0.9275\n",
            "Epoch 115/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 0.9643\n",
            "Epoch 115: val_loss improved from 0.22557 to 0.22459, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1060 - accuracy: 0.9644 - val_loss: 0.2246 - val_accuracy: 0.9325\n",
            "Epoch 116/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1019 - accuracy: 0.9662\n",
            "Epoch 116: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1015 - accuracy: 0.9663 - val_loss: 0.2319 - val_accuracy: 0.9325\n",
            "Epoch 117/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1046 - accuracy: 0.9649\n",
            "Epoch 117: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1039 - accuracy: 0.9650 - val_loss: 0.2345 - val_accuracy: 0.9300\n",
            "Epoch 118/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0860 - accuracy: 0.9751\n",
            "Epoch 118: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0887 - accuracy: 0.9744 - val_loss: 0.2335 - val_accuracy: 0.9275\n",
            "Epoch 119/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0877 - accuracy: 0.9707\n",
            "Epoch 119: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0907 - accuracy: 0.9700 - val_loss: 0.2290 - val_accuracy: 0.9325\n",
            "Epoch 120/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.9681\n",
            "Epoch 120: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 0.1002 - accuracy: 0.9681 - val_loss: 0.2326 - val_accuracy: 0.9300\n",
            "Epoch 121/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9737\n",
            "Epoch 121: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0886 - accuracy: 0.9737 - val_loss: 0.2298 - val_accuracy: 0.9275\n",
            "Epoch 122/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0952 - accuracy: 0.9694\n",
            "Epoch 122: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0959 - accuracy: 0.9694 - val_loss: 0.2311 - val_accuracy: 0.9275\n",
            "Epoch 123/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9694\n",
            "Epoch 123: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0852 - accuracy: 0.9681 - val_loss: 0.2417 - val_accuracy: 0.9275\n",
            "Epoch 124/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9694\n",
            "Epoch 124: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0925 - accuracy: 0.9700 - val_loss: 0.2327 - val_accuracy: 0.9275\n",
            "Epoch 125/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9713\n",
            "Epoch 125: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0902 - accuracy: 0.9706 - val_loss: 0.2255 - val_accuracy: 0.9300\n",
            "Epoch 126/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0942 - accuracy: 0.9688\n",
            "Epoch 126: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0949 - accuracy: 0.9675 - val_loss: 0.2265 - val_accuracy: 0.9300\n",
            "Epoch 127/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 0.9713\n",
            "Epoch 127: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0876 - accuracy: 0.9712 - val_loss: 0.2253 - val_accuracy: 0.9300\n",
            "Epoch 128/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 0.9777\n",
            "Epoch 128: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0860 - accuracy: 0.9769 - val_loss: 0.2294 - val_accuracy: 0.9300\n",
            "Epoch 129/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9806\n",
            "Epoch 129: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0728 - accuracy: 0.9806 - val_loss: 0.2261 - val_accuracy: 0.9275\n",
            "Epoch 130/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0812 - accuracy: 0.9662\n",
            "Epoch 130: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.0816 - accuracy: 0.9669 - val_loss: 0.2303 - val_accuracy: 0.9275\n",
            "Epoch 131/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9662\n",
            "Epoch 131: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0852 - accuracy: 0.9669 - val_loss: 0.2261 - val_accuracy: 0.9275\n",
            "Epoch 132/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 0.9745\n",
            "Epoch 132: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0831 - accuracy: 0.9750 - val_loss: 0.2251 - val_accuracy: 0.9325\n",
            "Epoch 133/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 0.9726\n",
            "Epoch 133: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0827 - accuracy: 0.9725 - val_loss: 0.2256 - val_accuracy: 0.9325\n",
            "Epoch 134/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0869 - accuracy: 0.9681\n",
            "Epoch 134: val_loss did not improve from 0.22459\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0889 - accuracy: 0.9681 - val_loss: 0.2258 - val_accuracy: 0.9325\n",
            "Epoch 135/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0886 - accuracy: 0.9656\n",
            "Epoch 135: val_loss improved from 0.22459 to 0.21977, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 93ms/step - loss: 0.0883 - accuracy: 0.9663 - val_loss: 0.2198 - val_accuracy: 0.9350\n",
            "Epoch 136/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9739\n",
            "Epoch 136: val_loss did not improve from 0.21977\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0728 - accuracy: 0.9744 - val_loss: 0.2226 - val_accuracy: 0.9375\n",
            "Epoch 137/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0866 - accuracy: 0.9707\n",
            "Epoch 137: val_loss did not improve from 0.21977\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0854 - accuracy: 0.9712 - val_loss: 0.2268 - val_accuracy: 0.9325\n",
            "Epoch 138/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9688\n",
            "Epoch 138: val_loss did not improve from 0.21977\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0882 - accuracy: 0.9681 - val_loss: 0.2210 - val_accuracy: 0.9350\n",
            "Epoch 139/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9726\n",
            "Epoch 139: val_loss improved from 0.21977 to 0.21488, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 125ms/step - loss: 0.0792 - accuracy: 0.9731 - val_loss: 0.2149 - val_accuracy: 0.9350\n",
            "Epoch 140/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9764\n",
            "Epoch 140: val_loss did not improve from 0.21488\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0736 - accuracy: 0.9756 - val_loss: 0.2180 - val_accuracy: 0.9325\n",
            "Epoch 141/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0798 - accuracy: 0.9727\n",
            "Epoch 141: val_loss improved from 0.21488 to 0.21372, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.0793 - accuracy: 0.9731 - val_loss: 0.2137 - val_accuracy: 0.9350\n",
            "Epoch 142/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9770\n",
            "Epoch 142: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0716 - accuracy: 0.9775 - val_loss: 0.2225 - val_accuracy: 0.9300\n",
            "Epoch 143/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9770\n",
            "Epoch 143: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0727 - accuracy: 0.9762 - val_loss: 0.2183 - val_accuracy: 0.9375\n",
            "Epoch 144/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9751\n",
            "Epoch 144: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0724 - accuracy: 0.9756 - val_loss: 0.2255 - val_accuracy: 0.9375\n",
            "Epoch 145/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9739\n",
            "Epoch 145: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0733 - accuracy: 0.9737 - val_loss: 0.2163 - val_accuracy: 0.9375\n",
            "Epoch 146/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9758\n",
            "Epoch 146: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0687 - accuracy: 0.9762 - val_loss: 0.2207 - val_accuracy: 0.9350\n",
            "Epoch 147/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0668 - accuracy: 0.9792\n",
            "Epoch 147: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0652 - accuracy: 0.9800 - val_loss: 0.2233 - val_accuracy: 0.9350\n",
            "Epoch 148/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9783\n",
            "Epoch 148: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0712 - accuracy: 0.9775 - val_loss: 0.2193 - val_accuracy: 0.9300\n",
            "Epoch 149/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0660 - accuracy: 0.9785\n",
            "Epoch 149: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0654 - accuracy: 0.9787 - val_loss: 0.2185 - val_accuracy: 0.9325\n",
            "Epoch 150/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0584 - accuracy: 0.9805\n",
            "Epoch 150: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0581 - accuracy: 0.9806 - val_loss: 0.2303 - val_accuracy: 0.9300\n",
            "Epoch 151/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9790\n",
            "Epoch 151: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0706 - accuracy: 0.9787 - val_loss: 0.2277 - val_accuracy: 0.9325\n",
            "Epoch 152/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9764\n",
            "Epoch 152: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0601 - accuracy: 0.9769 - val_loss: 0.2178 - val_accuracy: 0.9350\n",
            "Epoch 153/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9809\n",
            "Epoch 153: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0665 - accuracy: 0.9800 - val_loss: 0.2183 - val_accuracy: 0.9375\n",
            "Epoch 154/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9764\n",
            "Epoch 154: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0649 - accuracy: 0.9769 - val_loss: 0.2296 - val_accuracy: 0.9300\n",
            "Epoch 155/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9775\n",
            "Epoch 155: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0656 - accuracy: 0.9775 - val_loss: 0.2238 - val_accuracy: 0.9325\n",
            "Epoch 156/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9770\n",
            "Epoch 156: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.2272 - val_accuracy: 0.9325\n",
            "Epoch 157/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9796\n",
            "Epoch 157: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0697 - accuracy: 0.9787 - val_loss: 0.2158 - val_accuracy: 0.9375\n",
            "Epoch 158/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0725 - accuracy: 0.9753\n",
            "Epoch 158: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0712 - accuracy: 0.9762 - val_loss: 0.2202 - val_accuracy: 0.9350\n",
            "Epoch 159/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 0.9796\n",
            "Epoch 159: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0613 - accuracy: 0.9800 - val_loss: 0.2217 - val_accuracy: 0.9375\n",
            "Epoch 160/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0531 - accuracy: 0.9785\n",
            "Epoch 160: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0515 - accuracy: 0.9794 - val_loss: 0.2224 - val_accuracy: 0.9400\n",
            "Epoch 161/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9815\n",
            "Epoch 161: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0606 - accuracy: 0.9812 - val_loss: 0.2165 - val_accuracy: 0.9300\n",
            "Epoch 162/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9777\n",
            "Epoch 162: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0653 - accuracy: 0.9775 - val_loss: 0.2195 - val_accuracy: 0.9375\n",
            "Epoch 163/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9770\n",
            "Epoch 163: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0593 - accuracy: 0.9775 - val_loss: 0.2198 - val_accuracy: 0.9375\n",
            "Epoch 164/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0563 - accuracy: 0.9785\n",
            "Epoch 164: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0543 - accuracy: 0.9794 - val_loss: 0.2295 - val_accuracy: 0.9325\n",
            "Epoch 165/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9796\n",
            "Epoch 165: val_loss did not improve from 0.21372\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0612 - accuracy: 0.9800 - val_loss: 0.2203 - val_accuracy: 0.9375\n",
            "Epoch 166/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9841\n",
            "Epoch 166: val_loss improved from 0.21372 to 0.21247, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 107ms/step - loss: 0.0521 - accuracy: 0.9837 - val_loss: 0.2125 - val_accuracy: 0.9425\n",
            "Epoch 167/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9821\n",
            "Epoch 167: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0519 - accuracy: 0.9825 - val_loss: 0.2159 - val_accuracy: 0.9425\n",
            "Epoch 168/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0512 - accuracy: 0.9831\n",
            "Epoch 168: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 0.2192 - val_accuracy: 0.9350\n",
            "Epoch 169/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9787\n",
            "Epoch 169: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0616 - accuracy: 0.9787 - val_loss: 0.2201 - val_accuracy: 0.9350\n",
            "Epoch 170/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9809\n",
            "Epoch 170: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0524 - accuracy: 0.9800 - val_loss: 0.2189 - val_accuracy: 0.9375\n",
            "Epoch 171/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0478 - accuracy: 0.9847\n",
            "Epoch 171: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0474 - accuracy: 0.9850 - val_loss: 0.2178 - val_accuracy: 0.9375\n",
            "Epoch 172/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9796\n",
            "Epoch 172: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0588 - accuracy: 0.9794 - val_loss: 0.2142 - val_accuracy: 0.9400\n",
            "Epoch 173/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9821\n",
            "Epoch 173: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0540 - accuracy: 0.9825 - val_loss: 0.2132 - val_accuracy: 0.9425\n",
            "Epoch 174/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9879\n",
            "Epoch 174: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 0.2163 - val_accuracy: 0.9375\n",
            "Epoch 175/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0510 - accuracy: 0.9818\n",
            "Epoch 175: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0499 - accuracy: 0.9825 - val_loss: 0.2197 - val_accuracy: 0.9375\n",
            "Epoch 176/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9860\n",
            "Epoch 176: val_loss did not improve from 0.21247\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.2165 - val_accuracy: 0.9400\n",
            "Epoch 177/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0536 - accuracy: 0.9805\n",
            "Epoch 177: val_loss improved from 0.21247 to 0.21101, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.0533 - accuracy: 0.9812 - val_loss: 0.2110 - val_accuracy: 0.9375\n",
            "Epoch 178/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9815\n",
            "Epoch 178: val_loss did not improve from 0.21101\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0529 - accuracy: 0.9819 - val_loss: 0.2171 - val_accuracy: 0.9350\n",
            "Epoch 179/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9802\n",
            "Epoch 179: val_loss improved from 0.21101 to 0.20591, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.0549 - accuracy: 0.9806 - val_loss: 0.2059 - val_accuracy: 0.9400\n",
            "Epoch 180/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 0.9821\n",
            "Epoch 180: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0538 - accuracy: 0.9819 - val_loss: 0.2248 - val_accuracy: 0.9375\n",
            "Epoch 181/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0529 - accuracy: 0.9798\n",
            "Epoch 181: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0522 - accuracy: 0.9806 - val_loss: 0.2180 - val_accuracy: 0.9375\n",
            "Epoch 182/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9841\n",
            "Epoch 182: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0455 - accuracy: 0.9837 - val_loss: 0.2194 - val_accuracy: 0.9400\n",
            "Epoch 183/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9841\n",
            "Epoch 183: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0461 - accuracy: 0.9844 - val_loss: 0.2123 - val_accuracy: 0.9425\n",
            "Epoch 184/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9860\n",
            "Epoch 184: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.2095 - val_accuracy: 0.9450\n",
            "Epoch 185/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9777\n",
            "Epoch 185: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0494 - accuracy: 0.9781 - val_loss: 0.2219 - val_accuracy: 0.9350\n",
            "Epoch 186/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9806\n",
            "Epoch 186: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0487 - accuracy: 0.9806 - val_loss: 0.2141 - val_accuracy: 0.9425\n",
            "Epoch 187/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9860\n",
            "Epoch 187: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 0.2121 - val_accuracy: 0.9425\n",
            "Epoch 188/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0502 - accuracy: 0.9779\n",
            "Epoch 188: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0488 - accuracy: 0.9787 - val_loss: 0.2167 - val_accuracy: 0.9375\n",
            "Epoch 189/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0454 - accuracy: 0.9811\n",
            "Epoch 189: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0461 - accuracy: 0.9812 - val_loss: 0.2142 - val_accuracy: 0.9375\n",
            "Epoch 190/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9856\n",
            "Epoch 190: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.2180 - val_accuracy: 0.9375\n",
            "Epoch 191/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0435 - accuracy: 0.9857\n",
            "Epoch 191: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0428 - accuracy: 0.9856 - val_loss: 0.2207 - val_accuracy: 0.9400\n",
            "Epoch 192/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9860\n",
            "Epoch 192: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0421 - accuracy: 0.9862 - val_loss: 0.2119 - val_accuracy: 0.9400\n",
            "Epoch 193/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9911\n",
            "Epoch 193: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0372 - accuracy: 0.9906 - val_loss: 0.2124 - val_accuracy: 0.9425\n",
            "Epoch 194/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0464 - accuracy: 0.9837\n",
            "Epoch 194: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0457 - accuracy: 0.9837 - val_loss: 0.2151 - val_accuracy: 0.9450\n",
            "Epoch 195/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9885\n",
            "Epoch 195: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0393 - accuracy: 0.9887 - val_loss: 0.2085 - val_accuracy: 0.9400\n",
            "Epoch 196/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0475 - accuracy: 0.9837\n",
            "Epoch 196: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 0.2132 - val_accuracy: 0.9450\n",
            "Epoch 197/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9894\n",
            "Epoch 197: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0381 - accuracy: 0.9894 - val_loss: 0.2090 - val_accuracy: 0.9450\n",
            "Epoch 198/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9821\n",
            "Epoch 198: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0442 - accuracy: 0.9825 - val_loss: 0.2209 - val_accuracy: 0.9400\n",
            "Epoch 199/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0483 - accuracy: 0.9824\n",
            "Epoch 199: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.2175 - val_accuracy: 0.9375\n",
            "Epoch 200/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9847\n",
            "Epoch 200: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0442 - accuracy: 0.9850 - val_loss: 0.2163 - val_accuracy: 0.9400\n",
            "Epoch 201/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9872\n",
            "Epoch 201: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0427 - accuracy: 0.9862 - val_loss: 0.2064 - val_accuracy: 0.9450\n",
            "Epoch 202/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.9815\n",
            "Epoch 202: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0452 - accuracy: 0.9819 - val_loss: 0.2072 - val_accuracy: 0.9450\n",
            "Epoch 203/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0404 - accuracy: 0.9876\n",
            "Epoch 203: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.2152 - val_accuracy: 0.9400\n",
            "Epoch 204/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9911\n",
            "Epoch 204: val_loss did not improve from 0.20591\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.2170 - val_accuracy: 0.9375\n",
            "Epoch 205/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0471 - accuracy: 0.9837\n",
            "Epoch 205: val_loss improved from 0.20591 to 0.19978, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 112ms/step - loss: 0.0466 - accuracy: 0.9837 - val_loss: 0.1998 - val_accuracy: 0.9475\n",
            "Epoch 206/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9860\n",
            "Epoch 206: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 0.2114 - val_accuracy: 0.9475\n",
            "Epoch 207/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0361 - accuracy: 0.9863\n",
            "Epoch 207: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0357 - accuracy: 0.9862 - val_loss: 0.2083 - val_accuracy: 0.9450\n",
            "Epoch 208/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9860\n",
            "Epoch 208: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0383 - accuracy: 0.9862 - val_loss: 0.2168 - val_accuracy: 0.9450\n",
            "Epoch 209/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.9872\n",
            "Epoch 209: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.2136 - val_accuracy: 0.9425\n",
            "Epoch 210/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0377 - accuracy: 0.9863\n",
            "Epoch 210: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.2158 - val_accuracy: 0.9425\n",
            "Epoch 211/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9847\n",
            "Epoch 211: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0446 - accuracy: 0.9837 - val_loss: 0.2090 - val_accuracy: 0.9475\n",
            "Epoch 212/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9894\n",
            "Epoch 212: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0377 - accuracy: 0.9894 - val_loss: 0.2137 - val_accuracy: 0.9425\n",
            "Epoch 213/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9911\n",
            "Epoch 213: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.2163 - val_accuracy: 0.9475\n",
            "Epoch 214/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9879\n",
            "Epoch 214: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0369 - accuracy: 0.9881 - val_loss: 0.2097 - val_accuracy: 0.9500\n",
            "Epoch 215/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9912\n",
            "Epoch 215: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.2085 - val_accuracy: 0.9475\n",
            "Epoch 216/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9911\n",
            "Epoch 216: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.2166 - val_accuracy: 0.9475\n",
            "Epoch 217/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9850\n",
            "Epoch 217: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0383 - accuracy: 0.9850 - val_loss: 0.2167 - val_accuracy: 0.9450\n",
            "Epoch 218/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9892\n",
            "Epoch 218: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 0.2260 - val_accuracy: 0.9500\n",
            "Epoch 219/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0272 - accuracy: 0.9922\n",
            "Epoch 219: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0266 - accuracy: 0.9925 - val_loss: 0.2057 - val_accuracy: 0.9525\n",
            "Epoch 220/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9885\n",
            "Epoch 220: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.2122 - val_accuracy: 0.9475\n",
            "Epoch 221/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9904\n",
            "Epoch 221: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0325 - accuracy: 0.9906 - val_loss: 0.2136 - val_accuracy: 0.9475\n",
            "Epoch 222/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9885\n",
            "Epoch 222: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.2128 - val_accuracy: 0.9425\n",
            "Epoch 223/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9898\n",
            "Epoch 223: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.2238 - val_accuracy: 0.9375\n",
            "Epoch 224/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9936\n",
            "Epoch 224: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0273 - accuracy: 0.9937 - val_loss: 0.2133 - val_accuracy: 0.9425\n",
            "Epoch 225/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9862\n",
            "Epoch 225: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.2168 - val_accuracy: 0.9450\n",
            "Epoch 226/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9911\n",
            "Epoch 226: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.2133 - val_accuracy: 0.9450\n",
            "Epoch 227/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0284 - accuracy: 0.9889\n",
            "Epoch 227: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0280 - accuracy: 0.9894 - val_loss: 0.2115 - val_accuracy: 0.9500\n",
            "Epoch 228/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9898\n",
            "Epoch 228: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0266 - accuracy: 0.9900 - val_loss: 0.2152 - val_accuracy: 0.9525\n",
            "Epoch 229/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9904\n",
            "Epoch 229: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.2142 - val_accuracy: 0.9500\n",
            "Epoch 230/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0382 - accuracy: 0.9857\n",
            "Epoch 230: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0376 - accuracy: 0.9862 - val_loss: 0.2192 - val_accuracy: 0.9450\n",
            "Epoch 231/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0317 - accuracy: 0.9889\n",
            "Epoch 231: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.2232 - val_accuracy: 0.9425\n",
            "Epoch 232/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9923\n",
            "Epoch 232: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.2242 - val_accuracy: 0.9425\n",
            "Epoch 233/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9904\n",
            "Epoch 233: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.2153 - val_accuracy: 0.9450\n",
            "Epoch 234/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9917\n",
            "Epoch 234: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.2193 - val_accuracy: 0.9400\n",
            "Epoch 235/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9892\n",
            "Epoch 235: val_loss did not improve from 0.19978\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.2165 - val_accuracy: 0.9500\n",
            "63/63 [==============================] - 2s 16ms/step - loss: 0.4688 - accuracy: 0.8860\n",
            "Test accuracy, 16 run, after finetuning: 0.8859999775886536\n",
            "Epoch 1/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 2.4614 - accuracy: 0.6075\n",
            "Epoch 1: val_loss improved from inf to 1.69085, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 32s 219ms/step - loss: 2.4614 - accuracy: 0.6075 - val_loss: 1.6909 - val_accuracy: 0.6675\n",
            "Epoch 2/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.6423 - accuracy: 0.6650\n",
            "Epoch 2: val_loss improved from 1.69085 to 1.24934, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6423 - accuracy: 0.6650 - val_loss: 1.2493 - val_accuracy: 0.7025\n",
            "Epoch 3/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 1.2720 - accuracy: 0.7025\n",
            "Epoch 3: val_loss improved from 1.24934 to 1.00255, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 1.2696 - accuracy: 0.7019 - val_loss: 1.0025 - val_accuracy: 0.7200\n",
            "Epoch 4/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 1.0593 - accuracy: 0.7122\n",
            "Epoch 4: val_loss improved from 1.00255 to 0.85127, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 1.0667 - accuracy: 0.7113 - val_loss: 0.8513 - val_accuracy: 0.7475\n",
            "Epoch 5/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9358 - accuracy: 0.7344\n",
            "Epoch 5: val_loss improved from 0.85127 to 0.75512, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.9358 - accuracy: 0.7344 - val_loss: 0.7551 - val_accuracy: 0.7525\n",
            "Epoch 6/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8557 - accuracy: 0.7406\n",
            "Epoch 6: val_loss improved from 0.75512 to 0.68879, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.8557 - accuracy: 0.7406 - val_loss: 0.6888 - val_accuracy: 0.7725\n",
            "Epoch 7/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.8128 - accuracy: 0.7493\n",
            "Epoch 7: val_loss improved from 0.68879 to 0.63678, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.8159 - accuracy: 0.7500 - val_loss: 0.6368 - val_accuracy: 0.7900\n",
            "Epoch 8/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7416 - accuracy: 0.7710\n",
            "Epoch 8: val_loss improved from 0.63678 to 0.60680, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.7407 - accuracy: 0.7719 - val_loss: 0.6068 - val_accuracy: 0.7975\n",
            "Epoch 9/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7052 - accuracy: 0.7738\n",
            "Epoch 9: val_loss improved from 0.60680 to 0.58340, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.7052 - accuracy: 0.7738 - val_loss: 0.5834 - val_accuracy: 0.8050\n",
            "Epoch 10/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6503 - accuracy: 0.7934\n",
            "Epoch 10: val_loss improved from 0.58340 to 0.55819, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.6498 - accuracy: 0.7931 - val_loss: 0.5582 - val_accuracy: 0.8150\n",
            "Epoch 11/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6624 - accuracy: 0.7915\n",
            "Epoch 11: val_loss improved from 0.55819 to 0.53498, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.6631 - accuracy: 0.7900 - val_loss: 0.5350 - val_accuracy: 0.8175\n",
            "Epoch 12/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.8031\n",
            "Epoch 12: val_loss improved from 0.53498 to 0.51388, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.6129 - accuracy: 0.8031 - val_loss: 0.5139 - val_accuracy: 0.8300\n",
            "Epoch 13/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6049 - accuracy: 0.8006\n",
            "Epoch 13: val_loss improved from 0.51388 to 0.49595, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.6049 - accuracy: 0.8006 - val_loss: 0.4959 - val_accuracy: 0.8275\n",
            "Epoch 14/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5979 - accuracy: 0.7988\n",
            "Epoch 14: val_loss improved from 0.49595 to 0.48160, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.5979 - accuracy: 0.7981 - val_loss: 0.4816 - val_accuracy: 0.8350\n",
            "Epoch 15/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5541 - accuracy: 0.8190\n",
            "Epoch 15: val_loss improved from 0.48160 to 0.46829, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.5522 - accuracy: 0.8181 - val_loss: 0.4683 - val_accuracy: 0.8400\n",
            "Epoch 16/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.8144\n",
            "Epoch 16: val_loss improved from 0.46829 to 0.45334, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.5581 - accuracy: 0.8163 - val_loss: 0.4533 - val_accuracy: 0.8500\n",
            "Epoch 17/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5167 - accuracy: 0.8189\n",
            "Epoch 17: val_loss improved from 0.45334 to 0.44212, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.5169 - accuracy: 0.8200 - val_loss: 0.4421 - val_accuracy: 0.8525\n",
            "Epoch 18/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5173 - accuracy: 0.8242\n",
            "Epoch 18: val_loss improved from 0.44212 to 0.43122, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 93ms/step - loss: 0.5177 - accuracy: 0.8219 - val_loss: 0.4312 - val_accuracy: 0.8650\n",
            "Epoch 19/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.8374\n",
            "Epoch 19: val_loss improved from 0.43122 to 0.42160, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.4875 - accuracy: 0.8356 - val_loss: 0.4216 - val_accuracy: 0.8725\n",
            "Epoch 20/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4968 - accuracy: 0.8310\n",
            "Epoch 20: val_loss improved from 0.42160 to 0.41257, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.5026 - accuracy: 0.8294 - val_loss: 0.4126 - val_accuracy: 0.8725\n",
            "Epoch 21/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4672 - accuracy: 0.8386\n",
            "Epoch 21: val_loss improved from 0.41257 to 0.40367, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.4646 - accuracy: 0.8381 - val_loss: 0.4037 - val_accuracy: 0.8725\n",
            "Epoch 22/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.8546\n",
            "Epoch 22: val_loss improved from 0.40367 to 0.39245, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.4522 - accuracy: 0.8525 - val_loss: 0.3925 - val_accuracy: 0.8775\n",
            "Epoch 23/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4283 - accuracy: 0.8561\n",
            "Epoch 23: val_loss improved from 0.39245 to 0.38895, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.4329 - accuracy: 0.8569 - val_loss: 0.3890 - val_accuracy: 0.8775\n",
            "Epoch 24/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4442 - accuracy: 0.8568\n",
            "Epoch 24: val_loss improved from 0.38895 to 0.37797, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.4361 - accuracy: 0.8594 - val_loss: 0.3780 - val_accuracy: 0.8850\n",
            "Epoch 25/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4427 - accuracy: 0.8509\n",
            "Epoch 25: val_loss improved from 0.37797 to 0.36959, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.4435 - accuracy: 0.8525 - val_loss: 0.3696 - val_accuracy: 0.8875\n",
            "Epoch 26/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.8525\n",
            "Epoch 26: val_loss improved from 0.36959 to 0.36253, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.4444 - accuracy: 0.8525 - val_loss: 0.3625 - val_accuracy: 0.8875\n",
            "Epoch 27/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4032 - accuracy: 0.8705\n",
            "Epoch 27: val_loss improved from 0.36253 to 0.35584, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.4039 - accuracy: 0.8700 - val_loss: 0.3558 - val_accuracy: 0.8900\n",
            "Epoch 28/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3958 - accuracy: 0.8661\n",
            "Epoch 28: val_loss improved from 0.35584 to 0.34747, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.3974 - accuracy: 0.8644 - val_loss: 0.3475 - val_accuracy: 0.8950\n",
            "Epoch 29/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3845 - accuracy: 0.8686\n",
            "Epoch 29: val_loss improved from 0.34747 to 0.33969, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.3825 - accuracy: 0.8694 - val_loss: 0.3397 - val_accuracy: 0.9000\n",
            "Epoch 30/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3741 - accuracy: 0.8763\n",
            "Epoch 30: val_loss improved from 0.33969 to 0.33497, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3772 - accuracy: 0.8756 - val_loss: 0.3350 - val_accuracy: 0.9025\n",
            "Epoch 31/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.8769\n",
            "Epoch 31: val_loss improved from 0.33497 to 0.32836, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.3632 - accuracy: 0.8769 - val_loss: 0.3284 - val_accuracy: 0.9050\n",
            "Epoch 32/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3546 - accuracy: 0.8750\n",
            "Epoch 32: val_loss improved from 0.32836 to 0.32219, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.3563 - accuracy: 0.8737 - val_loss: 0.3222 - val_accuracy: 0.9050\n",
            "Epoch 33/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.8839\n",
            "Epoch 33: val_loss improved from 0.32219 to 0.31816, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.3483 - accuracy: 0.8831 - val_loss: 0.3182 - val_accuracy: 0.9050\n",
            "Epoch 34/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3658 - accuracy: 0.8744\n",
            "Epoch 34: val_loss improved from 0.31816 to 0.31188, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.3642 - accuracy: 0.8731 - val_loss: 0.3119 - val_accuracy: 0.9075\n",
            "Epoch 35/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.8788\n",
            "Epoch 35: val_loss improved from 0.31188 to 0.30697, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.3493 - accuracy: 0.8794 - val_loss: 0.3070 - val_accuracy: 0.9050\n",
            "Epoch 36/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3482 - accuracy: 0.8833\n",
            "Epoch 36: val_loss improved from 0.30697 to 0.30366, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 102ms/step - loss: 0.3463 - accuracy: 0.8838 - val_loss: 0.3037 - val_accuracy: 0.9075\n",
            "Epoch 37/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3141 - accuracy: 0.8878\n",
            "Epoch 37: val_loss improved from 0.30366 to 0.29794, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3132 - accuracy: 0.8881 - val_loss: 0.2979 - val_accuracy: 0.9075\n",
            "Epoch 38/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3262 - accuracy: 0.8893\n",
            "Epoch 38: val_loss improved from 0.29794 to 0.29506, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3294 - accuracy: 0.8875 - val_loss: 0.2951 - val_accuracy: 0.9100\n",
            "Epoch 39/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.9005\n",
            "Epoch 39: val_loss improved from 0.29506 to 0.29120, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.2976 - accuracy: 0.9013 - val_loss: 0.2912 - val_accuracy: 0.9150\n",
            "Epoch 40/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3242 - accuracy: 0.8925\n",
            "Epoch 40: val_loss improved from 0.29120 to 0.28925, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3242 - accuracy: 0.8925 - val_loss: 0.2893 - val_accuracy: 0.9100\n",
            "Epoch 41/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3024 - accuracy: 0.8945\n",
            "Epoch 41: val_loss improved from 0.28925 to 0.28404, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3017 - accuracy: 0.8938 - val_loss: 0.2840 - val_accuracy: 0.9100\n",
            "Epoch 42/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3040 - accuracy: 0.8986\n",
            "Epoch 42: val_loss improved from 0.28404 to 0.27926, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.3053 - accuracy: 0.8981 - val_loss: 0.2793 - val_accuracy: 0.9150\n",
            "Epoch 43/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.8992\n",
            "Epoch 43: val_loss improved from 0.27926 to 0.27418, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.2818 - accuracy: 0.9006 - val_loss: 0.2742 - val_accuracy: 0.9125\n",
            "Epoch 44/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2755 - accuracy: 0.9011\n",
            "Epoch 44: val_loss improved from 0.27418 to 0.27258, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2809 - accuracy: 0.8988 - val_loss: 0.2726 - val_accuracy: 0.9200\n",
            "Epoch 45/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2758 - accuracy: 0.9037\n",
            "Epoch 45: val_loss improved from 0.27258 to 0.26831, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2746 - accuracy: 0.9038 - val_loss: 0.2683 - val_accuracy: 0.9200\n",
            "Epoch 46/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.9037\n",
            "Epoch 46: val_loss improved from 0.26831 to 0.26374, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.2781 - accuracy: 0.9031 - val_loss: 0.2637 - val_accuracy: 0.9225\n",
            "Epoch 47/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2804 - accuracy: 0.9075\n",
            "Epoch 47: val_loss improved from 0.26374 to 0.26010, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2768 - accuracy: 0.9087 - val_loss: 0.2601 - val_accuracy: 0.9250\n",
            "Epoch 48/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2726 - accuracy: 0.9095\n",
            "Epoch 48: val_loss improved from 0.26010 to 0.25794, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2750 - accuracy: 0.9069 - val_loss: 0.2579 - val_accuracy: 0.9250\n",
            "Epoch 49/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9184\n",
            "Epoch 49: val_loss improved from 0.25794 to 0.25603, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.2492 - accuracy: 0.9175 - val_loss: 0.2560 - val_accuracy: 0.9275\n",
            "Epoch 50/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2500 - accuracy: 0.9126\n",
            "Epoch 50: val_loss improved from 0.25603 to 0.25441, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.2515 - accuracy: 0.9112 - val_loss: 0.2544 - val_accuracy: 0.9300\n",
            "Epoch 51/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2475 - accuracy: 0.9184\n",
            "Epoch 51: val_loss improved from 0.25441 to 0.25129, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2454 - accuracy: 0.9194 - val_loss: 0.2513 - val_accuracy: 0.9225\n",
            "Epoch 52/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.9152\n",
            "Epoch 52: val_loss improved from 0.25129 to 0.24676, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.2443 - accuracy: 0.9162 - val_loss: 0.2468 - val_accuracy: 0.9325\n",
            "Epoch 53/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2471 - accuracy: 0.9128\n",
            "Epoch 53: val_loss improved from 0.24676 to 0.24228, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.2434 - accuracy: 0.9144 - val_loss: 0.2423 - val_accuracy: 0.9350\n",
            "Epoch 54/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2458 - accuracy: 0.9089\n",
            "Epoch 54: val_loss did not improve from 0.24228\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.2479 - accuracy: 0.9094 - val_loss: 0.2428 - val_accuracy: 0.9325\n",
            "Epoch 55/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2184 - accuracy: 0.9180\n",
            "Epoch 55: val_loss improved from 0.24228 to 0.23912, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2286 - accuracy: 0.9144 - val_loss: 0.2391 - val_accuracy: 0.9350\n",
            "Epoch 56/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2493 - accuracy: 0.9152\n",
            "Epoch 56: val_loss improved from 0.23912 to 0.23392, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2485 - accuracy: 0.9156 - val_loss: 0.2339 - val_accuracy: 0.9350\n",
            "Epoch 57/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9216\n",
            "Epoch 57: val_loss improved from 0.23392 to 0.23314, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.2429 - accuracy: 0.9219 - val_loss: 0.2331 - val_accuracy: 0.9375\n",
            "Epoch 58/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2240 - accuracy: 0.9193\n",
            "Epoch 58: val_loss did not improve from 0.23314\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.2250 - accuracy: 0.9181 - val_loss: 0.2343 - val_accuracy: 0.9350\n",
            "Epoch 59/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2292 - accuracy: 0.9184\n",
            "Epoch 59: val_loss improved from 0.23314 to 0.23266, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2294 - accuracy: 0.9175 - val_loss: 0.2327 - val_accuracy: 0.9375\n",
            "Epoch 60/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2160 - accuracy: 0.9219\n",
            "Epoch 60: val_loss improved from 0.23266 to 0.22853, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2123 - accuracy: 0.9231 - val_loss: 0.2285 - val_accuracy: 0.9350\n",
            "Epoch 61/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2109 - accuracy: 0.9238\n",
            "Epoch 61: val_loss improved from 0.22853 to 0.22586, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.2094 - accuracy: 0.9250 - val_loss: 0.2259 - val_accuracy: 0.9375\n",
            "Epoch 62/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2208 - accuracy: 0.9186\n",
            "Epoch 62: val_loss improved from 0.22586 to 0.22420, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2262 - accuracy: 0.9181 - val_loss: 0.2242 - val_accuracy: 0.9400\n",
            "Epoch 63/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9247\n",
            "Epoch 63: val_loss improved from 0.22420 to 0.22274, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2210 - accuracy: 0.9244 - val_loss: 0.2227 - val_accuracy: 0.9400\n",
            "Epoch 64/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9318\n",
            "Epoch 64: val_loss improved from 0.22274 to 0.22234, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 96ms/step - loss: 0.1973 - accuracy: 0.9319 - val_loss: 0.2223 - val_accuracy: 0.9400\n",
            "Epoch 65/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9177\n",
            "Epoch 65: val_loss improved from 0.22234 to 0.22092, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.2150 - accuracy: 0.9181 - val_loss: 0.2209 - val_accuracy: 0.9425\n",
            "Epoch 66/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9287\n",
            "Epoch 66: val_loss improved from 0.22092 to 0.21830, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2064 - accuracy: 0.9287 - val_loss: 0.2183 - val_accuracy: 0.9400\n",
            "Epoch 67/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9331\n",
            "Epoch 67: val_loss did not improve from 0.21830\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.2034 - accuracy: 0.9331 - val_loss: 0.2195 - val_accuracy: 0.9400\n",
            "Epoch 68/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.9292\n",
            "Epoch 68: val_loss improved from 0.21830 to 0.21584, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.2112 - accuracy: 0.9294 - val_loss: 0.2158 - val_accuracy: 0.9425\n",
            "Epoch 69/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1904 - accuracy: 0.9310\n",
            "Epoch 69: val_loss improved from 0.21584 to 0.21433, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.1861 - accuracy: 0.9331 - val_loss: 0.2143 - val_accuracy: 0.9400\n",
            "Epoch 70/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1974 - accuracy: 0.9286\n",
            "Epoch 70: val_loss improved from 0.21433 to 0.21427, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1961 - accuracy: 0.9287 - val_loss: 0.2143 - val_accuracy: 0.9425\n",
            "Epoch 71/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.9256\n",
            "Epoch 71: val_loss improved from 0.21427 to 0.21292, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1991 - accuracy: 0.9256 - val_loss: 0.2129 - val_accuracy: 0.9475\n",
            "Epoch 72/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1737 - accuracy: 0.9447\n",
            "Epoch 72: val_loss did not improve from 0.21292\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1790 - accuracy: 0.9419 - val_loss: 0.2133 - val_accuracy: 0.9375\n",
            "Epoch 73/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1577 - accuracy: 0.9477\n",
            "Epoch 73: val_loss improved from 0.21292 to 0.20961, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1576 - accuracy: 0.9475 - val_loss: 0.2096 - val_accuracy: 0.9425\n",
            "Epoch 74/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1724 - accuracy: 0.9381\n",
            "Epoch 74: val_loss did not improve from 0.20961\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1727 - accuracy: 0.9381 - val_loss: 0.2112 - val_accuracy: 0.9400\n",
            "Epoch 75/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1878 - accuracy: 0.9434\n",
            "Epoch 75: val_loss improved from 0.20961 to 0.20518, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1851 - accuracy: 0.9438 - val_loss: 0.2052 - val_accuracy: 0.9450\n",
            "Epoch 76/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9458\n",
            "Epoch 76: val_loss improved from 0.20518 to 0.20512, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.1655 - accuracy: 0.9463 - val_loss: 0.2051 - val_accuracy: 0.9450\n",
            "Epoch 77/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9369\n",
            "Epoch 77: val_loss improved from 0.20512 to 0.20400, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.1694 - accuracy: 0.9369 - val_loss: 0.2040 - val_accuracy: 0.9475\n",
            "Epoch 78/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1595 - accuracy: 0.9388\n",
            "Epoch 78: val_loss improved from 0.20400 to 0.20250, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1587 - accuracy: 0.9394 - val_loss: 0.2025 - val_accuracy: 0.9450\n",
            "Epoch 79/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1573 - accuracy: 0.9440\n",
            "Epoch 79: val_loss improved from 0.20250 to 0.20151, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1544 - accuracy: 0.9463 - val_loss: 0.2015 - val_accuracy: 0.9475\n",
            "Epoch 80/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1657 - accuracy: 0.9452\n",
            "Epoch 80: val_loss did not improve from 0.20151\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1639 - accuracy: 0.9456 - val_loss: 0.2022 - val_accuracy: 0.9500\n",
            "Epoch 81/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9452\n",
            "Epoch 81: val_loss improved from 0.20151 to 0.20141, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.1661 - accuracy: 0.9444 - val_loss: 0.2014 - val_accuracy: 0.9500\n",
            "Epoch 82/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1694 - accuracy: 0.9375\n",
            "Epoch 82: val_loss improved from 0.20141 to 0.19699, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1673 - accuracy: 0.9388 - val_loss: 0.1970 - val_accuracy: 0.9475\n",
            "Epoch 83/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1543 - accuracy: 0.9401\n",
            "Epoch 83: val_loss improved from 0.19699 to 0.19624, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1563 - accuracy: 0.9406 - val_loss: 0.1962 - val_accuracy: 0.9475\n",
            "Epoch 84/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1378 - accuracy: 0.9560\n",
            "Epoch 84: val_loss improved from 0.19624 to 0.19483, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1408 - accuracy: 0.9550 - val_loss: 0.1948 - val_accuracy: 0.9500\n",
            "Epoch 85/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.9579\n",
            "Epoch 85: val_loss did not improve from 0.19483\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.1341 - accuracy: 0.9575 - val_loss: 0.1967 - val_accuracy: 0.9450\n",
            "Epoch 86/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9401\n",
            "Epoch 86: val_loss did not improve from 0.19483\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1490 - accuracy: 0.9388 - val_loss: 0.1948 - val_accuracy: 0.9500\n",
            "Epoch 87/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1299 - accuracy: 0.9577\n",
            "Epoch 87: val_loss did not improve from 0.19483\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1335 - accuracy: 0.9556 - val_loss: 0.1958 - val_accuracy: 0.9525\n",
            "Epoch 88/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1336 - accuracy: 0.9583\n",
            "Epoch 88: val_loss improved from 0.19483 to 0.19442, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1361 - accuracy: 0.9569 - val_loss: 0.1944 - val_accuracy: 0.9450\n",
            "Epoch 89/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.9547\n",
            "Epoch 89: val_loss improved from 0.19442 to 0.19424, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1295 - accuracy: 0.9544 - val_loss: 0.1942 - val_accuracy: 0.9450\n",
            "Epoch 90/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9554\n",
            "Epoch 90: val_loss improved from 0.19424 to 0.19021, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1310 - accuracy: 0.9544 - val_loss: 0.1902 - val_accuracy: 0.9500\n",
            "Epoch 91/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9506\n",
            "Epoch 91: val_loss did not improve from 0.19021\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1425 - accuracy: 0.9506 - val_loss: 0.1911 - val_accuracy: 0.9475\n",
            "Epoch 92/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1370 - accuracy: 0.9566\n",
            "Epoch 92: val_loss did not improve from 0.19021\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1388 - accuracy: 0.9550 - val_loss: 0.1940 - val_accuracy: 0.9450\n",
            "Epoch 93/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.9579\n",
            "Epoch 93: val_loss did not improve from 0.19021\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1217 - accuracy: 0.9575 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 94/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9512\n",
            "Epoch 94: val_loss did not improve from 0.19021\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.1347 - accuracy: 0.9513 - val_loss: 0.1934 - val_accuracy: 0.9475\n",
            "Epoch 95/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9490\n",
            "Epoch 95: val_loss did not improve from 0.19021\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.1404 - accuracy: 0.9488 - val_loss: 0.1941 - val_accuracy: 0.9450\n",
            "Epoch 96/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 0.9528\n",
            "Epoch 96: val_loss improved from 0.19021 to 0.18937, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 107ms/step - loss: 0.1336 - accuracy: 0.9531 - val_loss: 0.1894 - val_accuracy: 0.9475\n",
            "Epoch 97/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1208 - accuracy: 0.9544\n",
            "Epoch 97: val_loss improved from 0.18937 to 0.18770, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.1215 - accuracy: 0.9544 - val_loss: 0.1877 - val_accuracy: 0.9500\n",
            "Epoch 98/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9573\n",
            "Epoch 98: val_loss improved from 0.18770 to 0.18682, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.1302 - accuracy: 0.9569 - val_loss: 0.1868 - val_accuracy: 0.9500\n",
            "Epoch 99/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1132 - accuracy: 0.9609\n",
            "Epoch 99: val_loss did not improve from 0.18682\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.1137 - accuracy: 0.9594 - val_loss: 0.1906 - val_accuracy: 0.9500\n",
            "Epoch 100/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.9619\n",
            "Epoch 100: val_loss did not improve from 0.18682\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.1171 - accuracy: 0.9619 - val_loss: 0.1895 - val_accuracy: 0.9475\n",
            "Epoch 101/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9569\n",
            "Epoch 101: val_loss did not improve from 0.18682\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.1216 - accuracy: 0.9569 - val_loss: 0.1881 - val_accuracy: 0.9475\n",
            "Epoch 102/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1237 - accuracy: 0.9547\n",
            "Epoch 102: val_loss did not improve from 0.18682\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.1226 - accuracy: 0.9556 - val_loss: 0.1869 - val_accuracy: 0.9525\n",
            "Epoch 103/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1056 - accuracy: 0.9656\n",
            "Epoch 103: val_loss improved from 0.18682 to 0.18546, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 117ms/step - loss: 0.1069 - accuracy: 0.9644 - val_loss: 0.1855 - val_accuracy: 0.9475\n",
            "Epoch 104/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9550\n",
            "Epoch 104: val_loss improved from 0.18546 to 0.18392, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 112ms/step - loss: 0.1218 - accuracy: 0.9550 - val_loss: 0.1839 - val_accuracy: 0.9550\n",
            "Epoch 105/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 0.9719\n",
            "Epoch 105: val_loss improved from 0.18392 to 0.18308, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.1028 - accuracy: 0.9719 - val_loss: 0.1831 - val_accuracy: 0.9550\n",
            "Epoch 106/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9587\n",
            "Epoch 106: val_loss improved from 0.18308 to 0.17994, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 110ms/step - loss: 0.1152 - accuracy: 0.9588 - val_loss: 0.1799 - val_accuracy: 0.9500\n",
            "Epoch 107/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9613\n",
            "Epoch 107: val_loss did not improve from 0.17994\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.1121 - accuracy: 0.9613 - val_loss: 0.1806 - val_accuracy: 0.9525\n",
            "Epoch 108/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9638\n",
            "Epoch 108: val_loss did not improve from 0.17994\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.1028 - accuracy: 0.9638 - val_loss: 0.1816 - val_accuracy: 0.9475\n",
            "Epoch 109/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1166 - accuracy: 0.9624\n",
            "Epoch 109: val_loss did not improve from 0.17994\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.1206 - accuracy: 0.9606 - val_loss: 0.1824 - val_accuracy: 0.9550\n",
            "Epoch 110/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9636\n",
            "Epoch 110: val_loss did not improve from 0.17994\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.1102 - accuracy: 0.9631 - val_loss: 0.1828 - val_accuracy: 0.9450\n",
            "Epoch 111/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1051 - accuracy: 0.9605\n",
            "Epoch 111: val_loss did not improve from 0.17994\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.1040 - accuracy: 0.9606 - val_loss: 0.1838 - val_accuracy: 0.9500\n",
            "Epoch 112/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9644\n",
            "Epoch 112: val_loss did not improve from 0.17994\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.1042 - accuracy: 0.9644 - val_loss: 0.1806 - val_accuracy: 0.9500\n",
            "Epoch 113/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9606\n",
            "Epoch 113: val_loss improved from 0.17994 to 0.17634, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.1038 - accuracy: 0.9606 - val_loss: 0.1763 - val_accuracy: 0.9575\n",
            "Epoch 114/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1199 - accuracy: 0.9611\n",
            "Epoch 114: val_loss did not improve from 0.17634\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.1192 - accuracy: 0.9613 - val_loss: 0.1792 - val_accuracy: 0.9575\n",
            "Epoch 115/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9644\n",
            "Epoch 115: val_loss did not improve from 0.17634\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.1028 - accuracy: 0.9644 - val_loss: 0.1821 - val_accuracy: 0.9450\n",
            "Epoch 116/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0980 - accuracy: 0.9655\n",
            "Epoch 116: val_loss did not improve from 0.17634\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0996 - accuracy: 0.9644 - val_loss: 0.1801 - val_accuracy: 0.9525\n",
            "Epoch 117/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0885 - accuracy: 0.9719\n",
            "Epoch 117: val_loss did not improve from 0.17634\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0891 - accuracy: 0.9712 - val_loss: 0.1788 - val_accuracy: 0.9550\n",
            "Epoch 118/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 0.9566\n",
            "Epoch 118: val_loss did not improve from 0.17634\n",
            "50/50 [==============================] - 3s 50ms/step - loss: 0.1056 - accuracy: 0.9575 - val_loss: 0.1780 - val_accuracy: 0.9550\n",
            "Epoch 119/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9656\n",
            "Epoch 119: val_loss did not improve from 0.17634\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 0.1011 - accuracy: 0.9656 - val_loss: 0.1784 - val_accuracy: 0.9550\n",
            "Epoch 120/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9719\n",
            "Epoch 120: val_loss improved from 0.17634 to 0.17353, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 125ms/step - loss: 0.0831 - accuracy: 0.9712 - val_loss: 0.1735 - val_accuracy: 0.9575\n",
            "Epoch 121/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0847 - accuracy: 0.9714\n",
            "Epoch 121: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0836 - accuracy: 0.9712 - val_loss: 0.1772 - val_accuracy: 0.9500\n",
            "Epoch 122/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.9750\n",
            "Epoch 122: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0849 - accuracy: 0.9750 - val_loss: 0.1788 - val_accuracy: 0.9525\n",
            "Epoch 123/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9706\n",
            "Epoch 123: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 3s 62ms/step - loss: 0.0858 - accuracy: 0.9706 - val_loss: 0.1774 - val_accuracy: 0.9550\n",
            "Epoch 124/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9631\n",
            "Epoch 124: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0959 - accuracy: 0.9631 - val_loss: 0.1829 - val_accuracy: 0.9500\n",
            "Epoch 125/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0791 - accuracy: 0.9719\n",
            "Epoch 125: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 3s 66ms/step - loss: 0.0792 - accuracy: 0.9719 - val_loss: 0.1787 - val_accuracy: 0.9550\n",
            "Epoch 126/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.9636\n",
            "Epoch 126: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 0.0997 - accuracy: 0.9644 - val_loss: 0.1749 - val_accuracy: 0.9575\n",
            "Epoch 127/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9688\n",
            "Epoch 127: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.0843 - accuracy: 0.9688 - val_loss: 0.1773 - val_accuracy: 0.9550\n",
            "Epoch 128/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0894 - accuracy: 0.9688\n",
            "Epoch 128: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0910 - accuracy: 0.9688 - val_loss: 0.1741 - val_accuracy: 0.9575\n",
            "Epoch 129/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9669\n",
            "Epoch 129: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0798 - accuracy: 0.9669 - val_loss: 0.1740 - val_accuracy: 0.9575\n",
            "Epoch 130/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9732\n",
            "Epoch 130: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0792 - accuracy: 0.9737 - val_loss: 0.1755 - val_accuracy: 0.9575\n",
            "Epoch 131/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9781\n",
            "Epoch 131: val_loss did not improve from 0.17353\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0735 - accuracy: 0.9781 - val_loss: 0.1764 - val_accuracy: 0.9550\n",
            "Epoch 132/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9737\n",
            "Epoch 132: val_loss improved from 0.17353 to 0.17315, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 0.0817 - accuracy: 0.9737 - val_loss: 0.1732 - val_accuracy: 0.9575\n",
            "Epoch 133/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9600\n",
            "Epoch 133: val_loss improved from 0.17315 to 0.17155, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.0955 - accuracy: 0.9600 - val_loss: 0.1716 - val_accuracy: 0.9550\n",
            "Epoch 134/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0924 - accuracy: 0.9681\n",
            "Epoch 134: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0919 - accuracy: 0.9681 - val_loss: 0.1783 - val_accuracy: 0.9575\n",
            "Epoch 135/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0707 - accuracy: 0.9746\n",
            "Epoch 135: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0699 - accuracy: 0.9750 - val_loss: 0.1762 - val_accuracy: 0.9575\n",
            "Epoch 136/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9706\n",
            "Epoch 136: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0807 - accuracy: 0.9706 - val_loss: 0.1727 - val_accuracy: 0.9550\n",
            "Epoch 137/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9770\n",
            "Epoch 137: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 3s 60ms/step - loss: 0.0729 - accuracy: 0.9775 - val_loss: 0.1732 - val_accuracy: 0.9575\n",
            "Epoch 138/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9796\n",
            "Epoch 138: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0700 - accuracy: 0.9794 - val_loss: 0.1750 - val_accuracy: 0.9500\n",
            "Epoch 139/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9756\n",
            "Epoch 139: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 0.1716 - val_accuracy: 0.9600\n",
            "Epoch 140/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0682 - accuracy: 0.9740\n",
            "Epoch 140: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0678 - accuracy: 0.9737 - val_loss: 0.1766 - val_accuracy: 0.9575\n",
            "Epoch 141/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9731\n",
            "Epoch 141: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0742 - accuracy: 0.9731 - val_loss: 0.1719 - val_accuracy: 0.9600\n",
            "Epoch 142/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9744\n",
            "Epoch 142: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0719 - accuracy: 0.9744 - val_loss: 0.1749 - val_accuracy: 0.9575\n",
            "Epoch 143/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0697 - accuracy: 0.9746\n",
            "Epoch 143: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0688 - accuracy: 0.9750 - val_loss: 0.1744 - val_accuracy: 0.9575\n",
            "Epoch 144/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9726\n",
            "Epoch 144: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0664 - accuracy: 0.9725 - val_loss: 0.1763 - val_accuracy: 0.9575\n",
            "Epoch 145/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9758\n",
            "Epoch 145: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0695 - accuracy: 0.9762 - val_loss: 0.1729 - val_accuracy: 0.9575\n",
            "Epoch 146/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 0.9828\n",
            "Epoch 146: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.1745 - val_accuracy: 0.9575\n",
            "Epoch 147/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9806\n",
            "Epoch 147: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0596 - accuracy: 0.9806 - val_loss: 0.1763 - val_accuracy: 0.9575\n",
            "Epoch 148/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9769\n",
            "Epoch 148: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0709 - accuracy: 0.9769 - val_loss: 0.1729 - val_accuracy: 0.9575\n",
            "Epoch 149/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9762\n",
            "Epoch 149: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0726 - accuracy: 0.9762 - val_loss: 0.1723 - val_accuracy: 0.9550\n",
            "Epoch 150/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9802\n",
            "Epoch 150: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0633 - accuracy: 0.9806 - val_loss: 0.1724 - val_accuracy: 0.9575\n",
            "Epoch 151/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0792 - accuracy: 0.9688\n",
            "Epoch 151: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0777 - accuracy: 0.9694 - val_loss: 0.1768 - val_accuracy: 0.9525\n",
            "Epoch 152/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0619 - accuracy: 0.9798\n",
            "Epoch 152: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.1770 - val_accuracy: 0.9575\n",
            "Epoch 153/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9812\n",
            "Epoch 153: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0626 - accuracy: 0.9812 - val_loss: 0.1787 - val_accuracy: 0.9525\n",
            "Epoch 154/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9719\n",
            "Epoch 154: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0650 - accuracy: 0.9725 - val_loss: 0.1742 - val_accuracy: 0.9575\n",
            "Epoch 155/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9783\n",
            "Epoch 155: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0615 - accuracy: 0.9787 - val_loss: 0.1754 - val_accuracy: 0.9575\n",
            "Epoch 156/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9831\n",
            "Epoch 156: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 0.1736 - val_accuracy: 0.9575\n",
            "Epoch 157/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9769\n",
            "Epoch 157: val_loss did not improve from 0.17155\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0703 - accuracy: 0.9769 - val_loss: 0.1724 - val_accuracy: 0.9575\n",
            "Epoch 158/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9850\n",
            "Epoch 158: val_loss improved from 0.17155 to 0.16966, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 111ms/step - loss: 0.0539 - accuracy: 0.9850 - val_loss: 0.1697 - val_accuracy: 0.9575\n",
            "Epoch 159/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0657 - accuracy: 0.9753\n",
            "Epoch 159: val_loss did not improve from 0.16966\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0656 - accuracy: 0.9750 - val_loss: 0.1705 - val_accuracy: 0.9600\n",
            "Epoch 160/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9831\n",
            "Epoch 160: val_loss did not improve from 0.16966\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0529 - accuracy: 0.9831 - val_loss: 0.1714 - val_accuracy: 0.9600\n",
            "Epoch 161/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0500 - accuracy: 0.9824\n",
            "Epoch 161: val_loss did not improve from 0.16966\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0518 - accuracy: 0.9825 - val_loss: 0.1758 - val_accuracy: 0.9550\n",
            "Epoch 162/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0454 - accuracy: 0.9850\n",
            "Epoch 162: val_loss did not improve from 0.16966\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.1703 - val_accuracy: 0.9600\n",
            "Epoch 163/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0536 - accuracy: 0.9811\n",
            "Epoch 163: val_loss did not improve from 0.16966\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0544 - accuracy: 0.9806 - val_loss: 0.1699 - val_accuracy: 0.9600\n",
            "Epoch 164/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9745\n",
            "Epoch 164: val_loss improved from 0.16966 to 0.16753, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 95ms/step - loss: 0.0615 - accuracy: 0.9744 - val_loss: 0.1675 - val_accuracy: 0.9600\n",
            "Epoch 165/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9812\n",
            "Epoch 165: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.1716 - val_accuracy: 0.9600\n",
            "Epoch 166/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9777\n",
            "Epoch 166: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0741 - accuracy: 0.9775 - val_loss: 0.1701 - val_accuracy: 0.9600\n",
            "Epoch 167/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9821\n",
            "Epoch 167: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0514 - accuracy: 0.9812 - val_loss: 0.1680 - val_accuracy: 0.9575\n",
            "Epoch 168/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9879\n",
            "Epoch 168: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0471 - accuracy: 0.9875 - val_loss: 0.1678 - val_accuracy: 0.9575\n",
            "Epoch 169/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9841\n",
            "Epoch 169: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: 0.1681 - val_accuracy: 0.9600\n",
            "Epoch 170/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9844\n",
            "Epoch 170: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.1706 - val_accuracy: 0.9600\n",
            "Epoch 171/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9775\n",
            "Epoch 171: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0614 - accuracy: 0.9775 - val_loss: 0.1745 - val_accuracy: 0.9575\n",
            "Epoch 172/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0514 - accuracy: 0.9857\n",
            "Epoch 172: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0526 - accuracy: 0.9856 - val_loss: 0.1746 - val_accuracy: 0.9575\n",
            "Epoch 173/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9850\n",
            "Epoch 173: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0473 - accuracy: 0.9850 - val_loss: 0.1754 - val_accuracy: 0.9600\n",
            "Epoch 174/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9825\n",
            "Epoch 174: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0526 - accuracy: 0.9825 - val_loss: 0.1748 - val_accuracy: 0.9600\n",
            "Epoch 175/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0439 - accuracy: 0.9883\n",
            "Epoch 175: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0440 - accuracy: 0.9887 - val_loss: 0.1759 - val_accuracy: 0.9575\n",
            "Epoch 176/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9834\n",
            "Epoch 176: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0515 - accuracy: 0.9831 - val_loss: 0.1733 - val_accuracy: 0.9600\n",
            "Epoch 177/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0403 - accuracy: 0.9883\n",
            "Epoch 177: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.1710 - val_accuracy: 0.9575\n",
            "Epoch 178/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0544 - accuracy: 0.9818\n",
            "Epoch 178: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0532 - accuracy: 0.9825 - val_loss: 0.1710 - val_accuracy: 0.9575\n",
            "Epoch 179/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9834\n",
            "Epoch 179: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0526 - accuracy: 0.9837 - val_loss: 0.1705 - val_accuracy: 0.9600\n",
            "Epoch 180/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9862\n",
            "Epoch 180: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.1705 - val_accuracy: 0.9600\n",
            "Epoch 181/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9837\n",
            "Epoch 181: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0459 - accuracy: 0.9837 - val_loss: 0.1715 - val_accuracy: 0.9575\n",
            "Epoch 182/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0507 - accuracy: 0.9824\n",
            "Epoch 182: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0529 - accuracy: 0.9825 - val_loss: 0.1686 - val_accuracy: 0.9600\n",
            "Epoch 183/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0454 - accuracy: 0.9889\n",
            "Epoch 183: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 3s 68ms/step - loss: 0.0467 - accuracy: 0.9881 - val_loss: 0.1707 - val_accuracy: 0.9575\n",
            "Epoch 184/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9875\n",
            "Epoch 184: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 0.1728 - val_accuracy: 0.9600\n",
            "Epoch 185/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9866\n",
            "Epoch 185: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0479 - accuracy: 0.9869 - val_loss: 0.1696 - val_accuracy: 0.9625\n",
            "Epoch 186/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0424 - accuracy: 0.9883\n",
            "Epoch 186: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0463 - accuracy: 0.9869 - val_loss: 0.1703 - val_accuracy: 0.9600\n",
            "Epoch 187/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9837\n",
            "Epoch 187: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0428 - accuracy: 0.9837 - val_loss: 0.1729 - val_accuracy: 0.9600\n",
            "Epoch 188/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0491 - accuracy: 0.9857\n",
            "Epoch 188: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.1689 - val_accuracy: 0.9625\n",
            "Epoch 189/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9879\n",
            "Epoch 189: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.1708 - val_accuracy: 0.9575\n",
            "Epoch 190/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9879\n",
            "Epoch 190: val_loss did not improve from 0.16753\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.1694 - val_accuracy: 0.9625\n",
            "Epoch 191/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9887\n",
            "Epoch 191: val_loss improved from 0.16753 to 0.16676, saving model to /content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 106ms/step - loss: 0.0388 - accuracy: 0.9887 - val_loss: 0.1668 - val_accuracy: 0.9625\n",
            "Epoch 192/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9853\n",
            "Epoch 192: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 0.1720 - val_accuracy: 0.9600\n",
            "Epoch 193/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9847\n",
            "Epoch 193: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0397 - accuracy: 0.9850 - val_loss: 0.1728 - val_accuracy: 0.9600\n",
            "Epoch 194/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9815\n",
            "Epoch 194: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0513 - accuracy: 0.9819 - val_loss: 0.1715 - val_accuracy: 0.9575\n",
            "Epoch 195/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9875\n",
            "Epoch 195: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 3s 59ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 0.1732 - val_accuracy: 0.9550\n",
            "Epoch 196/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.9828\n",
            "Epoch 196: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.1729 - val_accuracy: 0.9600\n",
            "Epoch 197/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9898\n",
            "Epoch 197: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0372 - accuracy: 0.9900 - val_loss: 0.1742 - val_accuracy: 0.9550\n",
            "Epoch 198/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9847\n",
            "Epoch 198: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0455 - accuracy: 0.9844 - val_loss: 0.1744 - val_accuracy: 0.9625\n",
            "Epoch 199/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9869\n",
            "Epoch 199: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0407 - accuracy: 0.9869 - val_loss: 0.1706 - val_accuracy: 0.9625\n",
            "Epoch 200/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9866\n",
            "Epoch 200: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.1715 - val_accuracy: 0.9625\n",
            "Epoch 201/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0355 - accuracy: 0.9883\n",
            "Epoch 201: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 0.1817 - val_accuracy: 0.9525\n",
            "Epoch 202/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9856\n",
            "Epoch 202: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0393 - accuracy: 0.9856 - val_loss: 0.1795 - val_accuracy: 0.9575\n",
            "Epoch 203/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9919\n",
            "Epoch 203: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0319 - accuracy: 0.9919 - val_loss: 0.1752 - val_accuracy: 0.9600\n",
            "Epoch 204/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9881\n",
            "Epoch 204: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.1767 - val_accuracy: 0.9575\n",
            "Epoch 205/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9850\n",
            "Epoch 205: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0435 - accuracy: 0.9850 - val_loss: 0.1735 - val_accuracy: 0.9575\n",
            "Epoch 206/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0351 - accuracy: 0.9857\n",
            "Epoch 206: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0343 - accuracy: 0.9862 - val_loss: 0.1766 - val_accuracy: 0.9575\n",
            "Epoch 207/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9831\n",
            "Epoch 207: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 0.1727 - val_accuracy: 0.9575\n",
            "Epoch 208/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9885\n",
            "Epoch 208: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0333 - accuracy: 0.9887 - val_loss: 0.1773 - val_accuracy: 0.9600\n",
            "Epoch 209/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9906\n",
            "Epoch 209: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0365 - accuracy: 0.9906 - val_loss: 0.1779 - val_accuracy: 0.9600\n",
            "Epoch 210/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9900\n",
            "Epoch 210: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 3s 55ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 0.1797 - val_accuracy: 0.9575\n",
            "Epoch 211/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9892\n",
            "Epoch 211: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.1771 - val_accuracy: 0.9575\n",
            "Epoch 212/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9911\n",
            "Epoch 212: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.1754 - val_accuracy: 0.9600\n",
            "Epoch 213/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9911\n",
            "Epoch 213: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.1801 - val_accuracy: 0.9575\n",
            "Epoch 214/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9900\n",
            "Epoch 214: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.1787 - val_accuracy: 0.9600\n",
            "Epoch 215/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9885\n",
            "Epoch 215: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.1763 - val_accuracy: 0.9625\n",
            "Epoch 216/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9923\n",
            "Epoch 216: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0300 - accuracy: 0.9925 - val_loss: 0.1729 - val_accuracy: 0.9625\n",
            "Epoch 217/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9869\n",
            "Epoch 217: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0348 - accuracy: 0.9869 - val_loss: 0.1697 - val_accuracy: 0.9575\n",
            "Epoch 218/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0268 - accuracy: 0.9909\n",
            "Epoch 218: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.1731 - val_accuracy: 0.9625\n",
            "Epoch 219/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9881\n",
            "Epoch 219: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0332 - accuracy: 0.9881 - val_loss: 0.1783 - val_accuracy: 0.9625\n",
            "Epoch 220/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9917\n",
            "Epoch 220: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 0.1802 - val_accuracy: 0.9575\n",
            "Epoch 221/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0300 - accuracy: 0.9922\n",
            "Epoch 221: val_loss did not improve from 0.16676\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0297 - accuracy: 0.9925 - val_loss: 0.1746 - val_accuracy: 0.9575\n",
            "63/63 [==============================] - 2s 20ms/step - loss: 0.4635 - accuracy: 0.8830\n",
            "Test accuracy, 17 run, after finetuning: 0.8830000162124634\n",
            "Epoch 1/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 2.5308 - accuracy: 0.6126\n",
            "Epoch 1: val_loss improved from inf to 1.70283, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 34s 231ms/step - loss: 2.5059 - accuracy: 0.6106 - val_loss: 1.7028 - val_accuracy: 0.6800\n",
            "Epoch 2/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.6904 - accuracy: 0.6781\n",
            "Epoch 2: val_loss improved from 1.70283 to 1.26938, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 97ms/step - loss: 1.6904 - accuracy: 0.6781 - val_loss: 1.2694 - val_accuracy: 0.7150\n",
            "Epoch 3/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.3464 - accuracy: 0.7000\n",
            "Epoch 3: val_loss improved from 1.26938 to 1.02349, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 103ms/step - loss: 1.3464 - accuracy: 0.7000 - val_loss: 1.0235 - val_accuracy: 0.7375\n",
            "Epoch 4/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0942 - accuracy: 0.7262\n",
            "Epoch 4: val_loss improved from 1.02349 to 0.86490, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 1.0942 - accuracy: 0.7262 - val_loss: 0.8649 - val_accuracy: 0.7625\n",
            "Epoch 5/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9612 - accuracy: 0.7398\n",
            "Epoch 5: val_loss improved from 0.86490 to 0.76134, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.9660 - accuracy: 0.7387 - val_loss: 0.7613 - val_accuracy: 0.7750\n",
            "Epoch 6/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8173 - accuracy: 0.7761\n",
            "Epoch 6: val_loss improved from 0.76134 to 0.68817, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 97ms/step - loss: 0.8275 - accuracy: 0.7731 - val_loss: 0.6882 - val_accuracy: 0.7950\n",
            "Epoch 7/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7824 - accuracy: 0.7731\n",
            "Epoch 7: val_loss improved from 0.68817 to 0.64172, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.7824 - accuracy: 0.7731 - val_loss: 0.6417 - val_accuracy: 0.8025\n",
            "Epoch 8/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7117 - accuracy: 0.7781\n",
            "Epoch 8: val_loss improved from 0.64172 to 0.60144, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.7117 - accuracy: 0.7781 - val_loss: 0.6014 - val_accuracy: 0.8175\n",
            "Epoch 9/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.6993 - accuracy: 0.7793\n",
            "Epoch 9: val_loss improved from 0.60144 to 0.56737, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 97ms/step - loss: 0.6905 - accuracy: 0.7812 - val_loss: 0.5674 - val_accuracy: 0.8300\n",
            "Epoch 10/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.7806\n",
            "Epoch 10: val_loss improved from 0.56737 to 0.54502, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.6695 - accuracy: 0.7806 - val_loss: 0.5450 - val_accuracy: 0.8275\n",
            "Epoch 11/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.7812\n",
            "Epoch 11: val_loss improved from 0.54502 to 0.52331, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.6798 - accuracy: 0.7812 - val_loss: 0.5233 - val_accuracy: 0.8325\n",
            "Epoch 12/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6216 - accuracy: 0.7953\n",
            "Epoch 12: val_loss improved from 0.52331 to 0.50573, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.6203 - accuracy: 0.7950 - val_loss: 0.5057 - val_accuracy: 0.8375\n",
            "Epoch 13/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5852 - accuracy: 0.8106\n",
            "Epoch 13: val_loss improved from 0.50573 to 0.48836, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.5801 - accuracy: 0.8119 - val_loss: 0.4884 - val_accuracy: 0.8450\n",
            "Epoch 14/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.8119\n",
            "Epoch 14: val_loss improved from 0.48836 to 0.47132, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.5918 - accuracy: 0.8119 - val_loss: 0.4713 - val_accuracy: 0.8425\n",
            "Epoch 15/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5501 - accuracy: 0.8169\n",
            "Epoch 15: val_loss improved from 0.47132 to 0.46173, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.5501 - accuracy: 0.8169 - val_loss: 0.4617 - val_accuracy: 0.8450\n",
            "Epoch 16/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.8156\n",
            "Epoch 16: val_loss improved from 0.46173 to 0.45085, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.5203 - accuracy: 0.8156 - val_loss: 0.4509 - val_accuracy: 0.8500\n",
            "Epoch 17/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5156 - accuracy: 0.8210\n",
            "Epoch 17: val_loss improved from 0.45085 to 0.43597, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.5075 - accuracy: 0.8250 - val_loss: 0.4360 - val_accuracy: 0.8575\n",
            "Epoch 18/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5127 - accuracy: 0.8216\n",
            "Epoch 18: val_loss improved from 0.43597 to 0.42642, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.5111 - accuracy: 0.8219 - val_loss: 0.4264 - val_accuracy: 0.8575\n",
            "Epoch 19/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.8462\n",
            "Epoch 19: val_loss improved from 0.42642 to 0.41552, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.4745 - accuracy: 0.8462 - val_loss: 0.4155 - val_accuracy: 0.8625\n",
            "Epoch 20/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.8361\n",
            "Epoch 20: val_loss improved from 0.41552 to 0.40636, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.4642 - accuracy: 0.8375 - val_loss: 0.4064 - val_accuracy: 0.8675\n",
            "Epoch 21/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4540 - accuracy: 0.8438\n",
            "Epoch 21: val_loss improved from 0.40636 to 0.39829, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.4558 - accuracy: 0.8413 - val_loss: 0.3983 - val_accuracy: 0.8650\n",
            "Epoch 22/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4332 - accuracy: 0.8469\n",
            "Epoch 22: val_loss improved from 0.39829 to 0.38848, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 96ms/step - loss: 0.4323 - accuracy: 0.8469 - val_loss: 0.3885 - val_accuracy: 0.8675\n",
            "Epoch 23/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4246 - accuracy: 0.8540\n",
            "Epoch 23: val_loss improved from 0.38848 to 0.38186, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.4226 - accuracy: 0.8531 - val_loss: 0.3819 - val_accuracy: 0.8725\n",
            "Epoch 24/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4309 - accuracy: 0.8667\n",
            "Epoch 24: val_loss improved from 0.38186 to 0.37091, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.4309 - accuracy: 0.8656 - val_loss: 0.3709 - val_accuracy: 0.8750\n",
            "Epoch 25/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4167 - accuracy: 0.8561\n",
            "Epoch 25: val_loss improved from 0.37091 to 0.36344, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.4162 - accuracy: 0.8556 - val_loss: 0.3634 - val_accuracy: 0.8825\n",
            "Epoch 26/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3864 - accuracy: 0.8680\n",
            "Epoch 26: val_loss improved from 0.36344 to 0.35823, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.3868 - accuracy: 0.8675 - val_loss: 0.3582 - val_accuracy: 0.8825\n",
            "Epoch 27/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3901 - accuracy: 0.8620\n",
            "Epoch 27: val_loss improved from 0.35823 to 0.35242, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3885 - accuracy: 0.8631 - val_loss: 0.3524 - val_accuracy: 0.8875\n",
            "Epoch 28/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8801\n",
            "Epoch 28: val_loss improved from 0.35242 to 0.34386, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3800 - accuracy: 0.8806 - val_loss: 0.3439 - val_accuracy: 0.8850\n",
            "Epoch 29/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.8769\n",
            "Epoch 29: val_loss improved from 0.34386 to 0.33861, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.3669 - accuracy: 0.8769 - val_loss: 0.3386 - val_accuracy: 0.8925\n",
            "Epoch 30/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3715 - accuracy: 0.8763\n",
            "Epoch 30: val_loss improved from 0.33861 to 0.33477, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.3684 - accuracy: 0.8775 - val_loss: 0.3348 - val_accuracy: 0.8975\n",
            "Epoch 31/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3731 - accuracy: 0.8711\n",
            "Epoch 31: val_loss improved from 0.33477 to 0.32878, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3683 - accuracy: 0.8719 - val_loss: 0.3288 - val_accuracy: 0.8950\n",
            "Epoch 32/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3494 - accuracy: 0.8822\n",
            "Epoch 32: val_loss improved from 0.32878 to 0.32556, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3489 - accuracy: 0.8813 - val_loss: 0.3256 - val_accuracy: 0.8950\n",
            "Epoch 33/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3335 - accuracy: 0.8822\n",
            "Epoch 33: val_loss improved from 0.32556 to 0.31827, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.3332 - accuracy: 0.8800 - val_loss: 0.3183 - val_accuracy: 0.8975\n",
            "Epoch 34/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3299 - accuracy: 0.8906\n",
            "Epoch 34: val_loss improved from 0.31827 to 0.31246, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.3261 - accuracy: 0.8913 - val_loss: 0.3125 - val_accuracy: 0.9000\n",
            "Epoch 35/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8820\n",
            "Epoch 35: val_loss improved from 0.31246 to 0.30913, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.3291 - accuracy: 0.8819 - val_loss: 0.3091 - val_accuracy: 0.9050\n",
            "Epoch 36/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.8909\n",
            "Epoch 36: val_loss improved from 0.30913 to 0.30050, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.3238 - accuracy: 0.8919 - val_loss: 0.3005 - val_accuracy: 0.9025\n",
            "Epoch 37/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.8956\n",
            "Epoch 37: val_loss improved from 0.30050 to 0.29894, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.3059 - accuracy: 0.8956 - val_loss: 0.2989 - val_accuracy: 0.9100\n",
            "Epoch 38/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3107 - accuracy: 0.9010\n",
            "Epoch 38: val_loss improved from 0.29894 to 0.29725, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.3142 - accuracy: 0.8988 - val_loss: 0.2972 - val_accuracy: 0.9125\n",
            "Epoch 39/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.8967\n",
            "Epoch 39: val_loss improved from 0.29725 to 0.29295, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.3074 - accuracy: 0.8969 - val_loss: 0.2930 - val_accuracy: 0.9125\n",
            "Epoch 40/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3077 - accuracy: 0.8945\n",
            "Epoch 40: val_loss improved from 0.29295 to 0.28844, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.3021 - accuracy: 0.8969 - val_loss: 0.2884 - val_accuracy: 0.9125\n",
            "Epoch 41/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2873 - accuracy: 0.8991\n",
            "Epoch 41: val_loss improved from 0.28844 to 0.28551, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2874 - accuracy: 0.9006 - val_loss: 0.2855 - val_accuracy: 0.9150\n",
            "Epoch 42/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2852 - accuracy: 0.8929\n",
            "Epoch 42: val_loss improved from 0.28551 to 0.28226, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2917 - accuracy: 0.8894 - val_loss: 0.2823 - val_accuracy: 0.9150\n",
            "Epoch 43/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9050\n",
            "Epoch 43: val_loss improved from 0.28226 to 0.28026, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.2694 - accuracy: 0.9050 - val_loss: 0.2803 - val_accuracy: 0.9175\n",
            "Epoch 44/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8986\n",
            "Epoch 44: val_loss improved from 0.28026 to 0.27273, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.2922 - accuracy: 0.8969 - val_loss: 0.2727 - val_accuracy: 0.9150\n",
            "Epoch 45/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9063\n",
            "Epoch 45: val_loss improved from 0.27273 to 0.27078, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2667 - accuracy: 0.9075 - val_loss: 0.2708 - val_accuracy: 0.9125\n",
            "Epoch 46/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9037\n",
            "Epoch 46: val_loss improved from 0.27078 to 0.26679, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.2591 - accuracy: 0.9044 - val_loss: 0.2668 - val_accuracy: 0.9150\n",
            "Epoch 47/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.9056\n",
            "Epoch 47: val_loss improved from 0.26679 to 0.26525, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.2657 - accuracy: 0.9050 - val_loss: 0.2652 - val_accuracy: 0.9200\n",
            "Epoch 48/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2647 - accuracy: 0.9102\n",
            "Epoch 48: val_loss improved from 0.26525 to 0.26316, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2612 - accuracy: 0.9125 - val_loss: 0.2632 - val_accuracy: 0.9150\n",
            "Epoch 49/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2349 - accuracy: 0.9199\n",
            "Epoch 49: val_loss improved from 0.26316 to 0.25850, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2424 - accuracy: 0.9194 - val_loss: 0.2585 - val_accuracy: 0.9175\n",
            "Epoch 50/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2432 - accuracy: 0.9228\n",
            "Epoch 50: val_loss improved from 0.25850 to 0.25518, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.2434 - accuracy: 0.9225 - val_loss: 0.2552 - val_accuracy: 0.9175\n",
            "Epoch 51/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.9107\n",
            "Epoch 51: val_loss improved from 0.25518 to 0.25433, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.2481 - accuracy: 0.9112 - val_loss: 0.2543 - val_accuracy: 0.9200\n",
            "Epoch 52/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2397 - accuracy: 0.9199\n",
            "Epoch 52: val_loss improved from 0.25433 to 0.25212, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2377 - accuracy: 0.9200 - val_loss: 0.2521 - val_accuracy: 0.9200\n",
            "Epoch 53/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2452 - accuracy: 0.9190\n",
            "Epoch 53: val_loss improved from 0.25212 to 0.24928, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.2462 - accuracy: 0.9175 - val_loss: 0.2493 - val_accuracy: 0.9225\n",
            "Epoch 54/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2465 - accuracy: 0.9139\n",
            "Epoch 54: val_loss improved from 0.24928 to 0.24495, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.2448 - accuracy: 0.9144 - val_loss: 0.2450 - val_accuracy: 0.9175\n",
            "Epoch 55/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2212 - accuracy: 0.9258\n",
            "Epoch 55: val_loss improved from 0.24495 to 0.24319, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2232 - accuracy: 0.9256 - val_loss: 0.2432 - val_accuracy: 0.9200\n",
            "Epoch 56/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2098 - accuracy: 0.9303\n",
            "Epoch 56: val_loss improved from 0.24319 to 0.23958, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2120 - accuracy: 0.9294 - val_loss: 0.2396 - val_accuracy: 0.9250\n",
            "Epoch 57/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2418 - accuracy: 0.9094\n",
            "Epoch 57: val_loss improved from 0.23958 to 0.23866, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 93ms/step - loss: 0.2387 - accuracy: 0.9106 - val_loss: 0.2387 - val_accuracy: 0.9250\n",
            "Epoch 58/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2062 - accuracy: 0.9238\n",
            "Epoch 58: val_loss improved from 0.23866 to 0.23729, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.2130 - accuracy: 0.9212 - val_loss: 0.2373 - val_accuracy: 0.9300\n",
            "Epoch 59/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9387\n",
            "Epoch 59: val_loss improved from 0.23729 to 0.23519, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1962 - accuracy: 0.9388 - val_loss: 0.2352 - val_accuracy: 0.9225\n",
            "Epoch 60/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.9388\n",
            "Epoch 60: val_loss improved from 0.23519 to 0.23050, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1985 - accuracy: 0.9400 - val_loss: 0.2305 - val_accuracy: 0.9225\n",
            "Epoch 61/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2110 - accuracy: 0.9225\n",
            "Epoch 61: val_loss improved from 0.23050 to 0.22779, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.2113 - accuracy: 0.9219 - val_loss: 0.2278 - val_accuracy: 0.9275\n",
            "Epoch 62/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1916 - accuracy: 0.9336\n",
            "Epoch 62: val_loss improved from 0.22779 to 0.22561, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1937 - accuracy: 0.9337 - val_loss: 0.2256 - val_accuracy: 0.9275\n",
            "Epoch 63/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9311\n",
            "Epoch 63: val_loss did not improve from 0.22561\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.2124 - accuracy: 0.9319 - val_loss: 0.2272 - val_accuracy: 0.9275\n",
            "Epoch 64/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1919 - accuracy: 0.9362\n",
            "Epoch 64: val_loss improved from 0.22561 to 0.22286, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1918 - accuracy: 0.9356 - val_loss: 0.2229 - val_accuracy: 0.9250\n",
            "Epoch 65/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1891 - accuracy: 0.9290\n",
            "Epoch 65: val_loss improved from 0.22286 to 0.22159, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.1930 - accuracy: 0.9281 - val_loss: 0.2216 - val_accuracy: 0.9300\n",
            "Epoch 66/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.9350\n",
            "Epoch 66: val_loss improved from 0.22159 to 0.21951, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1929 - accuracy: 0.9350 - val_loss: 0.2195 - val_accuracy: 0.9300\n",
            "Epoch 67/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9381\n",
            "Epoch 67: val_loss did not improve from 0.21951\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1939 - accuracy: 0.9388 - val_loss: 0.2221 - val_accuracy: 0.9300\n",
            "Epoch 68/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.9362\n",
            "Epoch 68: val_loss improved from 0.21951 to 0.21769, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1912 - accuracy: 0.9356 - val_loss: 0.2177 - val_accuracy: 0.9300\n",
            "Epoch 69/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 0.9452\n",
            "Epoch 69: val_loss improved from 0.21769 to 0.21735, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.1724 - accuracy: 0.9456 - val_loss: 0.2173 - val_accuracy: 0.9300\n",
            "Epoch 70/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9444\n",
            "Epoch 70: val_loss improved from 0.21735 to 0.21458, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1782 - accuracy: 0.9444 - val_loss: 0.2146 - val_accuracy: 0.9300\n",
            "Epoch 71/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1853 - accuracy: 0.9349\n",
            "Epoch 71: val_loss improved from 0.21458 to 0.21186, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1872 - accuracy: 0.9350 - val_loss: 0.2119 - val_accuracy: 0.9300\n",
            "Epoch 72/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9324\n",
            "Epoch 72: val_loss improved from 0.21186 to 0.21149, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1888 - accuracy: 0.9337 - val_loss: 0.2115 - val_accuracy: 0.9325\n",
            "Epoch 73/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1790 - accuracy: 0.9375\n",
            "Epoch 73: val_loss improved from 0.21149 to 0.21096, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.1808 - accuracy: 0.9369 - val_loss: 0.2110 - val_accuracy: 0.9325\n",
            "Epoch 74/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1650 - accuracy: 0.9421\n",
            "Epoch 74: val_loss improved from 0.21096 to 0.20951, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1651 - accuracy: 0.9425 - val_loss: 0.2095 - val_accuracy: 0.9325\n",
            "Epoch 75/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9381\n",
            "Epoch 75: val_loss improved from 0.20951 to 0.20657, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1742 - accuracy: 0.9388 - val_loss: 0.2066 - val_accuracy: 0.9325\n",
            "Epoch 76/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1594 - accuracy: 0.9453\n",
            "Epoch 76: val_loss improved from 0.20657 to 0.20466, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.1572 - accuracy: 0.9450 - val_loss: 0.2047 - val_accuracy: 0.9275\n",
            "Epoch 77/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1674 - accuracy: 0.9496\n",
            "Epoch 77: val_loss did not improve from 0.20466\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1683 - accuracy: 0.9494 - val_loss: 0.2060 - val_accuracy: 0.9300\n",
            "Epoch 78/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1488 - accuracy: 0.9486\n",
            "Epoch 78: val_loss did not improve from 0.20466\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1525 - accuracy: 0.9481 - val_loss: 0.2064 - val_accuracy: 0.9275\n",
            "Epoch 79/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1660 - accuracy: 0.9401\n",
            "Epoch 79: val_loss improved from 0.20466 to 0.20406, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1641 - accuracy: 0.9413 - val_loss: 0.2041 - val_accuracy: 0.9300\n",
            "Epoch 80/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9458\n",
            "Epoch 80: val_loss improved from 0.20406 to 0.20275, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1572 - accuracy: 0.9456 - val_loss: 0.2027 - val_accuracy: 0.9325\n",
            "Epoch 81/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9407\n",
            "Epoch 81: val_loss improved from 0.20275 to 0.20227, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.1619 - accuracy: 0.9419 - val_loss: 0.2023 - val_accuracy: 0.9350\n",
            "Epoch 82/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9469\n",
            "Epoch 82: val_loss improved from 0.20227 to 0.19880, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1561 - accuracy: 0.9469 - val_loss: 0.1988 - val_accuracy: 0.9275\n",
            "Epoch 83/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1491 - accuracy: 0.9518\n",
            "Epoch 83: val_loss improved from 0.19880 to 0.19550, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1460 - accuracy: 0.9531 - val_loss: 0.1955 - val_accuracy: 0.9325\n",
            "Epoch 84/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1575 - accuracy: 0.9464\n",
            "Epoch 84: val_loss did not improve from 0.19550\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1575 - accuracy: 0.9463 - val_loss: 0.1968 - val_accuracy: 0.9300\n",
            "Epoch 85/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1387 - accuracy: 0.9460\n",
            "Epoch 85: val_loss improved from 0.19550 to 0.19445, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1397 - accuracy: 0.9450 - val_loss: 0.1944 - val_accuracy: 0.9325\n",
            "Epoch 86/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1445 - accuracy: 0.9518\n",
            "Epoch 86: val_loss did not improve from 0.19445\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1468 - accuracy: 0.9506 - val_loss: 0.1947 - val_accuracy: 0.9325\n",
            "Epoch 87/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1381 - accuracy: 0.9531\n",
            "Epoch 87: val_loss improved from 0.19445 to 0.19186, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1364 - accuracy: 0.9538 - val_loss: 0.1919 - val_accuracy: 0.9350\n",
            "Epoch 88/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1315 - accuracy: 0.9547\n",
            "Epoch 88: val_loss improved from 0.19186 to 0.19146, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.1302 - accuracy: 0.9556 - val_loss: 0.1915 - val_accuracy: 0.9350\n",
            "Epoch 89/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1585 - accuracy: 0.9452\n",
            "Epoch 89: val_loss did not improve from 0.19146\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.1571 - accuracy: 0.9456 - val_loss: 0.1917 - val_accuracy: 0.9350\n",
            "Epoch 90/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1445 - accuracy: 0.9421\n",
            "Epoch 90: val_loss improved from 0.19146 to 0.18953, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1413 - accuracy: 0.9444 - val_loss: 0.1895 - val_accuracy: 0.9350\n",
            "Epoch 91/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9512\n",
            "Epoch 91: val_loss improved from 0.18953 to 0.18714, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1303 - accuracy: 0.9513 - val_loss: 0.1871 - val_accuracy: 0.9350\n",
            "Epoch 92/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 0.9560\n",
            "Epoch 92: val_loss did not improve from 0.18714\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1284 - accuracy: 0.9569 - val_loss: 0.1877 - val_accuracy: 0.9350\n",
            "Epoch 93/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9617\n",
            "Epoch 93: val_loss improved from 0.18714 to 0.18582, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.1256 - accuracy: 0.9606 - val_loss: 0.1858 - val_accuracy: 0.9375\n",
            "Epoch 94/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1291 - accuracy: 0.9560\n",
            "Epoch 94: val_loss did not improve from 0.18582\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1283 - accuracy: 0.9563 - val_loss: 0.1874 - val_accuracy: 0.9350\n",
            "Epoch 95/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1250 - accuracy: 0.9551\n",
            "Epoch 95: val_loss did not improve from 0.18582\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1250 - accuracy: 0.9556 - val_loss: 0.1877 - val_accuracy: 0.9325\n",
            "Epoch 96/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1296 - accuracy: 0.9531\n",
            "Epoch 96: val_loss did not improve from 0.18582\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1347 - accuracy: 0.9513 - val_loss: 0.1870 - val_accuracy: 0.9350\n",
            "Epoch 97/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.9605\n",
            "Epoch 97: val_loss improved from 0.18582 to 0.18562, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1153 - accuracy: 0.9606 - val_loss: 0.1856 - val_accuracy: 0.9375\n",
            "Epoch 98/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1152 - accuracy: 0.9596\n",
            "Epoch 98: val_loss did not improve from 0.18562\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1149 - accuracy: 0.9606 - val_loss: 0.1860 - val_accuracy: 0.9375\n",
            "Epoch 99/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9624\n",
            "Epoch 99: val_loss improved from 0.18562 to 0.18373, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1128 - accuracy: 0.9631 - val_loss: 0.1837 - val_accuracy: 0.9375\n",
            "Epoch 100/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9506\n",
            "Epoch 100: val_loss improved from 0.18373 to 0.18309, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1381 - accuracy: 0.9506 - val_loss: 0.1831 - val_accuracy: 0.9375\n",
            "Epoch 101/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9707\n",
            "Epoch 101: val_loss did not improve from 0.18309\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1005 - accuracy: 0.9700 - val_loss: 0.1838 - val_accuracy: 0.9375\n",
            "Epoch 102/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9600\n",
            "Epoch 102: val_loss improved from 0.18309 to 0.18142, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1113 - accuracy: 0.9600 - val_loss: 0.1814 - val_accuracy: 0.9425\n",
            "Epoch 103/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.9636\n",
            "Epoch 103: val_loss improved from 0.18142 to 0.18098, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1026 - accuracy: 0.9631 - val_loss: 0.1810 - val_accuracy: 0.9400\n",
            "Epoch 104/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1048 - accuracy: 0.9656\n",
            "Epoch 104: val_loss did not improve from 0.18098\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.1038 - accuracy: 0.9663 - val_loss: 0.1825 - val_accuracy: 0.9400\n",
            "Epoch 105/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9656\n",
            "Epoch 105: val_loss did not improve from 0.18098\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1065 - accuracy: 0.9656 - val_loss: 0.1814 - val_accuracy: 0.9375\n",
            "Epoch 106/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1275 - accuracy: 0.9570\n",
            "Epoch 106: val_loss improved from 0.18098 to 0.17869, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1287 - accuracy: 0.9569 - val_loss: 0.1787 - val_accuracy: 0.9400\n",
            "Epoch 107/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9566\n",
            "Epoch 107: val_loss did not improve from 0.17869\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1187 - accuracy: 0.9569 - val_loss: 0.1813 - val_accuracy: 0.9350\n",
            "Epoch 108/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9560\n",
            "Epoch 108: val_loss improved from 0.17869 to 0.17703, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1105 - accuracy: 0.9563 - val_loss: 0.1770 - val_accuracy: 0.9400\n",
            "Epoch 109/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1001 - accuracy: 0.9720\n",
            "Epoch 109: val_loss did not improve from 0.17703\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1018 - accuracy: 0.9706 - val_loss: 0.1786 - val_accuracy: 0.9400\n",
            "Epoch 110/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0988 - accuracy: 0.9642\n",
            "Epoch 110: val_loss did not improve from 0.17703\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0973 - accuracy: 0.9650 - val_loss: 0.1806 - val_accuracy: 0.9350\n",
            "Epoch 111/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9694\n",
            "Epoch 111: val_loss improved from 0.17703 to 0.17483, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.0978 - accuracy: 0.9681 - val_loss: 0.1748 - val_accuracy: 0.9425\n",
            "Epoch 112/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1020 - accuracy: 0.9655\n",
            "Epoch 112: val_loss did not improve from 0.17483\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1001 - accuracy: 0.9663 - val_loss: 0.1759 - val_accuracy: 0.9425\n",
            "Epoch 113/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0996 - accuracy: 0.9681\n",
            "Epoch 113: val_loss did not improve from 0.17483\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0982 - accuracy: 0.9681 - val_loss: 0.1773 - val_accuracy: 0.9425\n",
            "Epoch 114/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1087 - accuracy: 0.9611\n",
            "Epoch 114: val_loss improved from 0.17483 to 0.17159, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.1075 - accuracy: 0.9619 - val_loss: 0.1716 - val_accuracy: 0.9400\n",
            "Epoch 115/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9700\n",
            "Epoch 115: val_loss did not improve from 0.17159\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0921 - accuracy: 0.9706 - val_loss: 0.1728 - val_accuracy: 0.9425\n",
            "Epoch 116/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9700\n",
            "Epoch 116: val_loss improved from 0.17159 to 0.17064, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.0935 - accuracy: 0.9700 - val_loss: 0.1706 - val_accuracy: 0.9425\n",
            "Epoch 117/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0895 - accuracy: 0.9694\n",
            "Epoch 117: val_loss did not improve from 0.17064\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0888 - accuracy: 0.9700 - val_loss: 0.1749 - val_accuracy: 0.9425\n",
            "Epoch 118/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0918 - accuracy: 0.9694\n",
            "Epoch 118: val_loss did not improve from 0.17064\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0913 - accuracy: 0.9700 - val_loss: 0.1756 - val_accuracy: 0.9375\n",
            "Epoch 119/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9688\n",
            "Epoch 119: val_loss did not improve from 0.17064\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0927 - accuracy: 0.9688 - val_loss: 0.1729 - val_accuracy: 0.9450\n",
            "Epoch 120/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 0.9675\n",
            "Epoch 120: val_loss improved from 0.17064 to 0.16718, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0969 - accuracy: 0.9663 - val_loss: 0.1672 - val_accuracy: 0.9450\n",
            "Epoch 121/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9681\n",
            "Epoch 121: val_loss did not improve from 0.16718\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0970 - accuracy: 0.9681 - val_loss: 0.1675 - val_accuracy: 0.9450\n",
            "Epoch 122/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0889 - accuracy: 0.9674\n",
            "Epoch 122: val_loss did not improve from 0.16718\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0892 - accuracy: 0.9675 - val_loss: 0.1728 - val_accuracy: 0.9350\n",
            "Epoch 123/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9663\n",
            "Epoch 123: val_loss did not improve from 0.16718\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0943 - accuracy: 0.9663 - val_loss: 0.1695 - val_accuracy: 0.9450\n",
            "Epoch 124/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9706\n",
            "Epoch 124: val_loss did not improve from 0.16718\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0859 - accuracy: 0.9706 - val_loss: 0.1679 - val_accuracy: 0.9475\n",
            "Epoch 125/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9775\n",
            "Epoch 125: val_loss did not improve from 0.16718\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0678 - accuracy: 0.9775 - val_loss: 0.1674 - val_accuracy: 0.9475\n",
            "Epoch 126/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0848 - accuracy: 0.9694\n",
            "Epoch 126: val_loss did not improve from 0.16718\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0834 - accuracy: 0.9700 - val_loss: 0.1714 - val_accuracy: 0.9400\n",
            "Epoch 127/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9770\n",
            "Epoch 127: val_loss did not improve from 0.16718\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0739 - accuracy: 0.9775 - val_loss: 0.1731 - val_accuracy: 0.9400\n",
            "Epoch 128/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0773 - accuracy: 0.9713\n",
            "Epoch 128: val_loss did not improve from 0.16718\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0776 - accuracy: 0.9712 - val_loss: 0.1676 - val_accuracy: 0.9450\n",
            "Epoch 129/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0785 - accuracy: 0.9714\n",
            "Epoch 129: val_loss improved from 0.16718 to 0.16300, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.0781 - accuracy: 0.9719 - val_loss: 0.1630 - val_accuracy: 0.9425\n",
            "Epoch 130/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 0.9668\n",
            "Epoch 130: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0883 - accuracy: 0.9675 - val_loss: 0.1669 - val_accuracy: 0.9425\n",
            "Epoch 131/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0735 - accuracy: 0.9727\n",
            "Epoch 131: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0714 - accuracy: 0.9737 - val_loss: 0.1678 - val_accuracy: 0.9425\n",
            "Epoch 132/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9777\n",
            "Epoch 132: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0766 - accuracy: 0.9781 - val_loss: 0.1661 - val_accuracy: 0.9425\n",
            "Epoch 133/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9707\n",
            "Epoch 133: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0827 - accuracy: 0.9694 - val_loss: 0.1632 - val_accuracy: 0.9425\n",
            "Epoch 134/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0661 - accuracy: 0.9792\n",
            "Epoch 134: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0652 - accuracy: 0.9800 - val_loss: 0.1639 - val_accuracy: 0.9475\n",
            "Epoch 135/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9758\n",
            "Epoch 135: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0725 - accuracy: 0.9762 - val_loss: 0.1631 - val_accuracy: 0.9450\n",
            "Epoch 136/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0716 - accuracy: 0.9727\n",
            "Epoch 136: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0739 - accuracy: 0.9725 - val_loss: 0.1645 - val_accuracy: 0.9450\n",
            "Epoch 137/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9732\n",
            "Epoch 137: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0733 - accuracy: 0.9725 - val_loss: 0.1644 - val_accuracy: 0.9425\n",
            "Epoch 138/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9769\n",
            "Epoch 138: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0689 - accuracy: 0.9769 - val_loss: 0.1648 - val_accuracy: 0.9450\n",
            "Epoch 139/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9809\n",
            "Epoch 139: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0670 - accuracy: 0.9800 - val_loss: 0.1670 - val_accuracy: 0.9425\n",
            "Epoch 140/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 0.9834\n",
            "Epoch 140: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0600 - accuracy: 0.9837 - val_loss: 0.1655 - val_accuracy: 0.9475\n",
            "Epoch 141/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9769\n",
            "Epoch 141: val_loss did not improve from 0.16300\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0671 - accuracy: 0.9769 - val_loss: 0.1687 - val_accuracy: 0.9475\n",
            "Epoch 142/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9745\n",
            "Epoch 142: val_loss improved from 0.16300 to 0.16100, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.0740 - accuracy: 0.9731 - val_loss: 0.1610 - val_accuracy: 0.9475\n",
            "Epoch 143/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9751\n",
            "Epoch 143: val_loss improved from 0.16100 to 0.15976, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0698 - accuracy: 0.9744 - val_loss: 0.1598 - val_accuracy: 0.9425\n",
            "Epoch 144/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9775\n",
            "Epoch 144: val_loss did not improve from 0.15976\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.1620 - val_accuracy: 0.9500\n",
            "Epoch 145/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0756 - accuracy: 0.9713\n",
            "Epoch 145: val_loss did not improve from 0.15976\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0746 - accuracy: 0.9719 - val_loss: 0.1660 - val_accuracy: 0.9525\n",
            "Epoch 146/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9731\n",
            "Epoch 146: val_loss did not improve from 0.15976\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0750 - accuracy: 0.9731 - val_loss: 0.1630 - val_accuracy: 0.9400\n",
            "Epoch 147/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0702 - accuracy: 0.9753\n",
            "Epoch 147: val_loss did not improve from 0.15976\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0717 - accuracy: 0.9750 - val_loss: 0.1612 - val_accuracy: 0.9475\n",
            "Epoch 148/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 0.9860\n",
            "Epoch 148: val_loss did not improve from 0.15976\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0587 - accuracy: 0.9856 - val_loss: 0.1598 - val_accuracy: 0.9500\n",
            "Epoch 149/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9802\n",
            "Epoch 149: val_loss did not improve from 0.15976\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0632 - accuracy: 0.9806 - val_loss: 0.1603 - val_accuracy: 0.9475\n",
            "Epoch 150/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0622 - accuracy: 0.9759\n",
            "Epoch 150: val_loss did not improve from 0.15976\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.0610 - accuracy: 0.9769 - val_loss: 0.1650 - val_accuracy: 0.9475\n",
            "Epoch 151/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9809\n",
            "Epoch 151: val_loss improved from 0.15976 to 0.15776, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 98ms/step - loss: 0.0540 - accuracy: 0.9812 - val_loss: 0.1578 - val_accuracy: 0.9475\n",
            "Epoch 152/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9802\n",
            "Epoch 152: val_loss did not improve from 0.15776\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0665 - accuracy: 0.9794 - val_loss: 0.1589 - val_accuracy: 0.9475\n",
            "Epoch 153/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0540 - accuracy: 0.9850\n",
            "Epoch 153: val_loss did not improve from 0.15776\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0539 - accuracy: 0.9844 - val_loss: 0.1606 - val_accuracy: 0.9500\n",
            "Epoch 154/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0571 - accuracy: 0.9792\n",
            "Epoch 154: val_loss did not improve from 0.15776\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0558 - accuracy: 0.9800 - val_loss: 0.1580 - val_accuracy: 0.9525\n",
            "Epoch 155/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9796\n",
            "Epoch 155: val_loss did not improve from 0.15776\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 0.1588 - val_accuracy: 0.9500\n",
            "Epoch 156/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9821\n",
            "Epoch 156: val_loss did not improve from 0.15776\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0518 - accuracy: 0.9825 - val_loss: 0.1614 - val_accuracy: 0.9450\n",
            "Epoch 157/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9800\n",
            "Epoch 157: val_loss did not improve from 0.15776\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0543 - accuracy: 0.9800 - val_loss: 0.1594 - val_accuracy: 0.9525\n",
            "Epoch 158/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0556 - accuracy: 0.9759\n",
            "Epoch 158: val_loss did not improve from 0.15776\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0558 - accuracy: 0.9756 - val_loss: 0.1621 - val_accuracy: 0.9400\n",
            "Epoch 159/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9825\n",
            "Epoch 159: val_loss improved from 0.15776 to 0.15649, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.0563 - accuracy: 0.9825 - val_loss: 0.1565 - val_accuracy: 0.9500\n",
            "Epoch 160/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9819\n",
            "Epoch 160: val_loss did not improve from 0.15649\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0525 - accuracy: 0.9819 - val_loss: 0.1570 - val_accuracy: 0.9425\n",
            "Epoch 161/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0500 - accuracy: 0.9863\n",
            "Epoch 161: val_loss did not improve from 0.15649\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0526 - accuracy: 0.9844 - val_loss: 0.1576 - val_accuracy: 0.9425\n",
            "Epoch 162/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.9758\n",
            "Epoch 162: val_loss did not improve from 0.15649\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0664 - accuracy: 0.9762 - val_loss: 0.1583 - val_accuracy: 0.9550\n",
            "Epoch 163/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9841\n",
            "Epoch 163: val_loss improved from 0.15649 to 0.15504, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 0.1550 - val_accuracy: 0.9500\n",
            "Epoch 164/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0599 - accuracy: 0.9798\n",
            "Epoch 164: val_loss improved from 0.15504 to 0.15369, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.0593 - accuracy: 0.9800 - val_loss: 0.1537 - val_accuracy: 0.9450\n",
            "Epoch 165/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9821\n",
            "Epoch 165: val_loss improved from 0.15369 to 0.15131, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.0482 - accuracy: 0.9819 - val_loss: 0.1513 - val_accuracy: 0.9450\n",
            "Epoch 166/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.9828\n",
            "Epoch 166: val_loss improved from 0.15131 to 0.15068, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.0505 - accuracy: 0.9819 - val_loss: 0.1507 - val_accuracy: 0.9475\n",
            "Epoch 167/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0556 - accuracy: 0.9818\n",
            "Epoch 167: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0564 - accuracy: 0.9819 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
            "Epoch 168/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9885\n",
            "Epoch 168: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.1561 - val_accuracy: 0.9475\n",
            "Epoch 169/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9866\n",
            "Epoch 169: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0437 - accuracy: 0.9869 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
            "Epoch 170/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9790\n",
            "Epoch 170: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 45ms/step - loss: 0.0579 - accuracy: 0.9794 - val_loss: 0.1566 - val_accuracy: 0.9500\n",
            "Epoch 171/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0478 - accuracy: 0.9831\n",
            "Epoch 171: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0486 - accuracy: 0.9825 - val_loss: 0.1566 - val_accuracy: 0.9500\n",
            "Epoch 172/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9806\n",
            "Epoch 172: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0513 - accuracy: 0.9806 - val_loss: 0.1545 - val_accuracy: 0.9500\n",
            "Epoch 173/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9860\n",
            "Epoch 173: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.1585 - val_accuracy: 0.9525\n",
            "Epoch 174/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0541 - accuracy: 0.9792\n",
            "Epoch 174: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0529 - accuracy: 0.9800 - val_loss: 0.1547 - val_accuracy: 0.9575\n",
            "Epoch 175/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9821\n",
            "Epoch 175: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0487 - accuracy: 0.9819 - val_loss: 0.1551 - val_accuracy: 0.9500\n",
            "Epoch 176/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9821\n",
            "Epoch 176: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.1523 - val_accuracy: 0.9500\n",
            "Epoch 177/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9821\n",
            "Epoch 177: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 0.1581 - val_accuracy: 0.9575\n",
            "Epoch 178/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9898\n",
            "Epoch 178: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0393 - accuracy: 0.9900 - val_loss: 0.1528 - val_accuracy: 0.9475\n",
            "Epoch 179/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9809\n",
            "Epoch 179: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0520 - accuracy: 0.9800 - val_loss: 0.1723 - val_accuracy: 0.9400\n",
            "Epoch 180/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9800\n",
            "Epoch 180: val_loss did not improve from 0.15068\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0463 - accuracy: 0.9800 - val_loss: 0.1551 - val_accuracy: 0.9500\n",
            "Epoch 181/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9834\n",
            "Epoch 181: val_loss improved from 0.15068 to 0.14806, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.0533 - accuracy: 0.9837 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
            "Epoch 182/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0336 - accuracy: 0.9876\n",
            "Epoch 182: val_loss did not improve from 0.14806\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0336 - accuracy: 0.9875 - val_loss: 0.1547 - val_accuracy: 0.9525\n",
            "Epoch 183/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9841\n",
            "Epoch 183: val_loss did not improve from 0.14806\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0457 - accuracy: 0.9844 - val_loss: 0.1501 - val_accuracy: 0.9500\n",
            "Epoch 184/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9841\n",
            "Epoch 184: val_loss improved from 0.14806 to 0.14794, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.0464 - accuracy: 0.9831 - val_loss: 0.1479 - val_accuracy: 0.9575\n",
            "Epoch 185/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9872\n",
            "Epoch 185: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.1480 - val_accuracy: 0.9575\n",
            "Epoch 186/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9828\n",
            "Epoch 186: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0460 - accuracy: 0.9831 - val_loss: 0.1511 - val_accuracy: 0.9525\n",
            "Epoch 187/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0398 - accuracy: 0.9850\n",
            "Epoch 187: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0409 - accuracy: 0.9837 - val_loss: 0.1524 - val_accuracy: 0.9500\n",
            "Epoch 188/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9834\n",
            "Epoch 188: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 0.1602 - val_accuracy: 0.9475\n",
            "Epoch 189/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9856\n",
            "Epoch 189: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0411 - accuracy: 0.9856 - val_loss: 0.1516 - val_accuracy: 0.9500\n",
            "Epoch 190/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0318 - accuracy: 0.9922\n",
            "Epoch 190: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0321 - accuracy: 0.9919 - val_loss: 0.1534 - val_accuracy: 0.9500\n",
            "Epoch 191/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9904\n",
            "Epoch 191: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.1508 - val_accuracy: 0.9500\n",
            "Epoch 192/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9860\n",
            "Epoch 192: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0405 - accuracy: 0.9856 - val_loss: 0.1549 - val_accuracy: 0.9500\n",
            "Epoch 193/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.9860\n",
            "Epoch 193: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0451 - accuracy: 0.9862 - val_loss: 0.1508 - val_accuracy: 0.9525\n",
            "Epoch 194/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9847\n",
            "Epoch 194: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0401 - accuracy: 0.9844 - val_loss: 0.1488 - val_accuracy: 0.9500\n",
            "Epoch 195/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0446 - accuracy: 0.9837\n",
            "Epoch 195: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.0440 - accuracy: 0.9844 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
            "Epoch 196/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9885\n",
            "Epoch 196: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.1543 - val_accuracy: 0.9475\n",
            "Epoch 197/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 0.9834\n",
            "Epoch 197: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0410 - accuracy: 0.9837 - val_loss: 0.1496 - val_accuracy: 0.9550\n",
            "Epoch 198/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0445 - accuracy: 0.9844\n",
            "Epoch 198: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0434 - accuracy: 0.9850 - val_loss: 0.1527 - val_accuracy: 0.9450\n",
            "Epoch 199/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 0.9892\n",
            "Epoch 199: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0420 - accuracy: 0.9894 - val_loss: 0.1521 - val_accuracy: 0.9500\n",
            "Epoch 200/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0342 - accuracy: 0.9876\n",
            "Epoch 200: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0334 - accuracy: 0.9881 - val_loss: 0.1528 - val_accuracy: 0.9525\n",
            "Epoch 201/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9879\n",
            "Epoch 201: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 0.1497 - val_accuracy: 0.9525\n",
            "Epoch 202/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0391 - accuracy: 0.9844\n",
            "Epoch 202: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0385 - accuracy: 0.9850 - val_loss: 0.1512 - val_accuracy: 0.9500\n",
            "Epoch 203/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9860\n",
            "Epoch 203: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0389 - accuracy: 0.9862 - val_loss: 0.1482 - val_accuracy: 0.9500\n",
            "Epoch 204/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0355 - accuracy: 0.9863\n",
            "Epoch 204: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0348 - accuracy: 0.9869 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
            "Epoch 205/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9881\n",
            "Epoch 205: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.1536 - val_accuracy: 0.9475\n",
            "Epoch 206/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0320 - accuracy: 0.9909\n",
            "Epoch 206: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0351 - accuracy: 0.9900 - val_loss: 0.1561 - val_accuracy: 0.9500\n",
            "Epoch 207/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9898\n",
            "Epoch 207: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0369 - accuracy: 0.9900 - val_loss: 0.1596 - val_accuracy: 0.9550\n",
            "Epoch 208/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9853\n",
            "Epoch 208: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0413 - accuracy: 0.9850 - val_loss: 0.1528 - val_accuracy: 0.9475\n",
            "Epoch 209/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9847\n",
            "Epoch 209: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0370 - accuracy: 0.9850 - val_loss: 0.1597 - val_accuracy: 0.9500\n",
            "Epoch 210/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9860\n",
            "Epoch 210: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0387 - accuracy: 0.9850 - val_loss: 0.1540 - val_accuracy: 0.9450\n",
            "Epoch 211/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9911\n",
            "Epoch 211: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0318 - accuracy: 0.9912 - val_loss: 0.1513 - val_accuracy: 0.9475\n",
            "Epoch 212/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9885\n",
            "Epoch 212: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0360 - accuracy: 0.9881 - val_loss: 0.1573 - val_accuracy: 0.9475\n",
            "Epoch 213/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0278 - accuracy: 0.9928\n",
            "Epoch 213: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0276 - accuracy: 0.9931 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
            "Epoch 214/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9962\n",
            "Epoch 214: val_loss improved from 0.14794 to 0.14497, saving model to /content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 107ms/step - loss: 0.0243 - accuracy: 0.9962 - val_loss: 0.1450 - val_accuracy: 0.9525\n",
            "Epoch 215/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0377 - accuracy: 0.9870\n",
            "Epoch 215: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 0.1556 - val_accuracy: 0.9575\n",
            "Epoch 216/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9879\n",
            "Epoch 216: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0327 - accuracy: 0.9881 - val_loss: 0.1493 - val_accuracy: 0.9550\n",
            "Epoch 217/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9866\n",
            "Epoch 217: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0370 - accuracy: 0.9869 - val_loss: 0.1482 - val_accuracy: 0.9500\n",
            "Epoch 218/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0309 - accuracy: 0.9902\n",
            "Epoch 218: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0302 - accuracy: 0.9906 - val_loss: 0.1471 - val_accuracy: 0.9550\n",
            "Epoch 219/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9906\n",
            "Epoch 219: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 0.1582 - val_accuracy: 0.9500\n",
            "Epoch 220/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0339 - accuracy: 0.9870\n",
            "Epoch 220: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.1550 - val_accuracy: 0.9500\n",
            "Epoch 221/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0328 - accuracy: 0.9909\n",
            "Epoch 221: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 0.1550 - val_accuracy: 0.9550\n",
            "Epoch 222/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0288 - accuracy: 0.9922\n",
            "Epoch 222: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.1524 - val_accuracy: 0.9525\n",
            "Epoch 223/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9860\n",
            "Epoch 223: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0382 - accuracy: 0.9856 - val_loss: 0.1464 - val_accuracy: 0.9550\n",
            "Epoch 224/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0259 - accuracy: 0.9928\n",
            "Epoch 224: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.1530 - val_accuracy: 0.9500\n",
            "Epoch 225/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9892\n",
            "Epoch 225: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 0.1545 - val_accuracy: 0.9500\n",
            "Epoch 226/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0302 - accuracy: 0.9909\n",
            "Epoch 226: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0327 - accuracy: 0.9906 - val_loss: 0.1507 - val_accuracy: 0.9525\n",
            "Epoch 227/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9917\n",
            "Epoch 227: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.1494 - val_accuracy: 0.9525\n",
            "Epoch 228/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9911\n",
            "Epoch 228: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.1546 - val_accuracy: 0.9525\n",
            "Epoch 229/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9911\n",
            "Epoch 229: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1615 - val_accuracy: 0.9500\n",
            "Epoch 230/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0341 - accuracy: 0.9896\n",
            "Epoch 230: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
            "Epoch 231/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9885\n",
            "Epoch 231: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 0.1522 - val_accuracy: 0.9525\n",
            "Epoch 232/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9919\n",
            "Epoch 232: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.1530 - val_accuracy: 0.9475\n",
            "Epoch 233/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0317 - accuracy: 0.9896\n",
            "Epoch 233: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.1532 - val_accuracy: 0.9500\n",
            "Epoch 234/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0254 - accuracy: 0.9922\n",
            "Epoch 234: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.1486 - val_accuracy: 0.9525\n",
            "Epoch 235/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9917\n",
            "Epoch 235: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0308 - accuracy: 0.9919 - val_loss: 0.1509 - val_accuracy: 0.9500\n",
            "Epoch 236/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9892\n",
            "Epoch 236: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0301 - accuracy: 0.9894 - val_loss: 0.1487 - val_accuracy: 0.9550\n",
            "Epoch 237/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9917\n",
            "Epoch 237: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.1486 - val_accuracy: 0.9525\n",
            "Epoch 238/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9930\n",
            "Epoch 238: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.1526 - val_accuracy: 0.9525\n",
            "Epoch 239/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9943\n",
            "Epoch 239: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0180 - accuracy: 0.9937 - val_loss: 0.1519 - val_accuracy: 0.9575\n",
            "Epoch 240/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9930\n",
            "Epoch 240: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 0.1473 - val_accuracy: 0.9525\n",
            "Epoch 241/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9881\n",
            "Epoch 241: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0335 - accuracy: 0.9881 - val_loss: 0.1668 - val_accuracy: 0.9525\n",
            "Epoch 242/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9911\n",
            "Epoch 242: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.1502 - val_accuracy: 0.9500\n",
            "Epoch 243/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9955\n",
            "Epoch 243: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0212 - accuracy: 0.9956 - val_loss: 0.1452 - val_accuracy: 0.9575\n",
            "Epoch 244/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9906\n",
            "Epoch 244: val_loss did not improve from 0.14497\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0256 - accuracy: 0.9906 - val_loss: 0.1464 - val_accuracy: 0.9550\n",
            "63/63 [==============================] - 2s 16ms/step - loss: 0.4770 - accuracy: 0.8870\n",
            "Test accuracy, 18 run, after finetuning: 0.8870000243186951\n",
            "Epoch 1/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 2.8237 - accuracy: 0.5814\n",
            "Epoch 1: val_loss improved from inf to 1.77695, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 31s 208ms/step - loss: 2.8138 - accuracy: 0.5800 - val_loss: 1.7770 - val_accuracy: 0.6650\n",
            "Epoch 2/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 1.8602 - accuracy: 0.6576\n",
            "Epoch 2: val_loss improved from 1.77695 to 1.25235, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 1.8387 - accuracy: 0.6587 - val_loss: 1.2524 - val_accuracy: 0.7125\n",
            "Epoch 3/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.3894 - accuracy: 0.6964\n",
            "Epoch 3: val_loss improved from 1.25235 to 0.99140, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 1.3916 - accuracy: 0.6963 - val_loss: 0.9914 - val_accuracy: 0.7300\n",
            "Epoch 4/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.1948 - accuracy: 0.6945\n",
            "Epoch 4: val_loss improved from 0.99140 to 0.82283, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.1921 - accuracy: 0.6931 - val_loss: 0.8228 - val_accuracy: 0.7500\n",
            "Epoch 5/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 1.0193 - accuracy: 0.7259\n",
            "Epoch 5: val_loss improved from 0.82283 to 0.71216, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 1.0199 - accuracy: 0.7281 - val_loss: 0.7122 - val_accuracy: 0.7600\n",
            "Epoch 6/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9281 - accuracy: 0.7328\n",
            "Epoch 6: val_loss improved from 0.71216 to 0.63718, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.9314 - accuracy: 0.7337 - val_loss: 0.6372 - val_accuracy: 0.7775\n",
            "Epoch 7/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8215 - accuracy: 0.7481\n",
            "Epoch 7: val_loss improved from 0.63718 to 0.58045, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.8222 - accuracy: 0.7475 - val_loss: 0.5804 - val_accuracy: 0.7900\n",
            "Epoch 8/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7609 - accuracy: 0.7666\n",
            "Epoch 8: val_loss improved from 0.58045 to 0.54168, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.7627 - accuracy: 0.7663 - val_loss: 0.5417 - val_accuracy: 0.8000\n",
            "Epoch 9/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7199 - accuracy: 0.7710\n",
            "Epoch 9: val_loss improved from 0.54168 to 0.51173, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.7281 - accuracy: 0.7700 - val_loss: 0.5117 - val_accuracy: 0.8200\n",
            "Epoch 10/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.7837\n",
            "Epoch 10: val_loss improved from 0.51173 to 0.48893, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.7170 - accuracy: 0.7837 - val_loss: 0.4889 - val_accuracy: 0.8325\n",
            "Epoch 11/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.7749\n",
            "Epoch 11: val_loss improved from 0.48893 to 0.47335, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.6694 - accuracy: 0.7756 - val_loss: 0.4733 - val_accuracy: 0.8275\n",
            "Epoch 12/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6655 - accuracy: 0.7813\n",
            "Epoch 12: val_loss improved from 0.47335 to 0.45276, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.6738 - accuracy: 0.7769 - val_loss: 0.4528 - val_accuracy: 0.8375\n",
            "Epoch 13/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6338 - accuracy: 0.8017\n",
            "Epoch 13: val_loss improved from 0.45276 to 0.43840, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.6332 - accuracy: 0.8019 - val_loss: 0.4384 - val_accuracy: 0.8450\n",
            "Epoch 14/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6246 - accuracy: 0.7966\n",
            "Epoch 14: val_loss improved from 0.43840 to 0.42591, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.6185 - accuracy: 0.7987 - val_loss: 0.4259 - val_accuracy: 0.8450\n",
            "Epoch 15/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5989 - accuracy: 0.7985\n",
            "Epoch 15: val_loss improved from 0.42591 to 0.41612, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.5986 - accuracy: 0.7994 - val_loss: 0.4161 - val_accuracy: 0.8525\n",
            "Epoch 16/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.8281\n",
            "Epoch 16: val_loss improved from 0.41612 to 0.40124, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.5379 - accuracy: 0.8281 - val_loss: 0.4012 - val_accuracy: 0.8550\n",
            "Epoch 17/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5533 - accuracy: 0.8092\n",
            "Epoch 17: val_loss improved from 0.40124 to 0.39268, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.5558 - accuracy: 0.8094 - val_loss: 0.3927 - val_accuracy: 0.8550\n",
            "Epoch 18/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5298 - accuracy: 0.8171\n",
            "Epoch 18: val_loss improved from 0.39268 to 0.38051, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.5189 - accuracy: 0.8213 - val_loss: 0.3805 - val_accuracy: 0.8600\n",
            "Epoch 19/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.8182\n",
            "Epoch 19: val_loss improved from 0.38051 to 0.37596, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.5503 - accuracy: 0.8200 - val_loss: 0.3760 - val_accuracy: 0.8525\n",
            "Epoch 20/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4886 - accuracy: 0.8359\n",
            "Epoch 20: val_loss improved from 0.37596 to 0.37326, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.4903 - accuracy: 0.8338 - val_loss: 0.3733 - val_accuracy: 0.8575\n",
            "Epoch 21/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.8482\n",
            "Epoch 21: val_loss improved from 0.37326 to 0.36350, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.4812 - accuracy: 0.8494 - val_loss: 0.3635 - val_accuracy: 0.8575\n",
            "Epoch 22/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4612 - accuracy: 0.8438\n",
            "Epoch 22: val_loss improved from 0.36350 to 0.35113, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.4665 - accuracy: 0.8425 - val_loss: 0.3511 - val_accuracy: 0.8625\n",
            "Epoch 23/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.8425\n",
            "Epoch 23: val_loss improved from 0.35113 to 0.34286, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.4613 - accuracy: 0.8419 - val_loss: 0.3429 - val_accuracy: 0.8650\n",
            "Epoch 24/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.8386\n",
            "Epoch 24: val_loss improved from 0.34286 to 0.33784, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.4710 - accuracy: 0.8375 - val_loss: 0.3378 - val_accuracy: 0.8675\n",
            "Epoch 25/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4235 - accuracy: 0.8622\n",
            "Epoch 25: val_loss improved from 0.33784 to 0.33287, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.4209 - accuracy: 0.8625 - val_loss: 0.3329 - val_accuracy: 0.8675\n",
            "Epoch 26/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4317 - accuracy: 0.8571\n",
            "Epoch 26: val_loss improved from 0.33287 to 0.32755, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.4325 - accuracy: 0.8562 - val_loss: 0.3276 - val_accuracy: 0.8700\n",
            "Epoch 27/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4072 - accuracy: 0.8597\n",
            "Epoch 27: val_loss improved from 0.32755 to 0.31769, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.4066 - accuracy: 0.8600 - val_loss: 0.3177 - val_accuracy: 0.8750\n",
            "Epoch 28/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4095 - accuracy: 0.8616\n",
            "Epoch 28: val_loss improved from 0.31769 to 0.31249, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.4081 - accuracy: 0.8619 - val_loss: 0.3125 - val_accuracy: 0.8725\n",
            "Epoch 29/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4030 - accuracy: 0.8724\n",
            "Epoch 29: val_loss improved from 0.31249 to 0.30432, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.4074 - accuracy: 0.8694 - val_loss: 0.3043 - val_accuracy: 0.8875\n",
            "Epoch 30/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4006 - accuracy: 0.8665\n",
            "Epoch 30: val_loss improved from 0.30432 to 0.30139, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.4022 - accuracy: 0.8662 - val_loss: 0.3014 - val_accuracy: 0.8875\n",
            "Epoch 31/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3858 - accuracy: 0.8724\n",
            "Epoch 31: val_loss improved from 0.30139 to 0.29607, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.3926 - accuracy: 0.8700 - val_loss: 0.2961 - val_accuracy: 0.8800\n",
            "Epoch 32/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3975 - accuracy: 0.8661\n",
            "Epoch 32: val_loss improved from 0.29607 to 0.28774, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.3947 - accuracy: 0.8675 - val_loss: 0.2877 - val_accuracy: 0.8875\n",
            "Epoch 33/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3748 - accuracy: 0.8685\n",
            "Epoch 33: val_loss improved from 0.28774 to 0.28743, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3745 - accuracy: 0.8687 - val_loss: 0.2874 - val_accuracy: 0.8900\n",
            "Epoch 34/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3758 - accuracy: 0.8686\n",
            "Epoch 34: val_loss improved from 0.28743 to 0.27791, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3797 - accuracy: 0.8669 - val_loss: 0.2779 - val_accuracy: 0.8925\n",
            "Epoch 35/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3442 - accuracy: 0.8848\n",
            "Epoch 35: val_loss improved from 0.27791 to 0.27431, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.3424 - accuracy: 0.8856 - val_loss: 0.2743 - val_accuracy: 0.8950\n",
            "Epoch 36/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3617 - accuracy: 0.8802\n",
            "Epoch 36: val_loss improved from 0.27431 to 0.27270, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.3642 - accuracy: 0.8800 - val_loss: 0.2727 - val_accuracy: 0.8950\n",
            "Epoch 37/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.8814\n",
            "Epoch 37: val_loss improved from 0.27270 to 0.26664, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3489 - accuracy: 0.8813 - val_loss: 0.2666 - val_accuracy: 0.8975\n",
            "Epoch 38/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3427 - accuracy: 0.8893\n",
            "Epoch 38: val_loss improved from 0.26664 to 0.25876, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.3459 - accuracy: 0.8894 - val_loss: 0.2588 - val_accuracy: 0.9025\n",
            "Epoch 39/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3301 - accuracy: 0.8865\n",
            "Epoch 39: val_loss improved from 0.25876 to 0.25611, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.3264 - accuracy: 0.8875 - val_loss: 0.2561 - val_accuracy: 0.9000\n",
            "Epoch 40/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3264 - accuracy: 0.8932\n",
            "Epoch 40: val_loss improved from 0.25611 to 0.25439, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.3249 - accuracy: 0.8950 - val_loss: 0.2544 - val_accuracy: 0.9050\n",
            "Epoch 41/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3028 - accuracy: 0.8941\n",
            "Epoch 41: val_loss improved from 0.25439 to 0.25434, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.3048 - accuracy: 0.8938 - val_loss: 0.2543 - val_accuracy: 0.9025\n",
            "Epoch 42/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.8881\n",
            "Epoch 42: val_loss improved from 0.25434 to 0.25140, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.3213 - accuracy: 0.8881 - val_loss: 0.2514 - val_accuracy: 0.9025\n",
            "Epoch 43/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3080 - accuracy: 0.8897\n",
            "Epoch 43: val_loss improved from 0.25140 to 0.24956, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3044 - accuracy: 0.8913 - val_loss: 0.2496 - val_accuracy: 0.9050\n",
            "Epoch 44/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3135 - accuracy: 0.8900\n",
            "Epoch 44: val_loss improved from 0.24956 to 0.24218, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3121 - accuracy: 0.8919 - val_loss: 0.2422 - val_accuracy: 0.9125\n",
            "Epoch 45/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3061 - accuracy: 0.8952\n",
            "Epoch 45: val_loss did not improve from 0.24218\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.3051 - accuracy: 0.8956 - val_loss: 0.2450 - val_accuracy: 0.9150\n",
            "Epoch 46/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2760 - accuracy: 0.9095\n",
            "Epoch 46: val_loss improved from 0.24218 to 0.23644, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.2783 - accuracy: 0.9087 - val_loss: 0.2364 - val_accuracy: 0.9125\n",
            "Epoch 47/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2799 - accuracy: 0.9030\n",
            "Epoch 47: val_loss improved from 0.23644 to 0.23594, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2785 - accuracy: 0.9044 - val_loss: 0.2359 - val_accuracy: 0.9125\n",
            "Epoch 48/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.9044\n",
            "Epoch 48: val_loss improved from 0.23594 to 0.23084, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 73ms/step - loss: 0.2936 - accuracy: 0.9044 - val_loss: 0.2308 - val_accuracy: 0.9200\n",
            "Epoch 49/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.9031\n",
            "Epoch 49: val_loss improved from 0.23084 to 0.22589, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.2853 - accuracy: 0.9031 - val_loss: 0.2259 - val_accuracy: 0.9325\n",
            "Epoch 50/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9063\n",
            "Epoch 50: val_loss improved from 0.22589 to 0.22468, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 99ms/step - loss: 0.2739 - accuracy: 0.9062 - val_loss: 0.2247 - val_accuracy: 0.9275\n",
            "Epoch 51/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2757 - accuracy: 0.9018\n",
            "Epoch 51: val_loss improved from 0.22468 to 0.22348, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2778 - accuracy: 0.9013 - val_loss: 0.2235 - val_accuracy: 0.9275\n",
            "Epoch 52/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9101\n",
            "Epoch 52: val_loss improved from 0.22348 to 0.22007, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2631 - accuracy: 0.9094 - val_loss: 0.2201 - val_accuracy: 0.9300\n",
            "Epoch 53/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2618 - accuracy: 0.9133\n",
            "Epoch 53: val_loss did not improve from 0.22007\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2609 - accuracy: 0.9131 - val_loss: 0.2224 - val_accuracy: 0.9275\n",
            "Epoch 54/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2453 - accuracy: 0.9120\n",
            "Epoch 54: val_loss improved from 0.22007 to 0.21602, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.2417 - accuracy: 0.9137 - val_loss: 0.2160 - val_accuracy: 0.9300\n",
            "Epoch 55/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2392 - accuracy: 0.9260\n",
            "Epoch 55: val_loss improved from 0.21602 to 0.21331, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2414 - accuracy: 0.9256 - val_loss: 0.2133 - val_accuracy: 0.9375\n",
            "Epoch 56/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.9119\n",
            "Epoch 56: val_loss did not improve from 0.21331\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.2647 - accuracy: 0.9119 - val_loss: 0.2157 - val_accuracy: 0.9250\n",
            "Epoch 57/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2280 - accuracy: 0.9303\n",
            "Epoch 57: val_loss improved from 0.21331 to 0.21167, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.2285 - accuracy: 0.9306 - val_loss: 0.2117 - val_accuracy: 0.9375\n",
            "Epoch 58/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9209\n",
            "Epoch 58: val_loss improved from 0.21167 to 0.20905, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.2389 - accuracy: 0.9225 - val_loss: 0.2091 - val_accuracy: 0.9325\n",
            "Epoch 59/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9152\n",
            "Epoch 59: val_loss improved from 0.20905 to 0.20816, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2393 - accuracy: 0.9156 - val_loss: 0.2082 - val_accuracy: 0.9325\n",
            "Epoch 60/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2538 - accuracy: 0.9133\n",
            "Epoch 60: val_loss improved from 0.20816 to 0.20383, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.2550 - accuracy: 0.9112 - val_loss: 0.2038 - val_accuracy: 0.9400\n",
            "Epoch 61/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9254\n",
            "Epoch 61: val_loss did not improve from 0.20383\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.2224 - accuracy: 0.9250 - val_loss: 0.2049 - val_accuracy: 0.9425\n",
            "Epoch 62/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.9190\n",
            "Epoch 62: val_loss improved from 0.20383 to 0.20070, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.2369 - accuracy: 0.9181 - val_loss: 0.2007 - val_accuracy: 0.9400\n",
            "Epoch 63/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2297 - accuracy: 0.9199\n",
            "Epoch 63: val_loss improved from 0.20070 to 0.19846, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2289 - accuracy: 0.9200 - val_loss: 0.1985 - val_accuracy: 0.9425\n",
            "Epoch 64/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2190 - accuracy: 0.9277\n",
            "Epoch 64: val_loss improved from 0.19846 to 0.19576, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2206 - accuracy: 0.9275 - val_loss: 0.1958 - val_accuracy: 0.9450\n",
            "Epoch 65/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1926 - accuracy: 0.9408\n",
            "Epoch 65: val_loss improved from 0.19576 to 0.19278, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1933 - accuracy: 0.9400 - val_loss: 0.1928 - val_accuracy: 0.9400\n",
            "Epoch 66/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2042 - accuracy: 0.9298\n",
            "Epoch 66: val_loss improved from 0.19278 to 0.19040, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.2023 - accuracy: 0.9300 - val_loss: 0.1904 - val_accuracy: 0.9400\n",
            "Epoch 67/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9319\n",
            "Epoch 67: val_loss did not improve from 0.19040\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1972 - accuracy: 0.9319 - val_loss: 0.1929 - val_accuracy: 0.9400\n",
            "Epoch 68/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1947 - accuracy: 0.9310\n",
            "Epoch 68: val_loss did not improve from 0.19040\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1915 - accuracy: 0.9319 - val_loss: 0.1917 - val_accuracy: 0.9400\n",
            "Epoch 69/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2110 - accuracy: 0.9311\n",
            "Epoch 69: val_loss improved from 0.19040 to 0.18858, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2116 - accuracy: 0.9312 - val_loss: 0.1886 - val_accuracy: 0.9475\n",
            "Epoch 70/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2057 - accuracy: 0.9336\n",
            "Epoch 70: val_loss improved from 0.18858 to 0.18793, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.2070 - accuracy: 0.9331 - val_loss: 0.1879 - val_accuracy: 0.9425\n",
            "Epoch 71/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1944 - accuracy: 0.9407\n",
            "Epoch 71: val_loss did not improve from 0.18793\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1917 - accuracy: 0.9419 - val_loss: 0.1920 - val_accuracy: 0.9375\n",
            "Epoch 72/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1920 - accuracy: 0.9303\n",
            "Epoch 72: val_loss did not improve from 0.18793\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1917 - accuracy: 0.9319 - val_loss: 0.1891 - val_accuracy: 0.9400\n",
            "Epoch 73/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1775 - accuracy: 0.9401\n",
            "Epoch 73: val_loss improved from 0.18793 to 0.18573, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1783 - accuracy: 0.9394 - val_loss: 0.1857 - val_accuracy: 0.9450\n",
            "Epoch 74/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.9337\n",
            "Epoch 74: val_loss did not improve from 0.18573\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1758 - accuracy: 0.9337 - val_loss: 0.1865 - val_accuracy: 0.9400\n",
            "Epoch 75/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9375\n",
            "Epoch 75: val_loss improved from 0.18573 to 0.18213, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.1889 - accuracy: 0.9381 - val_loss: 0.1821 - val_accuracy: 0.9475\n",
            "Epoch 76/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9331\n",
            "Epoch 76: val_loss did not improve from 0.18213\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1830 - accuracy: 0.9331 - val_loss: 0.1860 - val_accuracy: 0.9400\n",
            "Epoch 77/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9419\n",
            "Epoch 77: val_loss did not improve from 0.18213\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1794 - accuracy: 0.9419 - val_loss: 0.1826 - val_accuracy: 0.9425\n",
            "Epoch 78/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1810 - accuracy: 0.9394\n",
            "Epoch 78: val_loss did not improve from 0.18213\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1790 - accuracy: 0.9406 - val_loss: 0.1828 - val_accuracy: 0.9450\n",
            "Epoch 79/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9471\n",
            "Epoch 79: val_loss improved from 0.18213 to 0.18088, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1695 - accuracy: 0.9469 - val_loss: 0.1809 - val_accuracy: 0.9450\n",
            "Epoch 80/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9388\n",
            "Epoch 80: val_loss improved from 0.18088 to 0.17842, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.1682 - accuracy: 0.9400 - val_loss: 0.1784 - val_accuracy: 0.9500\n",
            "Epoch 81/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 0.9381\n",
            "Epoch 81: val_loss improved from 0.17842 to 0.17341, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.1874 - accuracy: 0.9388 - val_loss: 0.1734 - val_accuracy: 0.9550\n",
            "Epoch 82/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.9381\n",
            "Epoch 82: val_loss improved from 0.17341 to 0.17335, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.1642 - accuracy: 0.9381 - val_loss: 0.1733 - val_accuracy: 0.9500\n",
            "Epoch 83/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9401\n",
            "Epoch 83: val_loss did not improve from 0.17335\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1736 - accuracy: 0.9388 - val_loss: 0.1798 - val_accuracy: 0.9425\n",
            "Epoch 84/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1513 - accuracy: 0.9525\n",
            "Epoch 84: val_loss improved from 0.17335 to 0.16914, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1506 - accuracy: 0.9525 - val_loss: 0.1691 - val_accuracy: 0.9500\n",
            "Epoch 85/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1504 - accuracy: 0.9473\n",
            "Epoch 85: val_loss did not improve from 0.16914\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1609 - accuracy: 0.9444 - val_loss: 0.1713 - val_accuracy: 0.9575\n",
            "Epoch 86/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1600 - accuracy: 0.9492\n",
            "Epoch 86: val_loss did not improve from 0.16914\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1626 - accuracy: 0.9481 - val_loss: 0.1713 - val_accuracy: 0.9525\n",
            "Epoch 87/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1611 - accuracy: 0.9464\n",
            "Epoch 87: val_loss did not improve from 0.16914\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1611 - accuracy: 0.9456 - val_loss: 0.1745 - val_accuracy: 0.9500\n",
            "Epoch 88/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1473 - accuracy: 0.9522\n",
            "Epoch 88: val_loss did not improve from 0.16914\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.1479 - accuracy: 0.9519 - val_loss: 0.1723 - val_accuracy: 0.9525\n",
            "Epoch 89/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1614 - accuracy: 0.9440\n",
            "Epoch 89: val_loss did not improve from 0.16914\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.1662 - accuracy: 0.9419 - val_loss: 0.1731 - val_accuracy: 0.9450\n",
            "Epoch 90/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1475 - accuracy: 0.9458\n",
            "Epoch 90: val_loss did not improve from 0.16914\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.1484 - accuracy: 0.9450 - val_loss: 0.1734 - val_accuracy: 0.9475\n",
            "Epoch 91/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9509\n",
            "Epoch 91: val_loss did not improve from 0.16914\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1365 - accuracy: 0.9519 - val_loss: 0.1712 - val_accuracy: 0.9550\n",
            "Epoch 92/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.9522\n",
            "Epoch 92: val_loss improved from 0.16914 to 0.16777, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 95ms/step - loss: 0.1484 - accuracy: 0.9519 - val_loss: 0.1678 - val_accuracy: 0.9575\n",
            "Epoch 93/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1523 - accuracy: 0.9483\n",
            "Epoch 93: val_loss did not improve from 0.16777\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1551 - accuracy: 0.9481 - val_loss: 0.1691 - val_accuracy: 0.9550\n",
            "Epoch 94/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9581\n",
            "Epoch 94: val_loss did not improve from 0.16777\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1397 - accuracy: 0.9581 - val_loss: 0.1692 - val_accuracy: 0.9575\n",
            "Epoch 95/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.9487\n",
            "Epoch 95: val_loss improved from 0.16777 to 0.16767, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.1410 - accuracy: 0.9488 - val_loss: 0.1677 - val_accuracy: 0.9575\n",
            "Epoch 96/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9560\n",
            "Epoch 96: val_loss improved from 0.16767 to 0.16757, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1291 - accuracy: 0.9569 - val_loss: 0.1676 - val_accuracy: 0.9550\n",
            "Epoch 97/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1337 - accuracy: 0.9544\n",
            "Epoch 97: val_loss did not improve from 0.16757\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1362 - accuracy: 0.9531 - val_loss: 0.1706 - val_accuracy: 0.9525\n",
            "Epoch 98/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1285 - accuracy: 0.9596\n",
            "Epoch 98: val_loss improved from 0.16757 to 0.16378, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1293 - accuracy: 0.9581 - val_loss: 0.1638 - val_accuracy: 0.9575\n",
            "Epoch 99/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.9471\n",
            "Epoch 99: val_loss did not improve from 0.16378\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1414 - accuracy: 0.9475 - val_loss: 0.1657 - val_accuracy: 0.9500\n",
            "Epoch 100/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9522\n",
            "Epoch 100: val_loss did not improve from 0.16378\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1345 - accuracy: 0.9506 - val_loss: 0.1693 - val_accuracy: 0.9550\n",
            "Epoch 101/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9509\n",
            "Epoch 101: val_loss did not improve from 0.16378\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1319 - accuracy: 0.9519 - val_loss: 0.1687 - val_accuracy: 0.9550\n",
            "Epoch 102/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1288 - accuracy: 0.9509\n",
            "Epoch 102: val_loss did not improve from 0.16378\n",
            "50/50 [==============================] - 3s 52ms/step - loss: 0.1287 - accuracy: 0.9500 - val_loss: 0.1641 - val_accuracy: 0.9575\n",
            "Epoch 103/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9587\n",
            "Epoch 103: val_loss improved from 0.16378 to 0.16354, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 94ms/step - loss: 0.1129 - accuracy: 0.9588 - val_loss: 0.1635 - val_accuracy: 0.9575\n",
            "Epoch 104/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1222 - accuracy: 0.9573\n",
            "Epoch 104: val_loss did not improve from 0.16354\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1215 - accuracy: 0.9575 - val_loss: 0.1682 - val_accuracy: 0.9525\n",
            "Epoch 105/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1353 - accuracy: 0.9603\n",
            "Epoch 105: val_loss improved from 0.16354 to 0.16170, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.1352 - accuracy: 0.9594 - val_loss: 0.1617 - val_accuracy: 0.9575\n",
            "Epoch 106/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9579\n",
            "Epoch 106: val_loss did not improve from 0.16170\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1168 - accuracy: 0.9569 - val_loss: 0.1629 - val_accuracy: 0.9550\n",
            "Epoch 107/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9630\n",
            "Epoch 107: val_loss improved from 0.16170 to 0.15957, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1266 - accuracy: 0.9638 - val_loss: 0.1596 - val_accuracy: 0.9550\n",
            "Epoch 108/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 0.9603\n",
            "Epoch 108: val_loss improved from 0.15957 to 0.15854, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1168 - accuracy: 0.9606 - val_loss: 0.1585 - val_accuracy: 0.9575\n",
            "Epoch 109/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1082 - accuracy: 0.9649\n",
            "Epoch 109: val_loss did not improve from 0.15854\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1099 - accuracy: 0.9650 - val_loss: 0.1642 - val_accuracy: 0.9500\n",
            "Epoch 110/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9675\n",
            "Epoch 110: val_loss did not improve from 0.15854\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1135 - accuracy: 0.9675 - val_loss: 0.1648 - val_accuracy: 0.9500\n",
            "Epoch 111/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9649\n",
            "Epoch 111: val_loss did not improve from 0.15854\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1067 - accuracy: 0.9650 - val_loss: 0.1673 - val_accuracy: 0.9500\n",
            "Epoch 112/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9579\n",
            "Epoch 112: val_loss improved from 0.15854 to 0.15841, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1094 - accuracy: 0.9588 - val_loss: 0.1584 - val_accuracy: 0.9575\n",
            "Epoch 113/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9688\n",
            "Epoch 113: val_loss improved from 0.15841 to 0.15583, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1127 - accuracy: 0.9663 - val_loss: 0.1558 - val_accuracy: 0.9600\n",
            "Epoch 114/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.9707\n",
            "Epoch 114: val_loss improved from 0.15583 to 0.15420, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1022 - accuracy: 0.9712 - val_loss: 0.1542 - val_accuracy: 0.9575\n",
            "Epoch 115/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9630\n",
            "Epoch 115: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1084 - accuracy: 0.9638 - val_loss: 0.1556 - val_accuracy: 0.9575\n",
            "Epoch 116/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9668\n",
            "Epoch 116: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0995 - accuracy: 0.9656 - val_loss: 0.1602 - val_accuracy: 0.9575\n",
            "Epoch 117/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9675\n",
            "Epoch 117: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.1011 - accuracy: 0.9669 - val_loss: 0.1585 - val_accuracy: 0.9525\n",
            "Epoch 118/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9556\n",
            "Epoch 118: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 3s 56ms/step - loss: 0.1079 - accuracy: 0.9556 - val_loss: 0.1630 - val_accuracy: 0.9575\n",
            "Epoch 119/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9656\n",
            "Epoch 119: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0997 - accuracy: 0.9656 - val_loss: 0.1610 - val_accuracy: 0.9575\n",
            "Epoch 120/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9669\n",
            "Epoch 120: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.1011 - accuracy: 0.9669 - val_loss: 0.1621 - val_accuracy: 0.9575\n",
            "Epoch 121/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1088 - accuracy: 0.9603\n",
            "Epoch 121: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1073 - accuracy: 0.9613 - val_loss: 0.1547 - val_accuracy: 0.9550\n",
            "Epoch 122/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0985 - accuracy: 0.9642\n",
            "Epoch 122: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0996 - accuracy: 0.9631 - val_loss: 0.1582 - val_accuracy: 0.9575\n",
            "Epoch 123/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 0.9688\n",
            "Epoch 123: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0855 - accuracy: 0.9688 - val_loss: 0.1547 - val_accuracy: 0.9600\n",
            "Epoch 124/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9719\n",
            "Epoch 124: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0909 - accuracy: 0.9712 - val_loss: 0.1575 - val_accuracy: 0.9525\n",
            "Epoch 125/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9726\n",
            "Epoch 125: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0836 - accuracy: 0.9731 - val_loss: 0.1561 - val_accuracy: 0.9550\n",
            "Epoch 126/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0844 - accuracy: 0.9714\n",
            "Epoch 126: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0824 - accuracy: 0.9725 - val_loss: 0.1577 - val_accuracy: 0.9525\n",
            "Epoch 127/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9636\n",
            "Epoch 127: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0978 - accuracy: 0.9644 - val_loss: 0.1582 - val_accuracy: 0.9575\n",
            "Epoch 128/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9636\n",
            "Epoch 128: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0935 - accuracy: 0.9631 - val_loss: 0.1687 - val_accuracy: 0.9525\n",
            "Epoch 129/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0853 - accuracy: 0.9726\n",
            "Epoch 129: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0857 - accuracy: 0.9725 - val_loss: 0.1603 - val_accuracy: 0.9575\n",
            "Epoch 130/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 0.9649\n",
            "Epoch 130: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0883 - accuracy: 0.9650 - val_loss: 0.1619 - val_accuracy: 0.9500\n",
            "Epoch 131/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 0.9713\n",
            "Epoch 131: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0794 - accuracy: 0.9706 - val_loss: 0.1580 - val_accuracy: 0.9575\n",
            "Epoch 132/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9662\n",
            "Epoch 132: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0967 - accuracy: 0.9656 - val_loss: 0.1566 - val_accuracy: 0.9575\n",
            "Epoch 133/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9656\n",
            "Epoch 133: val_loss did not improve from 0.15420\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0854 - accuracy: 0.9656 - val_loss: 0.1604 - val_accuracy: 0.9550\n",
            "Epoch 134/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9636\n",
            "Epoch 134: val_loss improved from 0.15420 to 0.15229, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 109ms/step - loss: 0.0954 - accuracy: 0.9644 - val_loss: 0.1523 - val_accuracy: 0.9575\n",
            "Epoch 135/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9700\n",
            "Epoch 135: val_loss did not improve from 0.15229\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0820 - accuracy: 0.9706 - val_loss: 0.1532 - val_accuracy: 0.9600\n",
            "Epoch 136/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0955 - accuracy: 0.9694\n",
            "Epoch 136: val_loss improved from 0.15229 to 0.14838, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.0961 - accuracy: 0.9688 - val_loss: 0.1484 - val_accuracy: 0.9600\n",
            "Epoch 137/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9764\n",
            "Epoch 137: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0712 - accuracy: 0.9762 - val_loss: 0.1568 - val_accuracy: 0.9575\n",
            "Epoch 138/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9756\n",
            "Epoch 138: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0846 - accuracy: 0.9756 - val_loss: 0.1524 - val_accuracy: 0.9550\n",
            "Epoch 139/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9739\n",
            "Epoch 139: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0724 - accuracy: 0.9744 - val_loss: 0.1525 - val_accuracy: 0.9550\n",
            "Epoch 140/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 0.9739\n",
            "Epoch 140: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0762 - accuracy: 0.9737 - val_loss: 0.1506 - val_accuracy: 0.9575\n",
            "Epoch 141/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.9775\n",
            "Epoch 141: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0717 - accuracy: 0.9775 - val_loss: 0.1537 - val_accuracy: 0.9600\n",
            "Epoch 142/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 0.9739\n",
            "Epoch 142: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0814 - accuracy: 0.9731 - val_loss: 0.1528 - val_accuracy: 0.9575\n",
            "Epoch 143/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9796\n",
            "Epoch 143: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0717 - accuracy: 0.9800 - val_loss: 0.1514 - val_accuracy: 0.9525\n",
            "Epoch 144/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 0.9758\n",
            "Epoch 144: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0707 - accuracy: 0.9756 - val_loss: 0.1528 - val_accuracy: 0.9575\n",
            "Epoch 145/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0658 - accuracy: 0.9779\n",
            "Epoch 145: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0661 - accuracy: 0.9775 - val_loss: 0.1540 - val_accuracy: 0.9575\n",
            "Epoch 146/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0750 - accuracy: 0.9694\n",
            "Epoch 146: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 47ms/step - loss: 0.0736 - accuracy: 0.9700 - val_loss: 0.1492 - val_accuracy: 0.9600\n",
            "Epoch 147/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9681\n",
            "Epoch 147: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0790 - accuracy: 0.9681 - val_loss: 0.1507 - val_accuracy: 0.9575\n",
            "Epoch 148/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0757 - accuracy: 0.9681\n",
            "Epoch 148: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0747 - accuracy: 0.9688 - val_loss: 0.1522 - val_accuracy: 0.9575\n",
            "Epoch 149/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9737\n",
            "Epoch 149: val_loss did not improve from 0.14838\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0735 - accuracy: 0.9737 - val_loss: 0.1522 - val_accuracy: 0.9575\n",
            "Epoch 150/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0696 - accuracy: 0.9770\n",
            "Epoch 150: val_loss improved from 0.14838 to 0.14794, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 104ms/step - loss: 0.0694 - accuracy: 0.9769 - val_loss: 0.1479 - val_accuracy: 0.9600\n",
            "Epoch 151/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9790\n",
            "Epoch 151: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0702 - accuracy: 0.9781 - val_loss: 0.1555 - val_accuracy: 0.9550\n",
            "Epoch 152/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0660 - accuracy: 0.9772\n",
            "Epoch 152: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0653 - accuracy: 0.9781 - val_loss: 0.1512 - val_accuracy: 0.9550\n",
            "Epoch 153/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0727 - accuracy: 0.9785\n",
            "Epoch 153: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0713 - accuracy: 0.9794 - val_loss: 0.1511 - val_accuracy: 0.9600\n",
            "Epoch 154/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9841\n",
            "Epoch 154: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0548 - accuracy: 0.9837 - val_loss: 0.1550 - val_accuracy: 0.9575\n",
            "Epoch 155/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9831\n",
            "Epoch 155: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 3s 57ms/step - loss: 0.0529 - accuracy: 0.9831 - val_loss: 0.1508 - val_accuracy: 0.9600\n",
            "Epoch 156/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9725\n",
            "Epoch 156: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0728 - accuracy: 0.9725 - val_loss: 0.1524 - val_accuracy: 0.9600\n",
            "Epoch 157/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9796\n",
            "Epoch 157: val_loss did not improve from 0.14794\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0680 - accuracy: 0.9787 - val_loss: 0.1481 - val_accuracy: 0.9600\n",
            "Epoch 158/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0681 - accuracy: 0.9707\n",
            "Epoch 158: val_loss improved from 0.14794 to 0.14581, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.0698 - accuracy: 0.9694 - val_loss: 0.1458 - val_accuracy: 0.9600\n",
            "Epoch 159/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0678 - accuracy: 0.9766\n",
            "Epoch 159: val_loss did not improve from 0.14581\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0697 - accuracy: 0.9762 - val_loss: 0.1532 - val_accuracy: 0.9550\n",
            "Epoch 160/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9834\n",
            "Epoch 160: val_loss did not improve from 0.14581\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0625 - accuracy: 0.9831 - val_loss: 0.1496 - val_accuracy: 0.9575\n",
            "Epoch 161/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9764\n",
            "Epoch 161: val_loss did not improve from 0.14581\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0596 - accuracy: 0.9769 - val_loss: 0.1463 - val_accuracy: 0.9575\n",
            "Epoch 162/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9806\n",
            "Epoch 162: val_loss did not improve from 0.14581\n",
            "50/50 [==============================] - 2s 44ms/step - loss: 0.0588 - accuracy: 0.9806 - val_loss: 0.1523 - val_accuracy: 0.9575\n",
            "Epoch 163/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9853\n",
            "Epoch 163: val_loss did not improve from 0.14581\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0515 - accuracy: 0.9837 - val_loss: 0.1527 - val_accuracy: 0.9575\n",
            "Epoch 164/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0581 - accuracy: 0.9802\n",
            "Epoch 164: val_loss improved from 0.14581 to 0.14448, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 105ms/step - loss: 0.0574 - accuracy: 0.9806 - val_loss: 0.1445 - val_accuracy: 0.9575\n",
            "Epoch 165/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0532 - accuracy: 0.9798\n",
            "Epoch 165: val_loss improved from 0.14448 to 0.14124, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.0540 - accuracy: 0.9794 - val_loss: 0.1412 - val_accuracy: 0.9575\n",
            "Epoch 166/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0687 - accuracy: 0.9790\n",
            "Epoch 166: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0679 - accuracy: 0.9794 - val_loss: 0.1454 - val_accuracy: 0.9600\n",
            "Epoch 167/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9764\n",
            "Epoch 167: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0614 - accuracy: 0.9769 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
            "Epoch 168/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9872\n",
            "Epoch 168: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.1451 - val_accuracy: 0.9575\n",
            "Epoch 169/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0550 - accuracy: 0.9792\n",
            "Epoch 169: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0551 - accuracy: 0.9794 - val_loss: 0.1519 - val_accuracy: 0.9525\n",
            "Epoch 170/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9828\n",
            "Epoch 170: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 0.1427 - val_accuracy: 0.9600\n",
            "Epoch 171/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0509 - accuracy: 0.9834\n",
            "Epoch 171: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.0529 - accuracy: 0.9819 - val_loss: 0.1480 - val_accuracy: 0.9550\n",
            "Epoch 172/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9821\n",
            "Epoch 172: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0543 - accuracy: 0.9825 - val_loss: 0.1478 - val_accuracy: 0.9600\n",
            "Epoch 173/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9790\n",
            "Epoch 173: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0573 - accuracy: 0.9794 - val_loss: 0.1452 - val_accuracy: 0.9550\n",
            "Epoch 174/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9853\n",
            "Epoch 174: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0467 - accuracy: 0.9856 - val_loss: 0.1462 - val_accuracy: 0.9575\n",
            "Epoch 175/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0606 - accuracy: 0.9809\n",
            "Epoch 175: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.1484 - val_accuracy: 0.9600\n",
            "Epoch 176/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 0.9802\n",
            "Epoch 176: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 48ms/step - loss: 0.0515 - accuracy: 0.9806 - val_loss: 0.1478 - val_accuracy: 0.9600\n",
            "Epoch 177/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9802\n",
            "Epoch 177: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0671 - accuracy: 0.9806 - val_loss: 0.1468 - val_accuracy: 0.9575\n",
            "Epoch 178/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 0.9872\n",
            "Epoch 178: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0423 - accuracy: 0.9875 - val_loss: 0.1417 - val_accuracy: 0.9625\n",
            "Epoch 179/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9802\n",
            "Epoch 179: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
            "Epoch 180/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9841\n",
            "Epoch 180: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0503 - accuracy: 0.9837 - val_loss: 0.1443 - val_accuracy: 0.9600\n",
            "Epoch 181/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9847\n",
            "Epoch 181: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0474 - accuracy: 0.9850 - val_loss: 0.1510 - val_accuracy: 0.9500\n",
            "Epoch 182/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0492 - accuracy: 0.9818\n",
            "Epoch 182: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.1525 - val_accuracy: 0.9600\n",
            "Epoch 183/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0456 - accuracy: 0.9853\n",
            "Epoch 183: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0453 - accuracy: 0.9856 - val_loss: 0.1512 - val_accuracy: 0.9575\n",
            "Epoch 184/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0510 - accuracy: 0.9837\n",
            "Epoch 184: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 0.1477 - val_accuracy: 0.9575\n",
            "Epoch 185/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9777\n",
            "Epoch 185: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0705 - accuracy: 0.9775 - val_loss: 0.1523 - val_accuracy: 0.9550\n",
            "Epoch 186/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9860\n",
            "Epoch 186: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.1492 - val_accuracy: 0.9550\n",
            "Epoch 187/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0572 - accuracy: 0.9746\n",
            "Epoch 187: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0557 - accuracy: 0.9750 - val_loss: 0.1474 - val_accuracy: 0.9575\n",
            "Epoch 188/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9898\n",
            "Epoch 188: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0405 - accuracy: 0.9900 - val_loss: 0.1470 - val_accuracy: 0.9600\n",
            "Epoch 189/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0516 - accuracy: 0.9796\n",
            "Epoch 189: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0508 - accuracy: 0.9800 - val_loss: 0.1434 - val_accuracy: 0.9600\n",
            "Epoch 190/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9885\n",
            "Epoch 190: val_loss did not improve from 0.14124\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 0.1428 - val_accuracy: 0.9575\n",
            "Epoch 191/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0456 - accuracy: 0.9863\n",
            "Epoch 191: val_loss improved from 0.14124 to 0.14022, saving model to /content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.0457 - accuracy: 0.9856 - val_loss: 0.1402 - val_accuracy: 0.9575\n",
            "Epoch 192/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9872\n",
            "Epoch 192: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.1484 - val_accuracy: 0.9575\n",
            "Epoch 193/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9828\n",
            "Epoch 193: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 0.1491 - val_accuracy: 0.9575\n",
            "Epoch 194/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9834\n",
            "Epoch 194: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0423 - accuracy: 0.9837 - val_loss: 0.1466 - val_accuracy: 0.9575\n",
            "Epoch 195/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9841\n",
            "Epoch 195: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.1443 - val_accuracy: 0.9575\n",
            "Epoch 196/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9866\n",
            "Epoch 196: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 49ms/step - loss: 0.0437 - accuracy: 0.9856 - val_loss: 0.1467 - val_accuracy: 0.9600\n",
            "Epoch 197/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9866\n",
            "Epoch 197: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 0.1423 - val_accuracy: 0.9600\n",
            "Epoch 198/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0399 - accuracy: 0.9870\n",
            "Epoch 198: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0408 - accuracy: 0.9869 - val_loss: 0.1456 - val_accuracy: 0.9600\n",
            "Epoch 199/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0324 - accuracy: 0.9922\n",
            "Epoch 199: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0329 - accuracy: 0.9919 - val_loss: 0.1499 - val_accuracy: 0.9600\n",
            "Epoch 200/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9885\n",
            "Epoch 200: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0451 - accuracy: 0.9887 - val_loss: 0.1487 - val_accuracy: 0.9575\n",
            "Epoch 201/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0378 - accuracy: 0.9870\n",
            "Epoch 201: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 0.1496 - val_accuracy: 0.9575\n",
            "Epoch 202/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0373 - accuracy: 0.9844\n",
            "Epoch 202: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0376 - accuracy: 0.9844 - val_loss: 0.1486 - val_accuracy: 0.9575\n",
            "Epoch 203/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9828\n",
            "Epoch 203: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0505 - accuracy: 0.9831 - val_loss: 0.1453 - val_accuracy: 0.9575\n",
            "Epoch 204/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9872\n",
            "Epoch 204: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.1522 - val_accuracy: 0.9550\n",
            "Epoch 205/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9841\n",
            "Epoch 205: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 50ms/step - loss: 0.0403 - accuracy: 0.9844 - val_loss: 0.1499 - val_accuracy: 0.9575\n",
            "Epoch 206/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 0.9866\n",
            "Epoch 206: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0434 - accuracy: 0.9869 - val_loss: 0.1524 - val_accuracy: 0.9575\n",
            "Epoch 207/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9892\n",
            "Epoch 207: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 0.1486 - val_accuracy: 0.9600\n",
            "Epoch 208/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9834\n",
            "Epoch 208: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.1445 - val_accuracy: 0.9575\n",
            "Epoch 209/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0335 - accuracy: 0.9915\n",
            "Epoch 209: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0362 - accuracy: 0.9906 - val_loss: 0.1461 - val_accuracy: 0.9575\n",
            "Epoch 210/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9866\n",
            "Epoch 210: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0373 - accuracy: 0.9869 - val_loss: 0.1442 - val_accuracy: 0.9600\n",
            "Epoch 211/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9872\n",
            "Epoch 211: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 0.1534 - val_accuracy: 0.9575\n",
            "Epoch 212/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9885\n",
            "Epoch 212: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.1452 - val_accuracy: 0.9575\n",
            "Epoch 213/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9815\n",
            "Epoch 213: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0415 - accuracy: 0.9819 - val_loss: 0.1465 - val_accuracy: 0.9600\n",
            "Epoch 214/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9802\n",
            "Epoch 214: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0501 - accuracy: 0.9794 - val_loss: 0.1440 - val_accuracy: 0.9575\n",
            "Epoch 215/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9881\n",
            "Epoch 215: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0373 - accuracy: 0.9881 - val_loss: 0.1481 - val_accuracy: 0.9600\n",
            "Epoch 216/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9894\n",
            "Epoch 216: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0361 - accuracy: 0.9894 - val_loss: 0.1461 - val_accuracy: 0.9600\n",
            "Epoch 217/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9885\n",
            "Epoch 217: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.1441 - val_accuracy: 0.9600\n",
            "Epoch 218/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9872\n",
            "Epoch 218: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 0.1497 - val_accuracy: 0.9600\n",
            "Epoch 219/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0311 - accuracy: 0.9909\n",
            "Epoch 219: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.1451 - val_accuracy: 0.9600\n",
            "Epoch 220/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9943\n",
            "Epoch 220: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0239 - accuracy: 0.9944 - val_loss: 0.1468 - val_accuracy: 0.9575\n",
            "Epoch 221/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9828\n",
            "Epoch 221: val_loss did not improve from 0.14022\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0398 - accuracy: 0.9825 - val_loss: 0.1487 - val_accuracy: 0.9575\n",
            "63/63 [==============================] - 2s 16ms/step - loss: 0.4746 - accuracy: 0.8850\n",
            "Test accuracy, 19 run, after finetuning: 0.8849999904632568\n",
            "Epoch 1/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 2.5009 - accuracy: 0.6186\n",
            "Epoch 1: val_loss improved from inf to 1.79116, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 32s 207ms/step - loss: 2.4994 - accuracy: 0.6181 - val_loss: 1.7912 - val_accuracy: 0.6325\n",
            "Epoch 2/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.6848 - accuracy: 0.6700\n",
            "Epoch 2: val_loss improved from 1.79116 to 1.31046, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 1.6848 - accuracy: 0.6700 - val_loss: 1.3105 - val_accuracy: 0.6750\n",
            "Epoch 3/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.2882 - accuracy: 0.6964\n",
            "Epoch 3: val_loss improved from 1.31046 to 1.05116, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 1.2698 - accuracy: 0.6988 - val_loss: 1.0512 - val_accuracy: 0.7000\n",
            "Epoch 4/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.0507 - accuracy: 0.7092\n",
            "Epoch 4: val_loss improved from 1.05116 to 0.88680, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 1.0428 - accuracy: 0.7100 - val_loss: 0.8868 - val_accuracy: 0.7250\n",
            "Epoch 5/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9109 - accuracy: 0.7423\n",
            "Epoch 5: val_loss improved from 0.88680 to 0.78422, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 93ms/step - loss: 0.9041 - accuracy: 0.7437 - val_loss: 0.7842 - val_accuracy: 0.7325\n",
            "Epoch 6/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8501 - accuracy: 0.7469\n",
            "Epoch 6: val_loss improved from 0.78422 to 0.70846, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 9s 177ms/step - loss: 0.8501 - accuracy: 0.7469 - val_loss: 0.7085 - val_accuracy: 0.7550\n",
            "Epoch 7/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7662 - accuracy: 0.7596\n",
            "Epoch 7: val_loss improved from 0.70846 to 0.66211, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.7632 - accuracy: 0.7606 - val_loss: 0.6621 - val_accuracy: 0.7775\n",
            "Epoch 8/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7123 - accuracy: 0.7710\n",
            "Epoch 8: val_loss improved from 0.66211 to 0.62498, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.7066 - accuracy: 0.7725 - val_loss: 0.6250 - val_accuracy: 0.7825\n",
            "Epoch 9/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6754 - accuracy: 0.7666\n",
            "Epoch 9: val_loss improved from 0.62498 to 0.59761, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.6728 - accuracy: 0.7688 - val_loss: 0.5976 - val_accuracy: 0.7850\n",
            "Epoch 10/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6596 - accuracy: 0.7857\n",
            "Epoch 10: val_loss improved from 0.59761 to 0.57418, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.6635 - accuracy: 0.7831 - val_loss: 0.5742 - val_accuracy: 0.7900\n",
            "Epoch 11/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6340 - accuracy: 0.7925\n",
            "Epoch 11: val_loss improved from 0.57418 to 0.55119, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.6340 - accuracy: 0.7925 - val_loss: 0.5512 - val_accuracy: 0.7950\n",
            "Epoch 12/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.8125\n",
            "Epoch 12: val_loss improved from 0.55119 to 0.53194, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.5645 - accuracy: 0.8125 - val_loss: 0.5319 - val_accuracy: 0.8050\n",
            "Epoch 13/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.8093\n",
            "Epoch 13: val_loss improved from 0.53194 to 0.51534, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.5733 - accuracy: 0.8069 - val_loss: 0.5153 - val_accuracy: 0.8100\n",
            "Epoch 14/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.5624 - accuracy: 0.8112\n",
            "Epoch 14: val_loss improved from 0.51534 to 0.49829, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.5555 - accuracy: 0.8138 - val_loss: 0.4983 - val_accuracy: 0.8225\n",
            "Epoch 15/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5629 - accuracy: 0.8157\n",
            "Epoch 15: val_loss improved from 0.49829 to 0.48596, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.5637 - accuracy: 0.8156 - val_loss: 0.4860 - val_accuracy: 0.8275\n",
            "Epoch 16/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.8312\n",
            "Epoch 16: val_loss improved from 0.48596 to 0.47040, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.4920 - accuracy: 0.8313 - val_loss: 0.4704 - val_accuracy: 0.8425\n",
            "Epoch 17/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.8381\n",
            "Epoch 17: val_loss improved from 0.47040 to 0.45543, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.4876 - accuracy: 0.8381 - val_loss: 0.4554 - val_accuracy: 0.8400\n",
            "Epoch 18/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4850 - accuracy: 0.8361\n",
            "Epoch 18: val_loss improved from 0.45543 to 0.44214, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.4861 - accuracy: 0.8356 - val_loss: 0.4421 - val_accuracy: 0.8400\n",
            "Epoch 19/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4775 - accuracy: 0.8412\n",
            "Epoch 19: val_loss improved from 0.44214 to 0.43175, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.4737 - accuracy: 0.8425 - val_loss: 0.4317 - val_accuracy: 0.8450\n",
            "Epoch 20/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4568 - accuracy: 0.8450\n",
            "Epoch 20: val_loss improved from 0.43175 to 0.41959, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 91ms/step - loss: 0.4523 - accuracy: 0.8469 - val_loss: 0.4196 - val_accuracy: 0.8500\n",
            "Epoch 21/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4644 - accuracy: 0.8476\n",
            "Epoch 21: val_loss improved from 0.41959 to 0.40962, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.4593 - accuracy: 0.8500 - val_loss: 0.4096 - val_accuracy: 0.8600\n",
            "Epoch 22/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.4252 - accuracy: 0.8516\n",
            "Epoch 22: val_loss improved from 0.40962 to 0.39961, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.4275 - accuracy: 0.8519 - val_loss: 0.3996 - val_accuracy: 0.8600\n",
            "Epoch 23/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4317 - accuracy: 0.8501\n",
            "Epoch 23: val_loss improved from 0.39961 to 0.38836, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.4291 - accuracy: 0.8506 - val_loss: 0.3884 - val_accuracy: 0.8600\n",
            "Epoch 24/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.8667\n",
            "Epoch 24: val_loss improved from 0.38836 to 0.38026, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.4110 - accuracy: 0.8687 - val_loss: 0.3803 - val_accuracy: 0.8600\n",
            "Epoch 25/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4116 - accuracy: 0.8578\n",
            "Epoch 25: val_loss improved from 0.38026 to 0.37395, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.4119 - accuracy: 0.8575 - val_loss: 0.3739 - val_accuracy: 0.8625\n",
            "Epoch 26/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4202 - accuracy: 0.8686\n",
            "Epoch 26: val_loss improved from 0.37395 to 0.36598, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.4212 - accuracy: 0.8681 - val_loss: 0.3660 - val_accuracy: 0.8650\n",
            "Epoch 27/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.8706\n",
            "Epoch 27: val_loss improved from 0.36598 to 0.35939, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.3858 - accuracy: 0.8706 - val_loss: 0.3594 - val_accuracy: 0.8650\n",
            "Epoch 28/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.8718\n",
            "Epoch 28: val_loss improved from 0.35939 to 0.35473, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.3822 - accuracy: 0.8725 - val_loss: 0.3547 - val_accuracy: 0.8675\n",
            "Epoch 29/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3715 - accuracy: 0.8814\n",
            "Epoch 29: val_loss improved from 0.35473 to 0.34533, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.3672 - accuracy: 0.8831 - val_loss: 0.3453 - val_accuracy: 0.8750\n",
            "Epoch 30/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3396 - accuracy: 0.8835\n",
            "Epoch 30: val_loss improved from 0.34533 to 0.33900, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 0.3457 - accuracy: 0.8806 - val_loss: 0.3390 - val_accuracy: 0.8750\n",
            "Epoch 31/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3385 - accuracy: 0.8932\n",
            "Epoch 31: val_loss improved from 0.33900 to 0.33123, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.3365 - accuracy: 0.8944 - val_loss: 0.3312 - val_accuracy: 0.8850\n",
            "Epoch 32/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.3287 - accuracy: 0.8952\n",
            "Epoch 32: val_loss improved from 0.33123 to 0.32652, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.3376 - accuracy: 0.8925 - val_loss: 0.3265 - val_accuracy: 0.8800\n",
            "Epoch 33/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.8871\n",
            "Epoch 33: val_loss improved from 0.32652 to 0.32211, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3335 - accuracy: 0.8856 - val_loss: 0.3221 - val_accuracy: 0.8900\n",
            "Epoch 34/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.8890\n",
            "Epoch 34: val_loss improved from 0.32211 to 0.31597, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 85ms/step - loss: 0.3403 - accuracy: 0.8888 - val_loss: 0.3160 - val_accuracy: 0.8925\n",
            "Epoch 35/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.8865\n",
            "Epoch 35: val_loss improved from 0.31597 to 0.30982, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.3145 - accuracy: 0.8875 - val_loss: 0.3098 - val_accuracy: 0.8925\n",
            "Epoch 36/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3273 - accuracy: 0.8960\n",
            "Epoch 36: val_loss improved from 0.30982 to 0.30752, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.3284 - accuracy: 0.8944 - val_loss: 0.3075 - val_accuracy: 0.8950\n",
            "Epoch 37/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3199 - accuracy: 0.8922\n",
            "Epoch 37: val_loss improved from 0.30752 to 0.29977, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.3161 - accuracy: 0.8938 - val_loss: 0.2998 - val_accuracy: 0.8950\n",
            "Epoch 38/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.8884\n",
            "Epoch 38: val_loss improved from 0.29977 to 0.29450, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 90ms/step - loss: 0.3098 - accuracy: 0.8881 - val_loss: 0.2945 - val_accuracy: 0.9025\n",
            "Epoch 39/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2824 - accuracy: 0.9018\n",
            "Epoch 39: val_loss improved from 0.29450 to 0.29070, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.2817 - accuracy: 0.9019 - val_loss: 0.2907 - val_accuracy: 0.9025\n",
            "Epoch 40/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2968 - accuracy: 0.9018\n",
            "Epoch 40: val_loss improved from 0.29070 to 0.28507, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.2954 - accuracy: 0.9025 - val_loss: 0.2851 - val_accuracy: 0.9050\n",
            "Epoch 41/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.9056\n",
            "Epoch 41: val_loss improved from 0.28507 to 0.28293, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 92ms/step - loss: 0.2875 - accuracy: 0.9050 - val_loss: 0.2829 - val_accuracy: 0.9100\n",
            "Epoch 42/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.9062\n",
            "Epoch 42: val_loss improved from 0.28293 to 0.27877, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.2835 - accuracy: 0.9062 - val_loss: 0.2788 - val_accuracy: 0.9150\n",
            "Epoch 43/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9069\n",
            "Epoch 43: val_loss improved from 0.27877 to 0.27325, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2731 - accuracy: 0.9069 - val_loss: 0.2733 - val_accuracy: 0.9125\n",
            "Epoch 44/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.9094\n",
            "Epoch 44: val_loss improved from 0.27325 to 0.27154, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.2733 - accuracy: 0.9094 - val_loss: 0.2715 - val_accuracy: 0.9100\n",
            "Epoch 45/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2753 - accuracy: 0.9031\n",
            "Epoch 45: val_loss improved from 0.27154 to 0.26872, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.2753 - accuracy: 0.9031 - val_loss: 0.2687 - val_accuracy: 0.9125\n",
            "Epoch 46/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2609 - accuracy: 0.9049\n",
            "Epoch 46: val_loss improved from 0.26872 to 0.26602, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2644 - accuracy: 0.9050 - val_loss: 0.2660 - val_accuracy: 0.9200\n",
            "Epoch 47/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2636 - accuracy: 0.9145\n",
            "Epoch 47: val_loss improved from 0.26602 to 0.26286, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.2643 - accuracy: 0.9137 - val_loss: 0.2629 - val_accuracy: 0.9150\n",
            "Epoch 48/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2730 - accuracy: 0.9141\n",
            "Epoch 48: val_loss improved from 0.26286 to 0.25864, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 101ms/step - loss: 0.2728 - accuracy: 0.9144 - val_loss: 0.2586 - val_accuracy: 0.9175\n",
            "Epoch 49/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9260\n",
            "Epoch 49: val_loss improved from 0.25864 to 0.25525, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2306 - accuracy: 0.9262 - val_loss: 0.2552 - val_accuracy: 0.9200\n",
            "Epoch 50/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2572 - accuracy: 0.9114\n",
            "Epoch 50: val_loss improved from 0.25525 to 0.25117, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2568 - accuracy: 0.9119 - val_loss: 0.2512 - val_accuracy: 0.9200\n",
            "Epoch 51/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2313 - accuracy: 0.9180\n",
            "Epoch 51: val_loss improved from 0.25117 to 0.24752, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.2292 - accuracy: 0.9187 - val_loss: 0.2475 - val_accuracy: 0.9200\n",
            "Epoch 52/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2273 - accuracy: 0.9222\n",
            "Epoch 52: val_loss improved from 0.24752 to 0.24488, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 83ms/step - loss: 0.2272 - accuracy: 0.9219 - val_loss: 0.2449 - val_accuracy: 0.9175\n",
            "Epoch 53/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9175\n",
            "Epoch 53: val_loss improved from 0.24488 to 0.24350, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.2416 - accuracy: 0.9175 - val_loss: 0.2435 - val_accuracy: 0.9200\n",
            "Epoch 54/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2156 - accuracy: 0.9247\n",
            "Epoch 54: val_loss improved from 0.24350 to 0.24132, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2155 - accuracy: 0.9237 - val_loss: 0.2413 - val_accuracy: 0.9225\n",
            "Epoch 55/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2331 - accuracy: 0.9209\n",
            "Epoch 55: val_loss improved from 0.24132 to 0.24059, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 89ms/step - loss: 0.2301 - accuracy: 0.9225 - val_loss: 0.2406 - val_accuracy: 0.9250\n",
            "Epoch 56/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9292\n",
            "Epoch 56: val_loss improved from 0.24059 to 0.23816, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2213 - accuracy: 0.9287 - val_loss: 0.2382 - val_accuracy: 0.9250\n",
            "Epoch 57/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9267\n",
            "Epoch 57: val_loss improved from 0.23816 to 0.23621, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2200 - accuracy: 0.9256 - val_loss: 0.2362 - val_accuracy: 0.9275\n",
            "Epoch 58/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2269 - accuracy: 0.9290\n",
            "Epoch 58: val_loss improved from 0.23621 to 0.23450, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.2274 - accuracy: 0.9294 - val_loss: 0.2345 - val_accuracy: 0.9225\n",
            "Epoch 59/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2310 - accuracy: 0.9228\n",
            "Epoch 59: val_loss improved from 0.23450 to 0.23219, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.2281 - accuracy: 0.9237 - val_loss: 0.2322 - val_accuracy: 0.9300\n",
            "Epoch 60/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1991 - accuracy: 0.9316\n",
            "Epoch 60: val_loss improved from 0.23219 to 0.22812, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1978 - accuracy: 0.9319 - val_loss: 0.2281 - val_accuracy: 0.9300\n",
            "Epoch 61/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2072 - accuracy: 0.9298\n",
            "Epoch 61: val_loss improved from 0.22812 to 0.22716, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2045 - accuracy: 0.9306 - val_loss: 0.2272 - val_accuracy: 0.9275\n",
            "Epoch 62/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.2031 - accuracy: 0.9316\n",
            "Epoch 62: val_loss improved from 0.22716 to 0.22497, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 5s 91ms/step - loss: 0.2119 - accuracy: 0.9287 - val_loss: 0.2250 - val_accuracy: 0.9250\n",
            "Epoch 63/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.9356\n",
            "Epoch 63: val_loss improved from 0.22497 to 0.22371, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1955 - accuracy: 0.9356 - val_loss: 0.2237 - val_accuracy: 0.9350\n",
            "Epoch 64/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1988 - accuracy: 0.9316\n",
            "Epoch 64: val_loss improved from 0.22371 to 0.22049, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.2062 - accuracy: 0.9306 - val_loss: 0.2205 - val_accuracy: 0.9325\n",
            "Epoch 65/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.9324\n",
            "Epoch 65: val_loss improved from 0.22049 to 0.21875, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.2052 - accuracy: 0.9325 - val_loss: 0.2187 - val_accuracy: 0.9350\n",
            "Epoch 66/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.9324\n",
            "Epoch 66: val_loss improved from 0.21875 to 0.21609, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 6s 113ms/step - loss: 0.1887 - accuracy: 0.9325 - val_loss: 0.2161 - val_accuracy: 0.9325\n",
            "Epoch 67/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.9362\n",
            "Epoch 67: val_loss improved from 0.21609 to 0.21394, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.1828 - accuracy: 0.9356 - val_loss: 0.2139 - val_accuracy: 0.9350\n",
            "Epoch 68/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9462\n",
            "Epoch 68: val_loss improved from 0.21394 to 0.21243, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1720 - accuracy: 0.9463 - val_loss: 0.2124 - val_accuracy: 0.9350\n",
            "Epoch 69/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9381\n",
            "Epoch 69: val_loss improved from 0.21243 to 0.21009, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 86ms/step - loss: 0.1955 - accuracy: 0.9388 - val_loss: 0.2101 - val_accuracy: 0.9350\n",
            "Epoch 70/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.9318\n",
            "Epoch 70: val_loss did not improve from 0.21009\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1960 - accuracy: 0.9312 - val_loss: 0.2105 - val_accuracy: 0.9325\n",
            "Epoch 71/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9407\n",
            "Epoch 71: val_loss improved from 0.21009 to 0.20877, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1733 - accuracy: 0.9413 - val_loss: 0.2088 - val_accuracy: 0.9325\n",
            "Epoch 72/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1720 - accuracy: 0.9460\n",
            "Epoch 72: val_loss improved from 0.20877 to 0.20759, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.1730 - accuracy: 0.9444 - val_loss: 0.2076 - val_accuracy: 0.9325\n",
            "Epoch 73/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9439\n",
            "Epoch 73: val_loss improved from 0.20759 to 0.20612, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 87ms/step - loss: 0.1678 - accuracy: 0.9450 - val_loss: 0.2061 - val_accuracy: 0.9400\n",
            "Epoch 74/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1671 - accuracy: 0.9434\n",
            "Epoch 74: val_loss improved from 0.20612 to 0.20537, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1712 - accuracy: 0.9425 - val_loss: 0.2054 - val_accuracy: 0.9350\n",
            "Epoch 75/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1803 - accuracy: 0.9401\n",
            "Epoch 75: val_loss improved from 0.20537 to 0.20292, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1805 - accuracy: 0.9388 - val_loss: 0.2029 - val_accuracy: 0.9350\n",
            "Epoch 76/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9381\n",
            "Epoch 76: val_loss improved from 0.20292 to 0.20242, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.1798 - accuracy: 0.9381 - val_loss: 0.2024 - val_accuracy: 0.9350\n",
            "Epoch 77/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9519\n",
            "Epoch 77: val_loss improved from 0.20242 to 0.20168, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1608 - accuracy: 0.9519 - val_loss: 0.2017 - val_accuracy: 0.9400\n",
            "Epoch 78/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9452\n",
            "Epoch 78: val_loss improved from 0.20168 to 0.19829, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1657 - accuracy: 0.9438 - val_loss: 0.1983 - val_accuracy: 0.9400\n",
            "Epoch 79/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9481\n",
            "Epoch 79: val_loss improved from 0.19829 to 0.19678, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 75ms/step - loss: 0.1548 - accuracy: 0.9481 - val_loss: 0.1968 - val_accuracy: 0.9400\n",
            "Epoch 80/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9503\n",
            "Epoch 80: val_loss did not improve from 0.19678\n",
            "50/50 [==============================] - 3s 58ms/step - loss: 0.1583 - accuracy: 0.9500 - val_loss: 0.1975 - val_accuracy: 0.9400\n",
            "Epoch 81/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1468 - accuracy: 0.9506\n",
            "Epoch 81: val_loss improved from 0.19678 to 0.19575, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 88ms/step - loss: 0.1468 - accuracy: 0.9506 - val_loss: 0.1957 - val_accuracy: 0.9375\n",
            "Epoch 82/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1533 - accuracy: 0.9420\n",
            "Epoch 82: val_loss improved from 0.19575 to 0.19485, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 73ms/step - loss: 0.1538 - accuracy: 0.9419 - val_loss: 0.1949 - val_accuracy: 0.9375\n",
            "Epoch 83/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9362\n",
            "Epoch 83: val_loss improved from 0.19485 to 0.19430, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 71ms/step - loss: 0.1719 - accuracy: 0.9375 - val_loss: 0.1943 - val_accuracy: 0.9350\n",
            "Epoch 84/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1500 - accuracy: 0.9486\n",
            "Epoch 84: val_loss did not improve from 0.19430\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1489 - accuracy: 0.9500 - val_loss: 0.1960 - val_accuracy: 0.9400\n",
            "Epoch 85/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1273 - accuracy: 0.9538\n",
            "Epoch 85: val_loss did not improve from 0.19430\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1281 - accuracy: 0.9531 - val_loss: 0.1952 - val_accuracy: 0.9425\n",
            "Epoch 86/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1356 - accuracy: 0.9534\n",
            "Epoch 86: val_loss improved from 0.19430 to 0.19412, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.1369 - accuracy: 0.9531 - val_loss: 0.1941 - val_accuracy: 0.9375\n",
            "Epoch 87/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1567 - accuracy: 0.9460\n",
            "Epoch 87: val_loss improved from 0.19412 to 0.19261, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 71ms/step - loss: 0.1554 - accuracy: 0.9475 - val_loss: 0.1926 - val_accuracy: 0.9375\n",
            "Epoch 88/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9585\n",
            "Epoch 88: val_loss did not improve from 0.19261\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1304 - accuracy: 0.9575 - val_loss: 0.1931 - val_accuracy: 0.9375\n",
            "Epoch 89/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9506\n",
            "Epoch 89: val_loss improved from 0.19261 to 0.19053, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.1473 - accuracy: 0.9506 - val_loss: 0.1905 - val_accuracy: 0.9400\n",
            "Epoch 90/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1372 - accuracy: 0.9534\n",
            "Epoch 90: val_loss improved from 0.19053 to 0.18889, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 73ms/step - loss: 0.1368 - accuracy: 0.9538 - val_loss: 0.1889 - val_accuracy: 0.9400\n",
            "Epoch 91/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1320 - accuracy: 0.9577\n",
            "Epoch 91: val_loss improved from 0.18889 to 0.18691, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 72ms/step - loss: 0.1310 - accuracy: 0.9575 - val_loss: 0.1869 - val_accuracy: 0.9375\n",
            "Epoch 92/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.9515\n",
            "Epoch 92: val_loss improved from 0.18691 to 0.18527, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.1343 - accuracy: 0.9525 - val_loss: 0.1853 - val_accuracy: 0.9375\n",
            "Epoch 93/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1380 - accuracy: 0.9551\n",
            "Epoch 93: val_loss did not improve from 0.18527\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.1371 - accuracy: 0.9556 - val_loss: 0.1866 - val_accuracy: 0.9375\n",
            "Epoch 94/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9483\n",
            "Epoch 94: val_loss did not improve from 0.18527\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.1411 - accuracy: 0.9481 - val_loss: 0.1871 - val_accuracy: 0.9400\n",
            "Epoch 95/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9606\n",
            "Epoch 95: val_loss improved from 0.18527 to 0.18511, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.1339 - accuracy: 0.9606 - val_loss: 0.1851 - val_accuracy: 0.9400\n",
            "Epoch 96/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9596\n",
            "Epoch 96: val_loss improved from 0.18511 to 0.18199, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 71ms/step - loss: 0.1125 - accuracy: 0.9594 - val_loss: 0.1820 - val_accuracy: 0.9400\n",
            "Epoch 97/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.9624\n",
            "Epoch 97: val_loss did not improve from 0.18199\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1172 - accuracy: 0.9619 - val_loss: 0.1839 - val_accuracy: 0.9425\n",
            "Epoch 98/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9487\n",
            "Epoch 98: val_loss improved from 0.18199 to 0.18122, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.1318 - accuracy: 0.9488 - val_loss: 0.1812 - val_accuracy: 0.9400\n",
            "Epoch 99/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.9649\n",
            "Epoch 99: val_loss improved from 0.18122 to 0.18032, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.1104 - accuracy: 0.9638 - val_loss: 0.1803 - val_accuracy: 0.9400\n",
            "Epoch 100/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9554\n",
            "Epoch 100: val_loss did not improve from 0.18032\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1278 - accuracy: 0.9538 - val_loss: 0.1822 - val_accuracy: 0.9375\n",
            "Epoch 101/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1188 - accuracy: 0.9616\n",
            "Epoch 101: val_loss did not improve from 0.18032\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.1239 - accuracy: 0.9600 - val_loss: 0.1830 - val_accuracy: 0.9425\n",
            "Epoch 102/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9611\n",
            "Epoch 102: val_loss improved from 0.18032 to 0.18004, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 0.1177 - accuracy: 0.9613 - val_loss: 0.1800 - val_accuracy: 0.9400\n",
            "Epoch 103/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9605\n",
            "Epoch 103: val_loss improved from 0.18004 to 0.17842, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 74ms/step - loss: 0.1185 - accuracy: 0.9606 - val_loss: 0.1784 - val_accuracy: 0.9400\n",
            "Epoch 104/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9656\n",
            "Epoch 104: val_loss did not improve from 0.17842\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1064 - accuracy: 0.9656 - val_loss: 0.1796 - val_accuracy: 0.9400\n",
            "Epoch 105/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9630\n",
            "Epoch 105: val_loss improved from 0.17842 to 0.17479, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.1101 - accuracy: 0.9625 - val_loss: 0.1748 - val_accuracy: 0.9400\n",
            "Epoch 106/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9611\n",
            "Epoch 106: val_loss improved from 0.17479 to 0.17386, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 0.1080 - accuracy: 0.9581 - val_loss: 0.1739 - val_accuracy: 0.9400\n",
            "Epoch 107/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9630\n",
            "Epoch 107: val_loss did not improve from 0.17386\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.1155 - accuracy: 0.9625 - val_loss: 0.1757 - val_accuracy: 0.9425\n",
            "Epoch 108/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9611\n",
            "Epoch 108: val_loss did not improve from 0.17386\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.1134 - accuracy: 0.9613 - val_loss: 0.1764 - val_accuracy: 0.9450\n",
            "Epoch 109/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1073 - accuracy: 0.9629\n",
            "Epoch 109: val_loss did not improve from 0.17386\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1075 - accuracy: 0.9631 - val_loss: 0.1752 - val_accuracy: 0.9425\n",
            "Epoch 110/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1106 - accuracy: 0.9643\n",
            "Epoch 110: val_loss did not improve from 0.17386\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.1095 - accuracy: 0.9644 - val_loss: 0.1740 - val_accuracy: 0.9375\n",
            "Epoch 111/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0882 - accuracy: 0.9739\n",
            "Epoch 111: val_loss did not improve from 0.17386\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0877 - accuracy: 0.9737 - val_loss: 0.1774 - val_accuracy: 0.9375\n",
            "Epoch 112/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0912 - accuracy: 0.9681\n",
            "Epoch 112: val_loss did not improve from 0.17386\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0897 - accuracy: 0.9694 - val_loss: 0.1746 - val_accuracy: 0.9425\n",
            "Epoch 113/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9636\n",
            "Epoch 113: val_loss did not improve from 0.17386\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.1142 - accuracy: 0.9631 - val_loss: 0.1744 - val_accuracy: 0.9450\n",
            "Epoch 114/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0812 - accuracy: 0.9770\n",
            "Epoch 114: val_loss improved from 0.17386 to 0.17181, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 3s 71ms/step - loss: 0.0843 - accuracy: 0.9756 - val_loss: 0.1718 - val_accuracy: 0.9450\n",
            "Epoch 115/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0855 - accuracy: 0.9674\n",
            "Epoch 115: val_loss did not improve from 0.17181\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0852 - accuracy: 0.9675 - val_loss: 0.1753 - val_accuracy: 0.9425\n",
            "Epoch 116/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.9700\n",
            "Epoch 116: val_loss did not improve from 0.17181\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0992 - accuracy: 0.9700 - val_loss: 0.1731 - val_accuracy: 0.9400\n",
            "Epoch 117/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0985 - accuracy: 0.9648\n",
            "Epoch 117: val_loss did not improve from 0.17181\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0980 - accuracy: 0.9644 - val_loss: 0.1736 - val_accuracy: 0.9425\n",
            "Epoch 118/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9598\n",
            "Epoch 118: val_loss did not improve from 0.17181\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1103 - accuracy: 0.9600 - val_loss: 0.1722 - val_accuracy: 0.9425\n",
            "Epoch 119/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9706\n",
            "Epoch 119: val_loss improved from 0.17181 to 0.17080, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 0.0854 - accuracy: 0.9706 - val_loss: 0.1708 - val_accuracy: 0.9425\n",
            "Epoch 120/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0950 - accuracy: 0.9688\n",
            "Epoch 120: val_loss did not improve from 0.17080\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0980 - accuracy: 0.9688 - val_loss: 0.1741 - val_accuracy: 0.9400\n",
            "Epoch 121/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.1023 - accuracy: 0.9616\n",
            "Epoch 121: val_loss did not improve from 0.17080\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.1010 - accuracy: 0.9619 - val_loss: 0.1736 - val_accuracy: 0.9450\n",
            "Epoch 122/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9750\n",
            "Epoch 122: val_loss did not improve from 0.17080\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0821 - accuracy: 0.9750 - val_loss: 0.1729 - val_accuracy: 0.9450\n",
            "Epoch 123/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0830 - accuracy: 0.9733\n",
            "Epoch 123: val_loss improved from 0.17080 to 0.16844, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 73ms/step - loss: 0.0852 - accuracy: 0.9725 - val_loss: 0.1684 - val_accuracy: 0.9450\n",
            "Epoch 124/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9739\n",
            "Epoch 124: val_loss did not improve from 0.16844\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0797 - accuracy: 0.9744 - val_loss: 0.1688 - val_accuracy: 0.9425\n",
            "Epoch 125/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0978 - accuracy: 0.9655\n",
            "Epoch 125: val_loss did not improve from 0.16844\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0973 - accuracy: 0.9656 - val_loss: 0.1703 - val_accuracy: 0.9425\n",
            "Epoch 126/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9681\n",
            "Epoch 126: val_loss did not improve from 0.16844\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0873 - accuracy: 0.9669 - val_loss: 0.1754 - val_accuracy: 0.9400\n",
            "Epoch 127/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 0.9707\n",
            "Epoch 127: val_loss did not improve from 0.16844\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0833 - accuracy: 0.9700 - val_loss: 0.1716 - val_accuracy: 0.9425\n",
            "Epoch 128/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0784 - accuracy: 0.9758\n",
            "Epoch 128: val_loss did not improve from 0.16844\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0787 - accuracy: 0.9756 - val_loss: 0.1725 - val_accuracy: 0.9400\n",
            "Epoch 129/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9656\n",
            "Epoch 129: val_loss did not improve from 0.16844\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0898 - accuracy: 0.9663 - val_loss: 0.1733 - val_accuracy: 0.9375\n",
            "Epoch 130/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9745\n",
            "Epoch 130: val_loss improved from 0.16844 to 0.16807, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.1681 - val_accuracy: 0.9450\n",
            "Epoch 131/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 0.9643\n",
            "Epoch 131: val_loss did not improve from 0.16807\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0821 - accuracy: 0.9650 - val_loss: 0.1719 - val_accuracy: 0.9450\n",
            "Epoch 132/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0685 - accuracy: 0.9740\n",
            "Epoch 132: val_loss did not improve from 0.16807\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0684 - accuracy: 0.9731 - val_loss: 0.1708 - val_accuracy: 0.9400\n",
            "Epoch 133/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9769\n",
            "Epoch 133: val_loss did not improve from 0.16807\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0701 - accuracy: 0.9769 - val_loss: 0.1711 - val_accuracy: 0.9475\n",
            "Epoch 134/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9790\n",
            "Epoch 134: val_loss improved from 0.16807 to 0.16595, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 72ms/step - loss: 0.0663 - accuracy: 0.9794 - val_loss: 0.1660 - val_accuracy: 0.9450\n",
            "Epoch 135/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9731\n",
            "Epoch 135: val_loss improved from 0.16595 to 0.16558, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0812 - accuracy: 0.9731 - val_loss: 0.1656 - val_accuracy: 0.9450\n",
            "Epoch 136/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9739\n",
            "Epoch 136: val_loss did not improve from 0.16558\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0751 - accuracy: 0.9744 - val_loss: 0.1690 - val_accuracy: 0.9400\n",
            "Epoch 137/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0856 - accuracy: 0.9688\n",
            "Epoch 137: val_loss improved from 0.16558 to 0.16519, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 73ms/step - loss: 0.0848 - accuracy: 0.9694 - val_loss: 0.1652 - val_accuracy: 0.9475\n",
            "Epoch 138/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9790\n",
            "Epoch 138: val_loss did not improve from 0.16519\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0692 - accuracy: 0.9775 - val_loss: 0.1667 - val_accuracy: 0.9425\n",
            "Epoch 139/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0793 - accuracy: 0.9740\n",
            "Epoch 139: val_loss improved from 0.16519 to 0.16334, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 84ms/step - loss: 0.0781 - accuracy: 0.9744 - val_loss: 0.1633 - val_accuracy: 0.9450\n",
            "Epoch 140/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0760 - accuracy: 0.9727\n",
            "Epoch 140: val_loss did not improve from 0.16334\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0769 - accuracy: 0.9725 - val_loss: 0.1678 - val_accuracy: 0.9425\n",
            "Epoch 141/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9834\n",
            "Epoch 141: val_loss did not improve from 0.16334\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0653 - accuracy: 0.9831 - val_loss: 0.1675 - val_accuracy: 0.9450\n",
            "Epoch 142/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 0.9694\n",
            "Epoch 142: val_loss did not improve from 0.16334\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0863 - accuracy: 0.9688 - val_loss: 0.1671 - val_accuracy: 0.9425\n",
            "Epoch 143/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9726\n",
            "Epoch 143: val_loss did not improve from 0.16334\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0794 - accuracy: 0.9731 - val_loss: 0.1654 - val_accuracy: 0.9425\n",
            "Epoch 144/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 0.9796\n",
            "Epoch 144: val_loss did not improve from 0.16334\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0612 - accuracy: 0.9794 - val_loss: 0.1661 - val_accuracy: 0.9425\n",
            "Epoch 145/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9756\n",
            "Epoch 145: val_loss did not improve from 0.16334\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0747 - accuracy: 0.9756 - val_loss: 0.1674 - val_accuracy: 0.9400\n",
            "Epoch 146/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 0.9707\n",
            "Epoch 146: val_loss improved from 0.16334 to 0.16328, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 0.0788 - accuracy: 0.9700 - val_loss: 0.1633 - val_accuracy: 0.9475\n",
            "Epoch 147/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9815\n",
            "Epoch 147: val_loss did not improve from 0.16328\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0670 - accuracy: 0.9812 - val_loss: 0.1669 - val_accuracy: 0.9475\n",
            "Epoch 148/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0806 - accuracy: 0.9661\n",
            "Epoch 148: val_loss did not improve from 0.16328\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0819 - accuracy: 0.9669 - val_loss: 0.1645 - val_accuracy: 0.9475\n",
            "Epoch 149/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9762\n",
            "Epoch 149: val_loss did not improve from 0.16328\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0605 - accuracy: 0.9762 - val_loss: 0.1649 - val_accuracy: 0.9450\n",
            "Epoch 150/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9790\n",
            "Epoch 150: val_loss improved from 0.16328 to 0.16233, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 76ms/step - loss: 0.0703 - accuracy: 0.9787 - val_loss: 0.1623 - val_accuracy: 0.9475\n",
            "Epoch 151/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9796\n",
            "Epoch 151: val_loss did not improve from 0.16233\n",
            "50/50 [==============================] - 2s 43ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.1650 - val_accuracy: 0.9450\n",
            "Epoch 152/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0856 - accuracy: 0.9727\n",
            "Epoch 152: val_loss did not improve from 0.16233\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0868 - accuracy: 0.9725 - val_loss: 0.1627 - val_accuracy: 0.9475\n",
            "Epoch 153/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0543 - accuracy: 0.9837\n",
            "Epoch 153: val_loss improved from 0.16233 to 0.15828, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 73ms/step - loss: 0.0546 - accuracy: 0.9837 - val_loss: 0.1583 - val_accuracy: 0.9475\n",
            "Epoch 154/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9762\n",
            "Epoch 154: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0747 - accuracy: 0.9762 - val_loss: 0.1616 - val_accuracy: 0.9475\n",
            "Epoch 155/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0655 - accuracy: 0.9792\n",
            "Epoch 155: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0648 - accuracy: 0.9787 - val_loss: 0.1631 - val_accuracy: 0.9425\n",
            "Epoch 156/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0586 - accuracy: 0.9824\n",
            "Epoch 156: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0602 - accuracy: 0.9825 - val_loss: 0.1618 - val_accuracy: 0.9450\n",
            "Epoch 157/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9802\n",
            "Epoch 157: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0530 - accuracy: 0.9806 - val_loss: 0.1628 - val_accuracy: 0.9450\n",
            "Epoch 158/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0605 - accuracy: 0.9785\n",
            "Epoch 158: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0628 - accuracy: 0.9775 - val_loss: 0.1650 - val_accuracy: 0.9450\n",
            "Epoch 159/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9700\n",
            "Epoch 159: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0746 - accuracy: 0.9700 - val_loss: 0.1620 - val_accuracy: 0.9425\n",
            "Epoch 160/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9834\n",
            "Epoch 160: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0495 - accuracy: 0.9837 - val_loss: 0.1651 - val_accuracy: 0.9425\n",
            "Epoch 161/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9777\n",
            "Epoch 161: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0574 - accuracy: 0.9775 - val_loss: 0.1623 - val_accuracy: 0.9475\n",
            "Epoch 162/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9790\n",
            "Epoch 162: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0630 - accuracy: 0.9787 - val_loss: 0.1618 - val_accuracy: 0.9450\n",
            "Epoch 163/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0514 - accuracy: 0.9811\n",
            "Epoch 163: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0510 - accuracy: 0.9812 - val_loss: 0.1665 - val_accuracy: 0.9400\n",
            "Epoch 164/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0518 - accuracy: 0.9824\n",
            "Epoch 164: val_loss did not improve from 0.15828\n",
            "50/50 [==============================] - 3s 51ms/step - loss: 0.0507 - accuracy: 0.9831 - val_loss: 0.1605 - val_accuracy: 0.9450\n",
            "Epoch 165/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9783\n",
            "Epoch 165: val_loss improved from 0.15828 to 0.15541, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 3s 70ms/step - loss: 0.0657 - accuracy: 0.9775 - val_loss: 0.1554 - val_accuracy: 0.9475\n",
            "Epoch 166/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9815\n",
            "Epoch 166: val_loss did not improve from 0.15541\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0602 - accuracy: 0.9819 - val_loss: 0.1585 - val_accuracy: 0.9500\n",
            "Epoch 167/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9790\n",
            "Epoch 167: val_loss did not improve from 0.15541\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0623 - accuracy: 0.9787 - val_loss: 0.1571 - val_accuracy: 0.9500\n",
            "Epoch 168/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9787\n",
            "Epoch 168: val_loss improved from 0.15541 to 0.15519, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 82ms/step - loss: 0.0577 - accuracy: 0.9787 - val_loss: 0.1552 - val_accuracy: 0.9500\n",
            "Epoch 169/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9821\n",
            "Epoch 169: val_loss did not improve from 0.15519\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0528 - accuracy: 0.9819 - val_loss: 0.1569 - val_accuracy: 0.9500\n",
            "Epoch 170/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0592 - accuracy: 0.9831\n",
            "Epoch 170: val_loss did not improve from 0.15519\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0583 - accuracy: 0.9837 - val_loss: 0.1554 - val_accuracy: 0.9500\n",
            "Epoch 171/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0466 - accuracy: 0.9870\n",
            "Epoch 171: val_loss did not improve from 0.15519\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0464 - accuracy: 0.9869 - val_loss: 0.1600 - val_accuracy: 0.9475\n",
            "Epoch 172/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0556 - accuracy: 0.9772\n",
            "Epoch 172: val_loss did not improve from 0.15519\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0544 - accuracy: 0.9781 - val_loss: 0.1576 - val_accuracy: 0.9475\n",
            "Epoch 173/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9834\n",
            "Epoch 173: val_loss did not improve from 0.15519\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0509 - accuracy: 0.9825 - val_loss: 0.1562 - val_accuracy: 0.9525\n",
            "Epoch 174/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9809\n",
            "Epoch 174: val_loss did not improve from 0.15519\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0498 - accuracy: 0.9812 - val_loss: 0.1594 - val_accuracy: 0.9475\n",
            "Epoch 175/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0472 - accuracy: 0.9883\n",
            "Epoch 175: val_loss did not improve from 0.15519\n",
            "50/50 [==============================] - 2s 41ms/step - loss: 0.0489 - accuracy: 0.9869 - val_loss: 0.1585 - val_accuracy: 0.9500\n",
            "Epoch 176/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0494 - accuracy: 0.9837\n",
            "Epoch 176: val_loss did not improve from 0.15519\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0487 - accuracy: 0.9844 - val_loss: 0.1595 - val_accuracy: 0.9450\n",
            "Epoch 177/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9815\n",
            "Epoch 177: val_loss improved from 0.15519 to 0.15513, saving model to /content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3.h5\n",
            "50/50 [==============================] - 4s 72ms/step - loss: 0.0512 - accuracy: 0.9819 - val_loss: 0.1551 - val_accuracy: 0.9475\n",
            "Epoch 178/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9790\n",
            "Epoch 178: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0536 - accuracy: 0.9775 - val_loss: 0.1577 - val_accuracy: 0.9475\n",
            "Epoch 179/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9802\n",
            "Epoch 179: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0549 - accuracy: 0.9806 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
            "Epoch 180/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9860\n",
            "Epoch 180: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0426 - accuracy: 0.9856 - val_loss: 0.1594 - val_accuracy: 0.9500\n",
            "Epoch 181/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9790\n",
            "Epoch 181: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0512 - accuracy: 0.9794 - val_loss: 0.1604 - val_accuracy: 0.9475\n",
            "Epoch 182/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0455 - accuracy: 0.9837\n",
            "Epoch 182: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0470 - accuracy: 0.9831 - val_loss: 0.1642 - val_accuracy: 0.9475\n",
            "Epoch 183/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0507 - accuracy: 0.9821\n",
            "Epoch 183: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0501 - accuracy: 0.9825 - val_loss: 0.1605 - val_accuracy: 0.9500\n",
            "Epoch 184/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9892\n",
            "Epoch 184: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0383 - accuracy: 0.9887 - val_loss: 0.1616 - val_accuracy: 0.9475\n",
            "Epoch 185/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0472 - accuracy: 0.9821\n",
            "Epoch 185: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0477 - accuracy: 0.9819 - val_loss: 0.1596 - val_accuracy: 0.9475\n",
            "Epoch 186/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0512 - accuracy: 0.9844\n",
            "Epoch 186: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 0.1558 - val_accuracy: 0.9475\n",
            "Epoch 187/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9834\n",
            "Epoch 187: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 38ms/step - loss: 0.0419 - accuracy: 0.9837 - val_loss: 0.1602 - val_accuracy: 0.9475\n",
            "Epoch 188/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0438 - accuracy: 0.9872\n",
            "Epoch 188: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 42ms/step - loss: 0.0456 - accuracy: 0.9869 - val_loss: 0.1563 - val_accuracy: 0.9500\n",
            "Epoch 189/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9866\n",
            "Epoch 189: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.1570 - val_accuracy: 0.9500\n",
            "Epoch 190/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9856\n",
            "Epoch 190: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0497 - accuracy: 0.9856 - val_loss: 0.1557 - val_accuracy: 0.9525\n",
            "Epoch 191/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9869\n",
            "Epoch 191: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0479 - accuracy: 0.9869 - val_loss: 0.1563 - val_accuracy: 0.9500\n",
            "Epoch 192/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0433 - accuracy: 0.9883\n",
            "Epoch 192: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0432 - accuracy: 0.9875 - val_loss: 0.1579 - val_accuracy: 0.9475\n",
            "Epoch 193/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9872\n",
            "Epoch 193: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.1598 - val_accuracy: 0.9500\n",
            "Epoch 194/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0509 - accuracy: 0.9831\n",
            "Epoch 194: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0520 - accuracy: 0.9825 - val_loss: 0.1588 - val_accuracy: 0.9500\n",
            "Epoch 195/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9898\n",
            "Epoch 195: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0411 - accuracy: 0.9894 - val_loss: 0.1578 - val_accuracy: 0.9500\n",
            "Epoch 196/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0380 - accuracy: 0.9876\n",
            "Epoch 196: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0372 - accuracy: 0.9881 - val_loss: 0.1602 - val_accuracy: 0.9450\n",
            "Epoch 197/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0390 - accuracy: 0.9863\n",
            "Epoch 197: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.0385 - accuracy: 0.9862 - val_loss: 0.1592 - val_accuracy: 0.9525\n",
            "Epoch 198/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9860\n",
            "Epoch 198: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0379 - accuracy: 0.9862 - val_loss: 0.1591 - val_accuracy: 0.9500\n",
            "Epoch 199/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0295 - accuracy: 0.9941\n",
            "Epoch 199: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0289 - accuracy: 0.9944 - val_loss: 0.1590 - val_accuracy: 0.9475\n",
            "Epoch 200/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9866\n",
            "Epoch 200: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.0425 - accuracy: 0.9869 - val_loss: 0.1648 - val_accuracy: 0.9450\n",
            "Epoch 201/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9885\n",
            "Epoch 201: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 40ms/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 0.1600 - val_accuracy: 0.9425\n",
            "Epoch 202/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9866\n",
            "Epoch 202: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 39ms/step - loss: 0.0365 - accuracy: 0.9869 - val_loss: 0.1613 - val_accuracy: 0.9425\n",
            "Epoch 203/1500\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9837\n",
            "Epoch 203: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0490 - accuracy: 0.9837 - val_loss: 0.1576 - val_accuracy: 0.9475\n",
            "Epoch 204/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0269 - accuracy: 0.9915\n",
            "Epoch 204: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.1564 - val_accuracy: 0.9525\n",
            "Epoch 205/1500\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9879\n",
            "Epoch 205: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0415 - accuracy: 0.9881 - val_loss: 0.1586 - val_accuracy: 0.9475\n",
            "Epoch 206/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0400 - accuracy: 0.9876\n",
            "Epoch 206: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0391 - accuracy: 0.9881 - val_loss: 0.1561 - val_accuracy: 0.9500\n",
            "Epoch 207/1500\n",
            "48/50 [===========================>..] - ETA: 0s - loss: 0.0343 - accuracy: 0.9889\n",
            "Epoch 207: val_loss did not improve from 0.15513\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.1558 - val_accuracy: 0.9475\n",
            "63/63 [==============================] - 2s 18ms/step - loss: 0.4734 - accuracy: 0.8765\n",
            "Test accuracy, 20 run, after finetuning: 0.8765000104904175\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  res_net = create_model()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=res_net)\n",
        "  callbacks = [EarlyStopping(monitor='val_loss', patience=30, mode='min'), ModelCheckpoint('/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3_FTm3.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
        "  res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "  res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3.h5\")\n",
        "\n",
        "  for layer in res_net.layers[:-3]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  Known_data_X_finetune, Known_data_X_finetune_label = shuffle(Known_data_X_finetune, Known_data_X_finetune_label)\n",
        "\n",
        "  history = res_net.fit(Known_data_X_finetune, Known_data_X_finetune_label, epochs=1500, batch_size=32, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)\n",
        "\n",
        "  res_net.save_weights('/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3_FTm3_PP.h5')\n",
        "\n",
        "  test_loss, test_acc = res_net.evaluate(Known_data_X_test, Known_data_X_test_label)\n",
        "  print('Test accuracy, 01 run, after finetuning:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwvJhk93hDWM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZO9Gd7d2bhC",
        "outputId": "269e4211-d271-4e4f-9026-2ffee14451a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 14s 181ms/step - loss: 0.4370 - accuracy: 0.8935\n",
            "Test accuracy, 01 run: 0.8934999704360962\n",
            "63/63 [==============================] - 13s 182ms/step - loss: 0.4493 - accuracy: 0.8880\n",
            "Test accuracy, 02 run: 0.8880000114440918\n",
            "63/63 [==============================] - 13s 175ms/step - loss: 0.4790 - accuracy: 0.8760\n",
            "Test accuracy, 03 run: 0.8759999871253967\n",
            "63/63 [==============================] - 13s 178ms/step - loss: 0.4643 - accuracy: 0.8840\n",
            "Test accuracy, 04 run: 0.8840000033378601\n",
            "63/63 [==============================] - 13s 177ms/step - loss: 0.4512 - accuracy: 0.8800\n",
            "Test accuracy, 05 run: 0.8799999952316284\n",
            "63/63 [==============================] - 13s 174ms/step - loss: 0.4869 - accuracy: 0.8930\n",
            "Test accuracy, 06 run: 0.8930000066757202\n",
            "63/63 [==============================] - 13s 173ms/step - loss: 0.5136 - accuracy: 0.8755\n",
            "Test accuracy, 07 run: 0.8755000233650208\n",
            "63/63 [==============================] - 13s 176ms/step - loss: 0.4793 - accuracy: 0.8855\n",
            "Test accuracy, 08 run: 0.8855000138282776\n",
            "63/63 [==============================] - 13s 178ms/step - loss: 0.4494 - accuracy: 0.8820\n",
            "Test accuracy, 09 run: 0.8820000290870667\n",
            "63/63 [==============================] - 13s 176ms/step - loss: 0.4233 - accuracy: 0.8830\n",
            "Test accuracy, 10 run: 0.8830000162124634\n",
            "63/63 [==============================] - 13s 181ms/step - loss: 0.4175 - accuracy: 0.8855\n",
            "Test accuracy, 11 run: 0.8855000138282776\n",
            "63/63 [==============================] - 13s 176ms/step - loss: 0.4218 - accuracy: 0.8895\n",
            "Test accuracy, 12 run: 0.8895000219345093\n",
            "63/63 [==============================] - 14s 178ms/step - loss: 0.4113 - accuracy: 0.8900\n",
            "Test accuracy, 13 run: 0.8899999856948853\n",
            "63/63 [==============================] - 13s 175ms/step - loss: 0.4538 - accuracy: 0.8820\n",
            "Test accuracy, 14 run: 0.8820000290870667\n",
            "63/63 [==============================] - 13s 176ms/step - loss: 0.4410 - accuracy: 0.8870\n",
            "Test accuracy, 15 run: 0.8870000243186951\n",
            "63/63 [==============================] - 13s 176ms/step - loss: 0.4687 - accuracy: 0.8870\n",
            "Test accuracy, 16 run: 0.8870000243186951\n",
            "63/63 [==============================] - 13s 174ms/step - loss: 0.4625 - accuracy: 0.8825\n",
            "Test accuracy, 17 run: 0.8824999928474426\n",
            "63/63 [==============================] - 13s 175ms/step - loss: 0.4772 - accuracy: 0.8865\n",
            "Test accuracy, 18 run: 0.8865000009536743\n",
            "63/63 [==============================] - 13s 174ms/step - loss: 0.4759 - accuracy: 0.8855\n",
            "Test accuracy, 19 run: 0.8855000138282776\n",
            "63/63 [==============================] - 13s 179ms/step - loss: 0.4791 - accuracy: 0.8805\n",
            "Test accuracy, 20 run: 0.8805000185966492\n"
          ]
        }
      ],
      "source": [
        "# Now run and see the models with the best validation accuracy\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 01 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 02 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 03 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 04 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 05 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 06 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 07 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 08 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 09 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 10 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 11 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 12 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 13 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 14 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 15 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 16 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 17 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 18 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 19 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 20 run:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMf4aVbDOW6o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining the models into ensembles"
      ],
      "metadata": {
        "id": "RzmK6RqMObxS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNJc9zFaOW9T",
        "outputId": "92d6ebe9-6c82-4170-e78b-140360245317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 14s 197ms/step\n",
            "63/63 [==============================] - 12s 181ms/step\n",
            "63/63 [==============================] - 13s 182ms/step\n",
            "63/63 [==============================] - 12s 181ms/step\n",
            "63/63 [==============================] - 12s 181ms/step\n",
            "63/63 [==============================] - 13s 179ms/step\n",
            "63/63 [==============================] - 12s 179ms/step\n",
            "63/63 [==============================] - 12s 180ms/step\n",
            "63/63 [==============================] - 12s 179ms/step\n",
            "63/63 [==============================] - 12s 180ms/step\n",
            "63/63 [==============================] - 12s 177ms/step\n",
            "63/63 [==============================] - 13s 183ms/step\n",
            "63/63 [==============================] - 13s 189ms/step\n",
            "63/63 [==============================] - 12s 181ms/step\n",
            "63/63 [==============================] - 12s 180ms/step\n",
            "63/63 [==============================] - 12s 177ms/step\n",
            "63/63 [==============================] - 12s 181ms/step\n",
            "63/63 [==============================] - 13s 189ms/step\n",
            "63/63 [==============================] - 12s 181ms/step\n",
            "63/63 [==============================] - 12s 179ms/step\n",
            "Accuracy of the first ensemble on the knowns 0.8885\n",
            "Accuracy of the second ensemble on the knowns 0.891\n",
            "Accuracy of the third ensemble on the knowns 0.8905\n",
            "Accuracy of the fourth ensemble on the knowns 0.8885\n"
          ]
        }
      ],
      "source": [
        "res_net01 = create_model()\n",
        "res_net02 = create_model()\n",
        "res_net03 = create_model()\n",
        "res_net04 = create_model()\n",
        "res_net05 = create_model()\n",
        "res_net06 = create_model()\n",
        "res_net07 = create_model()\n",
        "res_net08 = create_model()\n",
        "res_net09 = create_model()\n",
        "res_net10 = create_model()\n",
        "res_net11 = create_model()\n",
        "res_net12 = create_model()\n",
        "res_net13 = create_model()\n",
        "res_net14 = create_model()\n",
        "res_net15 = create_model()\n",
        "res_net16 = create_model()\n",
        "res_net17 = create_model()\n",
        "res_net18 = create_model()\n",
        "res_net19 = create_model()\n",
        "res_net20 = create_model()\n",
        "\n",
        "res_net01.load_weights(\"/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net02.load_weights(\"/content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net03.load_weights(\"/content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net04.load_weights(\"/content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net05.load_weights(\"/content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net06.load_weights(\"/content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net07.load_weights(\"/content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net08.load_weights(\"/content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net09.load_weights(\"/content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net10.load_weights(\"/content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net11.load_weights(\"/content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net12.load_weights(\"/content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net13.load_weights(\"/content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net14.load_weights(\"/content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net15.load_weights(\"/content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net16.load_weights(\"/content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net17.load_weights(\"/content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net18.load_weights(\"/content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net19.load_weights(\"/content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "res_net20.load_weights(\"/content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p2_p3_FTm3_PP.h5\")\n",
        "\n",
        "\n",
        "\n",
        "prediction01_known = res_net01.predict(Known_data_X_test)\n",
        "prediction02_known = res_net02.predict(Known_data_X_test)\n",
        "prediction03_known = res_net03.predict(Known_data_X_test)\n",
        "prediction04_known = res_net04.predict(Known_data_X_test)\n",
        "prediction05_known = res_net05.predict(Known_data_X_test)\n",
        "prediction06_known = res_net06.predict(Known_data_X_test)\n",
        "prediction07_known = res_net07.predict(Known_data_X_test)\n",
        "prediction08_known = res_net08.predict(Known_data_X_test)\n",
        "prediction09_known = res_net09.predict(Known_data_X_test)\n",
        "prediction10_known = res_net10.predict(Known_data_X_test)\n",
        "\n",
        "prediction11_known = res_net11.predict(Known_data_X_test)\n",
        "prediction12_known = res_net12.predict(Known_data_X_test)\n",
        "prediction13_known = res_net13.predict(Known_data_X_test)\n",
        "prediction14_known = res_net14.predict(Known_data_X_test)\n",
        "prediction15_known = res_net15.predict(Known_data_X_test)\n",
        "prediction16_known = res_net16.predict(Known_data_X_test)\n",
        "prediction17_known = res_net17.predict(Known_data_X_test)\n",
        "prediction18_known = res_net18.predict(Known_data_X_test)\n",
        "prediction19_known = res_net19.predict(Known_data_X_test)\n",
        "prediction20_known = res_net20.predict(Known_data_X_test)\n",
        "\n",
        "\n",
        "prediction_known_ensemble_1 = (prediction01_known + prediction02_known + prediction03_known + prediction04_known + prediction05_known)/5\n",
        "\n",
        "true = 0\n",
        "for i in range(Known_data_X_test_label.shape[0]):\n",
        "  if prediction_known_ensemble_1.argmax(axis=1)[i] == Known_data_X_test_label_int[i]:\n",
        "    true += 1\n",
        "print(\"Accuracy of the first ensemble on the knowns\", true/(Known_data_X_test_label.shape[0]))\n",
        "\n",
        "prediction_known_ensemble_2 = (prediction06_known + prediction07_known + prediction08_known + prediction09_known + prediction10_known)/5\n",
        "\n",
        "true = 0\n",
        "for i in range(Known_data_X_test_label.shape[0]):\n",
        "  if prediction_known_ensemble_2.argmax(axis=1)[i] == Known_data_X_test_label_int[i]:\n",
        "    true += 1\n",
        "print(\"Accuracy of the second ensemble on the knowns\", true/(Known_data_X_test_label.shape[0]))\n",
        "\n",
        "prediction_known_ensemble_3 = (prediction11_known + prediction12_known + prediction13_known + prediction14_known + prediction15_known)/5\n",
        "\n",
        "true = 0\n",
        "for i in range(Known_data_X_test_label.shape[0]):\n",
        "  if prediction_known_ensemble_3.argmax(axis=1)[i] == Known_data_X_test_label_int[i]:\n",
        "    true += 1\n",
        "print(\"Accuracy of the third ensemble on the knowns\", true/(Known_data_X_test_label.shape[0]))\n",
        "\n",
        "prediction_known_ensemble_4 = (prediction16_known + prediction17_known + prediction18_known + prediction19_known + prediction20_known)/5\n",
        "\n",
        "true = 0\n",
        "for i in range(Known_data_X_test_label.shape[0]):\n",
        "  if prediction_known_ensemble_4.argmax(axis=1)[i] == Known_data_X_test_label_int[i]:\n",
        "    true += 1\n",
        "print(\"Accuracy of the fourth ensemble on the knowns\", true/(Known_data_X_test_label.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-kpXgw0OW_Q",
        "outputId": "7dd4619a-25a0-4eeb-b69d-9588e81f9d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 6s 180ms/step\n",
            "32/32 [==============================] - 6s 175ms/step\n",
            "32/32 [==============================] - 6s 182ms/step\n",
            "32/32 [==============================] - 6s 174ms/step\n",
            "32/32 [==============================] - 6s 179ms/step\n",
            "32/32 [==============================] - 6s 175ms/step\n",
            "32/32 [==============================] - 6s 184ms/step\n",
            "32/32 [==============================] - 5s 171ms/step\n",
            "32/32 [==============================] - 6s 177ms/step\n",
            "32/32 [==============================] - 6s 180ms/step\n",
            "32/32 [==============================] - 6s 185ms/step\n",
            "32/32 [==============================] - 6s 174ms/step\n",
            "32/32 [==============================] - 6s 180ms/step\n",
            "32/32 [==============================] - 6s 172ms/step\n",
            "32/32 [==============================] - 6s 175ms/step\n",
            "32/32 [==============================] - 6s 184ms/step\n",
            "32/32 [==============================] - 6s 172ms/step\n",
            "32/32 [==============================] - 6s 174ms/step\n",
            "32/32 [==============================] - 6s 183ms/step\n",
            "32/32 [==============================] - 6s 173ms/step\n"
          ]
        }
      ],
      "source": [
        "prediction01_unknown = res_net01.predict(NeverSeen_data_X_test)\n",
        "prediction02_unknown = res_net02.predict(NeverSeen_data_X_test)\n",
        "prediction03_unknown = res_net03.predict(NeverSeen_data_X_test)\n",
        "prediction04_unknown = res_net04.predict(NeverSeen_data_X_test)\n",
        "prediction05_unknown = res_net05.predict(NeverSeen_data_X_test)\n",
        "prediction06_unknown = res_net06.predict(NeverSeen_data_X_test)\n",
        "prediction07_unknown = res_net07.predict(NeverSeen_data_X_test)\n",
        "prediction08_unknown = res_net08.predict(NeverSeen_data_X_test)\n",
        "prediction09_unknown = res_net09.predict(NeverSeen_data_X_test)\n",
        "prediction10_unknown = res_net10.predict(NeverSeen_data_X_test)\n",
        "prediction11_unknown = res_net11.predict(NeverSeen_data_X_test)\n",
        "prediction12_unknown = res_net12.predict(NeverSeen_data_X_test)\n",
        "prediction13_unknown = res_net13.predict(NeverSeen_data_X_test)\n",
        "prediction14_unknown = res_net14.predict(NeverSeen_data_X_test)\n",
        "prediction15_unknown = res_net15.predict(NeverSeen_data_X_test)\n",
        "prediction16_unknown = res_net16.predict(NeverSeen_data_X_test)\n",
        "prediction17_unknown = res_net17.predict(NeverSeen_data_X_test)\n",
        "prediction18_unknown = res_net18.predict(NeverSeen_data_X_test)\n",
        "prediction19_unknown = res_net19.predict(NeverSeen_data_X_test)\n",
        "prediction20_unknown = res_net20.predict(NeverSeen_data_X_test)\n",
        "\n",
        "\n",
        "prediction_unknown_ensemble_1 = (prediction01_unknown + prediction02_unknown + prediction03_unknown + prediction04_unknown + prediction05_unknown)/5\n",
        "prediction_unknown_ensemble_2 = (prediction06_unknown + prediction07_unknown + prediction08_unknown + prediction09_unknown + prediction10_unknown)/5\n",
        "prediction_unknown_ensemble_3 = (prediction11_unknown + prediction12_unknown + prediction13_unknown + prediction14_unknown + prediction15_unknown)/5\n",
        "prediction_unknown_ensemble_4 = (prediction16_unknown + prediction17_unknown + prediction18_unknown + prediction19_unknown + prediction20_unknown)/5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_viWZzMwOXBd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computing ODIN scores"
      ],
      "metadata": {
        "id": "jHH4tqNtPMfn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jsxJab8ly-_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temperature = 1000\n",
        "magnitude = 0.001\n",
        "batch_size = 32\n",
        "threshold = 0.1\n",
        "\n",
        "loaded_models = [res_net01, res_net02, res_net03, res_net04, res_net05, res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "                 res_net11, res_net12, res_net13, res_net14, res_net15, res_net16, res_net17, res_net18, res_net19, res_net20]\n",
        "\n",
        "\n",
        "UN_Known_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "odin_scores_for_models = [np.array([]) for _ in loaded_models]\n",
        "\n",
        "def compute_odin_scores_for_model(model, images, threshold):\n",
        "    logits_layer = model.layers[-2].output\n",
        "    logits_model = tf.keras.Model(inputs=model.input, outputs=logits_layer)\n",
        "\n",
        "    odin_scores_UN_KNOWN = []\n",
        "\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch = images[i:i + batch_size]\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            logits = logits_model(batch)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(batch)\n",
        "            output = logits_model(batch)\n",
        "        grads = tape.gradient(output, batch)\n",
        "\n",
        "        signed_grads = tf.sign(grads)\n",
        "\n",
        "        perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "        scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "        perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "        max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "        max_logits = tf.reduce_max(tf.nn.softmax(logits), axis=1)\n",
        "        odin_scores_batch = max_logits - max_perturbed_softmax_scores\n",
        "\n",
        "        odin_scores_UN_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "    return np.array(odin_scores_UN_KNOWN)\n",
        "\n",
        "for model_index, model in enumerate(loaded_models):\n",
        "    odin_scores = compute_odin_scores_for_model(model, UN_Known_data_X_test_as_tensor, threshold)\n",
        "    odin_scores_for_models[model_index] = odin_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YjBHBOORsoE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMgtnFqnlzCM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "all_odin_scores = []\n",
        "for scores in odin_scores_for_models:\n",
        "    all_odin_scores.extend(scores)\n",
        "\n",
        "folder_path = \"/content/gdrive/MyDrive/Stanford_data\"\n",
        "\n",
        "file_name = \"all_odin_scores_NAIVEKp1p2p3.txt\"\n",
        "\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    for score in all_odin_scores:\n",
        "        file.write(f\"{score}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "2K4hYKOPlzGp",
        "outputId": "d9699203-c9f1-46c1-9fb6-eb0b201dd4d4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "magnitude = 0.001\n",
        "temperature = 1000\n",
        "num_models = 20\n",
        "\n",
        "loaded_models = [\n",
        "    res_net01, res_net02, res_net03, res_net04, res_net05,\n",
        "    res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "    res_net11, res_net12, res_net13, res_net14, res_net15,\n",
        "    res_net16, res_net17, res_net18, res_net19, res_net20\n",
        "]\n",
        "\n",
        "odin_scores_all_models = []\n",
        "\n",
        "for i in range(num_models):\n",
        "    logits_layer = loaded_models[i].layers[-2].output\n",
        "\n",
        "    logits_model = tf.keras.Model(inputs=loaded_models[i].input, outputs=logits_layer)\n",
        "\n",
        "    Known_data_X_test_as_tensor = tf.convert_to_tensor(Known_data_X_test)\n",
        "\n",
        "    odin_scores_KNOWN = []\n",
        "\n",
        "    for j in range(0, len(Known_data_X_test), batch_size):\n",
        "        batch = Known_data_X_test_as_tensor[j:j+batch_size]\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            logits = logits_model(batch)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(batch)\n",
        "            logits = logits_model(batch)\n",
        "        grads = tape.gradient(logits, batch)\n",
        "\n",
        "        signed_grads = tf.sign(grads)\n",
        "\n",
        "        perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "        scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "        perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "        max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "        original_softmax_output = tf.nn.softmax(logits / temperature)\n",
        "        max_softmax_scores = tf.reduce_max(original_softmax_output, axis=1)\n",
        "\n",
        "        odin_scores_batch = max_softmax_scores - max_perturbed_softmax_scores\n",
        "\n",
        "        odin_scores_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "    odin_scores_KNOWN = np.array(odin_scores_KNOWN)\n",
        "    odin_scores_all_models.append(odin_scores_KNOWN)\n",
        "\n",
        "combined_odin_scores = np.concatenate(odin_scores_all_models)\n",
        "\n",
        "plt.hist(combined_odin_scores, bins=10)\n",
        "\n",
        "plt.xlabel('ODIN Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of ODIN Scores for Known Data (All Models)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFRwGS6MlzJw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/gdrive/MyDrive/Stanford_data\"\n",
        "\n",
        "file_name = \"KNOWN_all_odin_scores_NAIVEKp1p2p3.txt\"\n",
        "\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    for score in combined_odin_scores:\n",
        "        file.write(f\"{score}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYRkt5ojlzM6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB0UJyZolzQP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute the OpenMax scores"
      ],
      "metadata": {
        "id": "tI7UFIjGP5sE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "Vj9mYt7FlzTT",
        "outputId": "d6d7f2d4-41ea-4e95-baf6-bbd125fe72e5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "alpha = 1.0\n",
        "num_models = 20\n",
        "\n",
        "loaded_models = [res_net01, res_net02, res_net03, res_net04, res_net05, res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "                 res_net11, res_net12, res_net13, res_net14, res_net15, res_net16, res_net17, res_net18, res_net19, res_net20]\n",
        "\n",
        "openmax_scores_known = []\n",
        "openmax_scores_unknown = []\n",
        "\n",
        "Known_data_X_test_as_tensor = tf.convert_to_tensor(Known_data_X_test)\n",
        "NeverSeen_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "for model in loaded_models:\n",
        "    logits_layer = model.layers[-2].output\n",
        "\n",
        "    logits_model = tf.keras.Model(inputs=model.input, outputs=logits_layer)\n",
        "\n",
        "    known_logits = logits_model(Known_data_X_test_as_tensor)\n",
        "    unknown_logits = logits_model(NeverSeen_data_X_test_as_tensor)\n",
        "\n",
        "    max_known_logits = tf.reduce_max(known_logits, axis=1)\n",
        "    max_unknown_logits = tf.reduce_max(unknown_logits, axis=1)\n",
        "\n",
        "    scores_known = tf.exp(alpha * max_known_logits) / tf.reduce_sum(tf.exp(alpha * max_known_logits))\n",
        "\n",
        "    scores_unknown = []\n",
        "    for max_known, max_unknown in zip(max_known_logits, max_unknown_logits):\n",
        "        unknown_score = tf.exp(alpha * max_known) / (tf.exp(alpha * max_known) + tf.exp(alpha * max_unknown))\n",
        "        scores_unknown.append(unknown_score)\n",
        "\n",
        "    openmax_scores_known.append(scores_known.numpy())\n",
        "    openmax_scores_unknown.append(scores_unknown)\n",
        "\n",
        "merged_openmax_scores_known = np.stack(openmax_scores_known, axis=1)\n",
        "merged_openmax_scores_unknown = np.stack(openmax_scores_unknown, axis=1)\n",
        "\n",
        "combined_openmax_scores_known = merged_openmax_scores_known.flatten()\n",
        "combined_openmax_scores_unknown = merged_openmax_scores_unknown.flatten()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(combined_openmax_scores_known, bins=10, alpha=0.5, label=[f'Model {i+1}' for i in range(num_models)])\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Known Data')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(combined_openmax_scores_unknown, bins=10, alpha=0.5, label=[f'Model {i+1}' for i in range(num_models)])\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Unknown Data')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoAymkPylzWS"
      },
      "outputs": [],
      "source": [
        "np.savetxt('/content/gdrive/MyDrive/Stanford_data/NaiveKp1p2p3_combined_openmax_scores_known.txt', combined_openmax_scores_known)\n",
        "np.savetxt('/content/gdrive/MyDrive/Stanford_data/NaiveKp1p2p3_combined_openmax_scores_unknown.txt', combined_openmax_scores_unknown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quf7550w_ZEc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Mahalanobis scores"
      ],
      "metadata": {
        "id": "URmYf58-Q-im"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgYvRhe5SXqZ",
        "outputId": "081aa0c1-78eb-4fba-fae4-aa9bcaca1eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 14s 198ms/step\n",
            "32/32 [==============================] - 8s 202ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 417492.6284128221\n",
            "63/63 [==============================] - 13s 184ms/step\n",
            "32/32 [==============================] - 7s 174ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 401024.67752110766\n",
            "63/63 [==============================] - 13s 182ms/step\n",
            "32/32 [==============================] - 7s 174ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 548955.9488767612\n",
            "63/63 [==============================] - 13s 180ms/step\n",
            "32/32 [==============================] - 7s 174ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 467276.41792176856\n",
            "63/63 [==============================] - 13s 181ms/step\n",
            "32/32 [==============================] - 7s 186ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 625734.1253146918\n",
            "63/63 [==============================] - 13s 181ms/step\n",
            "32/32 [==============================] - 7s 189ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 381065.04043457675\n",
            "63/63 [==============================] - 13s 182ms/step\n",
            "32/32 [==============================] - 7s 182ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 563430.2221475426\n",
            "63/63 [==============================] - 14s 196ms/step\n",
            "32/32 [==============================] - 7s 195ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 463161.29049284494\n",
            "63/63 [==============================] - 13s 186ms/step\n",
            "32/32 [==============================] - 7s 186ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 470409.576868067\n",
            "63/63 [==============================] - 15s 182ms/step\n",
            "32/32 [==============================] - 7s 173ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 463522.6247350428\n",
            "63/63 [==============================] - 12s 180ms/step\n",
            "32/32 [==============================] - 7s 173ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 396611.79812683194\n",
            "63/63 [==============================] - 13s 183ms/step\n",
            "32/32 [==============================] - 7s 184ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 484638.0660655257\n",
            "63/63 [==============================] - 13s 182ms/step\n",
            "32/32 [==============================] - 7s 173ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 520600.37024483294\n",
            "63/63 [==============================] - 13s 186ms/step\n",
            "32/32 [==============================] - 7s 176ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 511978.7633653968\n",
            "63/63 [==============================] - 13s 191ms/step\n",
            "32/32 [==============================] - 7s 184ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 443376.50807121966\n",
            "63/63 [==============================] - 13s 181ms/step\n",
            "32/32 [==============================] - 7s 172ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 551914.8095818647\n",
            "63/63 [==============================] - 13s 182ms/step\n",
            "32/32 [==============================] - 7s 188ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 427518.7223702481\n",
            "63/63 [==============================] - 13s 187ms/step\n",
            "32/32 [==============================] - 7s 184ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 467344.8969150929\n",
            "63/63 [==============================] - 13s 180ms/step\n",
            "32/32 [==============================] - 7s 176ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 427263.202850383\n",
            "63/63 [==============================] - 13s 184ms/step\n",
            "32/32 [==============================] - 7s 182ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 460765.94864077703\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def preprocess_data(data):\n",
        "    preprocessed_data = data\n",
        "    return preprocessed_data\n",
        "\n",
        "def extract_deep_features(model, data):\n",
        "    preprocessed_data = preprocess_data(data)\n",
        "\n",
        "    deep_features = model.layers[-2].output\n",
        "    deep_feature_model = tf.keras.Model(inputs=model.input, outputs=deep_features)\n",
        "    extracted_features = deep_feature_model.predict(preprocessed_data)\n",
        "\n",
        "    return extracted_features\n",
        "\n",
        "loaded_models = [res_net01, res_net02, res_net03, res_net04, res_net05, res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "                 res_net11, res_net12, res_net13, res_net14, res_net15, res_net16, res_net17, res_net18, res_net19, res_net20]\n",
        "\n",
        "deep_features_known_all = []\n",
        "mahalanobis_distances_known_all = []\n",
        "deep_features_unknown_all = []\n",
        "mahalanobis_distances_unknown_all = []\n",
        "\n",
        "n_components = min(deep_features_known.shape[0], deep_features_known.shape[1]) - 1\n",
        "\n",
        "for model in loaded_models:\n",
        "    deep_features_known = extract_deep_features(model, Known_data_X_test)\n",
        "    deep_features_unknown = extract_deep_features(model, NeverSeen_data_X_test)\n",
        "\n",
        "    pca = PCA(n_components=n_components)\n",
        "    deep_features_known_pca = pca.fit_transform(deep_features_known)\n",
        "    deep_features_unknown_pca = pca.transform(deep_features_unknown)\n",
        "\n",
        "    mean_known = np.mean(deep_features_known_pca, axis=0)\n",
        "    cov_known = np.cov(deep_features_known_pca, rowvar=False)\n",
        "\n",
        "    cond_number = np.linalg.cond(cov_known)\n",
        "    print(\"Condition Number of Covariance Matrix (Known Data):\", cond_number)\n",
        "\n",
        "    epsilon = 1e-5\n",
        "\n",
        "    if cond_number > 1 / epsilon:\n",
        "        cov_known_reg = cov_known + epsilon * np.eye(cov_known.shape[0])\n",
        "    else:\n",
        "        cov_known_reg = cov_known\n",
        "\n",
        "    mahalanobis_distances_known = []\n",
        "    for feature in deep_features_known_pca:\n",
        "        mahalanobis_distance = distance.mahalanobis(feature, mean_known, np.linalg.inv(cov_known_reg))\n",
        "        mahalanobis_distances_known.append(mahalanobis_distance)\n",
        "\n",
        "    mahalanobis_distances_unknown = []\n",
        "    for feature in deep_features_unknown_pca:\n",
        "        mahalanobis_distance = distance.mahalanobis(feature, mean_known, np.linalg.inv(cov_known_reg))\n",
        "        mahalanobis_distances_unknown.append(mahalanobis_distance)\n",
        "\n",
        "    deep_features_known_all.append(deep_features_known_pca)\n",
        "    mahalanobis_distances_known_all.append(mahalanobis_distances_known)\n",
        "    deep_features_unknown_all.append(deep_features_unknown_pca)\n",
        "    mahalanobis_distances_unknown_all.append(mahalanobis_distances_unknown)\n",
        "\n",
        "deep_features_known_combined = np.concatenate(deep_features_known_all, axis=-1)\n",
        "mahalanobis_distances_known_combined = np.mean(mahalanobis_distances_known_all, axis=0)\n",
        "\n",
        "deep_features_unknown_combined = np.concatenate(deep_features_unknown_all, axis=-1)\n",
        "mahalanobis_distances_unknown_combined = np.mean(mahalanobis_distances_unknown_all, axis=0)\n",
        "\n",
        "threshold_known = 3.0\n",
        "threshold_unknown = 4.0\n",
        "\n",
        "ood_samples_known = [i for i, distance in enumerate(mahalanobis_distances_known_combined) if distance > threshold_known]\n",
        "ood_samples_unknown = [i for i, distance in enumerate(mahalanobis_distances_unknown_combined) if distance > threshold_unknown]\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(mahalanobis_distances_known_combined, bins=10)\n",
        "plt.xlabel('Mahalanobis Distance')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Mahalanobis Scores for Known Data (Combined)')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(mahalanobis_distances_unknown_combined, bins=10)\n",
        "plt.xlabel('Mahalanobis Distance')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Mahalanobis Scores for Unknown Data (Combined)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SPxLp25rR1pi"
      },
      "outputs": [],
      "source": [
        "np.savetxt(f'{folder_path}/mahalanobis_distances_known_combined_Naivep1p2p3.txt', mahalanobis_distances_known_combined)\n",
        "np.savetxt(f'{folder_path}/mahalanobis_distances_unknown_combined_Naivep1p2p3.txt', mahalanobis_distances_unknown_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "QjVz_IZt1xxI",
        "outputId": "4bde8442-1fcc-43b6-f1df-0b4b2291643c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(odin_scores_for_models[0], bins=10)\n",
        "\n",
        "plt.xlabel('ODIN Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of ODIN UNKNOWN Scores')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T53p0E11xz7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iPw8rJA1x2u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRrasTWA1x5i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temperature = 1000\n",
        "magnitude = 0.001\n",
        "batch_size = 32\n",
        "threshold = 0.1\n",
        "\n",
        "loaded_models = [res_net01, res_net02, res_net03, res_net04, res_net05, res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "                 res_net11, res_net12, res_net13, res_net14, res_net15, res_net16, res_net17, res_net18, res_net19, res_net20]\n",
        "\n",
        "\n",
        "UN_Known_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "odin_scores_for_models = [np.array([]) for _ in loaded_models]\n",
        "\n",
        "def compute_odin_scores_for_model(model, images, threshold):\n",
        "    logits_layer = model.layers[-2].output\n",
        "    logits_model = tf.keras.Model(inputs=model.input, outputs=logits_layer)\n",
        "\n",
        "    odin_scores_UN_KNOWN = []\n",
        "\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch = images[i:i + batch_size]\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            logits = logits_model(batch)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(batch)\n",
        "            output = logits_model(batch)\n",
        "        grads = tape.gradient(output, batch)\n",
        "\n",
        "        signed_grads = tf.sign(grads)\n",
        "\n",
        "        perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "        scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "        perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "        max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "        max_logits = tf.reduce_max(tf.nn.softmax(logits), axis=1)\n",
        "        odin_scores_batch = max_logits - max_perturbed_softmax_scores\n",
        "\n",
        "        odin_scores_UN_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "    return np.array(odin_scores_UN_KNOWN)\n",
        "\n",
        "for model_index, model in enumerate(loaded_models):\n",
        "    odin_scores = compute_odin_scores_for_model(model, UN_Known_data_X_test_as_tensor, threshold)\n",
        "    odin_scores_for_models[model_index] = odin_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example for 1 model"
      ],
      "metadata": {
        "id": "_hMNBK8uSQGw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "sYCaEow6TjZX",
        "outputId": "fd32cd74-24ff-4f40-be04-c3cf0ff6f422"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temperature = 1000\n",
        "magnitude = 0.001\n",
        "\n",
        "UN_Known_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "logits_layer = res_net01.layers[-2].output\n",
        "logits_model = tf.keras.Model(inputs=res_net01.input, outputs=logits_layer)\n",
        "\n",
        "odin_scores_UN_KNOWN = []\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "for i in range(0, len(NeverSeen_data_X_test), batch_size):\n",
        "    batch = UN_Known_data_X_test_as_tensor[i:i+batch_size]\n",
        "\n",
        "    with tf.device(\"/CPU:0\"):\n",
        "        logits = logits_model(batch)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(batch)\n",
        "        output = logits_model(batch)\n",
        "    grads = tape.gradient(output, batch)\n",
        "\n",
        "    signed_grads = tf.sign(grads)\n",
        "\n",
        "    perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "    with tf.device(\"/CPU:0\"):\n",
        "        perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "    scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "    perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "    max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "    max_logits = tf.reduce_max(tf.nn.softmax(logits), axis=1)\n",
        "    odin_scores_batch = max_logits - max_perturbed_softmax_scores\n",
        "\n",
        "    odin_scores_UN_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "odin_scores_UN_KNOWN = np.array(odin_scores_UN_KNOWN)\n",
        "\n",
        "plt.hist(odin_scores_UN_KNOWN, bins=10)\n",
        "\n",
        "plt.xlabel('ODIN Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of ODIN UNKNOWN Scores')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILGfFvuNTjcG",
        "outputId": "0e07f01b-0ac8-4423-9ff2-7495c0b87704"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.027194751"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "min(odin_scores_UN_KNOWN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "q_TY7dM1TjeZ",
        "outputId": "c44c9870-0e47-4464-dba4-3836e2d396be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logits_layer = res_net01.layers[-2].output\n",
        "\n",
        "logits_model = tf.keras.Model(inputs=res_net01.input, outputs=logits_layer)\n",
        "\n",
        "Known_data_X_test_as_tensor = tf.convert_to_tensor(Known_data_X_test)\n",
        "\n",
        "odin_scores_KNOWN = []\n",
        "\n",
        "batch_size = 32\n",
        "magnitude = 0.001\n",
        "\n",
        "for i in range(0, len(Known_data_X_test), batch_size):\n",
        "    batch = Known_data_X_test_as_tensor[i:i+batch_size]\n",
        "\n",
        "    with tf.device(\"/CPU:0\"):\n",
        "        logits = logits_model(batch)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(batch)\n",
        "        logits = logits_model(batch)\n",
        "    grads = tape.gradient(logits, batch)\n",
        "\n",
        "    signed_grads = tf.sign(grads)\n",
        "\n",
        "    perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "    with tf.device(\"/CPU:0\"):\n",
        "        perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "    scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "    perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "    max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "    original_softmax_output = tf.nn.softmax(logits / temperature)\n",
        "    max_softmax_scores = tf.reduce_max(original_softmax_output, axis=1)\n",
        "\n",
        "    odin_scores_batch = max_softmax_scores - max_perturbed_softmax_scores\n",
        "\n",
        "    odin_scores_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "odin_scores_KNOWN = np.array(odin_scores_KNOWN)\n",
        "plt.hist(odin_scores_KNOWN, bins=10)\n",
        "\n",
        "plt.xlabel('ODIN Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of ODIN Scores KNOWN')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JALwLcdUNZPm",
        "outputId": "8bca6b70-ec6b-4b4e-f6d2-50cc84205ae4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.7805876e-08"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(odin_scores_KNOWN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "UAEfN6DoNZRv",
        "outputId": "baaf7f7d-6d58-41d9-932d-b5ff984483fc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist([odin_scores_KNOWN, odin_scores_UN_KNOWN], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])  # Specify the number of bins and labels\n",
        "\n",
        "plt.xlabel('Value of the ODIN score')\n",
        "plt.ylabel('Frequency of occurrence')\n",
        "plt.title('Comparison of ODIN scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "jN6kNhDByVtq",
        "outputId": "708c6bc8-7511-4e88-f683-4faf9d8c339e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logits_layer = res_net01.layers[-2].output\n",
        "\n",
        "logits_model = tf.keras.Model(inputs=res_net01.input, outputs=logits_layer)\n",
        "\n",
        "Known_data_X_test_as_tensor = tf.convert_to_tensor(Known_data_X_test)\n",
        "NeverSeen_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "known_logits = logits_model(Known_data_X_test_as_tensor)\n",
        "unknown_logits = logits_model(NeverSeen_data_X_test_as_tensor)\n",
        "\n",
        "max_known_logits = tf.reduce_max(known_logits, axis=1)\n",
        "max_unknown_logits = tf.reduce_max(unknown_logits, axis=1)\n",
        "\n",
        "def compute_openmax_scores_known(max_known_logits, alpha=1.0):\n",
        "    scores_known = tf.exp(alpha * max_known_logits) / tf.reduce_sum(tf.exp(alpha * max_known_logits))\n",
        "    return scores_known\n",
        "\n",
        "openmax_scores_known = compute_openmax_scores_known(max_known_logits)\n",
        "\n",
        "def compute_openmax_scores_unknown(max_known_logits, max_unknown_logits, alpha=1.0):\n",
        "    scores_unknown = []\n",
        "    for max_known, max_unknown in zip(max_known_logits, max_unknown_logits):\n",
        "        unknown_score = tf.exp(alpha * max_known) / (tf.exp(alpha * max_known) + tf.exp(alpha * max_unknown))\n",
        "        scores_unknown.append(unknown_score)\n",
        "    return tf.stack(scores_unknown)\n",
        "\n",
        "openmax_scores_unknown = compute_openmax_scores_unknown(max_known_logits, max_unknown_logits)\n",
        "\n",
        "openmax_scores_known = openmax_scores_known.numpy()\n",
        "openmax_scores_unknown = openmax_scores_unknown.numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(openmax_scores_known, bins=10)\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Known Data')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(openmax_scores_unknown, bins=10)\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Unknown Data')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "mfIQKwId0zIA",
        "outputId": "f4907818-c2e0-42e4-af15-4ad932d662a9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist([openmax_scores_known, openmax_scores_unknown], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])  # Specify the number of bins and labels\n",
        "\n",
        "plt.xlabel('Value of the OpenMax score')\n",
        "plt.ylabel('Frequency of occurrence')\n",
        "plt.title('Comparison of OpenMax scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-nBrEfbyVwY",
        "outputId": "22d6f597-e696-4dce-b7bc-5048d11ccb09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.15391746"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(openmax_scores_known)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l10GGVozyVzh",
        "outputId": "954c3ad2-518c-4721-84a6-a601e43ae486"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.39529e-05"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "min(openmax_scores_unknown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5WsoePtyV2O",
        "outputId": "007b7c52-0f68-43ba-b255-41a30a9238f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overlap (IoU): 2.42%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "openmax_scores_known_sorted = np.sort(openmax_scores_known)\n",
        "openmax_scores_unknown_sorted = np.sort(openmax_scores_unknown)\n",
        "\n",
        "min_known_score = openmax_scores_known_sorted.min()\n",
        "max_known_score = openmax_scores_known_sorted.max()\n",
        "min_unknown_score = openmax_scores_unknown_sorted.min()\n",
        "max_unknown_score = openmax_scores_unknown_sorted.max()\n",
        "\n",
        "bins = np.linspace(min(min_known_score, min_unknown_score), max(max_known_score, max_unknown_score), 1000)\n",
        "\n",
        "hist_known, _ = np.histogram(openmax_scores_known_sorted, bins)\n",
        "hist_unknown, _ = np.histogram(openmax_scores_unknown_sorted, bins)\n",
        "\n",
        "intersection = np.minimum(hist_known, hist_unknown)\n",
        "union = np.maximum(hist_known, hist_unknown)\n",
        "\n",
        "iou = np.sum(intersection) / np.sum(union) * 100\n",
        "\n",
        "print(f\"Overlap (IoU): {iou:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yellQdsW1fba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbQq6CNP5PJI"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data):\n",
        "    preprocessed_data = data\n",
        "    return preprocessed_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSYqyZCS5PMH",
        "outputId": "e452d29e-59d1-4202-be36-b255d954c941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 12s 175ms/step\n",
            "32/32 [==============================] - 6s 169ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 2.4366023256507043e+22\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-288ca2bca1c9>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mmahalanobis_distances_known\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeep_features_known\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mmahalanobis_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmahalanobis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_known\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_known_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mmahalanobis_distances_known\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmahalanobis_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "import tensorflow as tf\n",
        "\n",
        "def preprocess_data(data):\n",
        "    preprocessed_data = data\n",
        "    return preprocessed_data\n",
        "\n",
        "def extract_deep_features(model, data):\n",
        "\n",
        "    preprocessed_data = preprocess_data(data)\n",
        "\n",
        "    deep_features = model.layers[-2].output\n",
        "    deep_feature_model = tf.keras.Model(inputs=model.input, outputs=deep_features)\n",
        "    extracted_features = deep_feature_model.predict(preprocessed_data)\n",
        "\n",
        "    return extracted_features\n",
        "\n",
        "deep_features_known = extract_deep_features(res_net01, Known_data_X_test)\n",
        "deep_features_unknown = extract_deep_features(res_net01, NeverSeen_data_X_test)\n",
        "\n",
        "mean_known = np.mean(deep_features_known, axis=0)\n",
        "cov_known = np.cov(deep_features_known, rowvar=False)\n",
        "\n",
        "cond_number = np.linalg.cond(cov_known)\n",
        "print(\"Condition Number of Covariance Matrix (Known Data):\", cond_number)\n",
        "\n",
        "epsilon = 1e-6\n",
        "\n",
        "if cond_number > 1 / epsilon:\n",
        "    cov_known_reg = cov_known + epsilon * np.eye(cov_known.shape[0])\n",
        "else:\n",
        "    cov_known_reg = cov_known\n",
        "\n",
        "mahalanobis_distances_known = []\n",
        "for feature in deep_features_known:\n",
        "    mahalanobis_distance = distance.mahalanobis(feature, mean_known, np.linalg.inv(cov_known_reg))\n",
        "    mahalanobis_distances_known.append(mahalanobis_distance)\n",
        "\n",
        "mahalanobis_distances_unknown = []\n",
        "for feature in deep_features_unknown:\n",
        "    mahalanobis_distance = distance.mahalanobis(feature, mean_known, np.linalg.inv(cov_known_reg))\n",
        "    mahalanobis_distances_unknown.append(mahalanobis_distance)\n",
        "\n",
        "threshold_known = 3.0\n",
        "threshold_unknown = 4.0\n",
        "ood_samples_known = [i for i, distance in enumerate(mahalanobis_distances_known) if distance > threshold_known]\n",
        "ood_samples_unknown = [i for i, distance in enumerate(mahalanobis_distances_unknown) if distance > threshold_unknown]\n",
        "\n",
        "print(\"Out-of-Distribution Sample Indices (Known Data):\", ood_samples_known)\n",
        "print(\"Out-of-Distribution Sample Indices (Unknown Data):\", ood_samples_unknown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml0THzer5PPJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(mahalanobis_distances_known, bins=10)\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Known Data')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(mahalanobis_distances_unknown, bins=10)\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Unknown Data')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlgL09fo5PRy"
      },
      "outputs": [],
      "source": [
        "plt.hist([mahalanobis_distances_known, mahalanobis_distances_unknown], bins=25, label=['Samples belonging to the knowns', 'Never seen before samples'])  # Specify the number of bins and labels\n",
        "plt.xlim(2.5, 15)\n",
        "\n",
        "plt.xlabel('Value of the Mahalanobis score')\n",
        "plt.ylabel('Frequency of occurrence')\n",
        "plt.title('Comparison of Mahalanobis scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8Xxqpvr5PUV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "mahalanobis_scores_known_sorted = np.sort(mahalanobis_distances_known)\n",
        "mahalanobis_scores_unknown_sorted = np.sort(mahalanobis_distances_unknown)\n",
        "\n",
        "min_known_score = mahalanobis_scores_known_sorted.min()\n",
        "max_known_score = mahalanobis_scores_known_sorted.max()\n",
        "min_unknown_score = mahalanobis_scores_unknown_sorted.min()\n",
        "max_unknown_score = mahalanobis_scores_unknown_sorted.max()\n",
        "\n",
        "bins = np.linspace(min(min_known_score, min_unknown_score), max(max_known_score, max_unknown_score), 1000)\n",
        "\n",
        "hist_known, _ = np.histogram(mahalanobis_scores_known_sorted, bins)\n",
        "hist_unknown, _ = np.histogram(mahalanobis_scores_unknown_sorted, bins)\n",
        "\n",
        "intersection = np.minimum(hist_known, hist_unknown)\n",
        "union = np.maximum(hist_known, hist_unknown)\n",
        "\n",
        "iou = np.sum(intersection) / np.sum(union) * 100\n",
        "\n",
        "print(f\"Overlap (IoU): {iou:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCiMJfcc5PW5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuSPZIJdF49F"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(3, 1, figsize=(8, 12))\n",
        "\n",
        "axs[0].hist([odin_scores_KNOWN, odin_scores_UN_KNOWN], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[0].set_xlabel('Value of the ODIN score')\n",
        "axs[0].set_ylabel('Frequency of occurrence')\n",
        "axs[0].set_title('Comparison of ODIN scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].hist([openmax_scores_known, openmax_scores_unknown], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[1].set_xlabel('Value of the OpenMax score')\n",
        "axs[1].set_ylabel('Frequency of occurrence')\n",
        "axs[1].set_title('Comparison of OpenMax scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[2].hist([mahalanobis_distances_known, mahalanobis_distances_unknown], bins=25, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[2].set_xlabel('Value of the Mahalanobis score')\n",
        "axs[2].set_ylabel('Frequency of occurrence')\n",
        "axs[2].set_title('Comparison of Mahalanobis scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGqgXKZVF5AR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "axs[0].hist([odin_scores_KNOWN, odin_scores_UN_KNOWN], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[0].set_xlabel('Value of the ODIN score')\n",
        "axs[0].set_ylabel('Frequency of occurrence')\n",
        "axs[0].set_title('Comparison of ODIN scores, Obj.class, $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].hist([openmax_scores_known, openmax_scores_unknown], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[1].set_xlabel('Value of the OpenMax score')\n",
        "axs[1].set_ylabel('Frequency of occurrence')\n",
        "axs[1].set_title('Comparison of OpenMax scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[2].hist([mahalanobis_distances_known, mahalanobis_distances_unknown], bins=25, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[2].set_xlabel('Value of the Mahalanobis score')\n",
        "axs[2].set_ylabel('Frequency of occurrence')\n",
        "axs[2].set_title('Comparison of Mahalanobis scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Pq2KqHYYgM"
      },
      "source": [
        "# Separating $\\mathcal{K}$ and $\\mathcal{N}$ by a fixed (class-independendent) threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZfHJkznZ4Lq"
      },
      "outputs": [],
      "source": [
        "prediction_known = prediction_known_ensemble_1\n",
        "prediction_unknown = prediction_unknown_ensemble_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA75xLuUGNca"
      },
      "outputs": [],
      "source": [
        "def thresholding(threshold):\n",
        "  true = 0\n",
        "  for i in range(prediction_known.shape[0]):\n",
        "    if prediction_known.argmax(axis=1)[i] == Known_data_X_test_label_int[i] and max(prediction_known[i]) > threshold:\n",
        "      true += 1\n",
        "  return true/(prediction_known.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW6PGNX72bky",
        "outputId": "77ce3041-0e67-4fc9-a504-81287ba116f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.1, 88.85],\n",
              " [0.11, 88.85],\n",
              " [0.12000000000000001, 88.85],\n",
              " [0.13, 88.85],\n",
              " [0.14, 88.85],\n",
              " [0.15000000000000002, 88.85],\n",
              " [0.16, 88.85],\n",
              " [0.17, 88.85],\n",
              " [0.18, 88.85],\n",
              " [0.19, 88.85],\n",
              " [0.2, 88.85],\n",
              " [0.21000000000000002, 88.8],\n",
              " [0.22, 88.8],\n",
              " [0.23, 88.8],\n",
              " [0.24000000000000002, 88.8],\n",
              " [0.25, 88.8],\n",
              " [0.26, 88.8],\n",
              " [0.27, 88.8],\n",
              " [0.28, 88.8],\n",
              " [0.29000000000000004, 88.8],\n",
              " [0.30000000000000004, 88.8],\n",
              " [0.31, 88.8],\n",
              " [0.32, 88.8],\n",
              " [0.33, 88.8],\n",
              " [0.33999999999999997, 88.8],\n",
              " [0.35, 88.8],\n",
              " [0.36, 88.8],\n",
              " [0.37, 88.8],\n",
              " [0.38, 88.8],\n",
              " [0.39, 88.8],\n",
              " [0.4, 88.75],\n",
              " [0.41000000000000003, 88.75],\n",
              " [0.42000000000000004, 88.75],\n",
              " [0.43000000000000005, 88.7],\n",
              " [0.44000000000000006, 88.6],\n",
              " [0.45000000000000007, 88.6],\n",
              " [0.45999999999999996, 88.6],\n",
              " [0.47, 88.5],\n",
              " [0.48, 88.4],\n",
              " [0.49, 88.3],\n",
              " [0.5, 88.25],\n",
              " [0.51, 88.25],\n",
              " [0.52, 88.2],\n",
              " [0.53, 87.9],\n",
              " [0.54, 87.85],\n",
              " [0.55, 87.6],\n",
              " [0.56, 87.25],\n",
              " [0.5700000000000001, 87.15],\n",
              " [0.58, 86.95],\n",
              " [0.59, 86.8],\n",
              " [0.6, 86.45],\n",
              " [0.61, 86.3],\n",
              " [0.62, 86.1],\n",
              " [0.63, 85.95],\n",
              " [0.64, 85.9],\n",
              " [0.65, 85.65],\n",
              " [0.66, 85.45],\n",
              " [0.67, 85.35000000000001],\n",
              " [0.6799999999999999, 84.95],\n",
              " [0.69, 84.65],\n",
              " [0.7, 84.5],\n",
              " [0.71, 84.2],\n",
              " [0.72, 83.8],\n",
              " [0.73, 83.6],\n",
              " [0.74, 83.55],\n",
              " [0.75, 83.3],\n",
              " [0.76, 83.15],\n",
              " [0.77, 83.0],\n",
              " [0.78, 82.55],\n",
              " [0.79, 82.35],\n",
              " [0.8, 82.0],\n",
              " [0.8099999999999999, 81.69999999999999],\n",
              " [0.82, 81.39999999999999],\n",
              " [0.83, 80.9],\n",
              " [0.84, 80.55],\n",
              " [0.85, 79.75],\n",
              " [0.86, 79.55],\n",
              " [0.87, 79.2],\n",
              " [0.88, 78.5],\n",
              " [0.89, 77.95],\n",
              " [0.9, 77.55],\n",
              " [0.91, 77.05],\n",
              " [0.92, 76.44999999999999],\n",
              " [0.93, 75.55],\n",
              " [0.94, 74.6],\n",
              " [0.95, 73.6],\n",
              " [0.96, 72.1],\n",
              " [0.97, 70.15],\n",
              " [0.98, 67.35],\n",
              " [0.99, 62.64999999999999],\n",
              " [0.99, 62.64999999999999],\n",
              " [0.991, 61.550000000000004],\n",
              " [0.992, 61.050000000000004],\n",
              " [0.993, 60.050000000000004],\n",
              " [0.994, 59.45],\n",
              " [0.995, 57.99999999999999],\n",
              " [0.996, 56.599999999999994],\n",
              " [0.997, 54.300000000000004],\n",
              " [0.998, 50.64999999999999],\n",
              " [0.999, 46.050000000000004]]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CorrectThresholding = []\n",
        "for i in range(90):\n",
        "  CorrectThresholding.append([0.1 + 0.01*i,100*thresholding(0.1 + 0.01*i)])\n",
        "for i in range(10):\n",
        "  CorrectThresholding.append([0.99 + 0.001*i,100*thresholding(0.99 + 0.001*i)])\n",
        "CorrectThresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn2lRWxDM4G4"
      },
      "outputs": [],
      "source": [
        "def false_identify(threshold):\n",
        "  false_identify = 0\n",
        "  for i in range(prediction_known.shape[0]):\n",
        "    if prediction_known.argmax(axis=1)[i] != Known_data_X_test_label_int[i] and max(prediction_known[i]) > threshold:\n",
        "      false_identify += 1\n",
        "  return false_identify/(prediction_known.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M753dWrlM4Km",
        "outputId": "8cc286c4-020e-4aeb-c75f-63d314cfa2fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.1, 11.15],\n",
              " [0.11, 11.15],\n",
              " [0.12000000000000001, 11.15],\n",
              " [0.13, 11.15],\n",
              " [0.14, 11.15],\n",
              " [0.15000000000000002, 11.15],\n",
              " [0.16, 11.15],\n",
              " [0.17, 11.15],\n",
              " [0.18, 11.15],\n",
              " [0.19, 11.15],\n",
              " [0.2, 11.15],\n",
              " [0.21000000000000002, 11.15],\n",
              " [0.22, 11.15],\n",
              " [0.23, 11.15],\n",
              " [0.24000000000000002, 11.15],\n",
              " [0.25, 11.15],\n",
              " [0.26, 11.15],\n",
              " [0.27, 11.1],\n",
              " [0.28, 11.1],\n",
              " [0.29000000000000004, 11.1],\n",
              " [0.30000000000000004, 11.1],\n",
              " [0.31, 11.1],\n",
              " [0.32, 11.1],\n",
              " [0.33, 11.0],\n",
              " [0.33999999999999997, 10.9],\n",
              " [0.35, 10.7],\n",
              " [0.36, 10.65],\n",
              " [0.37, 10.6],\n",
              " [0.38, 10.5],\n",
              " [0.39, 10.4],\n",
              " [0.4, 10.299999999999999],\n",
              " [0.41000000000000003, 10.299999999999999],\n",
              " [0.42000000000000004, 10.15],\n",
              " [0.43000000000000005, 10.0],\n",
              " [0.44000000000000006, 9.85],\n",
              " [0.45000000000000007, 9.85],\n",
              " [0.45999999999999996, 9.85],\n",
              " [0.47, 9.85],\n",
              " [0.48, 9.75],\n",
              " [0.49, 9.75],\n",
              " [0.5, 9.65],\n",
              " [0.51, 9.55],\n",
              " [0.52, 9.4],\n",
              " [0.53, 9.2],\n",
              " [0.54, 9.049999999999999],\n",
              " [0.55, 8.95],\n",
              " [0.56, 8.649999999999999],\n",
              " [0.5700000000000001, 8.55],\n",
              " [0.58, 8.4],\n",
              " [0.59, 8.3],\n",
              " [0.6, 8.1],\n",
              " [0.61, 7.95],\n",
              " [0.62, 7.8],\n",
              " [0.63, 7.7],\n",
              " [0.64, 7.55],\n",
              " [0.65, 7.449999999999999],\n",
              " [0.66, 7.3],\n",
              " [0.67, 7.249999999999999],\n",
              " [0.6799999999999999, 7.049999999999999],\n",
              " [0.69, 6.800000000000001],\n",
              " [0.7, 6.5],\n",
              " [0.71, 6.5],\n",
              " [0.72, 6.15],\n",
              " [0.73, 6.05],\n",
              " [0.74, 5.8500000000000005],\n",
              " [0.75, 5.7],\n",
              " [0.76, 5.55],\n",
              " [0.77, 5.5],\n",
              " [0.78, 5.3],\n",
              " [0.79, 5.2],\n",
              " [0.8, 5.0],\n",
              " [0.8099999999999999, 4.8500000000000005],\n",
              " [0.82, 4.7],\n",
              " [0.83, 4.55],\n",
              " [0.84, 4.35],\n",
              " [0.85, 4.2],\n",
              " [0.86, 3.95],\n",
              " [0.87, 3.75],\n",
              " [0.88, 3.55],\n",
              " [0.89, 3.45],\n",
              " [0.9, 3.25],\n",
              " [0.91, 3.15],\n",
              " [0.92, 2.9000000000000004],\n",
              " [0.93, 2.85],\n",
              " [0.94, 2.4],\n",
              " [0.95, 2.1],\n",
              " [0.96, 1.9],\n",
              " [0.97, 1.7000000000000002],\n",
              " [0.98, 1.3],\n",
              " [0.99, 0.7000000000000001],\n",
              " [0.99, 0.7000000000000001],\n",
              " [0.991, 0.7000000000000001],\n",
              " [0.992, 0.7000000000000001],\n",
              " [0.993, 0.65],\n",
              " [0.994, 0.6],\n",
              " [0.995, 0.44999999999999996],\n",
              " [0.996, 0.35000000000000003],\n",
              " [0.997, 0.25],\n",
              " [0.998, 0.2],\n",
              " [0.999, 0.05]]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FalseIdentify = []\n",
        "for i in range(90):\n",
        "  FalseIdentify.append([0.1 + 0.01*i,100*false_identify(0.1 + 0.01*i)])\n",
        "for i in range(10):\n",
        "  FalseIdentify.append([0.99 + 0.001*i,100*false_identify(0.99 + 0.001*i)])\n",
        "FalseIdentify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InSYYnV1M4Of"
      },
      "outputs": [],
      "source": [
        "def misclassifyunknown(threshold):\n",
        "  misclassifyunknown = 0\n",
        "  for i in range(prediction_unknown.shape[0]):\n",
        "    if max(prediction_unknown[i]) > threshold:\n",
        "      misclassifyunknown += 1\n",
        "  return misclassifyunknown/(prediction_unknown.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKdfbnzZM4ST",
        "outputId": "02838aaa-a651-4b41-8d3b-ce553316a2bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.1, 100.0],\n",
              " [0.11, 100.0],\n",
              " [0.12000000000000001, 100.0],\n",
              " [0.13, 100.0],\n",
              " [0.14, 100.0],\n",
              " [0.15000000000000002, 100.0],\n",
              " [0.16, 100.0],\n",
              " [0.17, 100.0],\n",
              " [0.18, 100.0],\n",
              " [0.19, 100.0],\n",
              " [0.2, 100.0],\n",
              " [0.21000000000000002, 100.0],\n",
              " [0.22, 100.0],\n",
              " [0.23, 100.0],\n",
              " [0.24000000000000002, 100.0],\n",
              " [0.25, 100.0],\n",
              " [0.26, 100.0],\n",
              " [0.27, 100.0],\n",
              " [0.28, 100.0],\n",
              " [0.29000000000000004, 100.0],\n",
              " [0.30000000000000004, 99.8],\n",
              " [0.31, 99.8],\n",
              " [0.32, 99.8],\n",
              " [0.33, 99.7],\n",
              " [0.33999999999999997, 99.6],\n",
              " [0.35, 99.5],\n",
              " [0.36, 99.4],\n",
              " [0.37, 99.4],\n",
              " [0.38, 98.9],\n",
              " [0.39, 98.6],\n",
              " [0.4, 98.4],\n",
              " [0.41000000000000003, 98.3],\n",
              " [0.42000000000000004, 98.1],\n",
              " [0.43000000000000005, 97.89999999999999],\n",
              " [0.44000000000000006, 97.89999999999999],\n",
              " [0.45000000000000007, 97.2],\n",
              " [0.45999999999999996, 96.89999999999999],\n",
              " [0.47, 96.6],\n",
              " [0.48, 96.5],\n",
              " [0.49, 95.89999999999999],\n",
              " [0.5, 95.5],\n",
              " [0.51, 94.19999999999999],\n",
              " [0.52, 92.9],\n",
              " [0.53, 92.2],\n",
              " [0.54, 91.10000000000001],\n",
              " [0.55, 90.60000000000001],\n",
              " [0.56, 89.60000000000001],\n",
              " [0.5700000000000001, 88.4],\n",
              " [0.58, 87.3],\n",
              " [0.59, 85.9],\n",
              " [0.6, 84.3],\n",
              " [0.61, 83.39999999999999],\n",
              " [0.62, 82.8],\n",
              " [0.63, 81.5],\n",
              " [0.64, 80.9],\n",
              " [0.65, 80.30000000000001],\n",
              " [0.66, 79.0],\n",
              " [0.67, 77.8],\n",
              " [0.6799999999999999, 76.9],\n",
              " [0.69, 76.2],\n",
              " [0.7, 74.5],\n",
              " [0.71, 73.3],\n",
              " [0.72, 72.2],\n",
              " [0.73, 70.89999999999999],\n",
              " [0.74, 70.3],\n",
              " [0.75, 69.8],\n",
              " [0.76, 68.7],\n",
              " [0.77, 67.80000000000001],\n",
              " [0.78, 67.2],\n",
              " [0.79, 66.60000000000001],\n",
              " [0.8, 65.2],\n",
              " [0.8099999999999999, 64.2],\n",
              " [0.82, 62.9],\n",
              " [0.83, 62.0],\n",
              " [0.84, 60.9],\n",
              " [0.85, 59.099999999999994],\n",
              " [0.86, 57.9],\n",
              " [0.87, 56.8],\n",
              " [0.88, 55.2],\n",
              " [0.89, 54.400000000000006],\n",
              " [0.9, 52.7],\n",
              " [0.91, 50.6],\n",
              " [0.92, 48.0],\n",
              " [0.93, 46.400000000000006],\n",
              " [0.94, 45.0],\n",
              " [0.95, 42.1],\n",
              " [0.96, 39.7],\n",
              " [0.97, 36.8],\n",
              " [0.98, 31.6],\n",
              " [0.99, 25.6],\n",
              " [0.99, 25.6],\n",
              " [0.991, 24.6],\n",
              " [0.992, 23.599999999999998],\n",
              " [0.993, 22.7],\n",
              " [0.994, 21.8],\n",
              " [0.995, 20.5],\n",
              " [0.996, 19.2],\n",
              " [0.997, 17.8],\n",
              " [0.998, 16.0],\n",
              " [0.999, 12.8]]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "UnknownMisclassify = []\n",
        "for i in range(90):\n",
        "  UnknownMisclassify.append([0.1 + 0.01*i,100*misclassifyunknown(0.1 + 0.01*i)])\n",
        "for i in range(10):\n",
        "  UnknownMisclassify.append([0.99 + 0.001*i,100*misclassifyunknown(0.99 + 0.001*i)])\n",
        "UnknownMisclassify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXvKcD4fM4VD"
      },
      "outputs": [],
      "source": [
        "def dontknow(threshold):\n",
        "  notknown = 0\n",
        "  for i in range(prediction_known.shape[0]):\n",
        "    if max(prediction_known[i]) <= threshold:\n",
        "      notknown += 1\n",
        "  return notknown/(prediction_known.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGoW1WLO4_eu",
        "outputId": "01cea077-3532-455a-979b-2bfb4623e970"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.1, 0.0],\n",
              " [0.11, 0.0],\n",
              " [0.12000000000000001, 0.0],\n",
              " [0.13, 0.0],\n",
              " [0.14, 0.0],\n",
              " [0.15000000000000002, 0.0],\n",
              " [0.16, 0.0],\n",
              " [0.17, 0.0],\n",
              " [0.18, 0.0],\n",
              " [0.19, 0.0],\n",
              " [0.2, 0.0],\n",
              " [0.21000000000000002, 0.05],\n",
              " [0.22, 0.05],\n",
              " [0.23, 0.05],\n",
              " [0.24000000000000002, 0.05],\n",
              " [0.25, 0.05],\n",
              " [0.26, 0.05],\n",
              " [0.27, 0.1],\n",
              " [0.28, 0.1],\n",
              " [0.29000000000000004, 0.1],\n",
              " [0.30000000000000004, 0.1],\n",
              " [0.31, 0.1],\n",
              " [0.32, 0.1],\n",
              " [0.33, 0.2],\n",
              " [0.33999999999999997, 0.3],\n",
              " [0.35, 0.5],\n",
              " [0.36, 0.5499999999999999],\n",
              " [0.37, 0.6],\n",
              " [0.38, 0.7000000000000001],\n",
              " [0.39, 0.8],\n",
              " [0.4, 0.95],\n",
              " [0.41000000000000003, 0.95],\n",
              " [0.42000000000000004, 1.0999999999999999],\n",
              " [0.43000000000000005, 1.3],\n",
              " [0.44000000000000006, 1.55],\n",
              " [0.45000000000000007, 1.55],\n",
              " [0.45999999999999996, 1.55],\n",
              " [0.47, 1.6500000000000001],\n",
              " [0.48, 1.8499999999999999],\n",
              " [0.49, 1.95],\n",
              " [0.5, 2.1],\n",
              " [0.51, 2.1999999999999997],\n",
              " [0.52, 2.4],\n",
              " [0.53, 2.9000000000000004],\n",
              " [0.54, 3.1],\n",
              " [0.55, 3.45],\n",
              " [0.56, 4.1000000000000005],\n",
              " [0.5700000000000001, 4.3],\n",
              " [0.58, 4.65],\n",
              " [0.59, 4.9],\n",
              " [0.6, 5.45],\n",
              " [0.61, 5.75],\n",
              " [0.62, 6.1],\n",
              " [0.63, 6.35],\n",
              " [0.64, 6.550000000000001],\n",
              " [0.65, 6.9],\n",
              " [0.66, 7.249999999999999],\n",
              " [0.67, 7.3999999999999995],\n",
              " [0.6799999999999999, 8.0],\n",
              " [0.69, 8.55],\n",
              " [0.7, 9.0],\n",
              " [0.71, 9.3],\n",
              " [0.72, 10.05],\n",
              " [0.73, 10.35],\n",
              " [0.74, 10.6],\n",
              " [0.75, 11.0],\n",
              " [0.76, 11.3],\n",
              " [0.77, 11.5],\n",
              " [0.78, 12.15],\n",
              " [0.79, 12.45],\n",
              " [0.8, 13.0],\n",
              " [0.8099999999999999, 13.450000000000001],\n",
              " [0.82, 13.900000000000002],\n",
              " [0.83, 14.549999999999999],\n",
              " [0.84, 15.1],\n",
              " [0.85, 16.05],\n",
              " [0.86, 16.5],\n",
              " [0.87, 17.05],\n",
              " [0.88, 17.95],\n",
              " [0.89, 18.6],\n",
              " [0.9, 19.2],\n",
              " [0.91, 19.8],\n",
              " [0.92, 20.65],\n",
              " [0.93, 21.6],\n",
              " [0.94, 23.0],\n",
              " [0.95, 24.3],\n",
              " [0.96, 26.0],\n",
              " [0.97, 28.15],\n",
              " [0.98, 31.35],\n",
              " [0.99, 36.65],\n",
              " [0.99, 36.65],\n",
              " [0.991, 37.75],\n",
              " [0.992, 38.25],\n",
              " [0.993, 39.300000000000004],\n",
              " [0.994, 39.95],\n",
              " [0.995, 41.55],\n",
              " [0.996, 43.05],\n",
              " [0.997, 45.45],\n",
              " [0.998, 49.15],\n",
              " [0.999, 53.900000000000006]]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DontKnowThresholding = []\n",
        "for i in range(90):\n",
        "  DontKnowThresholding.append([0.1 + 0.01*i,100*dontknow(0.1 + 0.01*i)])\n",
        "for i in range(10):\n",
        "  DontKnowThresholding.append([0.99 + 0.001*i,100*dontknow(0.99 + 0.001*i)])\n",
        "DontKnowThresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whvlD7tVNOew",
        "outputId": "1f126fd6-abad-425f-d158-32d6fe811f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The maximum value in the aligned array is: 0.9999999\n"
          ]
        }
      ],
      "source": [
        "aligned_array = [element for row in prediction_unknown for element in row]\n",
        "max_value = max(aligned_array)\n",
        "\n",
        "print(\"The maximum value in the aligned array is:\", max_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQT16bp2f4xV",
        "outputId": "c5508a55-dd99-4efb-85a4-318f695b20e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thresholding(max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb8_5G4-hP8l",
        "outputId": "9a3d2f4c-b984-4636-fe79-0b354dd1b7f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dontknow(max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjStdK4hhS8K",
        "outputId": "ef61fc82-c43a-4f35-ecc7-2ff8ee788c34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "misclassifyunknown(max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ihRU5ZxhbjN",
        "outputId": "0da8c3b8-7fe5-4f14-cc0a-710d73c7b508"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "false_identify(max_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRKbUDYDNOSp",
        "outputId": "70b41d51-7e3b-4b69-db5e-d878f5bc157a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.85, 0.0],\n",
              " [88.8, 0.05],\n",
              " [88.8, 0.05],\n",
              " [88.8, 0.05],\n",
              " [88.8, 0.05],\n",
              " [88.8, 0.05],\n",
              " [88.8, 0.05],\n",
              " [88.8, 0.1],\n",
              " [88.8, 0.1],\n",
              " [88.8, 0.1],\n",
              " [88.8, 0.1],\n",
              " [88.8, 0.1],\n",
              " [88.8, 0.1],\n",
              " [88.8, 0.2],\n",
              " [88.8, 0.3],\n",
              " [88.8, 0.5],\n",
              " [88.8, 0.5499999999999999],\n",
              " [88.8, 0.6],\n",
              " [88.8, 0.7000000000000001],\n",
              " [88.8, 0.8],\n",
              " [88.75, 0.95],\n",
              " [88.75, 0.95],\n",
              " [88.75, 1.0999999999999999],\n",
              " [88.7, 1.3],\n",
              " [88.6, 1.55],\n",
              " [88.6, 1.55],\n",
              " [88.6, 1.55],\n",
              " [88.5, 1.6500000000000001],\n",
              " [88.4, 1.8499999999999999],\n",
              " [88.3, 1.95],\n",
              " [88.25, 2.1],\n",
              " [88.25, 2.1999999999999997],\n",
              " [88.2, 2.4],\n",
              " [87.9, 2.9000000000000004],\n",
              " [87.85, 3.1],\n",
              " [87.6, 3.45],\n",
              " [87.25, 4.1000000000000005],\n",
              " [87.15, 4.3],\n",
              " [86.95, 4.65],\n",
              " [86.8, 4.9],\n",
              " [86.45, 5.45],\n",
              " [86.3, 5.75],\n",
              " [86.1, 6.1],\n",
              " [85.95, 6.35],\n",
              " [85.9, 6.550000000000001],\n",
              " [85.65, 6.9],\n",
              " [85.45, 7.249999999999999],\n",
              " [85.35000000000001, 7.3999999999999995],\n",
              " [84.95, 8.0],\n",
              " [84.65, 8.55],\n",
              " [84.5, 9.0],\n",
              " [84.2, 9.3],\n",
              " [83.8, 10.05],\n",
              " [83.6, 10.35],\n",
              " [83.55, 10.6],\n",
              " [83.3, 11.0],\n",
              " [83.15, 11.3],\n",
              " [83.0, 11.5],\n",
              " [82.55, 12.15],\n",
              " [82.35, 12.45],\n",
              " [82.0, 13.0],\n",
              " [81.69999999999999, 13.450000000000001],\n",
              " [81.39999999999999, 13.900000000000002],\n",
              " [80.9, 14.549999999999999],\n",
              " [80.55, 15.1],\n",
              " [79.75, 16.05],\n",
              " [79.55, 16.5],\n",
              " [79.2, 17.05],\n",
              " [78.5, 17.95],\n",
              " [77.95, 18.6],\n",
              " [77.55, 19.2],\n",
              " [77.05, 19.8],\n",
              " [76.44999999999999, 20.65],\n",
              " [75.55, 21.6],\n",
              " [74.6, 23.0],\n",
              " [73.6, 24.3],\n",
              " [72.1, 26.0],\n",
              " [70.15, 28.15],\n",
              " [67.35, 31.35],\n",
              " [62.64999999999999, 36.65],\n",
              " [61.550000000000004, 37.75],\n",
              " [61.050000000000004, 38.25],\n",
              " [60.050000000000004, 39.300000000000004],\n",
              " [59.45, 39.95],\n",
              " [57.99999999999999, 41.55],\n",
              " [56.599999999999994, 43.05],\n",
              " [54.300000000000004, 45.45],\n",
              " [50.64999999999999, 49.15],\n",
              " [46.050000000000004, 53.900000000000006],\n",
              " [46.050000000000004, 53.900000000000006],\n",
              " [45.300000000000004, 54.65],\n",
              " [44.25, 55.7],\n",
              " [43.55, 56.39999999999999],\n",
              " [42.5, 57.45],\n",
              " [41.4, 58.550000000000004],\n",
              " [39.4, 60.550000000000004],\n",
              " [37.5, 62.45],\n",
              " [35.15, 64.85],\n",
              " [30.45, 69.55],\n",
              " [30.45, 69.55],\n",
              " [29.799999999999997, 70.19999999999999],\n",
              " [29.099999999999998, 70.89999999999999],\n",
              " [28.4, 71.6],\n",
              " [27.700000000000003, 72.3],\n",
              " [26.85, 73.15],\n",
              " [25.35, 74.65],\n",
              " [24.4, 75.6],\n",
              " [22.7, 77.3],\n",
              " [19.85, 80.15],\n",
              " [19.85, 80.15],\n",
              " [19.400000000000002, 80.60000000000001],\n",
              " [19.15, 80.85],\n",
              " [18.7, 81.3],\n",
              " [18.2, 81.8],\n",
              " [17.8, 82.19999999999999],\n",
              " [17.05, 82.95],\n",
              " [16.1, 83.89999999999999],\n",
              " [14.7, 85.3],\n",
              " [13.3, 86.7],\n",
              " [13.3, 86.7],\n",
              " [13.0, 87.0],\n",
              " [12.75, 87.25],\n",
              " [12.0, 88.0],\n",
              " [11.799999999999999, 88.2],\n",
              " [11.5, 88.5],\n",
              " [11.0, 89.0],\n",
              " [10.2, 89.8],\n",
              " [9.55, 90.45],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0],\n",
              " [0.0, 100.0]]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DontKnowThresholdingANOTHER = []\n",
        "\n",
        "for i in range(89):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.1 + 0.01*i),100*dontknow(0.1 + 0.01*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.99 + 0.001*i),100*dontknow(0.99 + 0.001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.999 + 0.0001*i),100*dontknow(0.999 + 0.0001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.9999 + 0.00001*i),100*dontknow(0.9999 + 0.00001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.99999 + 0.000001*i),100*dontknow(0.99999 + 0.000001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.999999 + 0.0000001*i),100*dontknow(0.999999 + 0.0000001*i),])\n",
        "\n",
        "for i in range(9):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.9999999 + 0.00000001*i),100*dontknow(0.9999999 + 0.00000001*i),])\n",
        "\n",
        "DontKnowThresholdingANOTHER.append([100*thresholding(max_value),100*dontknow(max_value)])\n",
        "\n",
        "DontKnowThresholdingANOTHER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkK7Pwx6b9vA",
        "outputId": "571db14c-4543-4e78-ca4d-5e3afa7d13ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.85, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 100.0],\n",
              " [88.8, 99.8],\n",
              " [88.8, 99.8],\n",
              " [88.8, 99.8],\n",
              " [88.8, 99.7],\n",
              " [88.8, 99.6],\n",
              " [88.8, 99.5],\n",
              " [88.8, 99.4],\n",
              " [88.8, 99.4],\n",
              " [88.8, 98.9],\n",
              " [88.8, 98.6],\n",
              " [88.75, 98.4],\n",
              " [88.75, 98.3],\n",
              " [88.75, 98.1],\n",
              " [88.7, 97.89999999999999],\n",
              " [88.6, 97.89999999999999],\n",
              " [88.6, 97.2],\n",
              " [88.6, 96.89999999999999],\n",
              " [88.5, 96.6],\n",
              " [88.4, 96.5],\n",
              " [88.3, 95.89999999999999],\n",
              " [88.25, 95.5],\n",
              " [88.25, 94.19999999999999],\n",
              " [88.2, 92.9],\n",
              " [87.9, 92.2],\n",
              " [87.85, 91.10000000000001],\n",
              " [87.6, 90.60000000000001],\n",
              " [87.25, 89.60000000000001],\n",
              " [87.15, 88.4],\n",
              " [86.95, 87.3],\n",
              " [86.8, 85.9],\n",
              " [86.45, 84.3],\n",
              " [86.3, 83.39999999999999],\n",
              " [86.1, 82.8],\n",
              " [85.95, 81.5],\n",
              " [85.9, 80.9],\n",
              " [85.65, 80.30000000000001],\n",
              " [85.45, 79.0],\n",
              " [85.35000000000001, 77.8],\n",
              " [84.95, 76.9],\n",
              " [84.65, 76.2],\n",
              " [84.5, 74.5],\n",
              " [84.2, 73.3],\n",
              " [83.8, 72.2],\n",
              " [83.6, 70.89999999999999],\n",
              " [83.55, 70.3],\n",
              " [83.3, 69.8],\n",
              " [83.15, 68.7],\n",
              " [83.0, 67.80000000000001],\n",
              " [82.55, 67.2],\n",
              " [82.35, 66.60000000000001],\n",
              " [82.0, 65.2],\n",
              " [81.69999999999999, 64.2],\n",
              " [81.39999999999999, 62.9],\n",
              " [80.9, 62.0],\n",
              " [80.55, 60.9],\n",
              " [79.75, 59.099999999999994],\n",
              " [79.55, 57.9],\n",
              " [79.2, 56.8],\n",
              " [78.5, 55.2],\n",
              " [77.95, 54.400000000000006],\n",
              " [77.55, 52.7],\n",
              " [77.05, 50.6],\n",
              " [76.44999999999999, 48.0],\n",
              " [75.55, 46.400000000000006],\n",
              " [74.6, 45.0],\n",
              " [73.6, 42.1],\n",
              " [72.1, 39.7],\n",
              " [70.15, 36.8],\n",
              " [67.35, 31.6],\n",
              " [62.64999999999999, 25.6],\n",
              " [61.550000000000004, 24.6],\n",
              " [61.050000000000004, 23.599999999999998],\n",
              " [60.050000000000004, 22.7],\n",
              " [59.45, 21.8],\n",
              " [57.99999999999999, 20.5],\n",
              " [56.599999999999994, 19.2],\n",
              " [54.300000000000004, 17.8],\n",
              " [50.64999999999999, 16.0],\n",
              " [46.050000000000004, 12.8],\n",
              " [46.050000000000004, 12.8],\n",
              " [45.300000000000004, 12.5],\n",
              " [44.25, 12.3],\n",
              " [43.55, 12.1],\n",
              " [42.5, 11.899999999999999],\n",
              " [41.4, 11.4],\n",
              " [39.4, 10.2],\n",
              " [37.5, 9.1],\n",
              " [35.15, 8.4],\n",
              " [30.45, 7.1],\n",
              " [30.45, 7.1],\n",
              " [29.799999999999997, 7.000000000000001],\n",
              " [29.099999999999998, 6.800000000000001],\n",
              " [28.4, 6.7],\n",
              " [27.700000000000003, 6.3],\n",
              " [26.85, 5.8999999999999995],\n",
              " [25.35, 5.7],\n",
              " [24.4, 5.6000000000000005],\n",
              " [22.7, 5.0],\n",
              " [19.85, 4.0],\n",
              " [19.85, 4.0],\n",
              " [19.400000000000002, 3.9],\n",
              " [19.15, 3.8],\n",
              " [18.7, 3.5999999999999996],\n",
              " [18.2, 3.3000000000000003],\n",
              " [17.8, 3.0],\n",
              " [17.05, 2.7],\n",
              " [16.1, 2.6],\n",
              " [14.7, 1.7000000000000002],\n",
              " [13.3, 1.0999999999999999],\n",
              " [13.3, 1.0999999999999999],\n",
              " [13.0, 1.0999999999999999],\n",
              " [12.75, 1.0999999999999999],\n",
              " [12.0, 1.0999999999999999],\n",
              " [11.799999999999999, 1.0999999999999999],\n",
              " [11.5, 1.0],\n",
              " [11.0, 0.8999999999999999],\n",
              " [10.2, 0.8],\n",
              " [9.55, 0.5],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0]]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "UnknownMisclassifyANOTHER = []\n",
        "for i in range(89):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.1 + 0.01*i),100*misclassifyunknown(0.1 + 0.01*i),])\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.99 + 0.001*i),100*misclassifyunknown(0.99 + 0.001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.999 + 0.0001*i),100*misclassifyunknown(0.999 + 0.0001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.9999 + 0.00001*i),100*misclassifyunknown(0.9999 + 0.00001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.99999 + 0.000001*i),100*misclassifyunknown(0.99999 + 0.000001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.999999 + 0.0000001*i),100*misclassifyunknown(0.999999 + 0.0000001*i),])\n",
        "\n",
        "for i in range(9):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.9999999 + 0.00000001*i),100*misclassifyunknown(0.9999999 + 0.00000001*i),])\n",
        "\n",
        "UnknownMisclassifyANOTHER.append([100*thresholding(max_value),100*misclassifyunknown(max_value),])\n",
        "\n",
        "UnknownMisclassifyANOTHER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe9DmTAKNOXR",
        "outputId": "b5b5522f-5be3-4efe-ab56-8da89998b2b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.85, 11.15],\n",
              " [88.8, 11.15],\n",
              " [88.8, 11.15],\n",
              " [88.8, 11.15],\n",
              " [88.8, 11.15],\n",
              " [88.8, 11.15],\n",
              " [88.8, 11.15],\n",
              " [88.8, 11.1],\n",
              " [88.8, 11.1],\n",
              " [88.8, 11.1],\n",
              " [88.8, 11.1],\n",
              " [88.8, 11.1],\n",
              " [88.8, 11.1],\n",
              " [88.8, 11.0],\n",
              " [88.8, 10.9],\n",
              " [88.8, 10.7],\n",
              " [88.8, 10.65],\n",
              " [88.8, 10.6],\n",
              " [88.8, 10.5],\n",
              " [88.8, 10.4],\n",
              " [88.75, 10.299999999999999],\n",
              " [88.75, 10.299999999999999],\n",
              " [88.75, 10.15],\n",
              " [88.7, 10.0],\n",
              " [88.6, 9.85],\n",
              " [88.6, 9.85],\n",
              " [88.6, 9.85],\n",
              " [88.5, 9.85],\n",
              " [88.4, 9.75],\n",
              " [88.3, 9.75],\n",
              " [88.25, 9.65],\n",
              " [88.25, 9.55],\n",
              " [88.2, 9.4],\n",
              " [87.9, 9.2],\n",
              " [87.85, 9.049999999999999],\n",
              " [87.6, 8.95],\n",
              " [87.25, 8.649999999999999],\n",
              " [87.15, 8.55],\n",
              " [86.95, 8.4],\n",
              " [86.8, 8.3],\n",
              " [86.45, 8.1],\n",
              " [86.3, 7.95],\n",
              " [86.1, 7.8],\n",
              " [85.95, 7.7],\n",
              " [85.9, 7.55],\n",
              " [85.65, 7.449999999999999],\n",
              " [85.45, 7.3],\n",
              " [85.35000000000001, 7.249999999999999],\n",
              " [84.95, 7.049999999999999],\n",
              " [84.65, 6.800000000000001],\n",
              " [84.5, 6.5],\n",
              " [84.2, 6.5],\n",
              " [83.8, 6.15],\n",
              " [83.6, 6.05],\n",
              " [83.55, 5.8500000000000005],\n",
              " [83.3, 5.7],\n",
              " [83.15, 5.55],\n",
              " [83.0, 5.5],\n",
              " [82.55, 5.3],\n",
              " [82.35, 5.2],\n",
              " [82.0, 5.0],\n",
              " [81.69999999999999, 4.8500000000000005],\n",
              " [81.39999999999999, 4.7],\n",
              " [80.9, 4.55],\n",
              " [80.55, 4.35],\n",
              " [79.75, 4.2],\n",
              " [79.55, 3.95],\n",
              " [79.2, 3.75],\n",
              " [78.5, 3.55],\n",
              " [77.95, 3.45],\n",
              " [77.55, 3.25],\n",
              " [77.05, 3.15],\n",
              " [76.44999999999999, 2.9000000000000004],\n",
              " [75.55, 2.85],\n",
              " [74.6, 2.4],\n",
              " [73.6, 2.1],\n",
              " [72.1, 1.9],\n",
              " [70.15, 1.7000000000000002],\n",
              " [67.35, 1.3],\n",
              " [62.64999999999999, 0.7000000000000001],\n",
              " [61.550000000000004, 0.7000000000000001],\n",
              " [61.050000000000004, 0.7000000000000001],\n",
              " [60.050000000000004, 0.65],\n",
              " [59.45, 0.6],\n",
              " [57.99999999999999, 0.44999999999999996],\n",
              " [56.599999999999994, 0.35000000000000003],\n",
              " [54.300000000000004, 0.25],\n",
              " [50.64999999999999, 0.2],\n",
              " [46.050000000000004, 0.05],\n",
              " [46.050000000000004, 0.05],\n",
              " [45.300000000000004, 0.05],\n",
              " [44.25, 0.05],\n",
              " [43.55, 0.05],\n",
              " [42.5, 0.05],\n",
              " [41.4, 0.05],\n",
              " [39.4, 0.05],\n",
              " [37.5, 0.05],\n",
              " [35.15, 0.0],\n",
              " [30.45, 0.0],\n",
              " [30.45, 0.0],\n",
              " [29.799999999999997, 0.0],\n",
              " [29.099999999999998, 0.0],\n",
              " [28.4, 0.0],\n",
              " [27.700000000000003, 0.0],\n",
              " [26.85, 0.0],\n",
              " [25.35, 0.0],\n",
              " [24.4, 0.0],\n",
              " [22.7, 0.0],\n",
              " [19.85, 0.0],\n",
              " [19.85, 0.0],\n",
              " [19.400000000000002, 0.0],\n",
              " [19.15, 0.0],\n",
              " [18.7, 0.0],\n",
              " [18.2, 0.0],\n",
              " [17.8, 0.0],\n",
              " [17.05, 0.0],\n",
              " [16.1, 0.0],\n",
              " [14.7, 0.0],\n",
              " [13.3, 0.0],\n",
              " [13.3, 0.0],\n",
              " [13.0, 0.0],\n",
              " [12.75, 0.0],\n",
              " [12.0, 0.0],\n",
              " [11.799999999999999, 0.0],\n",
              " [11.5, 0.0],\n",
              " [11.0, 0.0],\n",
              " [10.2, 0.0],\n",
              " [9.55, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0],\n",
              " [0.0, 0.0]]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FalseIdentifyANOTHER = []\n",
        "for i in range(89):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.1 + 0.01*i),100*false_identify(0.1 + 0.01*i),])\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.99 + 0.001*i),100*false_identify(0.99 + 0.001*i)])\n",
        "\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.999 + 0.0001*i),100*false_identify(0.999 + 0.0001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.9999 + 0.00001*i),100*false_identify(0.9999 + 0.00001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.99999 + 0.000001*i),100*false_identify(0.99999 + 0.000001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.999999 + 0.0000001*i),100*false_identify(0.999999 + 0.0000001*i),])\n",
        "\n",
        "for i in range(9):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.9999999 + 0.00000001*i),100*false_identify(0.9999999 + 0.00000001*i),])\n",
        "\n",
        "FalseIdentifyANOTHER.append([100*thresholding(max_value),100*false_identify(max_value),])\n",
        "FalseIdentifyANOTHER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6Vf4U_EQDh6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWInVYNk2bml"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hpjicpFNOAH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "astEHCwEWNFf"
      },
      "source": [
        "# Class-adaptive threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgZEtA56usFB"
      },
      "source": [
        "# Run #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEg9x6-vurgQ"
      },
      "outputs": [],
      "source": [
        "prediction_known = prediction_known_ensemble_1\n",
        "prediction_unknown = prediction_unknown_ensemble_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tyc8FzcWUk-"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores = []\n",
        "for i in range(20):\n",
        "  ThresholdNeverSeenBefores.append(np.max(prediction_unknown[:,i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRYDPQ34Qcdz",
        "outputId": "7a6edecf-d888-4745-bc7f-26af64444bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.9999999,\n",
              " 0.99993837,\n",
              " 0.99997413,\n",
              " 0.99955,\n",
              " 0.9849764,\n",
              " 0.13415858,\n",
              " 0.9520093,\n",
              " 0.99966794,\n",
              " 0.008279827,\n",
              " 0.31542295,\n",
              " 0.5280966,\n",
              " 0.00026533083,\n",
              " 0.99766034,\n",
              " 0.99993134,\n",
              " 0.9845427,\n",
              " 0.999987,\n",
              " 0.20938723,\n",
              " 0.00022063241,\n",
              " 0.7811894,\n",
              " 0.90735114]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ThresholdNeverSeenBefores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp_hvYS9WP6J",
        "outputId": "c7f9d426-8214-497f-9df7-df9787fdcd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "C_count0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAu3K9nEWP8P",
        "outputId": "52e4d13d-f15e-47b9-d428-cd1b155f65a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "mistake0\n",
        "print(\"Number of mistakes in this class:\",mistake0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHzot9WdXkC7",
        "outputId": "a2434b83-4f4f-40b8-cafa-ac16ed3e1a02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "C_count1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4RVufLtXkAR",
        "outputId": "87911b4e-2c55-432b-f649-5831216d5605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "117\n",
            "Number of mistakes in this class: 1\n"
          ]
        }
      ],
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xZ6sVoHNNI0"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[117])] = max(prediction_known[117])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG9PHsHdNQdK",
        "outputId": "dfb69049-45f8-476c-fbbf-9bda526c10b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmmpoficmsIo",
        "outputId": "fdd88792-49b7-428d-d06b-9994ea30ff00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "C_count2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTiQq-WKmsMB",
        "outputId": "c38d2e59-8456-45d6-f534-2ffed8267ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "mistake2\n",
        "print(\"Number of mistakes in this class:\",mistake2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsNwlMBAmsN3",
        "outputId": "60828772-8478-4e51-c47e-e787697ab678"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "C_count3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP9oRkpvmsPv",
        "outputId": "2e0eb41d-48f8-4b6a-b82a-44a1805ea0e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "306\n",
            "344\n",
            "Number of mistakes in this class: 2\n"
          ]
        }
      ],
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAXSlRUnQpaf"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[344])] = max(prediction_known[344])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHos0RoOQq96",
        "outputId": "41d3b213-300b-46d9-db70-819cd668bd16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGdmlHmUmsSi",
        "outputId": "86484f14-197a-4522-8923-6c2a7493fab7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "C_count4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTXAEphBmsU_",
        "outputId": "a2da3278-045e-491f-dd93-aaaec45aa014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "416\n",
            "418\n",
            "442\n",
            "Number of mistakes in this class: 3\n"
          ]
        }
      ],
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO3M7D1HQx5S"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[442])] = max(prediction_known[442])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXwySaziRIXY",
        "outputId": "3af4918f-7d68-4aa9-95aa-15660082f568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwuWW0SkqIB_",
        "outputId": "cc9b0c08-b598-46d6-c64c-57cf0b41251b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "C_count5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMRqQVgIqKWx",
        "outputId": "2302c083-ea1e-40e8-e35e-580d30f1d64d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJt2-_RjqhZM",
        "outputId": "2cb5337c-2c11-4cfe-bd3d-b56dfd2050f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "C_count6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ0sklVOqhbU",
        "outputId": "9d547d77-1295-47f8-fc17-71eacab9949e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "602\n",
            "603\n",
            "604\n",
            "607\n",
            "608\n",
            "616\n",
            "618\n",
            "619\n",
            "620\n",
            "623\n",
            "624\n",
            "628\n",
            "630\n",
            "651\n",
            "657\n",
            "661\n",
            "665\n",
            "697\n",
            "699\n",
            "Number of mistakes in this class: 19\n"
          ]
        }
      ],
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46R_9FV_Nv0u"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[699])] = max(prediction_known[699])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRmK5EjkN0bY",
        "outputId": "2d08da68-854e-40d5-ebe7-eab964ae8ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMsrIQt1qhe2",
        "outputId": "29893ec7-cf34-4022-df18-c3b22dcc06b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "C_count7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gau4TuhUqhiG",
        "outputId": "5b044ec7-85cc-432d-9460-8c6458c1f183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyufo5sUqhkP",
        "outputId": "af8d4ced-3fd6-46c3-cde5-d021e35f5715"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "C_count8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqBpRvSWqhnj",
        "outputId": "41b7820e-b1a7-45b9-b2ab-2a3b2d9426cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "801\n",
            "809\n",
            "815\n",
            "818\n",
            "824\n",
            "826\n",
            "832\n",
            "833\n",
            "835\n",
            "840\n",
            "853\n",
            "859\n",
            "865\n",
            "870\n",
            "872\n",
            "879\n",
            "Number of mistakes in this class: 16\n"
          ]
        }
      ],
      "source": [
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79kQww80Dt9S"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[853])] = max(prediction_known[853])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK_1ke3cDwz-",
        "outputId": "b4eec83c-352b-4fa0-acfc-856ec2d99c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbQcIVdBqhpv",
        "outputId": "10506e42-edba-40c2-b97b-17d54c99ae74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "C_count9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6TeE6FjrOKT",
        "outputId": "d1785880-3959-45f2-9b82-8c60faebd4de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "905\n",
            "907\n",
            "909\n",
            "910\n",
            "914\n",
            "939\n",
            "948\n",
            "956\n",
            "958\n",
            "970\n",
            "976\n",
            "988\n",
            "990\n",
            "996\n",
            "997\n",
            "Number of mistakes in this class: 15\n"
          ]
        }
      ],
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tymgmUjNR3H0"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[910])] = max(prediction_known[910])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmEeUDRUR5_1",
        "outputId": "e0e30bac-676a-4dad-8aa3-b9d523a19e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfyOeyVNONgV",
        "outputId": "9b87b2c2-3c30-4a8e-e5d7-230239e97cd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 10*100,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[i + 10*100]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "C_count10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekt_bBxvONcA",
        "outputId": "8b54ec46-c4ac-4bc2-bba9-9796709cce94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1025\n",
            "1071\n",
            "Number of mistakes in this class: 2\n"
          ]
        }
      ],
      "source": [
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr-HqE25SKmS"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[1025])] = max(prediction_known[1025])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHvjdVUkSOBh",
        "outputId": "0305fc5c-4134-40aa-ba30-b773040d7ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6byw4L6ONjQ",
        "outputId": "5755d4e3-77bb-4e2e-a972-fd00c48bdc4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 11*100,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[i + 11*100]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "C_count11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTo9fjq0ONn7",
        "outputId": "e454133d-1093-404a-c59b-3e45022e9e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZEkgZKTQHnK",
        "outputId": "7b49aca0-9167-44e3-9605-78f12adb975b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 12*100,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[i + 12*100]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "C_count12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B0SAhUMQHpb",
        "outputId": "fdbb0334-adc1-4935-d88b-6f9c19e0e2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1218\n",
            "1223\n",
            "1282\n",
            "1285\n",
            "Number of mistakes in this class: 4\n"
          ]
        }
      ],
      "source": [
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22lLSjHMSW2s"
      },
      "outputs": [],
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[1285])] = max(prediction_known[1285])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yV4yORASZRt",
        "outputId": "857724a1-8282-42c8-99d1-bae940a430ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIpPnc7NQHtA",
        "outputId": "50e223b1-1436-4fb5-c140-e829190c4244"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 13*100,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[i + 13*100]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "C_count13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-6dJoSlQHvl",
        "outputId": "3290ba61-5527-4e40-d24e-27bb1494c5cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulMey8s2QHy6",
        "outputId": "a767b6de-889e-43b2-b2c8-1dee79691113"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 14*100,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[i + 14*100]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0\n",
        "C_count14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3rfjenwQH37",
        "outputId": "fc5df13c-361e-4356-9d80-147657dc6732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_v0IzNGSfmA",
        "outputId": "670dac5f-18c9-41d8-c8e8-f6910d42cc76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count15 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 15*100,15] > ThresholdNeverSeenBefores[15] and np.argmax(prediction_known[i + 15*100]) == 15:\n",
        "    C_count15 += 1\n",
        "  else:\n",
        "    C_count15 += 0\n",
        "C_count15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7oQYQOiTaBS",
        "outputId": "c0080daa-9428-4b67-ca08-bbc4d2ba7959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake15 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1500 + i]) != 15 and max(prediction_known[1500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1500 + i])]:\n",
        "    mistake15 += 1\n",
        "    print(1500 + i)\n",
        "  else:\n",
        "    mistake15 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhIyQkxmTi_V",
        "outputId": "8a0b0c0a-5ffb-46ce-ead9-f459aa604494"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count16 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 16*100,16] > ThresholdNeverSeenBefores[16] and np.argmax(prediction_known[i + 16*100]) == 16:\n",
        "    C_count16 += 1\n",
        "  else:\n",
        "    C_count16 += 0\n",
        "C_count16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iao0uQMUZRq",
        "outputId": "d92faf8d-fdae-4568-c225-e836ef9d8075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake16 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1600 + i]) != 16 and max(prediction_known[1600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1600 + i])]:\n",
        "    mistake16 += 1\n",
        "    print(1600 + i)\n",
        "  else:\n",
        "    mistake16 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmnutHFrUide",
        "outputId": "39e90bce-f5d3-46b6-9f6c-5c2f05469d5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count17 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 17*100,17] > ThresholdNeverSeenBefores[17] and np.argmax(prediction_known[i + 17*100]) == 17:\n",
        "    C_count17 += 1\n",
        "  else:\n",
        "    C_count17 += 0\n",
        "C_count17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Eg8QkckUigJ",
        "outputId": "e2034cd3-9267-454a-dad6-834b707ca131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake17 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1700 + i]) != 17 and max(prediction_known[1700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1700 + i])]:\n",
        "    mistake17 += 1\n",
        "    print(1700 + i)\n",
        "  else:\n",
        "    mistake17 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1haT-EvUiiw",
        "outputId": "1f3e3ed1-ffd6-41a5-b33c-72c5ae772f15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count18 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 18*100,18] > ThresholdNeverSeenBefores[18] and np.argmax(prediction_known[i + 18*100]) == 18:\n",
        "    C_count18 += 1\n",
        "  else:\n",
        "    C_count18 += 0\n",
        "C_count18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yHblqD1U6ms",
        "outputId": "f2303f8f-973b-4316-d50d-35b07a3b1cc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake18 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1800 + i]) != 18 and max(prediction_known[1800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1800 + i])]:\n",
        "    mistake18 += 1\n",
        "    print(1800 + i)\n",
        "  else:\n",
        "    mistake18 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D4-6RfqU6oQ",
        "outputId": "d3eaa0e6-2395-4e67-997e-2c1736aadba7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count19 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 19*100,19] > ThresholdNeverSeenBefores[19] and np.argmax(prediction_known[i + 19*100]) == 19:\n",
        "    C_count19 += 1\n",
        "  else:\n",
        "    C_count19 += 0\n",
        "C_count19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_xmchToU6qG",
        "outputId": "151b546d-0a4e-48cd-cf1e-0c9e9e07f02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ],
      "source": [
        "mistake19 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1900 + i]) != 19 and max(prediction_known[1900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1900 + i])]:\n",
        "    mistake19 += 1\n",
        "    print(1900 + i)\n",
        "  else:\n",
        "    mistake19 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuMd-QJIU6tF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFTqb2dlQH-K",
        "outputId": "5f4bfcb2-39a7-47f0-f691-ec5a38c3863e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of mistakes in this class: 0\n",
            "Number of mistakes in this class: 0\n",
            "Number of mistakes in this class: 0\n",
            "Number of mistakes in this class: 0\n",
            "Number of mistakes in this class: 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "\n",
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "\n",
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "\n",
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "\n",
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "\n",
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "\n",
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "\n",
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "\n",
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "\n",
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "\n",
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "\n",
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "\n",
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "\n",
        "\n",
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "\n",
        "\n",
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "\n",
        "mistake15 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1500 + i]) != 15 and max(prediction_known[1500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1500 + i])]:\n",
        "    mistake15 += 1\n",
        "    print(1500 + i)\n",
        "  else:\n",
        "    mistake15 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake15)\n",
        "\n",
        "mistake16 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1600 + i]) != 16 and max(prediction_known[1600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1600 + i])]:\n",
        "    mistake16 += 1\n",
        "    print(1600 + i)\n",
        "  else:\n",
        "    mistake16 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake16)\n",
        "\n",
        "mistake17 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1700 + i]) != 17 and max(prediction_known[1700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1700 + i])]:\n",
        "    mistake17 += 1\n",
        "    print(1700 + i)\n",
        "  else:\n",
        "    mistake17 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake17)\n",
        "\n",
        "mistake18 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1800 + i]) != 18 and max(prediction_known[1800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1800 + i])]:\n",
        "    mistake18 += 1\n",
        "    print(1800 + i)\n",
        "  else:\n",
        "    mistake18 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake18)\n",
        "\n",
        "mistake19 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1900 + i]) != 19 and max(prediction_known[1900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1900 + i])]:\n",
        "    mistake19 += 1\n",
        "    print(1900 + i)\n",
        "  else:\n",
        "    mistake19 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake19)\n",
        "\n",
        "NumberOfMistakesAfterThrAdj = [mistake0, mistake1, mistake2, mistake3, mistake4, mistake5, mistake6, mistake7,mistake8,mistake9,mistake10,mistake11,mistake12,mistake13,mistake14,mistake15,mistake16,mistake17,mistake18,mistake19]\n",
        "NumberOfMistakesAfterThrAdj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXF3VkIGQIA1",
        "outputId": "7d73afc7-d03c-42ba-b44f-85c74d93d863"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "\n",
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "\n",
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "\n",
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "\n",
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "\n",
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "\n",
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "\n",
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "\n",
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "\n",
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "\n",
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1000 + i,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[1000 + i]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "\n",
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1100 + i,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[1100 + i]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "\n",
        "\n",
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1200 + i,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[1200 + i]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "\n",
        "\n",
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1300 + i,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[1300 + i]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "\n",
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1400 + i,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[1400 + i]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0\n",
        "\n",
        "C_count15 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 15*100,15] > ThresholdNeverSeenBefores[15] and np.argmax(prediction_known[i + 15*100]) == 15:\n",
        "    C_count15 += 1\n",
        "  else:\n",
        "    C_count15 += 0\n",
        "C_count15\n",
        "\n",
        "C_count16 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 16*100,16] > ThresholdNeverSeenBefores[16] and np.argmax(prediction_known[i + 16*100]) == 16:\n",
        "    C_count16 += 1\n",
        "  else:\n",
        "    C_count16 += 0\n",
        "C_count16\n",
        "\n",
        "C_count17 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 17*100,17] > ThresholdNeverSeenBefores[17] and np.argmax(prediction_known[i + 17*100]) == 17:\n",
        "    C_count17 += 1\n",
        "  else:\n",
        "    C_count17 += 0\n",
        "C_count17\n",
        "\n",
        "C_count18 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 18*100,18] > ThresholdNeverSeenBefores[18] and np.argmax(prediction_known[i + 18*100]) == 18:\n",
        "    C_count18 += 1\n",
        "  else:\n",
        "    C_count18 += 0\n",
        "C_count18\n",
        "\n",
        "C_count19 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 19*100,19] > ThresholdNeverSeenBefores[19] and np.argmax(prediction_known[i + 19*100]) == 19:\n",
        "    C_count19 += 1\n",
        "  else:\n",
        "    C_count19 += 0\n",
        "C_count19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tCq14c7KIKZ",
        "outputId": "b44494c5-1beb-471b-c8c3-6da7adbcace3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 3],\n",
              " [3, 10],\n",
              " [4, 38],\n",
              " [5, 10],\n",
              " [6, 61],\n",
              " [7, 60],\n",
              " [8, 74],\n",
              " [9, 41],\n",
              " [10, 66]]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FinalDistributionOver10ClassesRun1 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9]]\n",
        "FinalDistributionOver10ClassesRun1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDX1bRdiKKii",
        "outputId": "2cb3975d-21fe-47bf-d72f-ac6db61d71a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 3],\n",
              " [3, 10],\n",
              " [4, 38],\n",
              " [5, 10],\n",
              " [6, 61],\n",
              " [7, 60],\n",
              " [8, 74],\n",
              " [9, 41],\n",
              " [10, 66],\n",
              " [11, 42],\n",
              " [12, 91],\n",
              " [13, 29],\n",
              " [14, 4],\n",
              " [15, 43]]"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FinalDistributionOver15ClassesRun1 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9],[11,C_count10],[12,C_count11],[13,C_count12],[14,C_count13],[15,C_count14]]\n",
        "FinalDistributionOver15ClassesRun1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rri4_KlhW60Y",
        "outputId": "1a1056bf-6756-4bd3-9b7b-6c8a8687e851"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 3],\n",
              " [3, 10],\n",
              " [4, 38],\n",
              " [5, 10],\n",
              " [6, 61],\n",
              " [7, 60],\n",
              " [8, 74],\n",
              " [9, 41],\n",
              " [10, 66],\n",
              " [11, 42],\n",
              " [12, 91],\n",
              " [13, 29],\n",
              " [14, 4],\n",
              " [15, 43],\n",
              " [16, 2],\n",
              " [17, 43],\n",
              " [18, 99],\n",
              " [19, 81],\n",
              " [20, 98]]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FinalDistributionOver20ClassesRun1 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9],[11,C_count10],[12,C_count11],[13,C_count12],[14,C_count13],[15,C_count14],[16,C_count15],[17,C_count16],[18,C_count17],[19,C_count18],[20,C_count19]]\n",
        "FinalDistributionOver20ClassesRun1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8xTrLFWLVPX",
        "outputId": "69794604-44e7-41d2-fdf1-6f095acbe931"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.363"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9)/1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t0rgKFRLij_",
        "outputId": "1a8993e0-ad3e-44a9-d62c-2ebcfb498eb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.38133333333333336"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9 + C_count10 + C_count11 + C_count12 + C_count13 + C_count14)/1500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR8utfagXSov",
        "outputId": "a66ead0c-3c4e-4165-9818-4c15d80eae6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4475"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9 + C_count10 + C_count11 + C_count12 + C_count13 + C_count14 + C_count15 + C_count16 + C_count17 + C_count18 + C_count19)/2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l-JeNv2Xm2x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAd90HL_Xm5B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LxQwEOhUQCd",
        "outputId": "dcc0617c-120c-42d6-d221-8ba33e8a2d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 16.25, 28.145825622994256]\n",
            "[2, 2.75, 0.82915619758885]\n",
            "[3, 9.5, 3.278719262151]\n",
            "[4, 35.25, 2.165063509461097]\n",
            "[5, 9.75, 1.0897247358851685]\n",
            "[6, 65.5, 5.123475382979799]\n",
            "[7, 70.75, 6.378675411086537]\n",
            "[8, 66.5, 4.55521678957215]\n",
            "[9, 33.5, 5.408326913195984]\n",
            "[10, 60.25, 4.380353866983808]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "all_datasets = [FinalDistributionOver10ClassesRun1, FinalDistributionOver10ClassesRun2, FinalDistributionOver10ClassesRun3, FinalDistributionOver10ClassesRun4]\n",
        "\n",
        "new_dataset = []\n",
        "\n",
        "for x_value in range(1, 11):\n",
        "    y_values = []\n",
        "\n",
        "    for dataset in all_datasets:\n",
        "        for data_point in dataset:\n",
        "            if data_point[0] == x_value:\n",
        "                y_values.append(data_point[1])\n",
        "\n",
        "    avg_y = np.mean(y_values)\n",
        "    std_y = np.std(y_values)\n",
        "\n",
        "    new_dataset.append([x_value, avg_y, std_y])\n",
        "\n",
        "for data_point in new_dataset:\n",
        "    print(data_point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiOAa6olqnym",
        "outputId": "8371e19d-f591-4ccc-de42-d8b385356830"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 16.25, 28.145825622994256],\n",
              " [2, 2.75, 0.82915619758885],\n",
              " [3, 9.5, 3.278719262151],\n",
              " [4, 35.25, 2.165063509461097],\n",
              " [5, 9.75, 1.0897247358851685],\n",
              " [6, 65.5, 5.123475382979799],\n",
              " [7, 70.75, 6.378675411086537],\n",
              " [8, 66.5, 4.55521678957215],\n",
              " [9, 33.5, 5.408326913195984],\n",
              " [10, 60.25, 4.380353866983808]]"
            ]
          },
          "execution_count": 332,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WihmOq4ts158",
        "outputId": "a2dd3ebc-ade8-43b3-8d7f-a64f58b811ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 16.25, 28.145825622994256]\n",
            "[2, 2.75, 0.82915619758885]\n",
            "[3, 9.5, 3.278719262151]\n",
            "[4, 35.25, 2.165063509461097]\n",
            "[5, 9.75, 1.0897247358851685]\n",
            "[6, 65.5, 5.123475382979799]\n",
            "[7, 70.75, 6.378675411086537]\n",
            "[8, 66.5, 4.55521678957215]\n",
            "[9, 33.5, 5.408326913195984]\n",
            "[10, 60.25, 4.380353866983808]\n",
            "[11, 35.75, 5.84700778176325]\n",
            "[12, 91.0, 0.0]\n",
            "[13, 28.5, 0.5]\n",
            "[14, 6.5, 1.8027756377319946]\n",
            "[15, 40.25, 2.7726341266023544]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "all_datasets = [FinalDistributionOver15ClassesRun1, FinalDistributionOver15ClassesRun2, FinalDistributionOver15ClassesRun3, FinalDistributionOver15ClassesRun4]\n",
        "\n",
        "new_dataset = []\n",
        "\n",
        "for x_value in range(1, 16):\n",
        "    y_values = []\n",
        "\n",
        "    for dataset in all_datasets:\n",
        "        for data_point in dataset:\n",
        "            if data_point[0] == x_value:\n",
        "                y_values.append(data_point[1])\n",
        "\n",
        "    avg_y = np.mean(y_values)\n",
        "    std_y = np.std(y_values)\n",
        "\n",
        "    new_dataset.append([x_value, avg_y, std_y])\n",
        "\n",
        "for data_point in new_dataset:\n",
        "    print(data_point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH760zIIs9m-",
        "outputId": "f40cd8dc-644b-4f1f-fc91-02f41dedb4a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 16.25, 28.145825622994256],\n",
              " [2, 2.75, 0.82915619758885],\n",
              " [3, 9.5, 3.278719262151],\n",
              " [4, 35.25, 2.165063509461097],\n",
              " [5, 9.75, 1.0897247358851685],\n",
              " [6, 65.5, 5.123475382979799],\n",
              " [7, 70.75, 6.378675411086537],\n",
              " [8, 66.5, 4.55521678957215],\n",
              " [9, 33.5, 5.408326913195984],\n",
              " [10, 60.25, 4.380353866983808],\n",
              " [11, 35.75, 5.84700778176325],\n",
              " [12, 91.0, 0.0],\n",
              " [13, 28.5, 0.5],\n",
              " [14, 6.5, 1.8027756377319946],\n",
              " [15, 40.25, 2.7726341266023544]]"
            ]
          },
          "execution_count": 334,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZhK_k_MtDri",
        "outputId": "da5a1e05-b77b-45d2-d4c0-4a4092b94462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 16.25, 28.145825622994256]\n",
            "[2, 2.75, 0.82915619758885]\n",
            "[3, 9.5, 3.278719262151]\n",
            "[4, 35.25, 2.165063509461097]\n",
            "[5, 9.75, 1.0897247358851685]\n",
            "[6, 65.5, 5.123475382979799]\n",
            "[7, 70.75, 6.378675411086537]\n",
            "[8, 66.5, 4.55521678957215]\n",
            "[9, 33.5, 5.408326913195984]\n",
            "[10, 60.25, 4.380353866983808]\n",
            "[11, 35.75, 5.84700778176325]\n",
            "[12, 91.0, 0.0]\n",
            "[13, 28.5, 0.5]\n",
            "[14, 6.5, 1.8027756377319946]\n",
            "[15, 40.25, 2.7726341266023544]\n",
            "[16, 1.75, 1.479019945774904]\n",
            "[17, 38.5, 4.387482193696061]\n",
            "[18, 99.0, 0.0]\n",
            "[19, 83.0, 2.0]\n",
            "[20, 97.25, 0.4330127018922193]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "all_datasets = [FinalDistributionOver20ClassesRun1, FinalDistributionOver20ClassesRun2, FinalDistributionOver20ClassesRun3, FinalDistributionOver20ClassesRun4]\n",
        "\n",
        "new_dataset = []\n",
        "\n",
        "for x_value in range(1, 21):\n",
        "    y_values = []\n",
        "\n",
        "    for dataset in all_datasets:\n",
        "        for data_point in dataset:\n",
        "            if data_point[0] == x_value:\n",
        "                y_values.append(data_point[1])\n",
        "\n",
        "    avg_y = np.mean(y_values)\n",
        "    std_y = np.std(y_values)\n",
        "\n",
        "    new_dataset.append([x_value, avg_y, std_y])\n",
        "\n",
        "for data_point in new_dataset:\n",
        "    print(data_point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1ThJ1K8tSwW",
        "outputId": "1d29cf58-c4ab-4fb2-e9ee-24f39ba81eb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 16.25, 28.145825622994256],\n",
              " [2, 2.75, 0.82915619758885],\n",
              " [3, 9.5, 3.278719262151],\n",
              " [4, 35.25, 2.165063509461097],\n",
              " [5, 9.75, 1.0897247358851685],\n",
              " [6, 65.5, 5.123475382979799],\n",
              " [7, 70.75, 6.378675411086537],\n",
              " [8, 66.5, 4.55521678957215],\n",
              " [9, 33.5, 5.408326913195984],\n",
              " [10, 60.25, 4.380353866983808],\n",
              " [11, 35.75, 5.84700778176325],\n",
              " [12, 91.0, 0.0],\n",
              " [13, 28.5, 0.5],\n",
              " [14, 6.5, 1.8027756377319946],\n",
              " [15, 40.25, 2.7726341266023544],\n",
              " [16, 1.75, 1.479019945774904],\n",
              " [17, 38.5, 4.387482193696061],\n",
              " [18, 99.0, 0.0],\n",
              " [19, 83.0, 2.0],\n",
              " [20, 97.25, 0.4330127018922193]]"
            ]
          },
          "execution_count": 336,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_dataset"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMA0X+bMIxjkqPZ6Yfdfr+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}