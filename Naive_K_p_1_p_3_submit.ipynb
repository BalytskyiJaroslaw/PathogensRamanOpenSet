{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BalytskyiJaroslaw/PathogensRamanOpenSet/blob/main/Naive_K_p_1_p_3_submit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6MZtHw8cizd"
      },
      "source": [
        "# Naive thresholding, $\\mathcal{K} = p_1+p_3$, $\\mathcal{I}$ = $âˆ…$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlQ76qXvX-xJ"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "from pandas import read_csv\n",
        "\n",
        "from keras.layers import Lambda, Multiply\n",
        "import csv\n",
        "import pprint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "import keras\n",
        "#from keras.utils import to_categorical\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "#from keras.optimizers import SGD\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#from keras.optimizers import SGD\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import gspread\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import pywt\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "from time import time\n",
        "t00 = time()\n",
        "import os\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling1D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjMmDBRYc2nm"
      },
      "source": [
        "# Initializing TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEBeC3Gfc8Jg"
      },
      "outputs": [],
      "source": [
        "# Initialize the TPU and spread the computations across the 8 cores\n",
        "import tensorflow as tf\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "tf.config.list_logical_devices('TPU')\n",
        "#print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoXfC8vkdHIQ"
      },
      "source": [
        "# Uploading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEFKstcxdGnO",
        "outputId": "68168cc7-9586-45ef-c374-b91c5380b736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyFU_ZXCgHGG"
      },
      "source": [
        "# Reference dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2X6lpq-dOSV"
      },
      "outputs": [],
      "source": [
        "# Reference data\n",
        "data_X_reference = np.load(\"/content/gdrive/MyDrive/Stanford_data/X_reference.npy\")\n",
        "# Test data\n",
        "data_X_test = np.load(\"/content/gdrive/MyDrive/Stanford_data/X_test.npy\")\n",
        "\n",
        "data_y_reference = np.load(\"/content/gdrive/MyDrive/Stanford_data/y_reference.npy\")\n",
        "# Test labels\n",
        "data_y_test = np.load(\"/content/gdrive/MyDrive/Stanford_data/y_test.npy\")\n",
        "\n",
        "data_y_reference_int = []\n",
        "\n",
        "for i in range(data_y_reference.shape[0]):\n",
        "  data_y_reference_int.append(int(data_y_reference[i]))\n",
        "\n",
        "data_y_test_int = []\n",
        "\n",
        "for i in range(data_y_test.shape[0]):\n",
        "  data_y_test_int.append(int(data_y_test[i]))\n",
        "\n",
        "train_label = tf.keras.utils.to_categorical(data_y_reference_int)\n",
        "test_label = tf.keras.utils.to_categorical(data_y_test_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpn4ERtzdVkk"
      },
      "source": [
        "# The case of $\\mathcal{K} = p_1+p_3$, corresponds to the known training reference indices: 10000 - 14000, 18000 - 28000, 34000 - 38000, 42000 - 50000, 56000 - 60000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ76u-x7di-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62647341-d873-4739-dd07-a24ac9186cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the known data, reference: (30000, 1000)\n",
            "Shape of the known labels, reference: (30000, 15)\n"
          ]
        }
      ],
      "source": [
        "indices = [slice(10000, 14000),slice(18000, 28000),slice(34000, 38000),slice(42000, 50000),slice(56000, 60000)]\n",
        "\n",
        "Known_data_X_reference = np.concatenate([data_X_reference[idx, :] for idx in indices], axis=0)\n",
        "\n",
        "Known_data_X_train_label_int = []\n",
        "\n",
        "for i in range(2000*15):\n",
        "  Known_data_X_train_label_int.append(int(data_y_reference[i]))\n",
        "\n",
        "Known_data_X_train_label = tf.keras.utils.to_categorical(Known_data_X_train_label_int)\n",
        "print(\"Shape of the known data, reference:\", Known_data_X_reference.shape)\n",
        "print(\"Shape of the known labels, reference:\", Known_data_X_train_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZzs-rpIfJ9f"
      },
      "source": [
        "# Known data indices, testing dataset. Indices = 500 - 700, 900 - 1400, 1700 - 1900, 2100 - 2500, 2800 - 3000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1a48lk8djF5",
        "outputId": "317f102b-1eed-4fd4-84ad-cb48def84a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the known data, test: (1500, 1000)\n",
            "Shape of the known labels, test: (1500, 15)\n"
          ]
        }
      ],
      "source": [
        "indices = [slice(500, 700),slice(900, 1400),slice(1700, 1900),slice(2100, 2500),slice(2800, 3000)]\n",
        "\n",
        "Known_data_X_test = np.concatenate([data_X_test[idx, :] for idx in indices], axis=0)\n",
        "\n",
        "Known_data_X_test_label_int = []\n",
        "\n",
        "for i in range(100*15):\n",
        "  Known_data_X_test_label_int.append(int(data_y_test[i]))\n",
        "\n",
        "Known_data_X_test_label = tf.keras.utils.to_categorical(Known_data_X_test_label_int)\n",
        "print(\"Shape of the known data, test:\", Known_data_X_test.shape)\n",
        "print(\"Shape of the known labels, test:\", Known_data_X_test_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKGM50gJn43Q"
      },
      "source": [
        "# Never seen before, $\\mathcal{N} = p_4$, test: 0 - 500, 700 - 900, 1900 - 2100, 2500 - 2600.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RedGonT-oENJ",
        "outputId": "3834e629-71bb-4d04-97da-fad0e743d650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the Neverseen data, test: (1000, 1000)\n",
            "Shape of the Neverseen labels, test: (1000, 10)\n"
          ]
        }
      ],
      "source": [
        "indices = [slice(0, 500),slice(700, 900),slice(1900, 2100),slice(2500, 2600)]\n",
        "NeverSeen_data_X_test = np.concatenate([data_X_test[idx, :] for idx in indices], axis=0)\n",
        "\n",
        "NeverSeen_data_X_test_label_int = []\n",
        "\n",
        "for i in range(100*10):\n",
        "  NeverSeen_data_X_test_label_int.append(int(data_y_test[i]))\n",
        "\n",
        "NeverSeen_data_X_test_label = tf.keras.utils.to_categorical(NeverSeen_data_X_test_label_int)\n",
        "print(\"Shape of the Neverseen data, test:\", NeverSeen_data_X_test.shape)\n",
        "print(\"Shape of the Neverseen labels, test:\", NeverSeen_data_X_test_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TM7Jf_ugOVY"
      },
      "source": [
        "# Finetuning dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33-QtJx0djIS"
      },
      "outputs": [],
      "source": [
        "# Finetuning\n",
        "data_X_finetune = np.load(\"/content/gdrive/MyDrive/Stanford_data/X_finetune.npy\")\n",
        "# Test data\n",
        "data_X_test = np.load(\"/content/gdrive/MyDrive/Stanford_data/X_test.npy\")\n",
        "\n",
        "data_y_finetune = np.load(\"/content/gdrive/MyDrive/Stanford_data/y_finetune.npy\")\n",
        "# Test labels\n",
        "data_y_test = np.load(\"/content/gdrive/MyDrive/Stanford_data/y_test.npy\")\n",
        "\n",
        "data_y_finetune_int = []\n",
        "\n",
        "for i in range(data_y_finetune.shape[0]):\n",
        "  data_y_finetune_int.append(int(data_y_finetune[i]))\n",
        "\n",
        "data_y_test_int = []\n",
        "\n",
        "for i in range(data_y_test.shape[0]):\n",
        "  data_y_test_int.append(int(data_y_test[i]))\n",
        "\n",
        "train_label = tf.keras.utils.to_categorical(data_y_finetune_int)\n",
        "test_label = tf.keras.utils.to_categorical(data_y_test_int)\n",
        "\n",
        "#data_X_finetune, train_label = shuffle(data_X_finetune, train_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQhOuowIgkWf"
      },
      "source": [
        "# Known data for finetuning. Finetuning indices = 500 - 700, 900 - 1400, 1700 - 1900, 2100 - 2500, 2800 - 3000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDHDu8argdnn",
        "outputId": "2fd3bcb7-97bf-4529-b834-a11a54cc94f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the known data, finetune: (1500, 1000)\n",
            "Shape of the known labels, finetune: (1500, 15)\n"
          ]
        }
      ],
      "source": [
        "indices = [slice(500, 700),slice(900, 1400),slice(1700, 1900),slice(2100, 2500),slice(2800, 3000)]\n",
        "\n",
        "Known_data_X_finetune = np.concatenate([data_X_finetune[idx, :] for idx in indices], axis=0)\n",
        "\n",
        "Known_data_X_finetune_label_int = []\n",
        "\n",
        "for i in range(100*15):\n",
        "  Known_data_X_finetune_label_int.append(int(data_y_finetune[i]))\n",
        "\n",
        "Known_data_X_finetune_label = tf.keras.utils.to_categorical(Known_data_X_finetune_label_int)\n",
        "\n",
        "print(\"Shape of the known data, finetune:\", Known_data_X_finetune.shape)\n",
        "print(\"Shape of the known labels, finetune:\", Known_data_X_finetune_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkB5irz-g4nT"
      },
      "source": [
        "# Initializing the our NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va3BhxK3gdh9"
      },
      "outputs": [],
      "source": [
        "# Create a checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from numpy import interp\n",
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "#from sklearn.metrics import mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score, roc_curve, plot_roc_curve\n",
        "from sklearn.metrics import confusion_matrix, classification_report, auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, BatchNormalization, Activation, add\n",
        "from keras.layers import Conv2D, MaxPooling2D, Reshape, Flatten, Dense, GlobalAveragePooling1D, GlobalMaxPooling1D, Multiply, Conv1DTranspose, LeakyReLU, Dropout\n",
        "from keras.models import Model, model_from_json\n",
        "#from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "sns.set_theme(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFBxaPt1hDQQ",
        "outputId": "15f21ddb-71b5-4001-918a-80e2eef29293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ResNet29\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1000, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " zero_padding1d (ZeroPaddin  (None, 1006, 1)              0         ['input_1[0][0]']             \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " Convolution1 (Conv1D)       (None, 500, 64)              512       ['zero_padding1d[0][0]']      \n",
            "                                                                                                  \n",
            " BatchNormStage1 (BatchNorm  (None, 500, 64)              256       ['Convolution1[0][0]']        \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 500, 64)              0         ['BatchNormStage1[0][0]']     \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 249, 64)              0         ['activation[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 249, 64)              12352     ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 249, 64)              256       ['conv1d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 249, 64)              0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 249, 64)              12352     ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 249, 64)              256       ['conv1d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 249, 64)              0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " res2a_branch (Conv1D)       (None, 249, 256)             49408     ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 249, 256)             16640     ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 249, 256)             1024      ['res2a_branch[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 249, 256)             1024      ['conv1d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 249, 256)             0         ['batch_normalization_2[0][0]'\n",
            "                                                                    , 'batch_normalization_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 249, 256)             0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 249, 64)              16448     ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 249, 64)              256       ['conv1d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 249, 64)              0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 249, 64)              12352     ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 249, 64)              256       ['conv1d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 249, 64)              0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 249, 256)             16640     ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 249, 256)             1024      ['conv1d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 249, 256)             0         ['batch_normalization_6[0][0]'\n",
            "                                                                    , 'activation_3[0][0]']       \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 249, 256)             0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 125, 128)             98432     ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 125, 128)             512       ['conv1d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 125, 128)             0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 125, 128)             49280     ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 125, 128)             512       ['conv1d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 125, 128)             0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " res3a_branch (Conv1D)       (None, 125, 512)             197120    ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)           (None, 125, 512)             131584    ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 125, 512)             2048      ['res3a_branch[0][0]']        \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 125, 512)             2048      ['conv1d_8[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 125, 512)             0         ['batch_normalization_9[0][0]'\n",
            "                                                                    , 'batch_normalization_10[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 125, 512)             0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)           (None, 125, 128)             65664     ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 125, 128)             512       ['conv1d_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 125, 128)             0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)          (None, 125, 128)             49280     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 125, 128)             512       ['conv1d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 125, 128)             0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)          (None, 125, 512)             66048     ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 125, 512)             2048      ['conv1d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 125, 512)             0         ['batch_normalization_13[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 125, 512)             0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)          (None, 63, 256)              393472    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 63, 256)              1024      ['conv1d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 63, 256)              0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)          (None, 63, 256)              196864    ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 63, 256)              1024      ['conv1d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 63, 256)              0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " res4a_branch (Conv1D)       (None, 63, 1024)             787456    ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)          (None, 63, 1024)             525312    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 63, 1024)             4096      ['res4a_branch[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 63, 1024)             4096      ['conv1d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 63, 1024)             0         ['batch_normalization_16[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 63, 1024)             0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)          (None, 63, 256)              262400    ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 63, 256)              1024      ['conv1d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 63, 256)              0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)          (None, 63, 256)              196864    ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 63, 256)              1024      ['conv1d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 63, 256)              0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)          (None, 63, 1024)             263168    ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 63, 1024)             4096      ['conv1d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 63, 1024)             0         ['batch_normalization_20[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 63, 1024)             0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)          (None, 32, 256)              786688    ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 32, 256)              1024      ['conv1d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 32, 256)              0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)          (None, 32, 256)              196864    ['activation_19[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 32, 256)              1024      ['conv1d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 32, 256)              0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " res5a_branch (Conv1D)       (None, 32, 2048)             1574912   ['activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_20 (Conv1D)          (None, 32, 2048)             2099200   ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 32, 2048)             8192      ['res5a_branch[0][0]']        \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 32, 2048)             8192      ['conv1d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 32, 2048)             0         ['batch_normalization_23[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 32, 2048)             0         ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_21 (Conv1D)          (None, 32, 256)              524544    ['activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 32, 256)              1024      ['conv1d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 32, 256)              0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_22 (Conv1D)          (None, 32, 256)              196864    ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 32, 256)              1024      ['conv1d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 32, 256)              0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_23 (Conv1D)          (None, 32, 2048)             526336    ['activation_23[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 32, 2048)             8192      ['conv1d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 32, 2048)             0         ['batch_normalization_27[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'activation_21[0][0]']       \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 32, 2048)             0         ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 2048)                 0         ['activation_24[0][0]']       \n",
            " GlobalAveragePooling1D)                                                                          \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1, 2048)              0         ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1, 128)               262272    ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1, 2048)              264192    ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 32, 2048)             0         ['activation_24[0][0]',       \n",
            "                                                                     'dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_transpose (Conv1DTr  (None, 64, 64)               393280    ['multiply[0][0]']            \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 64, 64)               256       ['conv1d_transpose[0][0]']    \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)     (None, 64, 64)               0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 4096)                 0         ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 4096)                 0         ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 15)                   61455     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10364111 (39.54 MB)\n",
            "Trainable params: 10306383 (39.32 MB)\n",
            "Non-trainable params: 57728 (225.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "NoF = 64  # Number of filters in the first convolutional layer\n",
        "SE_RATIO = 16  # Squeeze-and-Excitation ratio\n",
        "\n",
        "nb_classes = 15\n",
        "\n",
        "\n",
        "initializer = tf.keras.initializers.GlorotUniform(seed=0)\n",
        "initializer2 = tf.keras.initializers.HeUniform(seed=0)\n",
        "\n",
        "def squeeze_excitation_block(X, ratio=16):\n",
        "    num_channels = X.shape[-1]\n",
        "    se = tf.keras.layers.GlobalAveragePooling1D()(X)\n",
        "    se = tf.keras.layers.Reshape((1, num_channels))(se)\n",
        "    se = tf.keras.layers.Dense(num_channels // ratio, activation='relu', kernel_initializer=initializer)(se)\n",
        "    se = tf.keras.layers.Dense(num_channels, activation='sigmoid', kernel_initializer=initializer)(se)\n",
        "    return tf.keras.layers.Multiply()([X, se])\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "initializer = tf.keras.initializers.GlorotUniform(seed=0)\n",
        "initializer2 = tf.keras.initializers.HeUniform(seed=0)\n",
        "Stride=1\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "\n",
        "  #defining name basis\n",
        "  ConvNameBase = 'res' + str(stage) + block + '_branch'\n",
        "  BatchNormBase = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "  #retrieve filters\n",
        "  F1,F2,F3 = filters\n",
        "\n",
        "  #save the input value. You'll need this later to add back the main path\n",
        "  x_shortcut = X\n",
        "\n",
        "  ### First component of the main path ###\n",
        "  X = tf.keras.layers.Conv1D(filters=F1, kernel_size=1, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer#, name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  ### Second component of main path ###\n",
        "  X = tf.keras.layers.Conv1D(filters=F2, kernel_size=f, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer, #name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  #Third Component of main path\n",
        "  X = tf.keras.layers.Conv1D(filters=F3, kernel_size=1, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer#,name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "\n",
        "  #Final step: add shortcut to the main path, and pass it through ReLU activation\n",
        "  X = tf.keras.layers.Add()([X, x_shortcut])\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  return X\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "\n",
        "  #Defining name bases\n",
        "  ConvNameBase = 'res' + str(stage) + block + '_branch'\n",
        "  BatchNormBase = 'res' + str(stage) + block + '_branch'\n",
        "\n",
        "  #retrive n_filters\n",
        "  F1, F2, F3 = filters\n",
        "\n",
        "  #Save the input value\n",
        "  x_shortcut = X\n",
        "\n",
        "  #First component of the main path\n",
        "  X = tf.keras.layers.Conv1D(F1, strides=s, kernel_size=f, kernel_initializer=initializer,\n",
        "             padding='same'#, name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  #Second Component of main path\n",
        "  X = tf.keras.layers.Conv1D(filters=F2, kernel_size=f, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer#, name=ConvNameBase\n",
        "             )(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                         )(X)\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  #Third component of main path\n",
        "  X = tf.keras.layers.Conv1D(filters=F3, kernel_size=f, strides=Stride, padding='same',\n",
        "             kernel_initializer=initializer, name=ConvNameBase)(X)\n",
        "  X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "  )(X)\n",
        "\n",
        "  ###### SHORTCUT PATH ######\n",
        "  x_shortcut = tf.keras.layers.Conv1D(filters = F3, kernel_size=1, strides=s,\n",
        "                      padding='same', #name=ConvNameBase,\n",
        "                      kernel_initializer=initializer)(x_shortcut)\n",
        "  x_shortcut = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,\n",
        "                                  )(x_shortcut)\n",
        "\n",
        "  #Add shortcut to main path and pass in through ReLU activation\n",
        "  X = tf.keras.layers.Add()([X, x_shortcut])\n",
        "  X = tf.keras.layers.Activation('relu')(X)\n",
        "\n",
        "  return X\n",
        "\n",
        "def create_model():\n",
        "    input_shape = (1000, 1)\n",
        "\n",
        "    x_input = tf.keras.layers.Input(input_shape)\n",
        "    X = tf.keras.layers.ZeroPadding1D(padding=3)(x_input)\n",
        "\n",
        "    X = tf.keras.layers.Conv1D(NoF, kernel_size=7, strides=2, name='Convolution1',\n",
        "                               kernel_initializer=initializer)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(name=\"BatchNormStage1\")(X)\n",
        "    X = tf.keras.layers.Activation('relu')(X)\n",
        "    X = tf.keras.layers.MaxPooling1D(3, strides=2)(X)\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[NoF, NoF, NoF * 4], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [NoF, NoF, NoF * 4], stage=2, block='b')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[NoF * 2, NoF * 2, NoF * 8], stage=3, block='a')\n",
        "    X = identity_block(X, 3, [NoF * 2, NoF * 2, NoF * 8], stage=3, block='b')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[NoF * 4, NoF * 4, NoF * 16], stage=4, block='a')\n",
        "    X = identity_block(X, 3, [NoF * 4, NoF * 4, NoF * 16], stage=4, block='b')\n",
        "\n",
        "    X = convolutional_block(X, f=3, filters=[NoF * 4, NoF * 4, NoF * 32], stage=5, block='a')\n",
        "    X = identity_block(X, f=3, filters=[NoF * 4, NoF * 4, NoF * 32], stage=5, block='b')\n",
        "\n",
        "    # Applying SE mechanism before transposed convolutional layers\n",
        "    X = squeeze_excitation_block(X)\n",
        "\n",
        "    # Adding transposed convolutional layers\n",
        "    X = Conv1DTranspose(filters=NoF, kernel_size=3, strides=2, padding='same', kernel_initializer=initializer)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis=2, momentum=0.99, trainable=False,)(X)\n",
        "    X = LeakyReLU(alpha=0.2)(X)\n",
        "\n",
        "    X = Flatten()(X)\n",
        "\n",
        "    # Adding dropout regularization\n",
        "    X = Dropout(0.5)(X)\n",
        "\n",
        "    X = Dense(nb_classes, activation='softmax', kernel_initializer=initializer)(X)\n",
        "\n",
        "    res_net = models.Model(inputs=x_input, outputs=X, name='ResNet29')\n",
        "\n",
        "    return res_net\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCtG5iFQyhUJ"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  res_net = create_model()\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=res_net)\n",
        "  callbacks = [EarlyStopping(monitor='val_loss', patience=10, mode='min'), ModelCheckpoint('/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p3.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
        "  res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "  Known_data_X_reference, Known_data_X_train_label = shuffle(Known_data_X_reference, Known_data_X_train_label)\n",
        "\n",
        "  history = res_net.fit(Known_data_X_reference, Known_data_X_train_label, epochs=200, batch_size=32, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)\n",
        "\n",
        "  test_loss, test_acc = res_net.evaluate(Known_data_X_test, Known_data_X_test_label)\n",
        "\n",
        "  print('Test accuracy, 01_SJ11:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlX_NfqohDTs",
        "outputId": "5f0606f5-3baf-43aa-a99a-1efbbfba8b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 41s 781ms/step - loss: 3.3412 - accuracy: 0.5160\n",
            "Test accuracy, 01 run: 0.515999972820282\n",
            "47/47 [==============================] - 71s 1s/step - loss: 3.9487 - accuracy: 0.5473\n",
            "Test accuracy, 02 run: 0.5473333597183228\n",
            "47/47 [==============================] - 49s 871ms/step - loss: 3.5961 - accuracy: 0.5113\n",
            "Test accuracy, 03 run: 0.5113333463668823\n",
            "47/47 [==============================] - 36s 724ms/step - loss: 3.3539 - accuracy: 0.5347\n",
            "Test accuracy, 04 run: 0.5346666574478149\n",
            "47/47 [==============================] - 43s 870ms/step - loss: 3.6036 - accuracy: 0.5387\n",
            "Test accuracy, 05 run: 0.5386666655540466\n",
            "47/47 [==============================] - 38s 767ms/step - loss: 3.2325 - accuracy: 0.5413\n",
            "Test accuracy, 06 run: 0.5413333177566528\n",
            "47/47 [==============================] - 42s 831ms/step - loss: 3.6076 - accuracy: 0.5380\n",
            "Test accuracy, 07 run: 0.5379999876022339\n",
            "47/47 [==============================] - 38s 775ms/step - loss: 3.3121 - accuracy: 0.5440\n",
            "Test accuracy, 08 run: 0.5440000295639038\n",
            "47/47 [==============================] - 38s 764ms/step - loss: 3.6402 - accuracy: 0.5160\n",
            "Test accuracy, 09 run: 0.515999972820282\n",
            "47/47 [==============================] - 37s 715ms/step - loss: 3.2883 - accuracy: 0.5253\n",
            "Test accuracy, 10 run: 0.5253333449363708\n",
            "47/47 [==============================] - 36s 719ms/step - loss: 3.2843 - accuracy: 0.5067\n",
            "Test accuracy, 11 run: 0.5066666603088379\n",
            "47/47 [==============================] - 38s 762ms/step - loss: 3.5559 - accuracy: 0.5353\n",
            "Test accuracy, 12 run: 0.5353333353996277\n",
            "47/47 [==============================] - 37s 742ms/step - loss: 3.3626 - accuracy: 0.5080\n",
            "Test accuracy, 13 run: 0.5080000162124634\n",
            "47/47 [==============================] - 38s 725ms/step - loss: 3.4604 - accuracy: 0.5247\n",
            "Test accuracy, 14 run: 0.5246666669845581\n",
            "47/47 [==============================] - 36s 714ms/step - loss: 3.4983 - accuracy: 0.5440\n",
            "Test accuracy, 15 run: 0.5440000295639038\n",
            "47/47 [==============================] - 35s 713ms/step - loss: 3.4700 - accuracy: 0.5327\n",
            "Test accuracy, 16 run: 0.5326666831970215\n",
            "47/47 [==============================] - 38s 752ms/step - loss: 3.2763 - accuracy: 0.5373\n",
            "Test accuracy, 17 run: 0.5373333096504211\n",
            "47/47 [==============================] - 38s 751ms/step - loss: 3.2589 - accuracy: 0.5500\n",
            "Test accuracy, 18 run: 0.550000011920929\n",
            "47/47 [==============================] - 39s 769ms/step - loss: 3.8447 - accuracy: 0.5300\n",
            "Test accuracy, 19 run: 0.5299999713897705\n",
            "47/47 [==============================] - 39s 759ms/step - loss: 3.4178 - accuracy: 0.5233\n",
            "Test accuracy, 20 run: 0.5233333110809326\n"
          ]
        }
      ],
      "source": [
        "# Now run and see the models with the best validation accuracy\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 01 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 02 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 03 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 04 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 05 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 06 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 07 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 08 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 09 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 10 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 11 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 12 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 13 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 14 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 15 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 16 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 17 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 18 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 19 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p3.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 20 run:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yQJTWTWYkt1",
        "outputId": "6b98143a-78a9-4dce-de2c-3e0e427d0c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 26/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4116 - accuracy: 0.8590\n",
            "Epoch 26: val_loss improved from 0.34326 to 0.33415, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.4095 - accuracy: 0.8592 - val_loss: 0.3342 - val_accuracy: 0.8767\n",
            "Epoch 27/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8692\n",
            "Epoch 27: val_loss did not improve from 0.33415\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.4166 - accuracy: 0.8692 - val_loss: 0.3392 - val_accuracy: 0.8867\n",
            "Epoch 28/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8733\n",
            "Epoch 28: val_loss improved from 0.33415 to 0.32376, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.3820 - accuracy: 0.8733 - val_loss: 0.3238 - val_accuracy: 0.8933\n",
            "Epoch 29/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.8717\n",
            "Epoch 29: val_loss improved from 0.32376 to 0.32174, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.3972 - accuracy: 0.8717 - val_loss: 0.3217 - val_accuracy: 0.8933\n",
            "Epoch 30/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.8758\n",
            "Epoch 30: val_loss improved from 0.32174 to 0.31624, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.3788 - accuracy: 0.8758 - val_loss: 0.3162 - val_accuracy: 0.8933\n",
            "Epoch 31/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3833 - accuracy: 0.8640\n",
            "Epoch 31: val_loss improved from 0.31624 to 0.30352, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.3820 - accuracy: 0.8642 - val_loss: 0.3035 - val_accuracy: 0.8933\n",
            "Epoch 32/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 0.8867\n",
            "Epoch 32: val_loss did not improve from 0.30352\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.3708 - accuracy: 0.8867 - val_loss: 0.3038 - val_accuracy: 0.8933\n",
            "Epoch 33/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.8917\n",
            "Epoch 33: val_loss improved from 0.30352 to 0.29283, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.3634 - accuracy: 0.8917 - val_loss: 0.2928 - val_accuracy: 0.8967\n",
            "Epoch 34/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3618 - accuracy: 0.8792\n",
            "Epoch 34: val_loss improved from 0.29283 to 0.28879, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.3664 - accuracy: 0.8758 - val_loss: 0.2888 - val_accuracy: 0.8967\n",
            "Epoch 35/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8708\n",
            "Epoch 35: val_loss improved from 0.28879 to 0.28598, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.3561 - accuracy: 0.8717 - val_loss: 0.2860 - val_accuracy: 0.9000\n",
            "Epoch 36/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3300 - accuracy: 0.8860\n",
            "Epoch 36: val_loss improved from 0.28598 to 0.28056, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3325 - accuracy: 0.8858 - val_loss: 0.2806 - val_accuracy: 0.9033\n",
            "Epoch 37/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.8883\n",
            "Epoch 37: val_loss improved from 0.28056 to 0.27645, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.3181 - accuracy: 0.8883 - val_loss: 0.2764 - val_accuracy: 0.9033\n",
            "Epoch 38/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3290 - accuracy: 0.8826\n",
            "Epoch 38: val_loss improved from 0.27645 to 0.27589, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.3283 - accuracy: 0.8833 - val_loss: 0.2759 - val_accuracy: 0.9000\n",
            "Epoch 39/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3164 - accuracy: 0.8992\n",
            "Epoch 39: val_loss improved from 0.27589 to 0.26967, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3164 - accuracy: 0.8992 - val_loss: 0.2697 - val_accuracy: 0.9000\n",
            "Epoch 40/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8894\n",
            "Epoch 40: val_loss improved from 0.26967 to 0.26170, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.3248 - accuracy: 0.8892 - val_loss: 0.2617 - val_accuracy: 0.9000\n",
            "Epoch 41/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.8975\n",
            "Epoch 41: val_loss improved from 0.26170 to 0.26007, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.2997 - accuracy: 0.8975 - val_loss: 0.2601 - val_accuracy: 0.9033\n",
            "Epoch 42/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.8975\n",
            "Epoch 42: val_loss improved from 0.26007 to 0.25483, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3010 - accuracy: 0.8975 - val_loss: 0.2548 - val_accuracy: 0.9067\n",
            "Epoch 43/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3016 - accuracy: 0.8958\n",
            "Epoch 43: val_loss improved from 0.25483 to 0.25096, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.3001 - accuracy: 0.8983 - val_loss: 0.2510 - val_accuracy: 0.9100\n",
            "Epoch 44/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2999 - accuracy: 0.9036\n",
            "Epoch 44: val_loss improved from 0.25096 to 0.24584, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.3051 - accuracy: 0.9033 - val_loss: 0.2458 - val_accuracy: 0.9100\n",
            "Epoch 45/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.9096\n",
            "Epoch 45: val_loss did not improve from 0.24584\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.2931 - accuracy: 0.9075 - val_loss: 0.2479 - val_accuracy: 0.9100\n",
            "Epoch 46/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2793 - accuracy: 0.9020\n",
            "Epoch 46: val_loss improved from 0.24584 to 0.24278, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2773 - accuracy: 0.9025 - val_loss: 0.2428 - val_accuracy: 0.9100\n",
            "Epoch 47/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.9046\n",
            "Epoch 47: val_loss improved from 0.24278 to 0.23907, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.2899 - accuracy: 0.9050 - val_loss: 0.2391 - val_accuracy: 0.9100\n",
            "Epoch 48/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.9139\n",
            "Epoch 48: val_loss did not improve from 0.23907\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.2792 - accuracy: 0.9125 - val_loss: 0.2393 - val_accuracy: 0.9100\n",
            "Epoch 49/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9172\n",
            "Epoch 49: val_loss improved from 0.23907 to 0.23258, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.2669 - accuracy: 0.9150 - val_loss: 0.2326 - val_accuracy: 0.9167\n",
            "Epoch 50/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2582 - accuracy: 0.9198\n",
            "Epoch 50: val_loss improved from 0.23258 to 0.23070, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2558 - accuracy: 0.9208 - val_loss: 0.2307 - val_accuracy: 0.9133\n",
            "Epoch 51/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9096\n",
            "Epoch 51: val_loss did not improve from 0.23070\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.2574 - accuracy: 0.9092 - val_loss: 0.2364 - val_accuracy: 0.9067\n",
            "Epoch 52/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2563 - accuracy: 0.9122\n",
            "Epoch 52: val_loss improved from 0.23070 to 0.22832, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.2537 - accuracy: 0.9133 - val_loss: 0.2283 - val_accuracy: 0.9133\n",
            "Epoch 53/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.8986\n",
            "Epoch 53: val_loss improved from 0.22832 to 0.22457, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2634 - accuracy: 0.9000 - val_loss: 0.2246 - val_accuracy: 0.9100\n",
            "Epoch 54/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.9142\n",
            "Epoch 54: val_loss did not improve from 0.22457\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.2433 - accuracy: 0.9142 - val_loss: 0.2262 - val_accuracy: 0.9100\n",
            "Epoch 55/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.9150\n",
            "Epoch 55: val_loss improved from 0.22457 to 0.22406, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.2456 - accuracy: 0.9150 - val_loss: 0.2241 - val_accuracy: 0.9133\n",
            "Epoch 56/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2530 - accuracy: 0.9193\n",
            "Epoch 56: val_loss improved from 0.22406 to 0.21672, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 142ms/step - loss: 0.2560 - accuracy: 0.9175 - val_loss: 0.2167 - val_accuracy: 0.9200\n",
            "Epoch 57/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.9208\n",
            "Epoch 57: val_loss improved from 0.21672 to 0.21578, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.2456 - accuracy: 0.9208 - val_loss: 0.2158 - val_accuracy: 0.9200\n",
            "Epoch 58/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2197 - accuracy: 0.9257\n",
            "Epoch 58: val_loss improved from 0.21578 to 0.21041, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.2187 - accuracy: 0.9258 - val_loss: 0.2104 - val_accuracy: 0.9200\n",
            "Epoch 59/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.9317\n",
            "Epoch 59: val_loss improved from 0.21041 to 0.21019, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 150ms/step - loss: 0.2145 - accuracy: 0.9317 - val_loss: 0.2102 - val_accuracy: 0.9267\n",
            "Epoch 60/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9299\n",
            "Epoch 60: val_loss did not improve from 0.21019\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.2207 - accuracy: 0.9283 - val_loss: 0.2117 - val_accuracy: 0.9167\n",
            "Epoch 61/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9300\n",
            "Epoch 61: val_loss improved from 0.21019 to 0.20653, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2212 - accuracy: 0.9300 - val_loss: 0.2065 - val_accuracy: 0.9267\n",
            "Epoch 62/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1922 - accuracy: 0.9350\n",
            "Epoch 62: val_loss improved from 0.20653 to 0.20368, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.1922 - accuracy: 0.9350 - val_loss: 0.2037 - val_accuracy: 0.9267\n",
            "Epoch 63/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9358\n",
            "Epoch 63: val_loss improved from 0.20368 to 0.20132, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.2166 - accuracy: 0.9350 - val_loss: 0.2013 - val_accuracy: 0.9267\n",
            "Epoch 64/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9409\n",
            "Epoch 64: val_loss did not improve from 0.20132\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1880 - accuracy: 0.9383 - val_loss: 0.2044 - val_accuracy: 0.9167\n",
            "Epoch 65/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.9299\n",
            "Epoch 65: val_loss improved from 0.20132 to 0.19987, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2012 - accuracy: 0.9308 - val_loss: 0.1999 - val_accuracy: 0.9267\n",
            "Epoch 66/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1973 - accuracy: 0.9291\n",
            "Epoch 66: val_loss improved from 0.19987 to 0.19977, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.2001 - accuracy: 0.9283 - val_loss: 0.1998 - val_accuracy: 0.9233\n",
            "Epoch 67/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1892 - accuracy: 0.9333\n",
            "Epoch 67: val_loss improved from 0.19977 to 0.19695, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.1908 - accuracy: 0.9333 - val_loss: 0.1969 - val_accuracy: 0.9267\n",
            "Epoch 68/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2031 - accuracy: 0.9283\n",
            "Epoch 68: val_loss improved from 0.19695 to 0.19610, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2031 - accuracy: 0.9283 - val_loss: 0.1961 - val_accuracy: 0.9233\n",
            "Epoch 69/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2140 - accuracy: 0.9231\n",
            "Epoch 69: val_loss improved from 0.19610 to 0.19275, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.2137 - accuracy: 0.9233 - val_loss: 0.1928 - val_accuracy: 0.9267\n",
            "Epoch 70/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9443\n",
            "Epoch 70: val_loss did not improve from 0.19275\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1771 - accuracy: 0.9433 - val_loss: 0.1994 - val_accuracy: 0.9200\n",
            "Epoch 71/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9350\n",
            "Epoch 71: val_loss did not improve from 0.19275\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1957 - accuracy: 0.9350 - val_loss: 0.1940 - val_accuracy: 0.9233\n",
            "Epoch 72/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1827 - accuracy: 0.9350\n",
            "Epoch 72: val_loss did not improve from 0.19275\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1824 - accuracy: 0.9350 - val_loss: 0.1938 - val_accuracy: 0.9200\n",
            "Epoch 73/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9383\n",
            "Epoch 73: val_loss did not improve from 0.19275\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.1846 - accuracy: 0.9383 - val_loss: 0.1945 - val_accuracy: 0.9233\n",
            "Epoch 74/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9392\n",
            "Epoch 74: val_loss improved from 0.19275 to 0.18647, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 162ms/step - loss: 0.1790 - accuracy: 0.9392 - val_loss: 0.1865 - val_accuracy: 0.9333\n",
            "Epoch 75/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.9425\n",
            "Epoch 75: val_loss did not improve from 0.18647\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1687 - accuracy: 0.9425 - val_loss: 0.1873 - val_accuracy: 0.9300\n",
            "Epoch 76/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9392\n",
            "Epoch 76: val_loss did not improve from 0.18647\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1695 - accuracy: 0.9383 - val_loss: 0.1883 - val_accuracy: 0.9267\n",
            "Epoch 77/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.9375\n",
            "Epoch 77: val_loss improved from 0.18647 to 0.18354, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.1563 - accuracy: 0.9375 - val_loss: 0.1835 - val_accuracy: 0.9367\n",
            "Epoch 78/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9443\n",
            "Epoch 78: val_loss did not improve from 0.18354\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1665 - accuracy: 0.9442 - val_loss: 0.1842 - val_accuracy: 0.9167\n",
            "Epoch 79/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1697 - accuracy: 0.9384\n",
            "Epoch 79: val_loss did not improve from 0.18354\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.1666 - accuracy: 0.9400 - val_loss: 0.1881 - val_accuracy: 0.9300\n",
            "Epoch 80/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9383\n",
            "Epoch 80: val_loss improved from 0.18354 to 0.18009, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.1721 - accuracy: 0.9383 - val_loss: 0.1801 - val_accuracy: 0.9367\n",
            "Epoch 81/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 0.9552\n",
            "Epoch 81: val_loss improved from 0.18009 to 0.17963, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1512 - accuracy: 0.9550 - val_loss: 0.1796 - val_accuracy: 0.9333\n",
            "Epoch 82/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1384 - accuracy: 0.9502\n",
            "Epoch 82: val_loss improved from 0.17963 to 0.17734, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.1377 - accuracy: 0.9508 - val_loss: 0.1773 - val_accuracy: 0.9333\n",
            "Epoch 83/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1644 - accuracy: 0.9468\n",
            "Epoch 83: val_loss did not improve from 0.17734\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.1631 - accuracy: 0.9475 - val_loss: 0.1835 - val_accuracy: 0.9233\n",
            "Epoch 84/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9383\n",
            "Epoch 84: val_loss did not improve from 0.17734\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.1770 - accuracy: 0.9383 - val_loss: 0.1788 - val_accuracy: 0.9333\n",
            "Epoch 85/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9510\n",
            "Epoch 85: val_loss improved from 0.17734 to 0.17717, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1463 - accuracy: 0.9517 - val_loss: 0.1772 - val_accuracy: 0.9333\n",
            "Epoch 86/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9476\n",
            "Epoch 86: val_loss did not improve from 0.17717\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1481 - accuracy: 0.9483 - val_loss: 0.1782 - val_accuracy: 0.9367\n",
            "Epoch 87/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9408\n",
            "Epoch 87: val_loss did not improve from 0.17717\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.1621 - accuracy: 0.9408 - val_loss: 0.1773 - val_accuracy: 0.9300\n",
            "Epoch 88/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9558\n",
            "Epoch 88: val_loss did not improve from 0.17717\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.1338 - accuracy: 0.9558 - val_loss: 0.1775 - val_accuracy: 0.9300\n",
            "Epoch 89/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9527\n",
            "Epoch 89: val_loss improved from 0.17717 to 0.17544, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 134ms/step - loss: 0.1449 - accuracy: 0.9533 - val_loss: 0.1754 - val_accuracy: 0.9333\n",
            "Epoch 90/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9533\n",
            "Epoch 90: val_loss improved from 0.17544 to 0.16977, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1434 - accuracy: 0.9533 - val_loss: 0.1698 - val_accuracy: 0.9367\n",
            "Epoch 91/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9519\n",
            "Epoch 91: val_loss did not improve from 0.16977\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1399 - accuracy: 0.9525 - val_loss: 0.1703 - val_accuracy: 0.9367\n",
            "Epoch 92/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1493 - accuracy: 0.9561\n",
            "Epoch 92: val_loss did not improve from 0.16977\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1506 - accuracy: 0.9558 - val_loss: 0.1721 - val_accuracy: 0.9400\n",
            "Epoch 93/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9525\n",
            "Epoch 93: val_loss did not improve from 0.16977\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.1420 - accuracy: 0.9525 - val_loss: 0.1707 - val_accuracy: 0.9433\n",
            "Epoch 94/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9508\n",
            "Epoch 94: val_loss did not improve from 0.16977\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.1445 - accuracy: 0.9508 - val_loss: 0.1703 - val_accuracy: 0.9433\n",
            "Epoch 95/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 0.9527\n",
            "Epoch 95: val_loss improved from 0.16977 to 0.16532, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 153ms/step - loss: 0.1288 - accuracy: 0.9533 - val_loss: 0.1653 - val_accuracy: 0.9367\n",
            "Epoch 96/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9433\n",
            "Epoch 96: val_loss did not improve from 0.16532\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1447 - accuracy: 0.9433 - val_loss: 0.1686 - val_accuracy: 0.9333\n",
            "Epoch 97/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.9525\n",
            "Epoch 97: val_loss did not improve from 0.16532\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1242 - accuracy: 0.9525 - val_loss: 0.1656 - val_accuracy: 0.9433\n",
            "Epoch 98/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9608\n",
            "Epoch 98: val_loss did not improve from 0.16532\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1185 - accuracy: 0.9608 - val_loss: 0.1681 - val_accuracy: 0.9433\n",
            "Epoch 99/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9542\n",
            "Epoch 99: val_loss improved from 0.16532 to 0.16259, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.1169 - accuracy: 0.9542 - val_loss: 0.1626 - val_accuracy: 0.9433\n",
            "Epoch 100/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.9550\n",
            "Epoch 100: val_loss did not improve from 0.16259\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1203 - accuracy: 0.9550 - val_loss: 0.1626 - val_accuracy: 0.9400\n",
            "Epoch 101/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9595\n",
            "Epoch 101: val_loss did not improve from 0.16259\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1183 - accuracy: 0.9600 - val_loss: 0.1678 - val_accuracy: 0.9333\n",
            "Epoch 102/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1247 - accuracy: 0.9535\n",
            "Epoch 102: val_loss improved from 0.16259 to 0.16211, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1233 - accuracy: 0.9542 - val_loss: 0.1621 - val_accuracy: 0.9367\n",
            "Epoch 103/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 0.9603\n",
            "Epoch 103: val_loss improved from 0.16211 to 0.15852, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1126 - accuracy: 0.9608 - val_loss: 0.1585 - val_accuracy: 0.9433\n",
            "Epoch 104/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9575\n",
            "Epoch 104: val_loss improved from 0.15852 to 0.15524, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.1304 - accuracy: 0.9575 - val_loss: 0.1552 - val_accuracy: 0.9467\n",
            "Epoch 105/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9500\n",
            "Epoch 105: val_loss did not improve from 0.15524\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1316 - accuracy: 0.9500 - val_loss: 0.1626 - val_accuracy: 0.9400\n",
            "Epoch 106/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1323 - accuracy: 0.9459\n",
            "Epoch 106: val_loss did not improve from 0.15524\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1312 - accuracy: 0.9467 - val_loss: 0.1586 - val_accuracy: 0.9433\n",
            "Epoch 107/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.9628\n",
            "Epoch 107: val_loss did not improve from 0.15524\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.1062 - accuracy: 0.9633 - val_loss: 0.1554 - val_accuracy: 0.9433\n",
            "Epoch 108/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1088 - accuracy: 0.9644\n",
            "Epoch 108: val_loss did not improve from 0.15524\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.1082 - accuracy: 0.9650 - val_loss: 0.1620 - val_accuracy: 0.9333\n",
            "Epoch 109/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9650\n",
            "Epoch 109: val_loss did not improve from 0.15524\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.1158 - accuracy: 0.9650 - val_loss: 0.1604 - val_accuracy: 0.9400\n",
            "Epoch 110/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9662\n",
            "Epoch 110: val_loss did not improve from 0.15524\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1047 - accuracy: 0.9650 - val_loss: 0.1612 - val_accuracy: 0.9367\n",
            "Epoch 111/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1007 - accuracy: 0.9670\n",
            "Epoch 111: val_loss improved from 0.15524 to 0.15114, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0983 - accuracy: 0.9683 - val_loss: 0.1511 - val_accuracy: 0.9500\n",
            "Epoch 112/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9611\n",
            "Epoch 112: val_loss improved from 0.15114 to 0.14960, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.1189 - accuracy: 0.9617 - val_loss: 0.1496 - val_accuracy: 0.9500\n",
            "Epoch 113/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9645\n",
            "Epoch 113: val_loss did not improve from 0.14960\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.1046 - accuracy: 0.9650 - val_loss: 0.1547 - val_accuracy: 0.9400\n",
            "Epoch 114/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0955 - accuracy: 0.9679\n",
            "Epoch 114: val_loss did not improve from 0.14960\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0953 - accuracy: 0.9675 - val_loss: 0.1545 - val_accuracy: 0.9433\n",
            "Epoch 115/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9650\n",
            "Epoch 115: val_loss did not improve from 0.14960\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1026 - accuracy: 0.9650 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
            "Epoch 116/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9633\n",
            "Epoch 116: val_loss improved from 0.14960 to 0.14954, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.1048 - accuracy: 0.9633 - val_loss: 0.1495 - val_accuracy: 0.9467\n",
            "Epoch 117/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.9671\n",
            "Epoch 117: val_loss improved from 0.14954 to 0.14725, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.0959 - accuracy: 0.9675 - val_loss: 0.1472 - val_accuracy: 0.9467\n",
            "Epoch 118/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9700\n",
            "Epoch 118: val_loss did not improve from 0.14725\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.0943 - accuracy: 0.9700 - val_loss: 0.1484 - val_accuracy: 0.9467\n",
            "Epoch 119/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9620\n",
            "Epoch 119: val_loss did not improve from 0.14725\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0963 - accuracy: 0.9617 - val_loss: 0.1516 - val_accuracy: 0.9533\n",
            "Epoch 120/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9808\n",
            "Epoch 120: val_loss improved from 0.14725 to 0.14664, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0756 - accuracy: 0.9808 - val_loss: 0.1466 - val_accuracy: 0.9533\n",
            "Epoch 121/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9637\n",
            "Epoch 121: val_loss improved from 0.14664 to 0.14400, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.1026 - accuracy: 0.9642 - val_loss: 0.1440 - val_accuracy: 0.9467\n",
            "Epoch 122/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.9708\n",
            "Epoch 122: val_loss did not improve from 0.14400\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0922 - accuracy: 0.9708 - val_loss: 0.1456 - val_accuracy: 0.9533\n",
            "Epoch 123/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9675\n",
            "Epoch 123: val_loss did not improve from 0.14400\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0995 - accuracy: 0.9675 - val_loss: 0.1469 - val_accuracy: 0.9500\n",
            "Epoch 124/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9708\n",
            "Epoch 124: val_loss did not improve from 0.14400\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0886 - accuracy: 0.9708 - val_loss: 0.1496 - val_accuracy: 0.9533\n",
            "Epoch 125/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.9717\n",
            "Epoch 125: val_loss did not improve from 0.14400\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0940 - accuracy: 0.9717 - val_loss: 0.1521 - val_accuracy: 0.9467\n",
            "Epoch 126/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9662\n",
            "Epoch 126: val_loss did not improve from 0.14400\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.1056 - accuracy: 0.9650 - val_loss: 0.1491 - val_accuracy: 0.9500\n",
            "Epoch 127/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9733\n",
            "Epoch 127: val_loss did not improve from 0.14400\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0789 - accuracy: 0.9733 - val_loss: 0.1464 - val_accuracy: 0.9500\n",
            "Epoch 128/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9717\n",
            "Epoch 128: val_loss did not improve from 0.14400\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0890 - accuracy: 0.9717 - val_loss: 0.1485 - val_accuracy: 0.9467\n",
            "Epoch 129/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9667\n",
            "Epoch 129: val_loss improved from 0.14400 to 0.14297, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 147ms/step - loss: 0.0962 - accuracy: 0.9667 - val_loss: 0.1430 - val_accuracy: 0.9500\n",
            "Epoch 130/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 0.9713\n",
            "Epoch 130: val_loss did not improve from 0.14297\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0847 - accuracy: 0.9717 - val_loss: 0.1467 - val_accuracy: 0.9533\n",
            "Epoch 131/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9688\n",
            "Epoch 131: val_loss did not improve from 0.14297\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0794 - accuracy: 0.9692 - val_loss: 0.1439 - val_accuracy: 0.9500\n",
            "Epoch 132/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9688\n",
            "Epoch 132: val_loss did not improve from 0.14297\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0926 - accuracy: 0.9692 - val_loss: 0.1478 - val_accuracy: 0.9533\n",
            "Epoch 133/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0928 - accuracy: 0.9671\n",
            "Epoch 133: val_loss did not improve from 0.14297\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0918 - accuracy: 0.9675 - val_loss: 0.1468 - val_accuracy: 0.9533\n",
            "Epoch 134/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9717\n",
            "Epoch 134: val_loss did not improve from 0.14297\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.0881 - accuracy: 0.9717 - val_loss: 0.1485 - val_accuracy: 0.9567\n",
            "Epoch 135/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0754 - accuracy: 0.9731\n",
            "Epoch 135: val_loss did not improve from 0.14297\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0775 - accuracy: 0.9725 - val_loss: 0.1468 - val_accuracy: 0.9533\n",
            "Epoch 136/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0731 - accuracy: 0.9705\n",
            "Epoch 136: val_loss did not improve from 0.14297\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0775 - accuracy: 0.9683 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
            "Epoch 137/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9742\n",
            "Epoch 137: val_loss did not improve from 0.14297\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0799 - accuracy: 0.9742 - val_loss: 0.1440 - val_accuracy: 0.9500\n",
            "Epoch 138/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9747\n",
            "Epoch 138: val_loss improved from 0.14297 to 0.14254, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.0721 - accuracy: 0.9742 - val_loss: 0.1425 - val_accuracy: 0.9567\n",
            "Epoch 139/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 0.9662\n",
            "Epoch 139: val_loss improved from 0.14254 to 0.13689, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.0901 - accuracy: 0.9667 - val_loss: 0.1369 - val_accuracy: 0.9600\n",
            "Epoch 140/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9742\n",
            "Epoch 140: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0852 - accuracy: 0.9742 - val_loss: 0.1398 - val_accuracy: 0.9500\n",
            "Epoch 141/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9725\n",
            "Epoch 141: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0706 - accuracy: 0.9725 - val_loss: 0.1447 - val_accuracy: 0.9533\n",
            "Epoch 142/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9708\n",
            "Epoch 142: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0790 - accuracy: 0.9708 - val_loss: 0.1430 - val_accuracy: 0.9533\n",
            "Epoch 143/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9833\n",
            "Epoch 143: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0676 - accuracy: 0.9833 - val_loss: 0.1412 - val_accuracy: 0.9567\n",
            "Epoch 144/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0911 - accuracy: 0.9704\n",
            "Epoch 144: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0925 - accuracy: 0.9692 - val_loss: 0.1425 - val_accuracy: 0.9567\n",
            "Epoch 145/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 0.9738\n",
            "Epoch 145: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0800 - accuracy: 0.9742 - val_loss: 0.1462 - val_accuracy: 0.9533\n",
            "Epoch 146/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0844 - accuracy: 0.9721\n",
            "Epoch 146: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0835 - accuracy: 0.9725 - val_loss: 0.1439 - val_accuracy: 0.9567\n",
            "Epoch 147/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9713\n",
            "Epoch 147: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0829 - accuracy: 0.9717 - val_loss: 0.1419 - val_accuracy: 0.9567\n",
            "Epoch 148/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9814\n",
            "Epoch 148: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0655 - accuracy: 0.9817 - val_loss: 0.1464 - val_accuracy: 0.9567\n",
            "Epoch 149/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9833\n",
            "Epoch 149: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 3s 71ms/step - loss: 0.0579 - accuracy: 0.9833 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
            "Epoch 150/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.9730\n",
            "Epoch 150: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0773 - accuracy: 0.9725 - val_loss: 0.1448 - val_accuracy: 0.9600\n",
            "Epoch 151/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9823\n",
            "Epoch 151: val_loss did not improve from 0.13689\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0620 - accuracy: 0.9825 - val_loss: 0.1407 - val_accuracy: 0.9600\n",
            "Epoch 152/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9775\n",
            "Epoch 152: val_loss improved from 0.13689 to 0.13442, saving model to /content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 152ms/step - loss: 0.0602 - accuracy: 0.9775 - val_loss: 0.1344 - val_accuracy: 0.9600\n",
            "Epoch 153/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9738\n",
            "Epoch 153: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0748 - accuracy: 0.9742 - val_loss: 0.1381 - val_accuracy: 0.9533\n",
            "Epoch 154/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9764\n",
            "Epoch 154: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0703 - accuracy: 0.9758 - val_loss: 0.1392 - val_accuracy: 0.9567\n",
            "Epoch 155/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9780\n",
            "Epoch 155: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0682 - accuracy: 0.9783 - val_loss: 0.1416 - val_accuracy: 0.9533\n",
            "Epoch 156/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 0.9747\n",
            "Epoch 156: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0674 - accuracy: 0.9742 - val_loss: 0.1394 - val_accuracy: 0.9567\n",
            "Epoch 157/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9833\n",
            "Epoch 157: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
            "Epoch 158/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9717\n",
            "Epoch 158: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0714 - accuracy: 0.9717 - val_loss: 0.1492 - val_accuracy: 0.9500\n",
            "Epoch 159/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9750\n",
            "Epoch 159: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 3s 70ms/step - loss: 0.0753 - accuracy: 0.9750 - val_loss: 0.1405 - val_accuracy: 0.9567\n",
            "Epoch 160/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9808\n",
            "Epoch 160: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0587 - accuracy: 0.9808 - val_loss: 0.1348 - val_accuracy: 0.9600\n",
            "Epoch 161/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9842\n",
            "Epoch 161: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0568 - accuracy: 0.9842 - val_loss: 0.1392 - val_accuracy: 0.9533\n",
            "Epoch 162/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9806\n",
            "Epoch 162: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.1391 - val_accuracy: 0.9500\n",
            "Epoch 163/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.9867\n",
            "Epoch 163: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0529 - accuracy: 0.9867 - val_loss: 0.1453 - val_accuracy: 0.9533\n",
            "Epoch 164/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9808\n",
            "Epoch 164: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0522 - accuracy: 0.9808 - val_loss: 0.1418 - val_accuracy: 0.9567\n",
            "Epoch 165/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9783\n",
            "Epoch 165: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0611 - accuracy: 0.9783 - val_loss: 0.1371 - val_accuracy: 0.9567\n",
            "Epoch 166/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 0.9856\n",
            "Epoch 166: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0560 - accuracy: 0.9858 - val_loss: 0.1394 - val_accuracy: 0.9567\n",
            "Epoch 167/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.9747\n",
            "Epoch 167: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0657 - accuracy: 0.9750 - val_loss: 0.1345 - val_accuracy: 0.9533\n",
            "Epoch 168/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9825\n",
            "Epoch 168: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0525 - accuracy: 0.9825 - val_loss: 0.1359 - val_accuracy: 0.9533\n",
            "Epoch 169/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.9823\n",
            "Epoch 169: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 0.1350 - val_accuracy: 0.9567\n",
            "Epoch 170/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9764\n",
            "Epoch 170: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0677 - accuracy: 0.9767 - val_loss: 0.1356 - val_accuracy: 0.9567\n",
            "Epoch 171/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9842\n",
            "Epoch 171: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0482 - accuracy: 0.9842 - val_loss: 0.1406 - val_accuracy: 0.9567\n",
            "Epoch 172/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9823\n",
            "Epoch 172: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0593 - accuracy: 0.9825 - val_loss: 0.1406 - val_accuracy: 0.9567\n",
            "Epoch 173/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9783\n",
            "Epoch 173: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0631 - accuracy: 0.9783 - val_loss: 0.1442 - val_accuracy: 0.9567\n",
            "Epoch 174/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9823\n",
            "Epoch 174: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0534 - accuracy: 0.9825 - val_loss: 0.1427 - val_accuracy: 0.9567\n",
            "Epoch 175/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.9797\n",
            "Epoch 175: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.1372 - val_accuracy: 0.9567\n",
            "Epoch 176/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9823\n",
            "Epoch 176: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0604 - accuracy: 0.9817 - val_loss: 0.1355 - val_accuracy: 0.9600\n",
            "Epoch 177/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9831\n",
            "Epoch 177: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0595 - accuracy: 0.9833 - val_loss: 0.1398 - val_accuracy: 0.9567\n",
            "Epoch 178/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9840\n",
            "Epoch 178: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0471 - accuracy: 0.9833 - val_loss: 0.1375 - val_accuracy: 0.9600\n",
            "Epoch 179/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9772\n",
            "Epoch 179: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0604 - accuracy: 0.9767 - val_loss: 0.1393 - val_accuracy: 0.9600\n",
            "Epoch 180/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9858\n",
            "Epoch 180: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0515 - accuracy: 0.9858 - val_loss: 0.1470 - val_accuracy: 0.9500\n",
            "Epoch 181/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9817\n",
            "Epoch 181: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 0.1356 - val_accuracy: 0.9533\n",
            "Epoch 182/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9823\n",
            "Epoch 182: val_loss did not improve from 0.13442\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.1395 - val_accuracy: 0.9567\n",
            "47/47 [==============================] - 3s 20ms/step - loss: 0.4822 - accuracy: 0.8780\n",
            "Test accuracy, 11 run, after finetuning: 0.878000020980835\n",
            "Epoch 1/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.8915 - accuracy: 0.5583\n",
            "Epoch 1: val_loss improved from inf to 2.13651, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 46s 589ms/step - loss: 2.8915 - accuracy: 0.5583 - val_loss: 2.1365 - val_accuracy: 0.5967\n",
            "Epoch 2/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.8626 - accuracy: 0.6333\n",
            "Epoch 2: val_loss improved from 2.13651 to 1.45308, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 1.8626 - accuracy: 0.6333 - val_loss: 1.4531 - val_accuracy: 0.6500\n",
            "Epoch 3/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.4578 - accuracy: 0.6758\n",
            "Epoch 3: val_loss improved from 1.45308 to 1.11020, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 1.4578 - accuracy: 0.6758 - val_loss: 1.1102 - val_accuracy: 0.7033\n",
            "Epoch 4/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.1765 - accuracy: 0.6993\n",
            "Epoch 4: val_loss improved from 1.11020 to 0.91669, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 1.1643 - accuracy: 0.7025 - val_loss: 0.9167 - val_accuracy: 0.7100\n",
            "Epoch 5/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.0181 - accuracy: 0.7167\n",
            "Epoch 5: val_loss improved from 0.91669 to 0.78483, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 1.0181 - accuracy: 0.7167 - val_loss: 0.7848 - val_accuracy: 0.7300\n",
            "Epoch 6/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.9033 - accuracy: 0.7432\n",
            "Epoch 6: val_loss improved from 0.78483 to 0.69735, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.9039 - accuracy: 0.7433 - val_loss: 0.6973 - val_accuracy: 0.7600\n",
            "Epoch 7/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.8388 - accuracy: 0.7492\n",
            "Epoch 7: val_loss improved from 0.69735 to 0.63965, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.8388 - accuracy: 0.7492 - val_loss: 0.6396 - val_accuracy: 0.7867\n",
            "Epoch 8/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7694 - accuracy: 0.7568\n",
            "Epoch 8: val_loss improved from 0.63965 to 0.59332, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.7676 - accuracy: 0.7567 - val_loss: 0.5933 - val_accuracy: 0.7967\n",
            "Epoch 9/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7574 - accuracy: 0.7627\n",
            "Epoch 9: val_loss improved from 0.59332 to 0.56115, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.7510 - accuracy: 0.7633 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
            "Epoch 10/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7316 - accuracy: 0.7669\n",
            "Epoch 10: val_loss improved from 0.56115 to 0.53425, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.7303 - accuracy: 0.7667 - val_loss: 0.5343 - val_accuracy: 0.8033\n",
            "Epoch 11/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6647 - accuracy: 0.7817\n",
            "Epoch 11: val_loss improved from 0.53425 to 0.50264, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.6647 - accuracy: 0.7817 - val_loss: 0.5026 - val_accuracy: 0.8233\n",
            "Epoch 12/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.6627 - accuracy: 0.7846\n",
            "Epoch 12: val_loss improved from 0.50264 to 0.48377, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.6648 - accuracy: 0.7850 - val_loss: 0.4838 - val_accuracy: 0.8300\n",
            "Epoch 13/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.7917\n",
            "Epoch 13: val_loss improved from 0.48377 to 0.46568, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.6151 - accuracy: 0.7917 - val_loss: 0.4657 - val_accuracy: 0.8333\n",
            "Epoch 14/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.7939\n",
            "Epoch 14: val_loss improved from 0.46568 to 0.44597, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.6028 - accuracy: 0.7950 - val_loss: 0.4460 - val_accuracy: 0.8500\n",
            "Epoch 15/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5651 - accuracy: 0.8015\n",
            "Epoch 15: val_loss improved from 0.44597 to 0.43070, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 134ms/step - loss: 0.5643 - accuracy: 0.8008 - val_loss: 0.4307 - val_accuracy: 0.8567\n",
            "Epoch 16/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5920 - accuracy: 0.7981\n",
            "Epoch 16: val_loss improved from 0.43070 to 0.41930, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.5885 - accuracy: 0.8000 - val_loss: 0.4193 - val_accuracy: 0.8633\n",
            "Epoch 17/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.8208\n",
            "Epoch 17: val_loss improved from 0.41930 to 0.40608, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.5438 - accuracy: 0.8208 - val_loss: 0.4061 - val_accuracy: 0.8700\n",
            "Epoch 18/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.8300\n",
            "Epoch 18: val_loss improved from 0.40608 to 0.39238, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.5070 - accuracy: 0.8300 - val_loss: 0.3924 - val_accuracy: 0.8767\n",
            "Epoch 19/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.8269\n",
            "Epoch 19: val_loss improved from 0.39238 to 0.38029, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.5071 - accuracy: 0.8250 - val_loss: 0.3803 - val_accuracy: 0.8900\n",
            "Epoch 20/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5112 - accuracy: 0.8345\n",
            "Epoch 20: val_loss improved from 0.38029 to 0.36991, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.5060 - accuracy: 0.8367 - val_loss: 0.3699 - val_accuracy: 0.8900\n",
            "Epoch 21/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.8311\n",
            "Epoch 21: val_loss improved from 0.36991 to 0.36344, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.4811 - accuracy: 0.8308 - val_loss: 0.3634 - val_accuracy: 0.8833\n",
            "Epoch 22/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4597 - accuracy: 0.8370\n",
            "Epoch 22: val_loss improved from 0.36344 to 0.35322, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.4679 - accuracy: 0.8350 - val_loss: 0.3532 - val_accuracy: 0.8933\n",
            "Epoch 23/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4773 - accuracy: 0.8421\n",
            "Epoch 23: val_loss improved from 0.35322 to 0.34203, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.4736 - accuracy: 0.8433 - val_loss: 0.3420 - val_accuracy: 0.8933\n",
            "Epoch 24/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.8450\n",
            "Epoch 24: val_loss improved from 0.34203 to 0.33483, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.4591 - accuracy: 0.8450 - val_loss: 0.3348 - val_accuracy: 0.8900\n",
            "Epoch 25/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4523 - accuracy: 0.8438\n",
            "Epoch 25: val_loss improved from 0.33483 to 0.32678, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.4489 - accuracy: 0.8450 - val_loss: 0.3268 - val_accuracy: 0.8933\n",
            "Epoch 26/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8649\n",
            "Epoch 26: val_loss improved from 0.32678 to 0.32213, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.4121 - accuracy: 0.8650 - val_loss: 0.3221 - val_accuracy: 0.8967\n",
            "Epoch 27/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3769 - accuracy: 0.8606\n",
            "Epoch 27: val_loss improved from 0.32213 to 0.31402, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.3776 - accuracy: 0.8608 - val_loss: 0.3140 - val_accuracy: 0.9100\n",
            "Epoch 28/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.8575\n",
            "Epoch 28: val_loss improved from 0.31402 to 0.30661, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.3948 - accuracy: 0.8575 - val_loss: 0.3066 - val_accuracy: 0.9033\n",
            "Epoch 29/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3842 - accuracy: 0.8733\n",
            "Epoch 29: val_loss improved from 0.30661 to 0.29748, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.3849 - accuracy: 0.8725 - val_loss: 0.2975 - val_accuracy: 0.9133\n",
            "Epoch 30/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.8742\n",
            "Epoch 30: val_loss improved from 0.29748 to 0.29398, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.3673 - accuracy: 0.8742 - val_loss: 0.2940 - val_accuracy: 0.9100\n",
            "Epoch 31/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3806 - accuracy: 0.8742\n",
            "Epoch 31: val_loss improved from 0.29398 to 0.28588, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.3806 - accuracy: 0.8742 - val_loss: 0.2859 - val_accuracy: 0.9200\n",
            "Epoch 32/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3703 - accuracy: 0.8775\n",
            "Epoch 32: val_loss improved from 0.28588 to 0.28030, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3690 - accuracy: 0.8783 - val_loss: 0.2803 - val_accuracy: 0.9233\n",
            "Epoch 33/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.8683\n",
            "Epoch 33: val_loss improved from 0.28030 to 0.27820, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.3686 - accuracy: 0.8683 - val_loss: 0.2782 - val_accuracy: 0.9233\n",
            "Epoch 34/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3612 - accuracy: 0.8758\n",
            "Epoch 34: val_loss improved from 0.27820 to 0.27193, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.3610 - accuracy: 0.8750 - val_loss: 0.2719 - val_accuracy: 0.9233\n",
            "Epoch 35/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3431 - accuracy: 0.8877\n",
            "Epoch 35: val_loss improved from 0.27193 to 0.26615, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.3444 - accuracy: 0.8858 - val_loss: 0.2662 - val_accuracy: 0.9267\n",
            "Epoch 36/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8817\n",
            "Epoch 36: val_loss improved from 0.26615 to 0.25940, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.3311 - accuracy: 0.8817 - val_loss: 0.2594 - val_accuracy: 0.9333\n",
            "Epoch 37/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8825\n",
            "Epoch 37: val_loss improved from 0.25940 to 0.25644, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.3109 - accuracy: 0.8825 - val_loss: 0.2564 - val_accuracy: 0.9333\n",
            "Epoch 38/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3121 - accuracy: 0.9010\n",
            "Epoch 38: val_loss improved from 0.25644 to 0.25079, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.3121 - accuracy: 0.9000 - val_loss: 0.2508 - val_accuracy: 0.9367\n",
            "Epoch 39/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.9033\n",
            "Epoch 39: val_loss improved from 0.25079 to 0.24721, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.3115 - accuracy: 0.9033 - val_loss: 0.2472 - val_accuracy: 0.9367\n",
            "Epoch 40/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3298 - accuracy: 0.8775\n",
            "Epoch 40: val_loss improved from 0.24721 to 0.24389, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.3298 - accuracy: 0.8775 - val_loss: 0.2439 - val_accuracy: 0.9367\n",
            "Epoch 41/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.8867\n",
            "Epoch 41: val_loss improved from 0.24389 to 0.23937, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3197 - accuracy: 0.8867 - val_loss: 0.2394 - val_accuracy: 0.9367\n",
            "Epoch 42/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.9037\n",
            "Epoch 42: val_loss improved from 0.23937 to 0.23581, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.2732 - accuracy: 0.9050 - val_loss: 0.2358 - val_accuracy: 0.9400\n",
            "Epoch 43/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2908 - accuracy: 0.8986\n",
            "Epoch 43: val_loss improved from 0.23581 to 0.23191, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.2896 - accuracy: 0.8992 - val_loss: 0.2319 - val_accuracy: 0.9433\n",
            "Epoch 44/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.8927\n",
            "Epoch 44: val_loss improved from 0.23191 to 0.23116, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.2958 - accuracy: 0.8925 - val_loss: 0.2312 - val_accuracy: 0.9433\n",
            "Epoch 45/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2470 - accuracy: 0.9206\n",
            "Epoch 45: val_loss improved from 0.23116 to 0.22803, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2458 - accuracy: 0.9208 - val_loss: 0.2280 - val_accuracy: 0.9433\n",
            "Epoch 46/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2753 - accuracy: 0.9071\n",
            "Epoch 46: val_loss improved from 0.22803 to 0.22267, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.2730 - accuracy: 0.9083 - val_loss: 0.2227 - val_accuracy: 0.9467\n",
            "Epoch 47/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2941 - accuracy: 0.8967\n",
            "Epoch 47: val_loss improved from 0.22267 to 0.22135, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.2908 - accuracy: 0.8983 - val_loss: 0.2213 - val_accuracy: 0.9467\n",
            "Epoch 48/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2844 - accuracy: 0.9037\n",
            "Epoch 48: val_loss improved from 0.22135 to 0.21890, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.2835 - accuracy: 0.9033 - val_loss: 0.2189 - val_accuracy: 0.9500\n",
            "Epoch 49/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.9200\n",
            "Epoch 49: val_loss improved from 0.21890 to 0.21558, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.2631 - accuracy: 0.9200 - val_loss: 0.2156 - val_accuracy: 0.9500\n",
            "Epoch 50/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.9139\n",
            "Epoch 50: val_loss improved from 0.21558 to 0.21286, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.2616 - accuracy: 0.9125 - val_loss: 0.2129 - val_accuracy: 0.9500\n",
            "Epoch 51/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2503 - accuracy: 0.9193\n",
            "Epoch 51: val_loss improved from 0.21286 to 0.20859, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2518 - accuracy: 0.9192 - val_loss: 0.2086 - val_accuracy: 0.9467\n",
            "Epoch 52/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2515 - accuracy: 0.9122\n",
            "Epoch 52: val_loss improved from 0.20859 to 0.20723, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.2522 - accuracy: 0.9117 - val_loss: 0.2072 - val_accuracy: 0.9500\n",
            "Epoch 53/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9155\n",
            "Epoch 53: val_loss improved from 0.20723 to 0.20648, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.2281 - accuracy: 0.9158 - val_loss: 0.2065 - val_accuracy: 0.9500\n",
            "Epoch 54/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9117\n",
            "Epoch 54: val_loss improved from 0.20648 to 0.20299, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2317 - accuracy: 0.9117 - val_loss: 0.2030 - val_accuracy: 0.9433\n",
            "Epoch 55/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2422 - accuracy: 0.9130\n",
            "Epoch 55: val_loss improved from 0.20299 to 0.20083, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.2407 - accuracy: 0.9142 - val_loss: 0.2008 - val_accuracy: 0.9500\n",
            "Epoch 56/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2317 - accuracy: 0.9231\n",
            "Epoch 56: val_loss improved from 0.20083 to 0.19750, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.2327 - accuracy: 0.9225 - val_loss: 0.1975 - val_accuracy: 0.9467\n",
            "Epoch 57/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2103 - accuracy: 0.9257\n",
            "Epoch 57: val_loss improved from 0.19750 to 0.19461, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2118 - accuracy: 0.9250 - val_loss: 0.1946 - val_accuracy: 0.9467\n",
            "Epoch 58/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9257\n",
            "Epoch 58: val_loss improved from 0.19461 to 0.19283, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.2239 - accuracy: 0.9233 - val_loss: 0.1928 - val_accuracy: 0.9467\n",
            "Epoch 59/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.9375\n",
            "Epoch 59: val_loss improved from 0.19283 to 0.19242, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 147ms/step - loss: 0.2126 - accuracy: 0.9367 - val_loss: 0.1924 - val_accuracy: 0.9467\n",
            "Epoch 60/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2074 - accuracy: 0.9242\n",
            "Epoch 60: val_loss improved from 0.19242 to 0.19080, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2074 - accuracy: 0.9242 - val_loss: 0.1908 - val_accuracy: 0.9500\n",
            "Epoch 61/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2181 - accuracy: 0.9193\n",
            "Epoch 61: val_loss improved from 0.19080 to 0.18782, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.2183 - accuracy: 0.9200 - val_loss: 0.1878 - val_accuracy: 0.9533\n",
            "Epoch 62/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.2169 - accuracy: 0.9280\n",
            "Epoch 62: val_loss improved from 0.18782 to 0.18566, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.2176 - accuracy: 0.9275 - val_loss: 0.1857 - val_accuracy: 0.9567\n",
            "Epoch 63/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9208\n",
            "Epoch 63: val_loss did not improve from 0.18566\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.2103 - accuracy: 0.9208 - val_loss: 0.1859 - val_accuracy: 0.9533\n",
            "Epoch 64/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.9200\n",
            "Epoch 64: val_loss improved from 0.18566 to 0.18428, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2329 - accuracy: 0.9200 - val_loss: 0.1843 - val_accuracy: 0.9533\n",
            "Epoch 65/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2009 - accuracy: 0.9307\n",
            "Epoch 65: val_loss improved from 0.18428 to 0.18153, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.2009 - accuracy: 0.9308 - val_loss: 0.1815 - val_accuracy: 0.9533\n",
            "Epoch 66/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9258\n",
            "Epoch 66: val_loss improved from 0.18153 to 0.18017, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.1977 - accuracy: 0.9258 - val_loss: 0.1802 - val_accuracy: 0.9533\n",
            "Epoch 67/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9231\n",
            "Epoch 67: val_loss improved from 0.18017 to 0.17785, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.2169 - accuracy: 0.9242 - val_loss: 0.1779 - val_accuracy: 0.9533\n",
            "Epoch 68/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9300\n",
            "Epoch 68: val_loss improved from 0.17785 to 0.17505, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.1886 - accuracy: 0.9300 - val_loss: 0.1751 - val_accuracy: 0.9533\n",
            "Epoch 69/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.9375\n",
            "Epoch 69: val_loss improved from 0.17505 to 0.17248, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1931 - accuracy: 0.9375 - val_loss: 0.1725 - val_accuracy: 0.9533\n",
            "Epoch 70/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1851 - accuracy: 0.9358\n",
            "Epoch 70: val_loss improved from 0.17248 to 0.17245, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1844 - accuracy: 0.9358 - val_loss: 0.1724 - val_accuracy: 0.9567\n",
            "Epoch 71/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1844 - accuracy: 0.9299\n",
            "Epoch 71: val_loss improved from 0.17245 to 0.17099, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1832 - accuracy: 0.9308 - val_loss: 0.1710 - val_accuracy: 0.9567\n",
            "Epoch 72/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9476\n",
            "Epoch 72: val_loss improved from 0.17099 to 0.16966, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.1631 - accuracy: 0.9467 - val_loss: 0.1697 - val_accuracy: 0.9567\n",
            "Epoch 73/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9425\n",
            "Epoch 73: val_loss improved from 0.16966 to 0.16748, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.1663 - accuracy: 0.9425 - val_loss: 0.1675 - val_accuracy: 0.9533\n",
            "Epoch 74/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9417\n",
            "Epoch 74: val_loss improved from 0.16748 to 0.16595, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1753 - accuracy: 0.9417 - val_loss: 0.1660 - val_accuracy: 0.9533\n",
            "Epoch 75/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1795 - accuracy: 0.9350\n",
            "Epoch 75: val_loss improved from 0.16595 to 0.16501, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.1806 - accuracy: 0.9342 - val_loss: 0.1650 - val_accuracy: 0.9567\n",
            "Epoch 76/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.9508\n",
            "Epoch 76: val_loss improved from 0.16501 to 0.16347, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.1564 - accuracy: 0.9508 - val_loss: 0.1635 - val_accuracy: 0.9533\n",
            "Epoch 77/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1552 - accuracy: 0.9450\n",
            "Epoch 77: val_loss did not improve from 0.16347\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1552 - accuracy: 0.9450 - val_loss: 0.1646 - val_accuracy: 0.9533\n",
            "Epoch 78/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1657 - accuracy: 0.9383\n",
            "Epoch 78: val_loss improved from 0.16347 to 0.16256, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1645 - accuracy: 0.9392 - val_loss: 0.1626 - val_accuracy: 0.9533\n",
            "Epoch 79/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9467\n",
            "Epoch 79: val_loss did not improve from 0.16256\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.1572 - accuracy: 0.9467 - val_loss: 0.1626 - val_accuracy: 0.9600\n",
            "Epoch 80/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1586 - accuracy: 0.9451\n",
            "Epoch 80: val_loss improved from 0.16256 to 0.16237, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 121ms/step - loss: 0.1570 - accuracy: 0.9458 - val_loss: 0.1624 - val_accuracy: 0.9600\n",
            "Epoch 81/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9542\n",
            "Epoch 81: val_loss did not improve from 0.16237\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1377 - accuracy: 0.9542 - val_loss: 0.1630 - val_accuracy: 0.9567\n",
            "Epoch 82/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 0.9485\n",
            "Epoch 82: val_loss improved from 0.16237 to 0.15985, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1465 - accuracy: 0.9492 - val_loss: 0.1598 - val_accuracy: 0.9600\n",
            "Epoch 83/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9500\n",
            "Epoch 83: val_loss improved from 0.15985 to 0.15834, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.1598 - accuracy: 0.9500 - val_loss: 0.1583 - val_accuracy: 0.9600\n",
            "Epoch 84/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9525\n",
            "Epoch 84: val_loss improved from 0.15834 to 0.15742, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.1571 - accuracy: 0.9525 - val_loss: 0.1574 - val_accuracy: 0.9600\n",
            "Epoch 85/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1375 - accuracy: 0.9527\n",
            "Epoch 85: val_loss improved from 0.15742 to 0.15452, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1381 - accuracy: 0.9525 - val_loss: 0.1545 - val_accuracy: 0.9633\n",
            "Epoch 86/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1418 - accuracy: 0.9493\n",
            "Epoch 86: val_loss did not improve from 0.15452\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1412 - accuracy: 0.9492 - val_loss: 0.1563 - val_accuracy: 0.9633\n",
            "Epoch 87/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9578\n",
            "Epoch 87: val_loss improved from 0.15452 to 0.15328, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.1396 - accuracy: 0.9575 - val_loss: 0.1533 - val_accuracy: 0.9600\n",
            "Epoch 88/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1231 - accuracy: 0.9609\n",
            "Epoch 88: val_loss did not improve from 0.15328\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1234 - accuracy: 0.9600 - val_loss: 0.1537 - val_accuracy: 0.9633\n",
            "Epoch 89/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9500\n",
            "Epoch 89: val_loss did not improve from 0.15328\n",
            "38/38 [==============================] - 3s 72ms/step - loss: 0.1352 - accuracy: 0.9500 - val_loss: 0.1535 - val_accuracy: 0.9600\n",
            "Epoch 90/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1302 - accuracy: 0.9552\n",
            "Epoch 90: val_loss did not improve from 0.15328\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1299 - accuracy: 0.9550 - val_loss: 0.1534 - val_accuracy: 0.9600\n",
            "Epoch 91/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9625\n",
            "Epoch 91: val_loss improved from 0.15328 to 0.15219, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1231 - accuracy: 0.9625 - val_loss: 0.1522 - val_accuracy: 0.9567\n",
            "Epoch 92/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9544\n",
            "Epoch 92: val_loss improved from 0.15219 to 0.15122, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1411 - accuracy: 0.9542 - val_loss: 0.1512 - val_accuracy: 0.9567\n",
            "Epoch 93/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1313 - accuracy: 0.9561\n",
            "Epoch 93: val_loss improved from 0.15122 to 0.15088, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1336 - accuracy: 0.9542 - val_loss: 0.1509 - val_accuracy: 0.9600\n",
            "Epoch 94/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9575\n",
            "Epoch 94: val_loss improved from 0.15088 to 0.14998, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1338 - accuracy: 0.9575 - val_loss: 0.1500 - val_accuracy: 0.9567\n",
            "Epoch 95/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9637\n",
            "Epoch 95: val_loss improved from 0.14998 to 0.14817, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1188 - accuracy: 0.9642 - val_loss: 0.1482 - val_accuracy: 0.9600\n",
            "Epoch 96/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1172 - accuracy: 0.9586\n",
            "Epoch 96: val_loss did not improve from 0.14817\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1165 - accuracy: 0.9592 - val_loss: 0.1487 - val_accuracy: 0.9633\n",
            "Epoch 97/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.9620\n",
            "Epoch 97: val_loss improved from 0.14817 to 0.14807, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1138 - accuracy: 0.9617 - val_loss: 0.1481 - val_accuracy: 0.9600\n",
            "Epoch 98/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9567\n",
            "Epoch 98: val_loss improved from 0.14807 to 0.14481, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.1277 - accuracy: 0.9567 - val_loss: 0.1448 - val_accuracy: 0.9600\n",
            "Epoch 99/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 0.9569\n",
            "Epoch 99: val_loss improved from 0.14481 to 0.14235, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.1239 - accuracy: 0.9575 - val_loss: 0.1424 - val_accuracy: 0.9600\n",
            "Epoch 100/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9625\n",
            "Epoch 100: val_loss improved from 0.14235 to 0.14221, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1071 - accuracy: 0.9625 - val_loss: 0.1422 - val_accuracy: 0.9633\n",
            "Epoch 101/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9620\n",
            "Epoch 101: val_loss did not improve from 0.14221\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1214 - accuracy: 0.9617 - val_loss: 0.1437 - val_accuracy: 0.9633\n",
            "Epoch 102/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9608\n",
            "Epoch 102: val_loss improved from 0.14221 to 0.14176, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.1057 - accuracy: 0.9608 - val_loss: 0.1418 - val_accuracy: 0.9600\n",
            "Epoch 103/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9583\n",
            "Epoch 103: val_loss improved from 0.14176 to 0.14169, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.1140 - accuracy: 0.9583 - val_loss: 0.1417 - val_accuracy: 0.9633\n",
            "Epoch 104/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9595\n",
            "Epoch 104: val_loss improved from 0.14169 to 0.14041, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1316 - accuracy: 0.9592 - val_loss: 0.1404 - val_accuracy: 0.9600\n",
            "Epoch 105/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9650\n",
            "Epoch 105: val_loss improved from 0.14041 to 0.13988, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0980 - accuracy: 0.9650 - val_loss: 0.1399 - val_accuracy: 0.9600\n",
            "Epoch 106/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.9595\n",
            "Epoch 106: val_loss improved from 0.13988 to 0.13938, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.1192 - accuracy: 0.9600 - val_loss: 0.1394 - val_accuracy: 0.9633\n",
            "Epoch 107/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9611\n",
            "Epoch 107: val_loss did not improve from 0.13938\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1154 - accuracy: 0.9608 - val_loss: 0.1402 - val_accuracy: 0.9633\n",
            "Epoch 108/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9688\n",
            "Epoch 108: val_loss did not improve from 0.13938\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0954 - accuracy: 0.9683 - val_loss: 0.1412 - val_accuracy: 0.9633\n",
            "Epoch 109/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9637\n",
            "Epoch 109: val_loss did not improve from 0.13938\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1026 - accuracy: 0.9642 - val_loss: 0.1409 - val_accuracy: 0.9633\n",
            "Epoch 110/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1059 - accuracy: 0.9642\n",
            "Epoch 110: val_loss did not improve from 0.13938\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1059 - accuracy: 0.9642 - val_loss: 0.1399 - val_accuracy: 0.9633\n",
            "Epoch 111/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.9662\n",
            "Epoch 111: val_loss improved from 0.13938 to 0.13657, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1038 - accuracy: 0.9667 - val_loss: 0.1366 - val_accuracy: 0.9600\n",
            "Epoch 112/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1060 - accuracy: 0.9609\n",
            "Epoch 112: val_loss improved from 0.13657 to 0.13433, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1069 - accuracy: 0.9600 - val_loss: 0.1343 - val_accuracy: 0.9600\n",
            "Epoch 113/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9625\n",
            "Epoch 113: val_loss did not improve from 0.13433\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0986 - accuracy: 0.9625 - val_loss: 0.1347 - val_accuracy: 0.9600\n",
            "Epoch 114/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9600\n",
            "Epoch 114: val_loss did not improve from 0.13433\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1100 - accuracy: 0.9600 - val_loss: 0.1350 - val_accuracy: 0.9600\n",
            "Epoch 115/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 0.9797\n",
            "Epoch 115: val_loss did not improve from 0.13433\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0803 - accuracy: 0.9792 - val_loss: 0.1348 - val_accuracy: 0.9633\n",
            "Epoch 116/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9679\n",
            "Epoch 116: val_loss improved from 0.13433 to 0.13342, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0917 - accuracy: 0.9683 - val_loss: 0.1334 - val_accuracy: 0.9633\n",
            "Epoch 117/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9667\n",
            "Epoch 117: val_loss did not improve from 0.13342\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0966 - accuracy: 0.9667 - val_loss: 0.1339 - val_accuracy: 0.9600\n",
            "Epoch 118/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9700\n",
            "Epoch 118: val_loss did not improve from 0.13342\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0832 - accuracy: 0.9700 - val_loss: 0.1341 - val_accuracy: 0.9633\n",
            "Epoch 119/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0921 - accuracy: 0.9688\n",
            "Epoch 119: val_loss improved from 0.13342 to 0.13220, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0912 - accuracy: 0.9692 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
            "Epoch 120/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9704\n",
            "Epoch 120: val_loss improved from 0.13220 to 0.13140, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 7s 196ms/step - loss: 0.0873 - accuracy: 0.9708 - val_loss: 0.1314 - val_accuracy: 0.9633\n",
            "Epoch 121/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9654\n",
            "Epoch 121: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0987 - accuracy: 0.9658 - val_loss: 0.1330 - val_accuracy: 0.9633\n",
            "Epoch 122/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9717\n",
            "Epoch 122: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.0818 - accuracy: 0.9717 - val_loss: 0.1329 - val_accuracy: 0.9633\n",
            "Epoch 123/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9608\n",
            "Epoch 123: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.0985 - accuracy: 0.9608 - val_loss: 0.1355 - val_accuracy: 0.9633\n",
            "Epoch 124/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9750\n",
            "Epoch 124: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0757 - accuracy: 0.9750 - val_loss: 0.1348 - val_accuracy: 0.9633\n",
            "Epoch 125/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.9738\n",
            "Epoch 125: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0968 - accuracy: 0.9742 - val_loss: 0.1331 - val_accuracy: 0.9633\n",
            "Epoch 126/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.9704\n",
            "Epoch 126: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0812 - accuracy: 0.9708 - val_loss: 0.1329 - val_accuracy: 0.9633\n",
            "Epoch 127/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0952 - accuracy: 0.9662\n",
            "Epoch 127: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0941 - accuracy: 0.9667 - val_loss: 0.1337 - val_accuracy: 0.9633\n",
            "Epoch 128/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9713\n",
            "Epoch 128: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0851 - accuracy: 0.9717 - val_loss: 0.1352 - val_accuracy: 0.9633\n",
            "Epoch 129/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9783\n",
            "Epoch 129: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0701 - accuracy: 0.9783 - val_loss: 0.1350 - val_accuracy: 0.9633\n",
            "Epoch 130/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9688\n",
            "Epoch 130: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0802 - accuracy: 0.9692 - val_loss: 0.1337 - val_accuracy: 0.9633\n",
            "Epoch 131/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9758\n",
            "Epoch 131: val_loss did not improve from 0.13140\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0835 - accuracy: 0.9758 - val_loss: 0.1318 - val_accuracy: 0.9633\n",
            "Epoch 132/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0785 - accuracy: 0.9757\n",
            "Epoch 132: val_loss improved from 0.13140 to 0.13093, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 154ms/step - loss: 0.0769 - accuracy: 0.9767 - val_loss: 0.1309 - val_accuracy: 0.9633\n",
            "Epoch 133/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9738\n",
            "Epoch 133: val_loss improved from 0.13093 to 0.12970, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0828 - accuracy: 0.9733 - val_loss: 0.1297 - val_accuracy: 0.9633\n",
            "Epoch 134/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9758\n",
            "Epoch 134: val_loss improved from 0.12970 to 0.12930, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 121ms/step - loss: 0.0753 - accuracy: 0.9758 - val_loss: 0.1293 - val_accuracy: 0.9633\n",
            "Epoch 135/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0877 - accuracy: 0.9714\n",
            "Epoch 135: val_loss did not improve from 0.12930\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0868 - accuracy: 0.9717 - val_loss: 0.1299 - val_accuracy: 0.9633\n",
            "Epoch 136/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9738\n",
            "Epoch 136: val_loss improved from 0.12930 to 0.12877, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0740 - accuracy: 0.9742 - val_loss: 0.1288 - val_accuracy: 0.9633\n",
            "Epoch 137/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.9797\n",
            "Epoch 137: val_loss improved from 0.12877 to 0.12799, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0664 - accuracy: 0.9800 - val_loss: 0.1280 - val_accuracy: 0.9633\n",
            "Epoch 138/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9767\n",
            "Epoch 138: val_loss improved from 0.12799 to 0.12771, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0826 - accuracy: 0.9767 - val_loss: 0.1277 - val_accuracy: 0.9600\n",
            "Epoch 139/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0792 - accuracy: 0.9755\n",
            "Epoch 139: val_loss improved from 0.12771 to 0.12640, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0808 - accuracy: 0.9750 - val_loss: 0.1264 - val_accuracy: 0.9633\n",
            "Epoch 140/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 0.9662\n",
            "Epoch 140: val_loss did not improve from 0.12640\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0964 - accuracy: 0.9658 - val_loss: 0.1312 - val_accuracy: 0.9633\n",
            "Epoch 141/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9721\n",
            "Epoch 141: val_loss improved from 0.12640 to 0.12587, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0775 - accuracy: 0.9717 - val_loss: 0.1259 - val_accuracy: 0.9633\n",
            "Epoch 142/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0654 - accuracy: 0.9797\n",
            "Epoch 142: val_loss did not improve from 0.12587\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0646 - accuracy: 0.9800 - val_loss: 0.1265 - val_accuracy: 0.9600\n",
            "Epoch 143/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.9733\n",
            "Epoch 143: val_loss did not improve from 0.12587\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0732 - accuracy: 0.9733 - val_loss: 0.1290 - val_accuracy: 0.9633\n",
            "Epoch 144/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9780\n",
            "Epoch 144: val_loss did not improve from 0.12587\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0612 - accuracy: 0.9783 - val_loss: 0.1268 - val_accuracy: 0.9633\n",
            "Epoch 145/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9700\n",
            "Epoch 145: val_loss did not improve from 0.12587\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0787 - accuracy: 0.9700 - val_loss: 0.1278 - val_accuracy: 0.9633\n",
            "Epoch 146/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9783\n",
            "Epoch 146: val_loss improved from 0.12587 to 0.12460, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 134ms/step - loss: 0.0603 - accuracy: 0.9783 - val_loss: 0.1246 - val_accuracy: 0.9600\n",
            "Epoch 147/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9808\n",
            "Epoch 147: val_loss did not improve from 0.12460\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0570 - accuracy: 0.9808 - val_loss: 0.1258 - val_accuracy: 0.9600\n",
            "Epoch 148/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9725\n",
            "Epoch 148: val_loss did not improve from 0.12460\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0762 - accuracy: 0.9725 - val_loss: 0.1281 - val_accuracy: 0.9567\n",
            "Epoch 149/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9750\n",
            "Epoch 149: val_loss did not improve from 0.12460\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0692 - accuracy: 0.9750 - val_loss: 0.1267 - val_accuracy: 0.9633\n",
            "Epoch 150/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0544 - accuracy: 0.9772\n",
            "Epoch 150: val_loss improved from 0.12460 to 0.12453, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.0539 - accuracy: 0.9775 - val_loss: 0.1245 - val_accuracy: 0.9533\n",
            "Epoch 151/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9831\n",
            "Epoch 151: val_loss improved from 0.12453 to 0.12452, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0519 - accuracy: 0.9825 - val_loss: 0.1245 - val_accuracy: 0.9533\n",
            "Epoch 152/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9842\n",
            "Epoch 152: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.0595 - accuracy: 0.9842 - val_loss: 0.1253 - val_accuracy: 0.9533\n",
            "Epoch 153/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9775\n",
            "Epoch 153: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0645 - accuracy: 0.9775 - val_loss: 0.1259 - val_accuracy: 0.9567\n",
            "Epoch 154/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9825\n",
            "Epoch 154: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0584 - accuracy: 0.9825 - val_loss: 0.1258 - val_accuracy: 0.9600\n",
            "Epoch 155/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 0.9823\n",
            "Epoch 155: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0593 - accuracy: 0.9825 - val_loss: 0.1257 - val_accuracy: 0.9567\n",
            "Epoch 156/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9775\n",
            "Epoch 156: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0614 - accuracy: 0.9775 - val_loss: 0.1260 - val_accuracy: 0.9633\n",
            "Epoch 157/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.9783\n",
            "Epoch 157: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0681 - accuracy: 0.9783 - val_loss: 0.1250 - val_accuracy: 0.9567\n",
            "Epoch 158/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9797\n",
            "Epoch 158: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0611 - accuracy: 0.9792 - val_loss: 0.1248 - val_accuracy: 0.9567\n",
            "Epoch 159/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0574 - accuracy: 0.9789\n",
            "Epoch 159: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0567 - accuracy: 0.9792 - val_loss: 0.1247 - val_accuracy: 0.9567\n",
            "Epoch 160/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9772\n",
            "Epoch 160: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0636 - accuracy: 0.9775 - val_loss: 0.1264 - val_accuracy: 0.9633\n",
            "Epoch 161/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9840\n",
            "Epoch 161: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0506 - accuracy: 0.9842 - val_loss: 0.1249 - val_accuracy: 0.9533\n",
            "Epoch 162/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9767\n",
            "Epoch 162: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0652 - accuracy: 0.9767 - val_loss: 0.1290 - val_accuracy: 0.9533\n",
            "Epoch 163/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9842\n",
            "Epoch 163: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0568 - accuracy: 0.9842 - val_loss: 0.1264 - val_accuracy: 0.9533\n",
            "Epoch 164/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9900\n",
            "Epoch 164: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0445 - accuracy: 0.9900 - val_loss: 0.1271 - val_accuracy: 0.9567\n",
            "Epoch 165/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9775\n",
            "Epoch 165: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0598 - accuracy: 0.9775 - val_loss: 0.1263 - val_accuracy: 0.9567\n",
            "Epoch 166/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9775\n",
            "Epoch 166: val_loss did not improve from 0.12452\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0545 - accuracy: 0.9775 - val_loss: 0.1276 - val_accuracy: 0.9600\n",
            "Epoch 167/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9780\n",
            "Epoch 167: val_loss improved from 0.12452 to 0.12307, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 147ms/step - loss: 0.0529 - accuracy: 0.9775 - val_loss: 0.1231 - val_accuracy: 0.9600\n",
            "Epoch 168/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9833\n",
            "Epoch 168: val_loss did not improve from 0.12307\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0582 - accuracy: 0.9833 - val_loss: 0.1237 - val_accuracy: 0.9567\n",
            "Epoch 169/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9883\n",
            "Epoch 169: val_loss did not improve from 0.12307\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0434 - accuracy: 0.9883 - val_loss: 0.1248 - val_accuracy: 0.9633\n",
            "Epoch 170/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9806\n",
            "Epoch 170: val_loss did not improve from 0.12307\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0561 - accuracy: 0.9792 - val_loss: 0.1249 - val_accuracy: 0.9567\n",
            "Epoch 171/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9856\n",
            "Epoch 171: val_loss did not improve from 0.12307\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.1244 - val_accuracy: 0.9600\n",
            "Epoch 172/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9850\n",
            "Epoch 172: val_loss did not improve from 0.12307\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.0526 - accuracy: 0.9850 - val_loss: 0.1250 - val_accuracy: 0.9600\n",
            "Epoch 173/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9814\n",
            "Epoch 173: val_loss improved from 0.12307 to 0.12283, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 144ms/step - loss: 0.0594 - accuracy: 0.9817 - val_loss: 0.1228 - val_accuracy: 0.9567\n",
            "Epoch 174/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9825\n",
            "Epoch 174: val_loss improved from 0.12283 to 0.11978, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0521 - accuracy: 0.9825 - val_loss: 0.1198 - val_accuracy: 0.9567\n",
            "Epoch 175/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9797\n",
            "Epoch 175: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.1214 - val_accuracy: 0.9600\n",
            "Epoch 176/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9867\n",
            "Epoch 176: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0377 - accuracy: 0.9867 - val_loss: 0.1236 - val_accuracy: 0.9633\n",
            "Epoch 177/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9900\n",
            "Epoch 177: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0388 - accuracy: 0.9900 - val_loss: 0.1205 - val_accuracy: 0.9633\n",
            "Epoch 178/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9772\n",
            "Epoch 178: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0516 - accuracy: 0.9775 - val_loss: 0.1225 - val_accuracy: 0.9667\n",
            "Epoch 179/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9858\n",
            "Epoch 179: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0384 - accuracy: 0.9858 - val_loss: 0.1236 - val_accuracy: 0.9633\n",
            "Epoch 180/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.9865\n",
            "Epoch 180: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.1206 - val_accuracy: 0.9600\n",
            "Epoch 181/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9850\n",
            "Epoch 181: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0417 - accuracy: 0.9850 - val_loss: 0.1218 - val_accuracy: 0.9633\n",
            "Epoch 182/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9789\n",
            "Epoch 182: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0670 - accuracy: 0.9792 - val_loss: 0.1232 - val_accuracy: 0.9533\n",
            "Epoch 183/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9873\n",
            "Epoch 183: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 0.1226 - val_accuracy: 0.9600\n",
            "Epoch 184/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9848\n",
            "Epoch 184: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0429 - accuracy: 0.9850 - val_loss: 0.1220 - val_accuracy: 0.9667\n",
            "Epoch 185/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9873\n",
            "Epoch 185: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 3s 73ms/step - loss: 0.0424 - accuracy: 0.9875 - val_loss: 0.1234 - val_accuracy: 0.9633\n",
            "Epoch 186/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9900\n",
            "Epoch 186: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0380 - accuracy: 0.9900 - val_loss: 0.1237 - val_accuracy: 0.9567\n",
            "Epoch 187/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9892\n",
            "Epoch 187: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 0.1238 - val_accuracy: 0.9633\n",
            "Epoch 188/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9840\n",
            "Epoch 188: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0441 - accuracy: 0.9842 - val_loss: 0.1248 - val_accuracy: 0.9700\n",
            "Epoch 189/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9882\n",
            "Epoch 189: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0399 - accuracy: 0.9883 - val_loss: 0.1262 - val_accuracy: 0.9633\n",
            "Epoch 190/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9823\n",
            "Epoch 190: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0479 - accuracy: 0.9817 - val_loss: 0.1246 - val_accuracy: 0.9633\n",
            "Epoch 191/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9833\n",
            "Epoch 191: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0382 - accuracy: 0.9833 - val_loss: 0.1233 - val_accuracy: 0.9600\n",
            "Epoch 192/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9848\n",
            "Epoch 192: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0423 - accuracy: 0.9850 - val_loss: 0.1272 - val_accuracy: 0.9633\n",
            "Epoch 193/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9848\n",
            "Epoch 193: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0431 - accuracy: 0.9842 - val_loss: 0.1270 - val_accuracy: 0.9600\n",
            "Epoch 194/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9882\n",
            "Epoch 194: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 0.1243 - val_accuracy: 0.9600\n",
            "Epoch 195/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9873\n",
            "Epoch 195: val_loss did not improve from 0.11978\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0378 - accuracy: 0.9867 - val_loss: 0.1207 - val_accuracy: 0.9567\n",
            "Epoch 196/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9882\n",
            "Epoch 196: val_loss improved from 0.11978 to 0.11907, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 143ms/step - loss: 0.0346 - accuracy: 0.9883 - val_loss: 0.1191 - val_accuracy: 0.9633\n",
            "Epoch 197/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9865\n",
            "Epoch 197: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0372 - accuracy: 0.9867 - val_loss: 0.1207 - val_accuracy: 0.9667\n",
            "Epoch 198/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9899\n",
            "Epoch 198: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.1252 - val_accuracy: 0.9633\n",
            "Epoch 199/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9899\n",
            "Epoch 199: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0425 - accuracy: 0.9892 - val_loss: 0.1227 - val_accuracy: 0.9600\n",
            "Epoch 200/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9908\n",
            "Epoch 200: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 0.1250 - val_accuracy: 0.9667\n",
            "Epoch 201/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9908\n",
            "Epoch 201: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.1250 - val_accuracy: 0.9667\n",
            "Epoch 202/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9842\n",
            "Epoch 202: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0422 - accuracy: 0.9842 - val_loss: 0.1209 - val_accuracy: 0.9667\n",
            "Epoch 203/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9856\n",
            "Epoch 203: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0369 - accuracy: 0.9858 - val_loss: 0.1238 - val_accuracy: 0.9600\n",
            "Epoch 204/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9892\n",
            "Epoch 204: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0342 - accuracy: 0.9892 - val_loss: 0.1231 - val_accuracy: 0.9667\n",
            "Epoch 205/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9890\n",
            "Epoch 205: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0388 - accuracy: 0.9892 - val_loss: 0.1230 - val_accuracy: 0.9633\n",
            "Epoch 206/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9890\n",
            "Epoch 206: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0348 - accuracy: 0.9892 - val_loss: 0.1222 - val_accuracy: 0.9667\n",
            "Epoch 207/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9941\n",
            "Epoch 207: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0322 - accuracy: 0.9925 - val_loss: 0.1236 - val_accuracy: 0.9633\n",
            "Epoch 208/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 0.9840\n",
            "Epoch 208: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0477 - accuracy: 0.9833 - val_loss: 0.1223 - val_accuracy: 0.9700\n",
            "Epoch 209/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9892\n",
            "Epoch 209: val_loss did not improve from 0.11907\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0371 - accuracy: 0.9892 - val_loss: 0.1218 - val_accuracy: 0.9700\n",
            "Epoch 210/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9900\n",
            "Epoch 210: val_loss improved from 0.11907 to 0.11825, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 149ms/step - loss: 0.0358 - accuracy: 0.9900 - val_loss: 0.1183 - val_accuracy: 0.9733\n",
            "Epoch 211/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9917\n",
            "Epoch 211: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.1183 - val_accuracy: 0.9700\n",
            "Epoch 212/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0248 - accuracy: 0.9922\n",
            "Epoch 212: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.1206 - val_accuracy: 0.9700\n",
            "Epoch 213/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9875\n",
            "Epoch 213: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0410 - accuracy: 0.9875 - val_loss: 0.1247 - val_accuracy: 0.9633\n",
            "Epoch 214/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9916\n",
            "Epoch 214: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.1204 - val_accuracy: 0.9667\n",
            "Epoch 215/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9925\n",
            "Epoch 215: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 4s 99ms/step - loss: 0.0321 - accuracy: 0.9925 - val_loss: 0.1218 - val_accuracy: 0.9600\n",
            "Epoch 216/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9883\n",
            "Epoch 216: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0328 - accuracy: 0.9883 - val_loss: 0.1206 - val_accuracy: 0.9600\n",
            "Epoch 217/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9907\n",
            "Epoch 217: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 0.1210 - val_accuracy: 0.9600\n",
            "Epoch 218/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9865\n",
            "Epoch 218: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.1186 - val_accuracy: 0.9633\n",
            "Epoch 219/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9890\n",
            "Epoch 219: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.1231 - val_accuracy: 0.9533\n",
            "Epoch 220/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9883\n",
            "Epoch 220: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0375 - accuracy: 0.9883 - val_loss: 0.1196 - val_accuracy: 0.9600\n",
            "Epoch 221/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9907\n",
            "Epoch 221: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.1201 - val_accuracy: 0.9600\n",
            "Epoch 222/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9916\n",
            "Epoch 222: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.1224 - val_accuracy: 0.9633\n",
            "Epoch 223/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9932\n",
            "Epoch 223: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0282 - accuracy: 0.9933 - val_loss: 0.1199 - val_accuracy: 0.9567\n",
            "Epoch 224/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9899\n",
            "Epoch 224: val_loss did not improve from 0.11825\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.1206 - val_accuracy: 0.9533\n",
            "Epoch 225/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9873\n",
            "Epoch 225: val_loss improved from 0.11825 to 0.11803, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.0338 - accuracy: 0.9875 - val_loss: 0.1180 - val_accuracy: 0.9600\n",
            "Epoch 226/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9899\n",
            "Epoch 226: val_loss did not improve from 0.11803\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.1210 - val_accuracy: 0.9600\n",
            "Epoch 227/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9850\n",
            "Epoch 227: val_loss improved from 0.11803 to 0.11802, saving model to /content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.0365 - accuracy: 0.9850 - val_loss: 0.1180 - val_accuracy: 0.9633\n",
            "Epoch 228/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9907\n",
            "Epoch 228: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.1183 - val_accuracy: 0.9633\n",
            "Epoch 229/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9917\n",
            "Epoch 229: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0370 - accuracy: 0.9917 - val_loss: 0.1220 - val_accuracy: 0.9633\n",
            "Epoch 230/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9949\n",
            "Epoch 230: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.1216 - val_accuracy: 0.9600\n",
            "Epoch 231/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9916\n",
            "Epoch 231: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.1235 - val_accuracy: 0.9633\n",
            "Epoch 232/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9932\n",
            "Epoch 232: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.1259 - val_accuracy: 0.9633\n",
            "Epoch 233/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9924\n",
            "Epoch 233: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.1239 - val_accuracy: 0.9567\n",
            "Epoch 234/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9899\n",
            "Epoch 234: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.1255 - val_accuracy: 0.9633\n",
            "Epoch 235/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9907\n",
            "Epoch 235: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 0.1256 - val_accuracy: 0.9633\n",
            "Epoch 236/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9899\n",
            "Epoch 236: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.1251 - val_accuracy: 0.9600\n",
            "Epoch 237/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9883\n",
            "Epoch 237: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 0.1255 - val_accuracy: 0.9600\n",
            "Epoch 238/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9916\n",
            "Epoch 238: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 63ms/step - loss: 0.0346 - accuracy: 0.9917 - val_loss: 0.1267 - val_accuracy: 0.9633\n",
            "Epoch 239/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9890\n",
            "Epoch 239: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0311 - accuracy: 0.9883 - val_loss: 0.1271 - val_accuracy: 0.9667\n",
            "Epoch 240/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9890\n",
            "Epoch 240: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0296 - accuracy: 0.9892 - val_loss: 0.1283 - val_accuracy: 0.9600\n",
            "Epoch 241/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9890\n",
            "Epoch 241: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0306 - accuracy: 0.9883 - val_loss: 0.1250 - val_accuracy: 0.9633\n",
            "Epoch 242/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9933\n",
            "Epoch 242: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 0.1234 - val_accuracy: 0.9667\n",
            "Epoch 243/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9892\n",
            "Epoch 243: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0253 - accuracy: 0.9892 - val_loss: 0.1269 - val_accuracy: 0.9633\n",
            "Epoch 244/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9890\n",
            "Epoch 244: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0282 - accuracy: 0.9892 - val_loss: 0.1235 - val_accuracy: 0.9600\n",
            "Epoch 245/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0222 - accuracy: 0.9939\n",
            "Epoch 245: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 0.1225 - val_accuracy: 0.9567\n",
            "Epoch 246/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9924\n",
            "Epoch 246: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.1233 - val_accuracy: 0.9600\n",
            "Epoch 247/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9925\n",
            "Epoch 247: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.1278 - val_accuracy: 0.9567\n",
            "Epoch 248/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9941\n",
            "Epoch 248: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0249 - accuracy: 0.9942 - val_loss: 0.1217 - val_accuracy: 0.9567\n",
            "Epoch 249/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0125 - accuracy: 0.9974\n",
            "Epoch 249: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.1223 - val_accuracy: 0.9600\n",
            "Epoch 250/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0203 - accuracy: 0.9948\n",
            "Epoch 250: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0198 - accuracy: 0.9950 - val_loss: 0.1202 - val_accuracy: 0.9600\n",
            "Epoch 251/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9908\n",
            "Epoch 251: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0222 - accuracy: 0.9908 - val_loss: 0.1222 - val_accuracy: 0.9633\n",
            "Epoch 252/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9941\n",
            "Epoch 252: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.1261 - val_accuracy: 0.9567\n",
            "Epoch 253/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9941\n",
            "Epoch 253: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 3s 70ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.1249 - val_accuracy: 0.9667\n",
            "Epoch 254/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9949\n",
            "Epoch 254: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.1261 - val_accuracy: 0.9700\n",
            "Epoch 255/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9975\n",
            "Epoch 255: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 0.1216 - val_accuracy: 0.9667\n",
            "Epoch 256/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9908\n",
            "Epoch 256: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 0.1251 - val_accuracy: 0.9667\n",
            "Epoch 257/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9933\n",
            "Epoch 257: val_loss did not improve from 0.11802\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.1250 - val_accuracy: 0.9667\n",
            "47/47 [==============================] - 2s 19ms/step - loss: 0.5503 - accuracy: 0.8833\n",
            "Test accuracy, 12 run, after finetuning: 0.8833333253860474\n",
            "Epoch 1/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.7263 - accuracy: 0.5333\n",
            "Epoch 1: val_loss improved from inf to 2.07864, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 47s 608ms/step - loss: 2.7263 - accuracy: 0.5333 - val_loss: 2.0786 - val_accuracy: 0.5533\n",
            "Epoch 2/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.6234 - accuracy: 0.6267\n",
            "Epoch 2: val_loss improved from 2.07864 to 1.46896, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 1.6340 - accuracy: 0.6250 - val_loss: 1.4690 - val_accuracy: 0.6033\n",
            "Epoch 3/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.2264 - accuracy: 0.6765\n",
            "Epoch 3: val_loss improved from 1.46896 to 1.18171, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 1.2199 - accuracy: 0.6783 - val_loss: 1.1817 - val_accuracy: 0.6500\n",
            "Epoch 4/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.0536 - accuracy: 0.6875\n",
            "Epoch 4: val_loss improved from 1.18171 to 1.01428, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 1.0576 - accuracy: 0.6850 - val_loss: 1.0143 - val_accuracy: 0.6867\n",
            "Epoch 5/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.9103 - accuracy: 0.7171\n",
            "Epoch 5: val_loss improved from 1.01428 to 0.90471, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.9124 - accuracy: 0.7150 - val_loss: 0.9047 - val_accuracy: 0.7033\n",
            "Epoch 6/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.8483 - accuracy: 0.7356\n",
            "Epoch 6: val_loss improved from 0.90471 to 0.83580, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.8458 - accuracy: 0.7358 - val_loss: 0.8358 - val_accuracy: 0.7267\n",
            "Epoch 7/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.8261 - accuracy: 0.7333\n",
            "Epoch 7: val_loss improved from 0.83580 to 0.77986, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.8261 - accuracy: 0.7333 - val_loss: 0.7799 - val_accuracy: 0.7400\n",
            "Epoch 8/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7746 - accuracy: 0.7399\n",
            "Epoch 8: val_loss improved from 0.77986 to 0.74254, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.7711 - accuracy: 0.7408 - val_loss: 0.7425 - val_accuracy: 0.7567\n",
            "Epoch 9/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.7205 - accuracy: 0.7583\n",
            "Epoch 9: val_loss improved from 0.74254 to 0.70780, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.7205 - accuracy: 0.7583 - val_loss: 0.7078 - val_accuracy: 0.7700\n",
            "Epoch 10/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.7658\n",
            "Epoch 10: val_loss improved from 0.70780 to 0.67832, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.7182 - accuracy: 0.7658 - val_loss: 0.6783 - val_accuracy: 0.7767\n",
            "Epoch 11/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.7804\n",
            "Epoch 11: val_loss improved from 0.67832 to 0.65229, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.6361 - accuracy: 0.7800 - val_loss: 0.6523 - val_accuracy: 0.7833\n",
            "Epoch 12/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.6594 - accuracy: 0.7669\n",
            "Epoch 12: val_loss improved from 0.65229 to 0.62140, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.6592 - accuracy: 0.7675 - val_loss: 0.6214 - val_accuracy: 0.7900\n",
            "Epoch 13/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5958 - accuracy: 0.7965\n",
            "Epoch 13: val_loss improved from 0.62140 to 0.60250, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.5942 - accuracy: 0.7967 - val_loss: 0.6025 - val_accuracy: 0.8033\n",
            "Epoch 14/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.8092\n",
            "Epoch 14: val_loss improved from 0.60250 to 0.57828, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.5928 - accuracy: 0.8092 - val_loss: 0.5783 - val_accuracy: 0.8067\n",
            "Epoch 15/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5495 - accuracy: 0.8133\n",
            "Epoch 15: val_loss improved from 0.57828 to 0.56470, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.5532 - accuracy: 0.8117 - val_loss: 0.5647 - val_accuracy: 0.8133\n",
            "Epoch 16/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.8100\n",
            "Epoch 16: val_loss improved from 0.56470 to 0.54714, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.5604 - accuracy: 0.8100 - val_loss: 0.5471 - val_accuracy: 0.8233\n",
            "Epoch 17/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5469 - accuracy: 0.8142\n",
            "Epoch 17: val_loss improved from 0.54714 to 0.52963, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.5523 - accuracy: 0.8133 - val_loss: 0.5296 - val_accuracy: 0.8333\n",
            "Epoch 18/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.8159\n",
            "Epoch 18: val_loss improved from 0.52963 to 0.51259, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.5220 - accuracy: 0.8158 - val_loss: 0.5126 - val_accuracy: 0.8333\n",
            "Epoch 19/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4921 - accuracy: 0.8370\n",
            "Epoch 19: val_loss improved from 0.51259 to 0.50124, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.4886 - accuracy: 0.8383 - val_loss: 0.5012 - val_accuracy: 0.8400\n",
            "Epoch 20/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8392\n",
            "Epoch 20: val_loss improved from 0.50124 to 0.49358, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 0.4609 - accuracy: 0.8392 - val_loss: 0.4936 - val_accuracy: 0.8467\n",
            "Epoch 21/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.8383\n",
            "Epoch 21: val_loss improved from 0.49358 to 0.47744, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.4472 - accuracy: 0.8383 - val_loss: 0.4774 - val_accuracy: 0.8467\n",
            "Epoch 22/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.8467\n",
            "Epoch 22: val_loss improved from 0.47744 to 0.46193, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.4575 - accuracy: 0.8467 - val_loss: 0.4619 - val_accuracy: 0.8500\n",
            "Epoch 23/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8442\n",
            "Epoch 23: val_loss improved from 0.46193 to 0.45585, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.4415 - accuracy: 0.8442 - val_loss: 0.4558 - val_accuracy: 0.8467\n",
            "Epoch 24/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4059 - accuracy: 0.8623\n",
            "Epoch 24: val_loss improved from 0.45585 to 0.43887, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.4052 - accuracy: 0.8617 - val_loss: 0.4389 - val_accuracy: 0.8533\n",
            "Epoch 25/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8633\n",
            "Epoch 25: val_loss improved from 0.43887 to 0.43277, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.4166 - accuracy: 0.8633 - val_loss: 0.4328 - val_accuracy: 0.8567\n",
            "Epoch 26/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.8675\n",
            "Epoch 26: val_loss improved from 0.43277 to 0.42501, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3957 - accuracy: 0.8675 - val_loss: 0.4250 - val_accuracy: 0.8567\n",
            "Epoch 27/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.8625\n",
            "Epoch 27: val_loss improved from 0.42501 to 0.41855, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.4028 - accuracy: 0.8625 - val_loss: 0.4186 - val_accuracy: 0.8600\n",
            "Epoch 28/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8692\n",
            "Epoch 28: val_loss improved from 0.41855 to 0.40360, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.3835 - accuracy: 0.8692 - val_loss: 0.4036 - val_accuracy: 0.8600\n",
            "Epoch 29/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8625\n",
            "Epoch 29: val_loss improved from 0.40360 to 0.39550, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 134ms/step - loss: 0.3992 - accuracy: 0.8625 - val_loss: 0.3955 - val_accuracy: 0.8600\n",
            "Epoch 30/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8675\n",
            "Epoch 30: val_loss improved from 0.39550 to 0.39130, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.3732 - accuracy: 0.8675 - val_loss: 0.3913 - val_accuracy: 0.8667\n",
            "Epoch 31/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 0.8833\n",
            "Epoch 31: val_loss improved from 0.39130 to 0.37991, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.3446 - accuracy: 0.8833 - val_loss: 0.3799 - val_accuracy: 0.8667\n",
            "Epoch 32/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3607 - accuracy: 0.8894\n",
            "Epoch 32: val_loss improved from 0.37991 to 0.37947, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.3599 - accuracy: 0.8892 - val_loss: 0.3795 - val_accuracy: 0.8633\n",
            "Epoch 33/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3546 - accuracy: 0.8758\n",
            "Epoch 33: val_loss improved from 0.37947 to 0.36159, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.3517 - accuracy: 0.8767 - val_loss: 0.3616 - val_accuracy: 0.8667\n",
            "Epoch 34/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.8877\n",
            "Epoch 34: val_loss improved from 0.36159 to 0.36036, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.3484 - accuracy: 0.8875 - val_loss: 0.3604 - val_accuracy: 0.8667\n",
            "Epoch 35/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8900\n",
            "Epoch 35: val_loss improved from 0.36036 to 0.35471, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3311 - accuracy: 0.8900 - val_loss: 0.3547 - val_accuracy: 0.8667\n",
            "Epoch 36/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.9037\n",
            "Epoch 36: val_loss improved from 0.35471 to 0.35125, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2849 - accuracy: 0.9050 - val_loss: 0.3512 - val_accuracy: 0.8667\n",
            "Epoch 37/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.9046\n",
            "Epoch 37: val_loss improved from 0.35125 to 0.33998, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.2955 - accuracy: 0.9058 - val_loss: 0.3400 - val_accuracy: 0.8767\n",
            "Epoch 38/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2978 - accuracy: 0.9012\n",
            "Epoch 38: val_loss improved from 0.33998 to 0.33777, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.3000 - accuracy: 0.9008 - val_loss: 0.3378 - val_accuracy: 0.8700\n",
            "Epoch 39/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.9017\n",
            "Epoch 39: val_loss improved from 0.33777 to 0.33773, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2935 - accuracy: 0.9017 - val_loss: 0.3377 - val_accuracy: 0.8733\n",
            "Epoch 40/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8942\n",
            "Epoch 40: val_loss improved from 0.33773 to 0.32826, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.3255 - accuracy: 0.8942 - val_loss: 0.3283 - val_accuracy: 0.8733\n",
            "Epoch 41/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.8961\n",
            "Epoch 41: val_loss improved from 0.32826 to 0.32109, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.3126 - accuracy: 0.8967 - val_loss: 0.3211 - val_accuracy: 0.8800\n",
            "Epoch 42/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2940 - accuracy: 0.9062\n",
            "Epoch 42: val_loss improved from 0.32109 to 0.31821, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2945 - accuracy: 0.9050 - val_loss: 0.3182 - val_accuracy: 0.8767\n",
            "Epoch 43/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9105\n",
            "Epoch 43: val_loss improved from 0.31821 to 0.31310, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.2622 - accuracy: 0.9108 - val_loss: 0.3131 - val_accuracy: 0.8800\n",
            "Epoch 44/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9079\n",
            "Epoch 44: val_loss improved from 0.31310 to 0.31056, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.2737 - accuracy: 0.9075 - val_loss: 0.3106 - val_accuracy: 0.8767\n",
            "Epoch 45/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2832 - accuracy: 0.9062\n",
            "Epoch 45: val_loss improved from 0.31056 to 0.30332, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2826 - accuracy: 0.9067 - val_loss: 0.3033 - val_accuracy: 0.8833\n",
            "Epoch 46/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.9113\n",
            "Epoch 46: val_loss improved from 0.30332 to 0.29935, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2621 - accuracy: 0.9108 - val_loss: 0.2993 - val_accuracy: 0.8800\n",
            "Epoch 47/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.9225\n",
            "Epoch 47: val_loss improved from 0.29935 to 0.29688, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.2478 - accuracy: 0.9225 - val_loss: 0.2969 - val_accuracy: 0.8867\n",
            "Epoch 48/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9088\n",
            "Epoch 48: val_loss improved from 0.29688 to 0.29602, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.2741 - accuracy: 0.9092 - val_loss: 0.2960 - val_accuracy: 0.8833\n",
            "Epoch 49/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2569 - accuracy: 0.9172\n",
            "Epoch 49: val_loss improved from 0.29602 to 0.28988, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 7s 192ms/step - loss: 0.2600 - accuracy: 0.9167 - val_loss: 0.2899 - val_accuracy: 0.8867\n",
            "Epoch 50/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.9092\n",
            "Epoch 50: val_loss improved from 0.28988 to 0.28174, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 8s 223ms/step - loss: 0.2606 - accuracy: 0.9092 - val_loss: 0.2817 - val_accuracy: 0.8967\n",
            "Epoch 51/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2313 - accuracy: 0.9206\n",
            "Epoch 51: val_loss did not improve from 0.28174\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.2296 - accuracy: 0.9217 - val_loss: 0.2822 - val_accuracy: 0.8867\n",
            "Epoch 52/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.9292\n",
            "Epoch 52: val_loss improved from 0.28174 to 0.27445, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 121ms/step - loss: 0.2309 - accuracy: 0.9292 - val_loss: 0.2744 - val_accuracy: 0.8967\n",
            "Epoch 53/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9274\n",
            "Epoch 53: val_loss did not improve from 0.27445\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.2342 - accuracy: 0.9275 - val_loss: 0.2757 - val_accuracy: 0.8933\n",
            "Epoch 54/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9181\n",
            "Epoch 54: val_loss improved from 0.27445 to 0.27111, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 136ms/step - loss: 0.2330 - accuracy: 0.9192 - val_loss: 0.2711 - val_accuracy: 0.8933\n",
            "Epoch 55/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9208\n",
            "Epoch 55: val_loss improved from 0.27111 to 0.26657, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2244 - accuracy: 0.9208 - val_loss: 0.2666 - val_accuracy: 0.9033\n",
            "Epoch 56/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2476 - accuracy: 0.9096\n",
            "Epoch 56: val_loss improved from 0.26657 to 0.26188, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.2454 - accuracy: 0.9108 - val_loss: 0.2619 - val_accuracy: 0.9000\n",
            "Epoch 57/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9350\n",
            "Epoch 57: val_loss did not improve from 0.26188\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.2149 - accuracy: 0.9350 - val_loss: 0.2697 - val_accuracy: 0.8900\n",
            "Epoch 58/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9183\n",
            "Epoch 58: val_loss did not improve from 0.26188\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.2248 - accuracy: 0.9183 - val_loss: 0.2628 - val_accuracy: 0.9000\n",
            "Epoch 59/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2201 - accuracy: 0.9341\n",
            "Epoch 59: val_loss improved from 0.26188 to 0.25097, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 138ms/step - loss: 0.2193 - accuracy: 0.9342 - val_loss: 0.2510 - val_accuracy: 0.9167\n",
            "Epoch 60/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9233\n",
            "Epoch 60: val_loss improved from 0.25097 to 0.25058, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2094 - accuracy: 0.9233 - val_loss: 0.2506 - val_accuracy: 0.9133\n",
            "Epoch 61/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1980 - accuracy: 0.9358\n",
            "Epoch 61: val_loss improved from 0.25058 to 0.24115, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.1962 - accuracy: 0.9367 - val_loss: 0.2411 - val_accuracy: 0.9167\n",
            "Epoch 62/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9308\n",
            "Epoch 62: val_loss did not improve from 0.24115\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.2087 - accuracy: 0.9308 - val_loss: 0.2507 - val_accuracy: 0.9100\n",
            "Epoch 63/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9240\n",
            "Epoch 63: val_loss did not improve from 0.24115\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.2235 - accuracy: 0.9250 - val_loss: 0.2567 - val_accuracy: 0.9033\n",
            "Epoch 64/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9383\n",
            "Epoch 64: val_loss improved from 0.24115 to 0.24028, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.1885 - accuracy: 0.9383 - val_loss: 0.2403 - val_accuracy: 0.9133\n",
            "Epoch 65/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9333\n",
            "Epoch 65: val_loss improved from 0.24028 to 0.23980, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1950 - accuracy: 0.9333 - val_loss: 0.2398 - val_accuracy: 0.9133\n",
            "Epoch 66/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9324\n",
            "Epoch 66: val_loss improved from 0.23980 to 0.23842, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2067 - accuracy: 0.9308 - val_loss: 0.2384 - val_accuracy: 0.9100\n",
            "Epoch 67/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.9317\n",
            "Epoch 67: val_loss improved from 0.23842 to 0.22846, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2100 - accuracy: 0.9317 - val_loss: 0.2285 - val_accuracy: 0.9167\n",
            "Epoch 68/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9434\n",
            "Epoch 68: val_loss did not improve from 0.22846\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1814 - accuracy: 0.9433 - val_loss: 0.2303 - val_accuracy: 0.9167\n",
            "Epoch 69/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1687 - accuracy: 0.9409\n",
            "Epoch 69: val_loss did not improve from 0.22846\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.1685 - accuracy: 0.9417 - val_loss: 0.2315 - val_accuracy: 0.9167\n",
            "Epoch 70/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9476\n",
            "Epoch 70: val_loss improved from 0.22846 to 0.22834, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.1653 - accuracy: 0.9467 - val_loss: 0.2283 - val_accuracy: 0.9133\n",
            "Epoch 71/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9283\n",
            "Epoch 71: val_loss improved from 0.22834 to 0.22219, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2043 - accuracy: 0.9283 - val_loss: 0.2222 - val_accuracy: 0.9167\n",
            "Epoch 72/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9308\n",
            "Epoch 72: val_loss did not improve from 0.22219\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1914 - accuracy: 0.9308 - val_loss: 0.2291 - val_accuracy: 0.9200\n",
            "Epoch 73/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9442\n",
            "Epoch 73: val_loss did not improve from 0.22219\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1645 - accuracy: 0.9442 - val_loss: 0.2244 - val_accuracy: 0.9200\n",
            "Epoch 74/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9342\n",
            "Epoch 74: val_loss did not improve from 0.22219\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.1874 - accuracy: 0.9342 - val_loss: 0.2242 - val_accuracy: 0.9167\n",
            "Epoch 75/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9383\n",
            "Epoch 75: val_loss improved from 0.22219 to 0.21974, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.1740 - accuracy: 0.9392 - val_loss: 0.2197 - val_accuracy: 0.9167\n",
            "Epoch 76/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1659 - accuracy: 0.9409\n",
            "Epoch 76: val_loss improved from 0.21974 to 0.21323, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1653 - accuracy: 0.9408 - val_loss: 0.2132 - val_accuracy: 0.9167\n",
            "Epoch 77/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1474 - accuracy: 0.9500\n",
            "Epoch 77: val_loss did not improve from 0.21323\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1474 - accuracy: 0.9500 - val_loss: 0.2213 - val_accuracy: 0.9167\n",
            "Epoch 78/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1795 - accuracy: 0.9400\n",
            "Epoch 78: val_loss did not improve from 0.21323\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1782 - accuracy: 0.9400 - val_loss: 0.2178 - val_accuracy: 0.9200\n",
            "Epoch 79/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9451\n",
            "Epoch 79: val_loss improved from 0.21323 to 0.21266, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.1693 - accuracy: 0.9458 - val_loss: 0.2127 - val_accuracy: 0.9200\n",
            "Epoch 80/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1414 - accuracy: 0.9544\n",
            "Epoch 80: val_loss improved from 0.21266 to 0.20828, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1449 - accuracy: 0.9542 - val_loss: 0.2083 - val_accuracy: 0.9233\n",
            "Epoch 81/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9485\n",
            "Epoch 81: val_loss did not improve from 0.20828\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1588 - accuracy: 0.9492 - val_loss: 0.2130 - val_accuracy: 0.9200\n",
            "Epoch 82/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1567 - accuracy: 0.9409\n",
            "Epoch 82: val_loss did not improve from 0.20828\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1585 - accuracy: 0.9408 - val_loss: 0.2093 - val_accuracy: 0.9233\n",
            "Epoch 83/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.9392\n",
            "Epoch 83: val_loss improved from 0.20828 to 0.20720, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.1883 - accuracy: 0.9392 - val_loss: 0.2072 - val_accuracy: 0.9233\n",
            "Epoch 84/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9492\n",
            "Epoch 84: val_loss improved from 0.20720 to 0.19995, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1605 - accuracy: 0.9492 - val_loss: 0.2000 - val_accuracy: 0.9200\n",
            "Epoch 85/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9392\n",
            "Epoch 85: val_loss improved from 0.19995 to 0.19881, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1504 - accuracy: 0.9400 - val_loss: 0.1988 - val_accuracy: 0.9133\n",
            "Epoch 86/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9542\n",
            "Epoch 86: val_loss did not improve from 0.19881\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1405 - accuracy: 0.9542 - val_loss: 0.2076 - val_accuracy: 0.9133\n",
            "Epoch 87/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1291 - accuracy: 0.9561\n",
            "Epoch 87: val_loss did not improve from 0.19881\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.1288 - accuracy: 0.9567 - val_loss: 0.2022 - val_accuracy: 0.9200\n",
            "Epoch 88/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9535\n",
            "Epoch 88: val_loss improved from 0.19881 to 0.19716, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.1390 - accuracy: 0.9542 - val_loss: 0.1972 - val_accuracy: 0.9233\n",
            "Epoch 89/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9468\n",
            "Epoch 89: val_loss did not improve from 0.19716\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1620 - accuracy: 0.9458 - val_loss: 0.1981 - val_accuracy: 0.9300\n",
            "Epoch 90/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1686 - accuracy: 0.9451\n",
            "Epoch 90: val_loss did not improve from 0.19716\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1672 - accuracy: 0.9458 - val_loss: 0.2015 - val_accuracy: 0.9233\n",
            "Epoch 91/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.9575\n",
            "Epoch 91: val_loss did not improve from 0.19716\n",
            "38/38 [==============================] - 3s 71ms/step - loss: 0.1360 - accuracy: 0.9575 - val_loss: 0.1981 - val_accuracy: 0.9233\n",
            "Epoch 92/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1236 - accuracy: 0.9586\n",
            "Epoch 92: val_loss did not improve from 0.19716\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.1227 - accuracy: 0.9592 - val_loss: 0.2003 - val_accuracy: 0.9167\n",
            "Epoch 93/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9552\n",
            "Epoch 93: val_loss did not improve from 0.19716\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.1369 - accuracy: 0.9542 - val_loss: 0.1981 - val_accuracy: 0.9233\n",
            "Epoch 94/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9533\n",
            "Epoch 94: val_loss did not improve from 0.19716\n",
            "38/38 [==============================] - 3s 74ms/step - loss: 0.1381 - accuracy: 0.9533 - val_loss: 0.2003 - val_accuracy: 0.9167\n",
            "Epoch 95/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.9575\n",
            "Epoch 95: val_loss improved from 0.19716 to 0.19010, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.1253 - accuracy: 0.9575 - val_loss: 0.1901 - val_accuracy: 0.9267\n",
            "Epoch 96/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1128 - accuracy: 0.9662\n",
            "Epoch 96: val_loss did not improve from 0.19010\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1139 - accuracy: 0.9650 - val_loss: 0.1941 - val_accuracy: 0.9267\n",
            "Epoch 97/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1225 - accuracy: 0.9609\n",
            "Epoch 97: val_loss did not improve from 0.19010\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.1268 - accuracy: 0.9608 - val_loss: 0.1934 - val_accuracy: 0.9300\n",
            "Epoch 98/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9583\n",
            "Epoch 98: val_loss did not improve from 0.19010\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.1204 - accuracy: 0.9583 - val_loss: 0.1918 - val_accuracy: 0.9267\n",
            "Epoch 99/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9645\n",
            "Epoch 99: val_loss did not improve from 0.19010\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.1148 - accuracy: 0.9650 - val_loss: 0.1965 - val_accuracy: 0.9167\n",
            "Epoch 100/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9575\n",
            "Epoch 100: val_loss improved from 0.19010 to 0.18527, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.1255 - accuracy: 0.9575 - val_loss: 0.1853 - val_accuracy: 0.9300\n",
            "Epoch 101/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9667\n",
            "Epoch 101: val_loss did not improve from 0.18527\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1108 - accuracy: 0.9667 - val_loss: 0.1900 - val_accuracy: 0.9267\n",
            "Epoch 102/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9692\n",
            "Epoch 102: val_loss improved from 0.18527 to 0.18498, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0998 - accuracy: 0.9692 - val_loss: 0.1850 - val_accuracy: 0.9267\n",
            "Epoch 103/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9620\n",
            "Epoch 103: val_loss did not improve from 0.18498\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.1256 - accuracy: 0.9617 - val_loss: 0.1921 - val_accuracy: 0.9300\n",
            "Epoch 104/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1150 - accuracy: 0.9661\n",
            "Epoch 104: val_loss did not improve from 0.18498\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.1141 - accuracy: 0.9658 - val_loss: 0.1875 - val_accuracy: 0.9333\n",
            "Epoch 105/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9645\n",
            "Epoch 105: val_loss did not improve from 0.18498\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.1107 - accuracy: 0.9642 - val_loss: 0.1894 - val_accuracy: 0.9333\n",
            "Epoch 106/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1382 - accuracy: 0.9519\n",
            "Epoch 106: val_loss did not improve from 0.18498\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1375 - accuracy: 0.9525 - val_loss: 0.1852 - val_accuracy: 0.9333\n",
            "Epoch 107/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9658\n",
            "Epoch 107: val_loss did not improve from 0.18498\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0950 - accuracy: 0.9658 - val_loss: 0.1910 - val_accuracy: 0.9267\n",
            "Epoch 108/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9637\n",
            "Epoch 108: val_loss improved from 0.18498 to 0.18371, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 142ms/step - loss: 0.1046 - accuracy: 0.9642 - val_loss: 0.1837 - val_accuracy: 0.9367\n",
            "Epoch 109/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9633\n",
            "Epoch 109: val_loss improved from 0.18371 to 0.17655, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.1164 - accuracy: 0.9633 - val_loss: 0.1765 - val_accuracy: 0.9300\n",
            "Epoch 110/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9628\n",
            "Epoch 110: val_loss did not improve from 0.17655\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1095 - accuracy: 0.9625 - val_loss: 0.1771 - val_accuracy: 0.9367\n",
            "Epoch 111/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9595\n",
            "Epoch 111: val_loss did not improve from 0.17655\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1126 - accuracy: 0.9600 - val_loss: 0.1848 - val_accuracy: 0.9233\n",
            "Epoch 112/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0976 - accuracy: 0.9688\n",
            "Epoch 112: val_loss did not improve from 0.17655\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0975 - accuracy: 0.9692 - val_loss: 0.1863 - val_accuracy: 0.9233\n",
            "Epoch 113/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1082 - accuracy: 0.9637\n",
            "Epoch 113: val_loss did not improve from 0.17655\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1074 - accuracy: 0.9642 - val_loss: 0.1825 - val_accuracy: 0.9233\n",
            "Epoch 114/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9645\n",
            "Epoch 114: val_loss improved from 0.17655 to 0.17614, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.0931 - accuracy: 0.9650 - val_loss: 0.1761 - val_accuracy: 0.9333\n",
            "Epoch 115/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9671\n",
            "Epoch 115: val_loss improved from 0.17614 to 0.17544, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0946 - accuracy: 0.9675 - val_loss: 0.1754 - val_accuracy: 0.9233\n",
            "Epoch 116/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9658\n",
            "Epoch 116: val_loss improved from 0.17544 to 0.17256, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0951 - accuracy: 0.9658 - val_loss: 0.1726 - val_accuracy: 0.9300\n",
            "Epoch 117/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9650\n",
            "Epoch 117: val_loss did not improve from 0.17256\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0983 - accuracy: 0.9650 - val_loss: 0.1732 - val_accuracy: 0.9333\n",
            "Epoch 118/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9611\n",
            "Epoch 118: val_loss did not improve from 0.17256\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0991 - accuracy: 0.9617 - val_loss: 0.1781 - val_accuracy: 0.9267\n",
            "Epoch 119/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.9628\n",
            "Epoch 119: val_loss did not improve from 0.17256\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.1034 - accuracy: 0.9633 - val_loss: 0.1779 - val_accuracy: 0.9300\n",
            "Epoch 120/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9608\n",
            "Epoch 120: val_loss did not improve from 0.17256\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0970 - accuracy: 0.9608 - val_loss: 0.1743 - val_accuracy: 0.9333\n",
            "Epoch 121/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9683\n",
            "Epoch 121: val_loss did not improve from 0.17256\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0904 - accuracy: 0.9683 - val_loss: 0.1750 - val_accuracy: 0.9267\n",
            "Epoch 122/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1060 - accuracy: 0.9603\n",
            "Epoch 122: val_loss improved from 0.17256 to 0.16780, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 152ms/step - loss: 0.1055 - accuracy: 0.9608 - val_loss: 0.1678 - val_accuracy: 0.9333\n",
            "Epoch 123/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0972 - accuracy: 0.9653\n",
            "Epoch 123: val_loss improved from 0.16780 to 0.16199, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.0977 - accuracy: 0.9650 - val_loss: 0.1620 - val_accuracy: 0.9333\n",
            "Epoch 124/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9675\n",
            "Epoch 124: val_loss did not improve from 0.16199\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0990 - accuracy: 0.9675 - val_loss: 0.1716 - val_accuracy: 0.9267\n",
            "Epoch 125/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9700\n",
            "Epoch 125: val_loss did not improve from 0.16199\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0867 - accuracy: 0.9700 - val_loss: 0.1710 - val_accuracy: 0.9333\n",
            "Epoch 126/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9671\n",
            "Epoch 126: val_loss did not improve from 0.16199\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0976 - accuracy: 0.9667 - val_loss: 0.1718 - val_accuracy: 0.9300\n",
            "Epoch 127/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9725\n",
            "Epoch 127: val_loss did not improve from 0.16199\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0896 - accuracy: 0.9725 - val_loss: 0.1702 - val_accuracy: 0.9267\n",
            "Epoch 128/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0964 - accuracy: 0.9654\n",
            "Epoch 128: val_loss did not improve from 0.16199\n",
            "38/38 [==============================] - 3s 72ms/step - loss: 0.0952 - accuracy: 0.9658 - val_loss: 0.1655 - val_accuracy: 0.9300\n",
            "Epoch 129/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9704\n",
            "Epoch 129: val_loss did not improve from 0.16199\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0840 - accuracy: 0.9708 - val_loss: 0.1683 - val_accuracy: 0.9333\n",
            "Epoch 130/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9767\n",
            "Epoch 130: val_loss did not improve from 0.16199\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0886 - accuracy: 0.9767 - val_loss: 0.1726 - val_accuracy: 0.9267\n",
            "Epoch 131/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9700\n",
            "Epoch 131: val_loss did not improve from 0.16199\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0928 - accuracy: 0.9700 - val_loss: 0.1678 - val_accuracy: 0.9300\n",
            "Epoch 132/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9679\n",
            "Epoch 132: val_loss improved from 0.16199 to 0.16072, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 137ms/step - loss: 0.0900 - accuracy: 0.9675 - val_loss: 0.1607 - val_accuracy: 0.9300\n",
            "Epoch 133/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9704\n",
            "Epoch 133: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0878 - accuracy: 0.9700 - val_loss: 0.1615 - val_accuracy: 0.9367\n",
            "Epoch 134/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9628\n",
            "Epoch 134: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0950 - accuracy: 0.9633 - val_loss: 0.1704 - val_accuracy: 0.9267\n",
            "Epoch 135/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.9733\n",
            "Epoch 135: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0917 - accuracy: 0.9733 - val_loss: 0.1613 - val_accuracy: 0.9367\n",
            "Epoch 136/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9738\n",
            "Epoch 136: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0960 - accuracy: 0.9733 - val_loss: 0.1672 - val_accuracy: 0.9267\n",
            "Epoch 137/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9625\n",
            "Epoch 137: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.1032 - accuracy: 0.9625 - val_loss: 0.1662 - val_accuracy: 0.9367\n",
            "Epoch 138/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9767\n",
            "Epoch 138: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0680 - accuracy: 0.9767 - val_loss: 0.1631 - val_accuracy: 0.9367\n",
            "Epoch 139/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9730\n",
            "Epoch 139: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0675 - accuracy: 0.9733 - val_loss: 0.1624 - val_accuracy: 0.9400\n",
            "Epoch 140/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9775\n",
            "Epoch 140: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0662 - accuracy: 0.9775 - val_loss: 0.1637 - val_accuracy: 0.9333\n",
            "Epoch 141/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 0.9713\n",
            "Epoch 141: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0835 - accuracy: 0.9708 - val_loss: 0.1695 - val_accuracy: 0.9333\n",
            "Epoch 142/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0806 - accuracy: 0.9740\n",
            "Epoch 142: val_loss did not improve from 0.16072\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0827 - accuracy: 0.9733 - val_loss: 0.1643 - val_accuracy: 0.9300\n",
            "Epoch 143/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9675\n",
            "Epoch 143: val_loss improved from 0.16072 to 0.15822, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.0910 - accuracy: 0.9675 - val_loss: 0.1582 - val_accuracy: 0.9367\n",
            "Epoch 144/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9675\n",
            "Epoch 144: val_loss did not improve from 0.15822\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0912 - accuracy: 0.9675 - val_loss: 0.1662 - val_accuracy: 0.9367\n",
            "Epoch 145/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9814\n",
            "Epoch 145: val_loss did not improve from 0.15822\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0694 - accuracy: 0.9817 - val_loss: 0.1607 - val_accuracy: 0.9400\n",
            "Epoch 146/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9833\n",
            "Epoch 146: val_loss did not improve from 0.15822\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0711 - accuracy: 0.9833 - val_loss: 0.1585 - val_accuracy: 0.9400\n",
            "Epoch 147/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9692\n",
            "Epoch 147: val_loss did not improve from 0.15822\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0857 - accuracy: 0.9692 - val_loss: 0.1600 - val_accuracy: 0.9367\n",
            "Epoch 148/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 0.9671\n",
            "Epoch 148: val_loss did not improve from 0.15822\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.0819 - accuracy: 0.9675 - val_loss: 0.1605 - val_accuracy: 0.9400\n",
            "Epoch 149/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9717\n",
            "Epoch 149: val_loss did not improve from 0.15822\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0780 - accuracy: 0.9717 - val_loss: 0.1666 - val_accuracy: 0.9400\n",
            "Epoch 150/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9758\n",
            "Epoch 150: val_loss did not improve from 0.15822\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0734 - accuracy: 0.9758 - val_loss: 0.1611 - val_accuracy: 0.9367\n",
            "Epoch 151/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9755\n",
            "Epoch 151: val_loss improved from 0.15822 to 0.15683, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.0706 - accuracy: 0.9750 - val_loss: 0.1568 - val_accuracy: 0.9333\n",
            "Epoch 152/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9775\n",
            "Epoch 152: val_loss improved from 0.15683 to 0.15471, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 158ms/step - loss: 0.0698 - accuracy: 0.9775 - val_loss: 0.1547 - val_accuracy: 0.9433\n",
            "Epoch 153/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9783\n",
            "Epoch 153: val_loss did not improve from 0.15471\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0822 - accuracy: 0.9783 - val_loss: 0.1654 - val_accuracy: 0.9333\n",
            "Epoch 154/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9780\n",
            "Epoch 154: val_loss did not improve from 0.15471\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0690 - accuracy: 0.9783 - val_loss: 0.1609 - val_accuracy: 0.9367\n",
            "Epoch 155/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0631 - accuracy: 0.9814\n",
            "Epoch 155: val_loss did not improve from 0.15471\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0644 - accuracy: 0.9808 - val_loss: 0.1594 - val_accuracy: 0.9400\n",
            "Epoch 156/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9772\n",
            "Epoch 156: val_loss did not improve from 0.15471\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0590 - accuracy: 0.9775 - val_loss: 0.1651 - val_accuracy: 0.9367\n",
            "Epoch 157/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9758\n",
            "Epoch 157: val_loss did not improve from 0.15471\n",
            "38/38 [==============================] - 3s 70ms/step - loss: 0.0811 - accuracy: 0.9758 - val_loss: 0.1552 - val_accuracy: 0.9433\n",
            "Epoch 158/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9833\n",
            "Epoch 158: val_loss improved from 0.15471 to 0.15107, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 150ms/step - loss: 0.0543 - accuracy: 0.9833 - val_loss: 0.1511 - val_accuracy: 0.9400\n",
            "Epoch 159/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9808\n",
            "Epoch 159: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0610 - accuracy: 0.9808 - val_loss: 0.1514 - val_accuracy: 0.9433\n",
            "Epoch 160/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9704\n",
            "Epoch 160: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0657 - accuracy: 0.9708 - val_loss: 0.1515 - val_accuracy: 0.9367\n",
            "Epoch 161/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9814\n",
            "Epoch 161: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0587 - accuracy: 0.9817 - val_loss: 0.1514 - val_accuracy: 0.9367\n",
            "Epoch 162/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9738\n",
            "Epoch 162: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0767 - accuracy: 0.9725 - val_loss: 0.1534 - val_accuracy: 0.9367\n",
            "Epoch 163/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9808\n",
            "Epoch 163: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.0649 - accuracy: 0.9808 - val_loss: 0.1619 - val_accuracy: 0.9333\n",
            "Epoch 164/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9800\n",
            "Epoch 164: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0659 - accuracy: 0.9800 - val_loss: 0.1524 - val_accuracy: 0.9400\n",
            "Epoch 165/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9808\n",
            "Epoch 165: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0668 - accuracy: 0.9808 - val_loss: 0.1624 - val_accuracy: 0.9367\n",
            "Epoch 166/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9800\n",
            "Epoch 166: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0573 - accuracy: 0.9800 - val_loss: 0.1561 - val_accuracy: 0.9433\n",
            "Epoch 167/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9817\n",
            "Epoch 167: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0678 - accuracy: 0.9817 - val_loss: 0.1513 - val_accuracy: 0.9400\n",
            "Epoch 168/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0598 - accuracy: 0.9766\n",
            "Epoch 168: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0586 - accuracy: 0.9775 - val_loss: 0.1524 - val_accuracy: 0.9433\n",
            "Epoch 169/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9806\n",
            "Epoch 169: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0539 - accuracy: 0.9808 - val_loss: 0.1527 - val_accuracy: 0.9433\n",
            "Epoch 170/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9767\n",
            "Epoch 170: val_loss did not improve from 0.15107\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0695 - accuracy: 0.9767 - val_loss: 0.1592 - val_accuracy: 0.9400\n",
            "Epoch 171/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9767\n",
            "Epoch 171: val_loss improved from 0.15107 to 0.14131, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 148ms/step - loss: 0.0655 - accuracy: 0.9767 - val_loss: 0.1413 - val_accuracy: 0.9433\n",
            "Epoch 172/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0581 - accuracy: 0.9797\n",
            "Epoch 172: val_loss did not improve from 0.14131\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.1552 - val_accuracy: 0.9433\n",
            "Epoch 173/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9764\n",
            "Epoch 173: val_loss did not improve from 0.14131\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0563 - accuracy: 0.9758 - val_loss: 0.1435 - val_accuracy: 0.9500\n",
            "Epoch 174/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9850\n",
            "Epoch 174: val_loss did not improve from 0.14131\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0566 - accuracy: 0.9850 - val_loss: 0.1502 - val_accuracy: 0.9433\n",
            "Epoch 175/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9882\n",
            "Epoch 175: val_loss did not improve from 0.14131\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0530 - accuracy: 0.9883 - val_loss: 0.1530 - val_accuracy: 0.9433\n",
            "Epoch 176/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9817\n",
            "Epoch 176: val_loss did not improve from 0.14131\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.0525 - accuracy: 0.9817 - val_loss: 0.1431 - val_accuracy: 0.9433\n",
            "Epoch 177/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9856\n",
            "Epoch 177: val_loss did not improve from 0.14131\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0528 - accuracy: 0.9858 - val_loss: 0.1559 - val_accuracy: 0.9400\n",
            "Epoch 178/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9875\n",
            "Epoch 178: val_loss did not improve from 0.14131\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0464 - accuracy: 0.9875 - val_loss: 0.1544 - val_accuracy: 0.9367\n",
            "Epoch 179/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9767\n",
            "Epoch 179: val_loss did not improve from 0.14131\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0682 - accuracy: 0.9767 - val_loss: 0.1530 - val_accuracy: 0.9467\n",
            "Epoch 180/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9797\n",
            "Epoch 180: val_loss improved from 0.14131 to 0.14073, saving model to /content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 134ms/step - loss: 0.0513 - accuracy: 0.9800 - val_loss: 0.1407 - val_accuracy: 0.9500\n",
            "Epoch 181/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9848\n",
            "Epoch 181: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.1500 - val_accuracy: 0.9367\n",
            "Epoch 182/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0568 - accuracy: 0.9774\n",
            "Epoch 182: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0582 - accuracy: 0.9767 - val_loss: 0.1514 - val_accuracy: 0.9367\n",
            "Epoch 183/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9842\n",
            "Epoch 183: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0473 - accuracy: 0.9842 - val_loss: 0.1530 - val_accuracy: 0.9500\n",
            "Epoch 184/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9831\n",
            "Epoch 184: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.0501 - accuracy: 0.9833 - val_loss: 0.1501 - val_accuracy: 0.9400\n",
            "Epoch 185/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9792\n",
            "Epoch 185: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0570 - accuracy: 0.9792 - val_loss: 0.1558 - val_accuracy: 0.9433\n",
            "Epoch 186/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9750\n",
            "Epoch 186: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0652 - accuracy: 0.9750 - val_loss: 0.1520 - val_accuracy: 0.9367\n",
            "Epoch 187/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9850\n",
            "Epoch 187: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 0.1544 - val_accuracy: 0.9400\n",
            "Epoch 188/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9882\n",
            "Epoch 188: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0390 - accuracy: 0.9883 - val_loss: 0.1480 - val_accuracy: 0.9433\n",
            "Epoch 189/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9792\n",
            "Epoch 189: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.1481 - val_accuracy: 0.9500\n",
            "Epoch 190/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9823\n",
            "Epoch 190: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0535 - accuracy: 0.9825 - val_loss: 0.1479 - val_accuracy: 0.9433\n",
            "Epoch 191/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9882\n",
            "Epoch 191: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0406 - accuracy: 0.9883 - val_loss: 0.1516 - val_accuracy: 0.9500\n",
            "Epoch 192/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9825\n",
            "Epoch 192: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.1473 - val_accuracy: 0.9433\n",
            "Epoch 193/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9873\n",
            "Epoch 193: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 0.1481 - val_accuracy: 0.9367\n",
            "Epoch 194/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9865\n",
            "Epoch 194: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0460 - accuracy: 0.9867 - val_loss: 0.1472 - val_accuracy: 0.9467\n",
            "Epoch 195/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9780\n",
            "Epoch 195: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.1496 - val_accuracy: 0.9500\n",
            "Epoch 196/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9907\n",
            "Epoch 196: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 0.1442 - val_accuracy: 0.9467\n",
            "Epoch 197/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9890\n",
            "Epoch 197: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0421 - accuracy: 0.9892 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
            "Epoch 198/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9883\n",
            "Epoch 198: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0423 - accuracy: 0.9883 - val_loss: 0.1490 - val_accuracy: 0.9500\n",
            "Epoch 199/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9842\n",
            "Epoch 199: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0412 - accuracy: 0.9842 - val_loss: 0.1531 - val_accuracy: 0.9433\n",
            "Epoch 200/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9848\n",
            "Epoch 200: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0430 - accuracy: 0.9850 - val_loss: 0.1526 - val_accuracy: 0.9467\n",
            "Epoch 201/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9789\n",
            "Epoch 201: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0504 - accuracy: 0.9783 - val_loss: 0.1490 - val_accuracy: 0.9500\n",
            "Epoch 202/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0482 - accuracy: 0.9852\n",
            "Epoch 202: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0475 - accuracy: 0.9858 - val_loss: 0.1462 - val_accuracy: 0.9433\n",
            "Epoch 203/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9823\n",
            "Epoch 203: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 0.1522 - val_accuracy: 0.9433\n",
            "Epoch 204/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9892\n",
            "Epoch 204: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0394 - accuracy: 0.9892 - val_loss: 0.1475 - val_accuracy: 0.9500\n",
            "Epoch 205/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9907\n",
            "Epoch 205: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0396 - accuracy: 0.9908 - val_loss: 0.1440 - val_accuracy: 0.9533\n",
            "Epoch 206/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9817\n",
            "Epoch 206: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0408 - accuracy: 0.9817 - val_loss: 0.1498 - val_accuracy: 0.9467\n",
            "Epoch 207/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9899\n",
            "Epoch 207: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0364 - accuracy: 0.9900 - val_loss: 0.1465 - val_accuracy: 0.9467\n",
            "Epoch 208/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9865\n",
            "Epoch 208: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0429 - accuracy: 0.9867 - val_loss: 0.1529 - val_accuracy: 0.9500\n",
            "Epoch 209/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9883\n",
            "Epoch 209: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 3s 71ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.1527 - val_accuracy: 0.9500\n",
            "Epoch 210/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9924\n",
            "Epoch 210: val_loss did not improve from 0.14073\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0353 - accuracy: 0.9917 - val_loss: 0.1414 - val_accuracy: 0.9467\n",
            "47/47 [==============================] - 2s 20ms/step - loss: 0.5145 - accuracy: 0.8773\n",
            "Test accuracy, 13 run, after finetuning: 0.8773333430290222\n",
            "Epoch 1/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.9800 - accuracy: 0.5342\n",
            "Epoch 1: val_loss improved from inf to 2.10668, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 44s 544ms/step - loss: 2.9800 - accuracy: 0.5342 - val_loss: 2.1067 - val_accuracy: 0.5900\n",
            "Epoch 2/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.9711 - accuracy: 0.6000\n",
            "Epoch 2: val_loss improved from 2.10668 to 1.45379, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 142ms/step - loss: 1.9711 - accuracy: 0.6000 - val_loss: 1.4538 - val_accuracy: 0.6500\n",
            "Epoch 3/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.4055 - accuracy: 0.6583\n",
            "Epoch 3: val_loss improved from 1.45379 to 1.11790, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 1.4055 - accuracy: 0.6583 - val_loss: 1.1179 - val_accuracy: 0.7033\n",
            "Epoch 4/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.1912 - accuracy: 0.6748\n",
            "Epoch 4: val_loss improved from 1.11790 to 0.94442, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 1.1804 - accuracy: 0.6775 - val_loss: 0.9444 - val_accuracy: 0.7400\n",
            "Epoch 5/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.0139 - accuracy: 0.7086\n",
            "Epoch 5: val_loss improved from 0.94442 to 0.82789, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 1.0077 - accuracy: 0.7100 - val_loss: 0.8279 - val_accuracy: 0.7533\n",
            "Epoch 6/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.9098 - accuracy: 0.7111\n",
            "Epoch 6: val_loss improved from 0.82789 to 0.76245, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 134ms/step - loss: 0.9045 - accuracy: 0.7125 - val_loss: 0.7625 - val_accuracy: 0.7600\n",
            "Epoch 7/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.8689 - accuracy: 0.7111\n",
            "Epoch 7: val_loss improved from 0.76245 to 0.71866, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.8693 - accuracy: 0.7100 - val_loss: 0.7187 - val_accuracy: 0.7733\n",
            "Epoch 8/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.8012 - accuracy: 0.7365\n",
            "Epoch 8: val_loss improved from 0.71866 to 0.68157, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.8029 - accuracy: 0.7367 - val_loss: 0.6816 - val_accuracy: 0.7833\n",
            "Epoch 9/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7506 - accuracy: 0.7627\n",
            "Epoch 9: val_loss improved from 0.68157 to 0.65319, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.7514 - accuracy: 0.7625 - val_loss: 0.6532 - val_accuracy: 0.7933\n",
            "Epoch 10/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.7775\n",
            "Epoch 10: val_loss improved from 0.65319 to 0.62744, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.6565 - accuracy: 0.7775 - val_loss: 0.6274 - val_accuracy: 0.8067\n",
            "Epoch 11/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.6675 - accuracy: 0.7728\n",
            "Epoch 11: val_loss improved from 0.62744 to 0.60382, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.6687 - accuracy: 0.7717 - val_loss: 0.6038 - val_accuracy: 0.8100\n",
            "Epoch 12/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.6691 - accuracy: 0.7644\n",
            "Epoch 12: val_loss improved from 0.60382 to 0.58403, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.6704 - accuracy: 0.7650 - val_loss: 0.5840 - val_accuracy: 0.8167\n",
            "Epoch 13/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5892 - accuracy: 0.7981\n",
            "Epoch 13: val_loss improved from 0.58403 to 0.56484, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.5875 - accuracy: 0.7992 - val_loss: 0.5648 - val_accuracy: 0.8233\n",
            "Epoch 14/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.7992\n",
            "Epoch 14: val_loss improved from 0.56484 to 0.54803, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.5733 - accuracy: 0.7992 - val_loss: 0.5480 - val_accuracy: 0.8333\n",
            "Epoch 15/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.7942\n",
            "Epoch 15: val_loss improved from 0.54803 to 0.53316, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.5921 - accuracy: 0.7942 - val_loss: 0.5332 - val_accuracy: 0.8367\n",
            "Epoch 16/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.8100\n",
            "Epoch 16: val_loss improved from 0.53316 to 0.51894, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.5571 - accuracy: 0.8083 - val_loss: 0.5189 - val_accuracy: 0.8333\n",
            "Epoch 17/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5522 - accuracy: 0.8049\n",
            "Epoch 17: val_loss improved from 0.51894 to 0.50593, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.5560 - accuracy: 0.8042 - val_loss: 0.5059 - val_accuracy: 0.8433\n",
            "Epoch 18/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5216 - accuracy: 0.8201\n",
            "Epoch 18: val_loss improved from 0.50593 to 0.49249, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.5203 - accuracy: 0.8200 - val_loss: 0.4925 - val_accuracy: 0.8433\n",
            "Epoch 19/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.8283\n",
            "Epoch 19: val_loss improved from 0.49249 to 0.48259, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.4970 - accuracy: 0.8283 - val_loss: 0.4826 - val_accuracy: 0.8467\n",
            "Epoch 20/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.8242\n",
            "Epoch 20: val_loss improved from 0.48259 to 0.47359, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.5038 - accuracy: 0.8242 - val_loss: 0.4736 - val_accuracy: 0.8500\n",
            "Epoch 21/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4822 - accuracy: 0.8308\n",
            "Epoch 21: val_loss improved from 0.47359 to 0.46182, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.4822 - accuracy: 0.8308 - val_loss: 0.4618 - val_accuracy: 0.8467\n",
            "Epoch 22/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.8308\n",
            "Epoch 22: val_loss improved from 0.46182 to 0.45324, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 136ms/step - loss: 0.4827 - accuracy: 0.8308 - val_loss: 0.4532 - val_accuracy: 0.8500\n",
            "Epoch 23/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.8450\n",
            "Epoch 23: val_loss improved from 0.45324 to 0.44213, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.4410 - accuracy: 0.8450 - val_loss: 0.4421 - val_accuracy: 0.8533\n",
            "Epoch 24/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.8508\n",
            "Epoch 24: val_loss improved from 0.44213 to 0.43339, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 158ms/step - loss: 0.4475 - accuracy: 0.8508 - val_loss: 0.4334 - val_accuracy: 0.8600\n",
            "Epoch 25/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4303 - accuracy: 0.8497\n",
            "Epoch 25: val_loss improved from 0.43339 to 0.42337, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 9s 229ms/step - loss: 0.4327 - accuracy: 0.8492 - val_loss: 0.4234 - val_accuracy: 0.8667\n",
            "Epoch 26/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4045 - accuracy: 0.8598\n",
            "Epoch 26: val_loss improved from 0.42337 to 0.41473, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.4029 - accuracy: 0.8608 - val_loss: 0.4147 - val_accuracy: 0.8633\n",
            "Epoch 27/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3942 - accuracy: 0.8539\n",
            "Epoch 27: val_loss improved from 0.41473 to 0.40828, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.3913 - accuracy: 0.8558 - val_loss: 0.4083 - val_accuracy: 0.8600\n",
            "Epoch 28/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4014 - accuracy: 0.8691\n",
            "Epoch 28: val_loss improved from 0.40828 to 0.40169, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.4013 - accuracy: 0.8683 - val_loss: 0.4017 - val_accuracy: 0.8600\n",
            "Epoch 29/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4015 - accuracy: 0.8699\n",
            "Epoch 29: val_loss improved from 0.40169 to 0.39414, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.3979 - accuracy: 0.8717 - val_loss: 0.3941 - val_accuracy: 0.8633\n",
            "Epoch 30/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3697 - accuracy: 0.8716\n",
            "Epoch 30: val_loss improved from 0.39414 to 0.38797, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.3693 - accuracy: 0.8708 - val_loss: 0.3880 - val_accuracy: 0.8700\n",
            "Epoch 31/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3557 - accuracy: 0.8742\n",
            "Epoch 31: val_loss improved from 0.38797 to 0.38447, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.3557 - accuracy: 0.8742 - val_loss: 0.3845 - val_accuracy: 0.8767\n",
            "Epoch 32/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3660 - accuracy: 0.8758\n",
            "Epoch 32: val_loss improved from 0.38447 to 0.37651, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3628 - accuracy: 0.8767 - val_loss: 0.3765 - val_accuracy: 0.8800\n",
            "Epoch 33/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8875\n",
            "Epoch 33: val_loss improved from 0.37651 to 0.37278, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.3471 - accuracy: 0.8875 - val_loss: 0.3728 - val_accuracy: 0.8800\n",
            "Epoch 34/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3519 - accuracy: 0.8716\n",
            "Epoch 34: val_loss improved from 0.37278 to 0.36707, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 155ms/step - loss: 0.3506 - accuracy: 0.8717 - val_loss: 0.3671 - val_accuracy: 0.8800\n",
            "Epoch 35/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3389 - accuracy: 0.8927\n",
            "Epoch 35: val_loss improved from 0.36707 to 0.36070, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.3381 - accuracy: 0.8933 - val_loss: 0.3607 - val_accuracy: 0.8833\n",
            "Epoch 36/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.8851\n",
            "Epoch 36: val_loss improved from 0.36070 to 0.35508, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.3294 - accuracy: 0.8850 - val_loss: 0.3551 - val_accuracy: 0.8867\n",
            "Epoch 37/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3157 - accuracy: 0.8908\n",
            "Epoch 37: val_loss improved from 0.35508 to 0.34917, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.3157 - accuracy: 0.8908 - val_loss: 0.3492 - val_accuracy: 0.8867\n",
            "Epoch 38/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3023 - accuracy: 0.9020\n",
            "Epoch 38: val_loss improved from 0.34917 to 0.34387, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.3010 - accuracy: 0.9025 - val_loss: 0.3439 - val_accuracy: 0.8833\n",
            "Epoch 39/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.9003\n",
            "Epoch 39: val_loss improved from 0.34387 to 0.33894, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.2954 - accuracy: 0.9000 - val_loss: 0.3389 - val_accuracy: 0.8867\n",
            "Epoch 40/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3111 - accuracy: 0.8927\n",
            "Epoch 40: val_loss improved from 0.33894 to 0.33642, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.3080 - accuracy: 0.8942 - val_loss: 0.3364 - val_accuracy: 0.8833\n",
            "Epoch 41/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.9025\n",
            "Epoch 41: val_loss improved from 0.33642 to 0.33244, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2832 - accuracy: 0.9025 - val_loss: 0.3324 - val_accuracy: 0.8867\n",
            "Epoch 42/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.9092\n",
            "Epoch 42: val_loss improved from 0.33244 to 0.32991, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2739 - accuracy: 0.9092 - val_loss: 0.3299 - val_accuracy: 0.8933\n",
            "Epoch 43/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2860 - accuracy: 0.9012\n",
            "Epoch 43: val_loss improved from 0.32991 to 0.32718, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 134ms/step - loss: 0.2867 - accuracy: 0.9008 - val_loss: 0.3272 - val_accuracy: 0.8833\n",
            "Epoch 44/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2785 - accuracy: 0.9020\n",
            "Epoch 44: val_loss improved from 0.32718 to 0.32307, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2785 - accuracy: 0.9008 - val_loss: 0.3231 - val_accuracy: 0.8933\n",
            "Epoch 45/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2659 - accuracy: 0.9088\n",
            "Epoch 45: val_loss improved from 0.32307 to 0.31775, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2680 - accuracy: 0.9083 - val_loss: 0.3177 - val_accuracy: 0.9000\n",
            "Epoch 46/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9283\n",
            "Epoch 46: val_loss improved from 0.31775 to 0.31337, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.2461 - accuracy: 0.9283 - val_loss: 0.3134 - val_accuracy: 0.9000\n",
            "Epoch 47/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9029\n",
            "Epoch 47: val_loss improved from 0.31337 to 0.30981, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2739 - accuracy: 0.9025 - val_loss: 0.3098 - val_accuracy: 0.9033\n",
            "Epoch 48/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2512 - accuracy: 0.9158\n",
            "Epoch 48: val_loss improved from 0.30981 to 0.30397, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.2512 - accuracy: 0.9158 - val_loss: 0.3040 - val_accuracy: 0.9000\n",
            "Epoch 49/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2473 - accuracy: 0.9189\n",
            "Epoch 49: val_loss improved from 0.30397 to 0.30187, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.2490 - accuracy: 0.9175 - val_loss: 0.3019 - val_accuracy: 0.8967\n",
            "Epoch 50/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.9150\n",
            "Epoch 50: val_loss improved from 0.30187 to 0.29788, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2618 - accuracy: 0.9150 - val_loss: 0.2979 - val_accuracy: 0.8967\n",
            "Epoch 51/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.9206\n",
            "Epoch 51: val_loss improved from 0.29788 to 0.29430, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2397 - accuracy: 0.9208 - val_loss: 0.2943 - val_accuracy: 0.9000\n",
            "Epoch 52/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2266 - accuracy: 0.9198\n",
            "Epoch 52: val_loss improved from 0.29430 to 0.29304, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.2290 - accuracy: 0.9175 - val_loss: 0.2930 - val_accuracy: 0.9067\n",
            "Epoch 53/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2435 - accuracy: 0.9155\n",
            "Epoch 53: val_loss improved from 0.29304 to 0.28967, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2450 - accuracy: 0.9150 - val_loss: 0.2897 - val_accuracy: 0.9033\n",
            "Epoch 54/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.9258\n",
            "Epoch 54: val_loss improved from 0.28967 to 0.28626, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2346 - accuracy: 0.9258 - val_loss: 0.2863 - val_accuracy: 0.9100\n",
            "Epoch 55/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.9242\n",
            "Epoch 55: val_loss improved from 0.28626 to 0.28460, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.2245 - accuracy: 0.9242 - val_loss: 0.2846 - val_accuracy: 0.9033\n",
            "Epoch 56/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.9275\n",
            "Epoch 56: val_loss improved from 0.28460 to 0.28136, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.2113 - accuracy: 0.9275 - val_loss: 0.2814 - val_accuracy: 0.9100\n",
            "Epoch 57/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.9242\n",
            "Epoch 57: val_loss improved from 0.28136 to 0.27721, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2329 - accuracy: 0.9242 - val_loss: 0.2772 - val_accuracy: 0.9100\n",
            "Epoch 58/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2156 - accuracy: 0.9282\n",
            "Epoch 58: val_loss improved from 0.27721 to 0.27680, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.2144 - accuracy: 0.9292 - val_loss: 0.2768 - val_accuracy: 0.9100\n",
            "Epoch 59/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.9307\n",
            "Epoch 59: val_loss improved from 0.27680 to 0.27338, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.2116 - accuracy: 0.9308 - val_loss: 0.2734 - val_accuracy: 0.9133\n",
            "Epoch 60/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1865 - accuracy: 0.9426\n",
            "Epoch 60: val_loss improved from 0.27338 to 0.27081, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1864 - accuracy: 0.9417 - val_loss: 0.2708 - val_accuracy: 0.9100\n",
            "Epoch 61/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1944 - accuracy: 0.9367\n",
            "Epoch 61: val_loss improved from 0.27081 to 0.26715, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.1931 - accuracy: 0.9367 - val_loss: 0.2672 - val_accuracy: 0.9167\n",
            "Epoch 62/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9274\n",
            "Epoch 62: val_loss improved from 0.26715 to 0.26685, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.2130 - accuracy: 0.9275 - val_loss: 0.2669 - val_accuracy: 0.9100\n",
            "Epoch 63/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9274\n",
            "Epoch 63: val_loss improved from 0.26685 to 0.26341, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2008 - accuracy: 0.9283 - val_loss: 0.2634 - val_accuracy: 0.9167\n",
            "Epoch 64/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1854 - accuracy: 0.9341\n",
            "Epoch 64: val_loss improved from 0.26341 to 0.26125, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.1861 - accuracy: 0.9333 - val_loss: 0.2613 - val_accuracy: 0.9133\n",
            "Epoch 65/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1982 - accuracy: 0.9358\n",
            "Epoch 65: val_loss improved from 0.26125 to 0.25805, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.1982 - accuracy: 0.9358 - val_loss: 0.2580 - val_accuracy: 0.9067\n",
            "Epoch 66/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1836 - accuracy: 0.9392\n",
            "Epoch 66: val_loss improved from 0.25805 to 0.25681, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.1835 - accuracy: 0.9392 - val_loss: 0.2568 - val_accuracy: 0.9100\n",
            "Epoch 67/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9367\n",
            "Epoch 67: val_loss improved from 0.25681 to 0.25312, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 137ms/step - loss: 0.1730 - accuracy: 0.9367 - val_loss: 0.2531 - val_accuracy: 0.9100\n",
            "Epoch 68/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.9392\n",
            "Epoch 68: val_loss improved from 0.25312 to 0.24849, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.1772 - accuracy: 0.9392 - val_loss: 0.2485 - val_accuracy: 0.9133\n",
            "Epoch 69/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1781 - accuracy: 0.9417\n",
            "Epoch 69: val_loss improved from 0.24849 to 0.24733, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.1771 - accuracy: 0.9425 - val_loss: 0.2473 - val_accuracy: 0.9167\n",
            "Epoch 70/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1745 - accuracy: 0.9468\n",
            "Epoch 70: val_loss improved from 0.24733 to 0.24605, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.1745 - accuracy: 0.9458 - val_loss: 0.2460 - val_accuracy: 0.9167\n",
            "Epoch 71/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1657 - accuracy: 0.9443\n",
            "Epoch 71: val_loss improved from 0.24605 to 0.24441, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.1657 - accuracy: 0.9442 - val_loss: 0.2444 - val_accuracy: 0.9133\n",
            "Epoch 72/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1622 - accuracy: 0.9459\n",
            "Epoch 72: val_loss improved from 0.24441 to 0.24099, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1668 - accuracy: 0.9442 - val_loss: 0.2410 - val_accuracy: 0.9167\n",
            "Epoch 73/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 0.9502\n",
            "Epoch 73: val_loss improved from 0.24099 to 0.23865, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.1503 - accuracy: 0.9508 - val_loss: 0.2386 - val_accuracy: 0.9200\n",
            "Epoch 74/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9417\n",
            "Epoch 74: val_loss improved from 0.23865 to 0.23549, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 137ms/step - loss: 0.1618 - accuracy: 0.9417 - val_loss: 0.2355 - val_accuracy: 0.9167\n",
            "Epoch 75/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.9552\n",
            "Epoch 75: val_loss improved from 0.23549 to 0.23463, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1393 - accuracy: 0.9558 - val_loss: 0.2346 - val_accuracy: 0.9167\n",
            "Epoch 76/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9475\n",
            "Epoch 76: val_loss improved from 0.23463 to 0.23397, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.1557 - accuracy: 0.9475 - val_loss: 0.2340 - val_accuracy: 0.9200\n",
            "Epoch 77/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9550\n",
            "Epoch 77: val_loss improved from 0.23397 to 0.23385, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 136ms/step - loss: 0.1463 - accuracy: 0.9550 - val_loss: 0.2338 - val_accuracy: 0.9200\n",
            "Epoch 78/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9450\n",
            "Epoch 78: val_loss improved from 0.23385 to 0.23190, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1726 - accuracy: 0.9450 - val_loss: 0.2319 - val_accuracy: 0.9267\n",
            "Epoch 79/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1469 - accuracy: 0.9519\n",
            "Epoch 79: val_loss improved from 0.23190 to 0.22938, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.1456 - accuracy: 0.9525 - val_loss: 0.2294 - val_accuracy: 0.9200\n",
            "Epoch 80/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9600\n",
            "Epoch 80: val_loss did not improve from 0.22938\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.1395 - accuracy: 0.9600 - val_loss: 0.2301 - val_accuracy: 0.9200\n",
            "Epoch 81/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9483\n",
            "Epoch 81: val_loss improved from 0.22938 to 0.22772, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.1481 - accuracy: 0.9483 - val_loss: 0.2277 - val_accuracy: 0.9200\n",
            "Epoch 82/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9485\n",
            "Epoch 82: val_loss improved from 0.22772 to 0.22691, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1521 - accuracy: 0.9467 - val_loss: 0.2269 - val_accuracy: 0.9167\n",
            "Epoch 83/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1279 - accuracy: 0.9578\n",
            "Epoch 83: val_loss improved from 0.22691 to 0.22353, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.1286 - accuracy: 0.9575 - val_loss: 0.2235 - val_accuracy: 0.9233\n",
            "Epoch 84/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1503 - accuracy: 0.9468\n",
            "Epoch 84: val_loss did not improve from 0.22353\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.1488 - accuracy: 0.9475 - val_loss: 0.2236 - val_accuracy: 0.9200\n",
            "Epoch 85/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9443\n",
            "Epoch 85: val_loss improved from 0.22353 to 0.21783, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.1571 - accuracy: 0.9442 - val_loss: 0.2178 - val_accuracy: 0.9200\n",
            "Epoch 86/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1504 - accuracy: 0.9417\n",
            "Epoch 86: val_loss improved from 0.21783 to 0.21743, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.1503 - accuracy: 0.9417 - val_loss: 0.2174 - val_accuracy: 0.9267\n",
            "Epoch 87/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9458\n",
            "Epoch 87: val_loss did not improve from 0.21743\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1425 - accuracy: 0.9458 - val_loss: 0.2175 - val_accuracy: 0.9233\n",
            "Epoch 88/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9552\n",
            "Epoch 88: val_loss improved from 0.21743 to 0.21669, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.1261 - accuracy: 0.9550 - val_loss: 0.2167 - val_accuracy: 0.9267\n",
            "Epoch 89/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 0.9544\n",
            "Epoch 89: val_loss improved from 0.21669 to 0.21491, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1298 - accuracy: 0.9542 - val_loss: 0.2149 - val_accuracy: 0.9233\n",
            "Epoch 90/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 0.9578\n",
            "Epoch 90: val_loss did not improve from 0.21491\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1270 - accuracy: 0.9575 - val_loss: 0.2155 - val_accuracy: 0.9233\n",
            "Epoch 91/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9569\n",
            "Epoch 91: val_loss did not improve from 0.21491\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1249 - accuracy: 0.9567 - val_loss: 0.2161 - val_accuracy: 0.9233\n",
            "Epoch 92/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9578\n",
            "Epoch 92: val_loss improved from 0.21491 to 0.21427, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.1256 - accuracy: 0.9583 - val_loss: 0.2143 - val_accuracy: 0.9200\n",
            "Epoch 93/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9476\n",
            "Epoch 93: val_loss improved from 0.21427 to 0.21255, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1320 - accuracy: 0.9483 - val_loss: 0.2125 - val_accuracy: 0.9167\n",
            "Epoch 94/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9645\n",
            "Epoch 94: val_loss did not improve from 0.21255\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.1125 - accuracy: 0.9642 - val_loss: 0.2133 - val_accuracy: 0.9233\n",
            "Epoch 95/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9575\n",
            "Epoch 95: val_loss did not improve from 0.21255\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1229 - accuracy: 0.9575 - val_loss: 0.2141 - val_accuracy: 0.9133\n",
            "Epoch 96/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9603\n",
            "Epoch 96: val_loss did not improve from 0.21255\n",
            "38/38 [==============================] - 3s 73ms/step - loss: 0.1166 - accuracy: 0.9600 - val_loss: 0.2148 - val_accuracy: 0.9200\n",
            "Epoch 97/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1270 - accuracy: 0.9552\n",
            "Epoch 97: val_loss improved from 0.21255 to 0.20872, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.1271 - accuracy: 0.9550 - val_loss: 0.2087 - val_accuracy: 0.9233\n",
            "Epoch 98/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1086 - accuracy: 0.9637\n",
            "Epoch 98: val_loss improved from 0.20872 to 0.20732, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1078 - accuracy: 0.9642 - val_loss: 0.2073 - val_accuracy: 0.9200\n",
            "Epoch 99/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9662\n",
            "Epoch 99: val_loss did not improve from 0.20732\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1070 - accuracy: 0.9667 - val_loss: 0.2086 - val_accuracy: 0.9200\n",
            "Epoch 100/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 0.9688\n",
            "Epoch 100: val_loss improved from 0.20732 to 0.20728, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.1068 - accuracy: 0.9692 - val_loss: 0.2073 - val_accuracy: 0.9200\n",
            "Epoch 101/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9618\n",
            "Epoch 101: val_loss did not improve from 0.20728\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.1137 - accuracy: 0.9617 - val_loss: 0.2076 - val_accuracy: 0.9300\n",
            "Epoch 102/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9628\n",
            "Epoch 102: val_loss improved from 0.20728 to 0.20703, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.1166 - accuracy: 0.9617 - val_loss: 0.2070 - val_accuracy: 0.9200\n",
            "Epoch 103/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.9662\n",
            "Epoch 103: val_loss improved from 0.20703 to 0.20313, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1077 - accuracy: 0.9667 - val_loss: 0.2031 - val_accuracy: 0.9333\n",
            "Epoch 104/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9645\n",
            "Epoch 104: val_loss improved from 0.20313 to 0.20166, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.1031 - accuracy: 0.9650 - val_loss: 0.2017 - val_accuracy: 0.9233\n",
            "Epoch 105/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9645\n",
            "Epoch 105: val_loss did not improve from 0.20166\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.1089 - accuracy: 0.9642 - val_loss: 0.2033 - val_accuracy: 0.9267\n",
            "Epoch 106/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 0.9688\n",
            "Epoch 106: val_loss did not improve from 0.20166\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0969 - accuracy: 0.9692 - val_loss: 0.2020 - val_accuracy: 0.9300\n",
            "Epoch 107/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9721\n",
            "Epoch 107: val_loss did not improve from 0.20166\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1015 - accuracy: 0.9725 - val_loss: 0.2031 - val_accuracy: 0.9267\n",
            "Epoch 108/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9758\n",
            "Epoch 108: val_loss did not improve from 0.20166\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0936 - accuracy: 0.9758 - val_loss: 0.2031 - val_accuracy: 0.9300\n",
            "Epoch 109/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9700\n",
            "Epoch 109: val_loss improved from 0.20166 to 0.20080, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.0927 - accuracy: 0.9700 - val_loss: 0.2008 - val_accuracy: 0.9267\n",
            "Epoch 110/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9725\n",
            "Epoch 110: val_loss improved from 0.20080 to 0.19896, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.0920 - accuracy: 0.9725 - val_loss: 0.1990 - val_accuracy: 0.9333\n",
            "Epoch 111/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0991 - accuracy: 0.9679\n",
            "Epoch 111: val_loss did not improve from 0.19896\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0986 - accuracy: 0.9683 - val_loss: 0.1999 - val_accuracy: 0.9233\n",
            "Epoch 112/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 0.9654\n",
            "Epoch 112: val_loss improved from 0.19896 to 0.19747, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.1042 - accuracy: 0.9650 - val_loss: 0.1975 - val_accuracy: 0.9233\n",
            "Epoch 113/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 0.9721\n",
            "Epoch 113: val_loss did not improve from 0.19747\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0924 - accuracy: 0.9717 - val_loss: 0.1981 - val_accuracy: 0.9267\n",
            "Epoch 114/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9755\n",
            "Epoch 114: val_loss did not improve from 0.19747\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0897 - accuracy: 0.9750 - val_loss: 0.1992 - val_accuracy: 0.9267\n",
            "Epoch 115/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0821 - accuracy: 0.9721\n",
            "Epoch 115: val_loss improved from 0.19747 to 0.19678, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.0826 - accuracy: 0.9717 - val_loss: 0.1968 - val_accuracy: 0.9267\n",
            "Epoch 116/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 0.9696\n",
            "Epoch 116: val_loss improved from 0.19678 to 0.19631, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0890 - accuracy: 0.9692 - val_loss: 0.1963 - val_accuracy: 0.9200\n",
            "Epoch 117/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9725\n",
            "Epoch 117: val_loss improved from 0.19631 to 0.19464, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.0827 - accuracy: 0.9725 - val_loss: 0.1946 - val_accuracy: 0.9300\n",
            "Epoch 118/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9645\n",
            "Epoch 118: val_loss improved from 0.19464 to 0.19411, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.0881 - accuracy: 0.9650 - val_loss: 0.1941 - val_accuracy: 0.9267\n",
            "Epoch 119/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 0.9696\n",
            "Epoch 119: val_loss improved from 0.19411 to 0.19162, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.0856 - accuracy: 0.9692 - val_loss: 0.1916 - val_accuracy: 0.9333\n",
            "Epoch 120/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9797\n",
            "Epoch 120: val_loss improved from 0.19162 to 0.19002, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0680 - accuracy: 0.9800 - val_loss: 0.1900 - val_accuracy: 0.9300\n",
            "Epoch 121/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.9692\n",
            "Epoch 121: val_loss improved from 0.19002 to 0.18987, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.0918 - accuracy: 0.9692 - val_loss: 0.1899 - val_accuracy: 0.9333\n",
            "Epoch 122/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.9758\n",
            "Epoch 122: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0772 - accuracy: 0.9758 - val_loss: 0.1927 - val_accuracy: 0.9333\n",
            "Epoch 123/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9772\n",
            "Epoch 123: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0716 - accuracy: 0.9775 - val_loss: 0.1942 - val_accuracy: 0.9300\n",
            "Epoch 124/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.9800\n",
            "Epoch 124: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0732 - accuracy: 0.9800 - val_loss: 0.1942 - val_accuracy: 0.9300\n",
            "Epoch 125/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9730\n",
            "Epoch 125: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0785 - accuracy: 0.9725 - val_loss: 0.1943 - val_accuracy: 0.9300\n",
            "Epoch 126/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9800\n",
            "Epoch 126: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.0646 - accuracy: 0.9800 - val_loss: 0.1920 - val_accuracy: 0.9333\n",
            "Epoch 127/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0845 - accuracy: 0.9713\n",
            "Epoch 127: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0837 - accuracy: 0.9717 - val_loss: 0.1916 - val_accuracy: 0.9333\n",
            "Epoch 128/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9696\n",
            "Epoch 128: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0822 - accuracy: 0.9700 - val_loss: 0.1908 - val_accuracy: 0.9333\n",
            "Epoch 129/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9780\n",
            "Epoch 129: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0707 - accuracy: 0.9775 - val_loss: 0.1936 - val_accuracy: 0.9300\n",
            "Epoch 130/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9750\n",
            "Epoch 130: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0741 - accuracy: 0.9750 - val_loss: 0.1959 - val_accuracy: 0.9300\n",
            "Epoch 131/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9792\n",
            "Epoch 131: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 65ms/step - loss: 0.0622 - accuracy: 0.9792 - val_loss: 0.1948 - val_accuracy: 0.9200\n",
            "Epoch 132/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9742\n",
            "Epoch 132: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0824 - accuracy: 0.9742 - val_loss: 0.1916 - val_accuracy: 0.9300\n",
            "Epoch 133/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9738\n",
            "Epoch 133: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0695 - accuracy: 0.9742 - val_loss: 0.1909 - val_accuracy: 0.9233\n",
            "Epoch 134/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9814\n",
            "Epoch 134: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0645 - accuracy: 0.9817 - val_loss: 0.1900 - val_accuracy: 0.9300\n",
            "Epoch 135/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0820 - accuracy: 0.9730\n",
            "Epoch 135: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0812 - accuracy: 0.9733 - val_loss: 0.1918 - val_accuracy: 0.9300\n",
            "Epoch 136/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9817\n",
            "Epoch 136: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 3s 70ms/step - loss: 0.0587 - accuracy: 0.9817 - val_loss: 0.1920 - val_accuracy: 0.9267\n",
            "Epoch 137/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9772\n",
            "Epoch 137: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 0.1921 - val_accuracy: 0.9300\n",
            "Epoch 138/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9772\n",
            "Epoch 138: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0661 - accuracy: 0.9758 - val_loss: 0.1906 - val_accuracy: 0.9333\n",
            "Epoch 139/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 0.9848\n",
            "Epoch 139: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0548 - accuracy: 0.9850 - val_loss: 0.1912 - val_accuracy: 0.9300\n",
            "Epoch 140/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9833\n",
            "Epoch 140: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0561 - accuracy: 0.9833 - val_loss: 0.1907 - val_accuracy: 0.9333\n",
            "Epoch 141/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9783\n",
            "Epoch 141: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0651 - accuracy: 0.9783 - val_loss: 0.1942 - val_accuracy: 0.9267\n",
            "Epoch 142/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9772\n",
            "Epoch 142: val_loss did not improve from 0.18987\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0680 - accuracy: 0.9767 - val_loss: 0.1899 - val_accuracy: 0.9267\n",
            "Epoch 143/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9817\n",
            "Epoch 143: val_loss improved from 0.18987 to 0.18966, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 140ms/step - loss: 0.0536 - accuracy: 0.9817 - val_loss: 0.1897 - val_accuracy: 0.9300\n",
            "Epoch 144/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.9780\n",
            "Epoch 144: val_loss improved from 0.18966 to 0.18695, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0584 - accuracy: 0.9775 - val_loss: 0.1869 - val_accuracy: 0.9300\n",
            "Epoch 145/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9783\n",
            "Epoch 145: val_loss improved from 0.18695 to 0.18680, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.0569 - accuracy: 0.9783 - val_loss: 0.1868 - val_accuracy: 0.9300\n",
            "Epoch 146/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 0.9764\n",
            "Epoch 146: val_loss improved from 0.18680 to 0.18601, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0662 - accuracy: 0.9767 - val_loss: 0.1860 - val_accuracy: 0.9267\n",
            "Epoch 147/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 0.9806\n",
            "Epoch 147: val_loss did not improve from 0.18601\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0521 - accuracy: 0.9808 - val_loss: 0.1865 - val_accuracy: 0.9333\n",
            "Epoch 148/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9840\n",
            "Epoch 148: val_loss improved from 0.18601 to 0.18598, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.0547 - accuracy: 0.9842 - val_loss: 0.1860 - val_accuracy: 0.9367\n",
            "Epoch 149/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9842\n",
            "Epoch 149: val_loss improved from 0.18598 to 0.18387, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.1839 - val_accuracy: 0.9333\n",
            "Epoch 150/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9747\n",
            "Epoch 150: val_loss did not improve from 0.18387\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0696 - accuracy: 0.9750 - val_loss: 0.1857 - val_accuracy: 0.9267\n",
            "Epoch 151/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9831\n",
            "Epoch 151: val_loss did not improve from 0.18387\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0507 - accuracy: 0.9833 - val_loss: 0.1906 - val_accuracy: 0.9267\n",
            "Epoch 152/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9823\n",
            "Epoch 152: val_loss did not improve from 0.18387\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0622 - accuracy: 0.9817 - val_loss: 0.1931 - val_accuracy: 0.9267\n",
            "Epoch 153/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.9850\n",
            "Epoch 153: val_loss did not improve from 0.18387\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0497 - accuracy: 0.9850 - val_loss: 0.1907 - val_accuracy: 0.9300\n",
            "Epoch 154/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9850\n",
            "Epoch 154: val_loss did not improve from 0.18387\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0486 - accuracy: 0.9850 - val_loss: 0.1927 - val_accuracy: 0.9200\n",
            "Epoch 155/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9806\n",
            "Epoch 155: val_loss did not improve from 0.18387\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0592 - accuracy: 0.9800 - val_loss: 0.1897 - val_accuracy: 0.9267\n",
            "Epoch 156/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9792\n",
            "Epoch 156: val_loss did not improve from 0.18387\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0557 - accuracy: 0.9792 - val_loss: 0.1853 - val_accuracy: 0.9367\n",
            "Epoch 157/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9814\n",
            "Epoch 157: val_loss improved from 0.18387 to 0.18193, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 139ms/step - loss: 0.0535 - accuracy: 0.9817 - val_loss: 0.1819 - val_accuracy: 0.9300\n",
            "Epoch 158/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9831\n",
            "Epoch 158: val_loss did not improve from 0.18193\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0505 - accuracy: 0.9833 - val_loss: 0.1880 - val_accuracy: 0.9233\n",
            "Epoch 159/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9848\n",
            "Epoch 159: val_loss did not improve from 0.18193\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0548 - accuracy: 0.9842 - val_loss: 0.1834 - val_accuracy: 0.9333\n",
            "Epoch 160/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0414 - accuracy: 0.9878\n",
            "Epoch 160: val_loss did not improve from 0.18193\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 0.1820 - val_accuracy: 0.9333\n",
            "Epoch 161/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0498 - accuracy: 0.9861\n",
            "Epoch 161: val_loss did not improve from 0.18193\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0565 - accuracy: 0.9833 - val_loss: 0.1826 - val_accuracy: 0.9333\n",
            "Epoch 162/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9924\n",
            "Epoch 162: val_loss improved from 0.18193 to 0.17891, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0443 - accuracy: 0.9925 - val_loss: 0.1789 - val_accuracy: 0.9400\n",
            "Epoch 163/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9764\n",
            "Epoch 163: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0638 - accuracy: 0.9767 - val_loss: 0.1826 - val_accuracy: 0.9367\n",
            "Epoch 164/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9858\n",
            "Epoch 164: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.1811 - val_accuracy: 0.9333\n",
            "Epoch 165/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9831\n",
            "Epoch 165: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0508 - accuracy: 0.9825 - val_loss: 0.1823 - val_accuracy: 0.9367\n",
            "Epoch 166/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9900\n",
            "Epoch 166: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0373 - accuracy: 0.9900 - val_loss: 0.1823 - val_accuracy: 0.9333\n",
            "Epoch 167/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.9842\n",
            "Epoch 167: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0468 - accuracy: 0.9842 - val_loss: 0.1832 - val_accuracy: 0.9367\n",
            "Epoch 168/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9833\n",
            "Epoch 168: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0526 - accuracy: 0.9833 - val_loss: 0.1794 - val_accuracy: 0.9367\n",
            "Epoch 169/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9823\n",
            "Epoch 169: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 0.1808 - val_accuracy: 0.9367\n",
            "Epoch 170/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9825\n",
            "Epoch 170: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0461 - accuracy: 0.9825 - val_loss: 0.1796 - val_accuracy: 0.9367\n",
            "Epoch 171/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9848\n",
            "Epoch 171: val_loss did not improve from 0.17891\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0460 - accuracy: 0.9850 - val_loss: 0.1825 - val_accuracy: 0.9333\n",
            "Epoch 172/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9848\n",
            "Epoch 172: val_loss improved from 0.17891 to 0.17502, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 121ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.1750 - val_accuracy: 0.9367\n",
            "Epoch 173/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9873\n",
            "Epoch 173: val_loss did not improve from 0.17502\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0478 - accuracy: 0.9875 - val_loss: 0.1751 - val_accuracy: 0.9400\n",
            "Epoch 174/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9800\n",
            "Epoch 174: val_loss improved from 0.17502 to 0.17286, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0452 - accuracy: 0.9800 - val_loss: 0.1729 - val_accuracy: 0.9367\n",
            "Epoch 175/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9831\n",
            "Epoch 175: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0460 - accuracy: 0.9833 - val_loss: 0.1756 - val_accuracy: 0.9367\n",
            "Epoch 176/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9882\n",
            "Epoch 176: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0408 - accuracy: 0.9883 - val_loss: 0.1753 - val_accuracy: 0.9400\n",
            "Epoch 177/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9890\n",
            "Epoch 177: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0395 - accuracy: 0.9875 - val_loss: 0.1762 - val_accuracy: 0.9333\n",
            "Epoch 178/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9899\n",
            "Epoch 178: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.1747 - val_accuracy: 0.9333\n",
            "Epoch 179/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.9907\n",
            "Epoch 179: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0357 - accuracy: 0.9908 - val_loss: 0.1763 - val_accuracy: 0.9400\n",
            "Epoch 180/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9792\n",
            "Epoch 180: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0590 - accuracy: 0.9792 - val_loss: 0.1765 - val_accuracy: 0.9367\n",
            "Epoch 181/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9892\n",
            "Epoch 181: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.1747 - val_accuracy: 0.9400\n",
            "Epoch 182/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9882\n",
            "Epoch 182: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0407 - accuracy: 0.9883 - val_loss: 0.1813 - val_accuracy: 0.9367\n",
            "Epoch 183/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9890\n",
            "Epoch 183: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0360 - accuracy: 0.9892 - val_loss: 0.1773 - val_accuracy: 0.9400\n",
            "Epoch 184/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9840\n",
            "Epoch 184: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.1824 - val_accuracy: 0.9333\n",
            "Epoch 185/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9840\n",
            "Epoch 185: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0445 - accuracy: 0.9842 - val_loss: 0.1747 - val_accuracy: 0.9333\n",
            "Epoch 186/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9865\n",
            "Epoch 186: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0419 - accuracy: 0.9867 - val_loss: 0.1774 - val_accuracy: 0.9333\n",
            "Epoch 187/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9892\n",
            "Epoch 187: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.0358 - accuracy: 0.9892 - val_loss: 0.1761 - val_accuracy: 0.9400\n",
            "Epoch 188/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9941\n",
            "Epoch 188: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 3s 71ms/step - loss: 0.0276 - accuracy: 0.9942 - val_loss: 0.1812 - val_accuracy: 0.9367\n",
            "Epoch 189/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9932\n",
            "Epoch 189: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0309 - accuracy: 0.9933 - val_loss: 0.1804 - val_accuracy: 0.9267\n",
            "Epoch 190/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9797\n",
            "Epoch 190: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0516 - accuracy: 0.9800 - val_loss: 0.1788 - val_accuracy: 0.9367\n",
            "Epoch 191/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9924\n",
            "Epoch 191: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0266 - accuracy: 0.9925 - val_loss: 0.1754 - val_accuracy: 0.9333\n",
            "Epoch 192/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9900\n",
            "Epoch 192: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.1767 - val_accuracy: 0.9300\n",
            "Epoch 193/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0465 - accuracy: 0.9809\n",
            "Epoch 193: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0469 - accuracy: 0.9808 - val_loss: 0.1780 - val_accuracy: 0.9300\n",
            "Epoch 194/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9858\n",
            "Epoch 194: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0391 - accuracy: 0.9858 - val_loss: 0.1753 - val_accuracy: 0.9367\n",
            "Epoch 195/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9882\n",
            "Epoch 195: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0356 - accuracy: 0.9883 - val_loss: 0.1784 - val_accuracy: 0.9367\n",
            "Epoch 196/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9924\n",
            "Epoch 196: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0343 - accuracy: 0.9917 - val_loss: 0.1776 - val_accuracy: 0.9367\n",
            "Epoch 197/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9958\n",
            "Epoch 197: val_loss did not improve from 0.17286\n",
            "38/38 [==============================] - 3s 72ms/step - loss: 0.0262 - accuracy: 0.9958 - val_loss: 0.1759 - val_accuracy: 0.9333\n",
            "Epoch 198/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9882\n",
            "Epoch 198: val_loss improved from 0.17286 to 0.17159, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 145ms/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.1716 - val_accuracy: 0.9433\n",
            "Epoch 199/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9892\n",
            "Epoch 199: val_loss did not improve from 0.17159\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0387 - accuracy: 0.9892 - val_loss: 0.1762 - val_accuracy: 0.9400\n",
            "Epoch 200/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9856\n",
            "Epoch 200: val_loss did not improve from 0.17159\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0424 - accuracy: 0.9858 - val_loss: 0.1755 - val_accuracy: 0.9333\n",
            "Epoch 201/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9916\n",
            "Epoch 201: val_loss improved from 0.17159 to 0.17125, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0303 - accuracy: 0.9917 - val_loss: 0.1713 - val_accuracy: 0.9433\n",
            "Epoch 202/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9899\n",
            "Epoch 202: val_loss improved from 0.17125 to 0.16645, saving model to /content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 160ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.1665 - val_accuracy: 0.9400\n",
            "Epoch 203/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9958\n",
            "Epoch 203: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 3s 68ms/step - loss: 0.0270 - accuracy: 0.9958 - val_loss: 0.1698 - val_accuracy: 0.9400\n",
            "Epoch 204/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9925\n",
            "Epoch 204: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0268 - accuracy: 0.9925 - val_loss: 0.1733 - val_accuracy: 0.9367\n",
            "Epoch 205/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9925\n",
            "Epoch 205: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 3s 79ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.1744 - val_accuracy: 0.9400\n",
            "Epoch 206/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9917\n",
            "Epoch 206: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.1757 - val_accuracy: 0.9300\n",
            "Epoch 207/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9942\n",
            "Epoch 207: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0290 - accuracy: 0.9942 - val_loss: 0.1739 - val_accuracy: 0.9300\n",
            "Epoch 208/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9875\n",
            "Epoch 208: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 0.1731 - val_accuracy: 0.9300\n",
            "Epoch 209/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9900\n",
            "Epoch 209: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.1718 - val_accuracy: 0.9367\n",
            "Epoch 210/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9925\n",
            "Epoch 210: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0304 - accuracy: 0.9925 - val_loss: 0.1758 - val_accuracy: 0.9367\n",
            "Epoch 211/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9941\n",
            "Epoch 211: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.1737 - val_accuracy: 0.9333\n",
            "Epoch 212/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9899\n",
            "Epoch 212: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 0.1726 - val_accuracy: 0.9400\n",
            "Epoch 213/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9933\n",
            "Epoch 213: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.1689 - val_accuracy: 0.9433\n",
            "Epoch 214/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9916\n",
            "Epoch 214: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.0298 - accuracy: 0.9917 - val_loss: 0.1783 - val_accuracy: 0.9333\n",
            "Epoch 215/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9856\n",
            "Epoch 215: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 0.1826 - val_accuracy: 0.9267\n",
            "Epoch 216/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9890\n",
            "Epoch 216: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0299 - accuracy: 0.9883 - val_loss: 0.1757 - val_accuracy: 0.9400\n",
            "Epoch 217/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9907\n",
            "Epoch 217: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 0.1780 - val_accuracy: 0.9433\n",
            "Epoch 218/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9882\n",
            "Epoch 218: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.1811 - val_accuracy: 0.9367\n",
            "Epoch 219/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9899\n",
            "Epoch 219: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 0.1814 - val_accuracy: 0.9433\n",
            "Epoch 220/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9941\n",
            "Epoch 220: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.1752 - val_accuracy: 0.9467\n",
            "Epoch 221/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9942\n",
            "Epoch 221: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.1742 - val_accuracy: 0.9467\n",
            "Epoch 222/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9932\n",
            "Epoch 222: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.1769 - val_accuracy: 0.9433\n",
            "Epoch 223/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9848\n",
            "Epoch 223: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0391 - accuracy: 0.9850 - val_loss: 0.1749 - val_accuracy: 0.9367\n",
            "Epoch 224/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9925\n",
            "Epoch 224: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.1784 - val_accuracy: 0.9333\n",
            "Epoch 225/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9900\n",
            "Epoch 225: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0313 - accuracy: 0.9900 - val_loss: 0.1727 - val_accuracy: 0.9367\n",
            "Epoch 226/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9966\n",
            "Epoch 226: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 3s 72ms/step - loss: 0.0170 - accuracy: 0.9967 - val_loss: 0.1728 - val_accuracy: 0.9367\n",
            "Epoch 227/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9941\n",
            "Epoch 227: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.1743 - val_accuracy: 0.9400\n",
            "Epoch 228/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9916\n",
            "Epoch 228: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 0.1778 - val_accuracy: 0.9333\n",
            "Epoch 229/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9949\n",
            "Epoch 229: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0198 - accuracy: 0.9950 - val_loss: 0.1854 - val_accuracy: 0.9333\n",
            "Epoch 230/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9942\n",
            "Epoch 230: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0236 - accuracy: 0.9942 - val_loss: 0.1828 - val_accuracy: 0.9400\n",
            "Epoch 231/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9925\n",
            "Epoch 231: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.1771 - val_accuracy: 0.9367\n",
            "Epoch 232/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9900\n",
            "Epoch 232: val_loss did not improve from 0.16645\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.1762 - val_accuracy: 0.9367\n",
            "47/47 [==============================] - 2s 20ms/step - loss: 0.6043 - accuracy: 0.8653\n",
            "Test accuracy, 14 run, after finetuning: 0.8653333187103271\n",
            "Epoch 1/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.9654 - accuracy: 0.5600\n",
            "Epoch 1: val_loss improved from inf to 1.64748, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 47s 611ms/step - loss: 2.9654 - accuracy: 0.5600 - val_loss: 1.6475 - val_accuracy: 0.6500\n",
            "Epoch 2/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.9622 - accuracy: 0.6157\n",
            "Epoch 2: val_loss improved from 1.64748 to 1.16433, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 1.9635 - accuracy: 0.6133 - val_loss: 1.1643 - val_accuracy: 0.7100\n",
            "Epoch 3/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.4705 - accuracy: 0.6715\n",
            "Epoch 3: val_loss improved from 1.16433 to 0.92363, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 1.4700 - accuracy: 0.6725 - val_loss: 0.9236 - val_accuracy: 0.7267\n",
            "Epoch 4/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.1967 - accuracy: 0.6976\n",
            "Epoch 4: val_loss improved from 0.92363 to 0.78775, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 1.2110 - accuracy: 0.6958 - val_loss: 0.7878 - val_accuracy: 0.7533\n",
            "Epoch 5/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.0878 - accuracy: 0.7044\n",
            "Epoch 5: val_loss improved from 0.78775 to 0.70393, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 1.0866 - accuracy: 0.7050 - val_loss: 0.7039 - val_accuracy: 0.7600\n",
            "Epoch 6/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.9212 - accuracy: 0.7221\n",
            "Epoch 6: val_loss improved from 0.70393 to 0.65157, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.9248 - accuracy: 0.7208 - val_loss: 0.6516 - val_accuracy: 0.7767\n",
            "Epoch 7/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.8684 - accuracy: 0.7356\n",
            "Epoch 7: val_loss improved from 0.65157 to 0.60691, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.8645 - accuracy: 0.7350 - val_loss: 0.6069 - val_accuracy: 0.7767\n",
            "Epoch 8/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.8211 - accuracy: 0.7407\n",
            "Epoch 8: val_loss improved from 0.60691 to 0.57544, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.8229 - accuracy: 0.7408 - val_loss: 0.5754 - val_accuracy: 0.7833\n",
            "Epoch 9/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7553 - accuracy: 0.7416\n",
            "Epoch 9: val_loss improved from 0.57544 to 0.54266, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.7489 - accuracy: 0.7442 - val_loss: 0.5427 - val_accuracy: 0.8067\n",
            "Epoch 10/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7319 - accuracy: 0.7635\n",
            "Epoch 10: val_loss improved from 0.54266 to 0.51854, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.7277 - accuracy: 0.7633 - val_loss: 0.5185 - val_accuracy: 0.8167\n",
            "Epoch 11/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.7692\n",
            "Epoch 11: val_loss improved from 0.51854 to 0.49564, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.6932 - accuracy: 0.7692 - val_loss: 0.4956 - val_accuracy: 0.8233\n",
            "Epoch 12/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.7725\n",
            "Epoch 12: val_loss improved from 0.49564 to 0.47396, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.6560 - accuracy: 0.7725 - val_loss: 0.4740 - val_accuracy: 0.8400\n",
            "Epoch 13/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.7750\n",
            "Epoch 13: val_loss improved from 0.47396 to 0.45761, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.6489 - accuracy: 0.7750 - val_loss: 0.4576 - val_accuracy: 0.8400\n",
            "Epoch 14/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5982 - accuracy: 0.7950\n",
            "Epoch 14: val_loss improved from 0.45761 to 0.43690, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.5982 - accuracy: 0.7950 - val_loss: 0.4369 - val_accuracy: 0.8500\n",
            "Epoch 15/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5784 - accuracy: 0.8032\n",
            "Epoch 15: val_loss improved from 0.43690 to 0.42411, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.5783 - accuracy: 0.8033 - val_loss: 0.4241 - val_accuracy: 0.8633\n",
            "Epoch 16/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5941 - accuracy: 0.7992\n",
            "Epoch 16: val_loss improved from 0.42411 to 0.41847, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.5941 - accuracy: 0.7992 - val_loss: 0.4185 - val_accuracy: 0.8533\n",
            "Epoch 17/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5430 - accuracy: 0.8066\n",
            "Epoch 17: val_loss improved from 0.41847 to 0.40118, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.5387 - accuracy: 0.8075 - val_loss: 0.4012 - val_accuracy: 0.8733\n",
            "Epoch 18/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5262 - accuracy: 0.8176\n",
            "Epoch 18: val_loss improved from 0.40118 to 0.38707, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 134ms/step - loss: 0.5277 - accuracy: 0.8158 - val_loss: 0.3871 - val_accuracy: 0.8800\n",
            "Epoch 19/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5015 - accuracy: 0.8285\n",
            "Epoch 19: val_loss improved from 0.38707 to 0.37207, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.5034 - accuracy: 0.8275 - val_loss: 0.3721 - val_accuracy: 0.8800\n",
            "Epoch 20/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4731 - accuracy: 0.8269\n",
            "Epoch 20: val_loss improved from 0.37207 to 0.35930, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.4788 - accuracy: 0.8225 - val_loss: 0.3593 - val_accuracy: 0.8767\n",
            "Epoch 21/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.8392\n",
            "Epoch 21: val_loss improved from 0.35930 to 0.35222, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.4799 - accuracy: 0.8392 - val_loss: 0.3522 - val_accuracy: 0.8800\n",
            "Epoch 22/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4748 - accuracy: 0.8385\n",
            "Epoch 22: val_loss improved from 0.35222 to 0.33820, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.4749 - accuracy: 0.8400 - val_loss: 0.3382 - val_accuracy: 0.8833\n",
            "Epoch 23/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4449 - accuracy: 0.8438\n",
            "Epoch 23: val_loss improved from 0.33820 to 0.33101, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.4468 - accuracy: 0.8442 - val_loss: 0.3310 - val_accuracy: 0.8800\n",
            "Epoch 24/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.8400\n",
            "Epoch 24: val_loss improved from 0.33101 to 0.31945, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.4686 - accuracy: 0.8400 - val_loss: 0.3195 - val_accuracy: 0.8900\n",
            "Epoch 25/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.8567\n",
            "Epoch 25: val_loss improved from 0.31945 to 0.31186, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.4153 - accuracy: 0.8567 - val_loss: 0.3119 - val_accuracy: 0.8933\n",
            "Epoch 26/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4293 - accuracy: 0.8467\n",
            "Epoch 26: val_loss improved from 0.31186 to 0.29994, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.4293 - accuracy: 0.8467 - val_loss: 0.2999 - val_accuracy: 0.8967\n",
            "Epoch 27/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.8492\n",
            "Epoch 27: val_loss improved from 0.29994 to 0.29089, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.4086 - accuracy: 0.8492 - val_loss: 0.2909 - val_accuracy: 0.9033\n",
            "Epoch 28/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4099 - accuracy: 0.8581\n",
            "Epoch 28: val_loss improved from 0.29089 to 0.28710, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.4079 - accuracy: 0.8583 - val_loss: 0.2871 - val_accuracy: 0.9000\n",
            "Epoch 29/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8438\n",
            "Epoch 29: val_loss did not improve from 0.28710\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.4307 - accuracy: 0.8458 - val_loss: 0.2874 - val_accuracy: 0.8967\n",
            "Epoch 30/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8625\n",
            "Epoch 30: val_loss improved from 0.28710 to 0.27457, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.3812 - accuracy: 0.8625 - val_loss: 0.2746 - val_accuracy: 0.9100\n",
            "Epoch 31/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8708\n",
            "Epoch 31: val_loss did not improve from 0.27457\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.3851 - accuracy: 0.8708 - val_loss: 0.2770 - val_accuracy: 0.9000\n",
            "Epoch 32/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.8742\n",
            "Epoch 32: val_loss improved from 0.27457 to 0.26822, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 150ms/step - loss: 0.3645 - accuracy: 0.8750 - val_loss: 0.2682 - val_accuracy: 0.9100\n",
            "Epoch 33/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3462 - accuracy: 0.8910\n",
            "Epoch 33: val_loss improved from 0.26822 to 0.26149, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.3506 - accuracy: 0.8883 - val_loss: 0.2615 - val_accuracy: 0.9133\n",
            "Epoch 34/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.8750\n",
            "Epoch 34: val_loss improved from 0.26149 to 0.25528, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3566 - accuracy: 0.8750 - val_loss: 0.2553 - val_accuracy: 0.9133\n",
            "Epoch 35/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3549 - accuracy: 0.8741\n",
            "Epoch 35: val_loss did not improve from 0.25528\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.3538 - accuracy: 0.8733 - val_loss: 0.2573 - val_accuracy: 0.9100\n",
            "Epoch 36/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8936\n",
            "Epoch 36: val_loss improved from 0.25528 to 0.24995, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.3265 - accuracy: 0.8908 - val_loss: 0.2499 - val_accuracy: 0.9133\n",
            "Epoch 37/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3505 - accuracy: 0.8860\n",
            "Epoch 37: val_loss improved from 0.24995 to 0.24878, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.3477 - accuracy: 0.8867 - val_loss: 0.2488 - val_accuracy: 0.9167\n",
            "Epoch 38/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.8925\n",
            "Epoch 38: val_loss improved from 0.24878 to 0.23963, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.3167 - accuracy: 0.8925 - val_loss: 0.2396 - val_accuracy: 0.9233\n",
            "Epoch 39/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.9042\n",
            "Epoch 39: val_loss improved from 0.23963 to 0.23641, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 152ms/step - loss: 0.3106 - accuracy: 0.9042 - val_loss: 0.2364 - val_accuracy: 0.9200\n",
            "Epoch 40/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3018 - accuracy: 0.9012\n",
            "Epoch 40: val_loss improved from 0.23641 to 0.23498, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3015 - accuracy: 0.9008 - val_loss: 0.2350 - val_accuracy: 0.9200\n",
            "Epoch 41/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.8944\n",
            "Epoch 41: val_loss improved from 0.23498 to 0.22573, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.3132 - accuracy: 0.8950 - val_loss: 0.2257 - val_accuracy: 0.9233\n",
            "Epoch 42/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.9025\n",
            "Epoch 42: val_loss improved from 0.22573 to 0.21940, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.2895 - accuracy: 0.9025 - val_loss: 0.2194 - val_accuracy: 0.9267\n",
            "Epoch 43/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2824 - accuracy: 0.9046\n",
            "Epoch 43: val_loss improved from 0.21940 to 0.21788, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.2869 - accuracy: 0.9042 - val_loss: 0.2179 - val_accuracy: 0.9267\n",
            "Epoch 44/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.9113\n",
            "Epoch 44: val_loss improved from 0.21788 to 0.21487, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2739 - accuracy: 0.9108 - val_loss: 0.2149 - val_accuracy: 0.9267\n",
            "Epoch 45/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.9025\n",
            "Epoch 45: val_loss improved from 0.21487 to 0.20737, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.2832 - accuracy: 0.9025 - val_loss: 0.2074 - val_accuracy: 0.9333\n",
            "Epoch 46/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9122\n",
            "Epoch 46: val_loss did not improve from 0.20737\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.2665 - accuracy: 0.9133 - val_loss: 0.2106 - val_accuracy: 0.9333\n",
            "Epoch 47/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.9150\n",
            "Epoch 47: val_loss improved from 0.20737 to 0.20564, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2558 - accuracy: 0.9150 - val_loss: 0.2056 - val_accuracy: 0.9367\n",
            "Epoch 48/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.9083\n",
            "Epoch 48: val_loss improved from 0.20564 to 0.20555, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.2652 - accuracy: 0.9083 - val_loss: 0.2056 - val_accuracy: 0.9333\n",
            "Epoch 49/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.9108\n",
            "Epoch 49: val_loss improved from 0.20555 to 0.20452, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.2459 - accuracy: 0.9108 - val_loss: 0.2045 - val_accuracy: 0.9333\n",
            "Epoch 50/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2522 - accuracy: 0.9172\n",
            "Epoch 50: val_loss improved from 0.20452 to 0.20139, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2560 - accuracy: 0.9175 - val_loss: 0.2014 - val_accuracy: 0.9367\n",
            "Epoch 51/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9133\n",
            "Epoch 51: val_loss improved from 0.20139 to 0.19721, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.2548 - accuracy: 0.9133 - val_loss: 0.1972 - val_accuracy: 0.9367\n",
            "Epoch 52/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9108\n",
            "Epoch 52: val_loss improved from 0.19721 to 0.19092, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 0.2528 - accuracy: 0.9108 - val_loss: 0.1909 - val_accuracy: 0.9367\n",
            "Epoch 53/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9267\n",
            "Epoch 53: val_loss improved from 0.19092 to 0.18673, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2311 - accuracy: 0.9267 - val_loss: 0.1867 - val_accuracy: 0.9400\n",
            "Epoch 54/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.9292\n",
            "Epoch 54: val_loss did not improve from 0.18673\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.2205 - accuracy: 0.9292 - val_loss: 0.1896 - val_accuracy: 0.9367\n",
            "Epoch 55/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2512 - accuracy: 0.9155\n",
            "Epoch 55: val_loss did not improve from 0.18673\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.2488 - accuracy: 0.9167 - val_loss: 0.1917 - val_accuracy: 0.9333\n",
            "Epoch 56/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.9167\n",
            "Epoch 56: val_loss improved from 0.18673 to 0.18504, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.2443 - accuracy: 0.9167 - val_loss: 0.1850 - val_accuracy: 0.9400\n",
            "Epoch 57/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9231\n",
            "Epoch 57: val_loss improved from 0.18504 to 0.18465, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2168 - accuracy: 0.9242 - val_loss: 0.1846 - val_accuracy: 0.9400\n",
            "Epoch 58/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9200\n",
            "Epoch 58: val_loss improved from 0.18465 to 0.18107, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2240 - accuracy: 0.9200 - val_loss: 0.1811 - val_accuracy: 0.9400\n",
            "Epoch 59/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9267\n",
            "Epoch 59: val_loss improved from 0.18107 to 0.17220, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.2232 - accuracy: 0.9267 - val_loss: 0.1722 - val_accuracy: 0.9500\n",
            "Epoch 60/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9383\n",
            "Epoch 60: val_loss improved from 0.17220 to 0.17060, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 135ms/step - loss: 0.2026 - accuracy: 0.9383 - val_loss: 0.1706 - val_accuracy: 0.9533\n",
            "Epoch 61/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9248\n",
            "Epoch 61: val_loss did not improve from 0.17060\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.2238 - accuracy: 0.9250 - val_loss: 0.1728 - val_accuracy: 0.9400\n",
            "Epoch 62/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9258\n",
            "Epoch 62: val_loss did not improve from 0.17060\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1999 - accuracy: 0.9258 - val_loss: 0.1722 - val_accuracy: 0.9467\n",
            "Epoch 63/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9383\n",
            "Epoch 63: val_loss improved from 0.17060 to 0.16822, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.1945 - accuracy: 0.9383 - val_loss: 0.1682 - val_accuracy: 0.9433\n",
            "Epoch 64/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9392\n",
            "Epoch 64: val_loss improved from 0.16822 to 0.16616, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 154ms/step - loss: 0.1941 - accuracy: 0.9400 - val_loss: 0.1662 - val_accuracy: 0.9500\n",
            "Epoch 65/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1889 - accuracy: 0.9409\n",
            "Epoch 65: val_loss did not improve from 0.16616\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.1906 - accuracy: 0.9400 - val_loss: 0.1667 - val_accuracy: 0.9433\n",
            "Epoch 66/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1879 - accuracy: 0.9358\n",
            "Epoch 66: val_loss did not improve from 0.16616\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1862 - accuracy: 0.9367 - val_loss: 0.1739 - val_accuracy: 0.9400\n",
            "Epoch 67/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1800 - accuracy: 0.9358\n",
            "Epoch 67: val_loss did not improve from 0.16616\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1788 - accuracy: 0.9367 - val_loss: 0.1665 - val_accuracy: 0.9467\n",
            "Epoch 68/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1940 - accuracy: 0.9350\n",
            "Epoch 68: val_loss improved from 0.16616 to 0.16008, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.1979 - accuracy: 0.9325 - val_loss: 0.1601 - val_accuracy: 0.9467\n",
            "Epoch 69/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9358\n",
            "Epoch 69: val_loss improved from 0.16008 to 0.15753, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.1769 - accuracy: 0.9358 - val_loss: 0.1575 - val_accuracy: 0.9600\n",
            "Epoch 70/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9468\n",
            "Epoch 70: val_loss improved from 0.15753 to 0.15676, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.1719 - accuracy: 0.9475 - val_loss: 0.1568 - val_accuracy: 0.9600\n",
            "Epoch 71/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9442\n",
            "Epoch 71: val_loss did not improve from 0.15676\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1630 - accuracy: 0.9442 - val_loss: 0.1580 - val_accuracy: 0.9467\n",
            "Epoch 72/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9475\n",
            "Epoch 72: val_loss improved from 0.15676 to 0.15184, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.1630 - accuracy: 0.9475 - val_loss: 0.1518 - val_accuracy: 0.9567\n",
            "Epoch 73/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9575\n",
            "Epoch 73: val_loss improved from 0.15184 to 0.14922, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 0.1506 - accuracy: 0.9575 - val_loss: 0.1492 - val_accuracy: 0.9467\n",
            "Epoch 74/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9476\n",
            "Epoch 74: val_loss did not improve from 0.14922\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1617 - accuracy: 0.9475 - val_loss: 0.1517 - val_accuracy: 0.9500\n",
            "Epoch 75/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9417\n",
            "Epoch 75: val_loss did not improve from 0.14922\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1662 - accuracy: 0.9417 - val_loss: 0.1524 - val_accuracy: 0.9467\n",
            "Epoch 76/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.9442\n",
            "Epoch 76: val_loss improved from 0.14922 to 0.14353, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.1491 - accuracy: 0.9442 - val_loss: 0.1435 - val_accuracy: 0.9533\n",
            "Epoch 77/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9425\n",
            "Epoch 77: val_loss did not improve from 0.14353\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1726 - accuracy: 0.9425 - val_loss: 0.1465 - val_accuracy: 0.9500\n",
            "Epoch 78/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9535\n",
            "Epoch 78: val_loss improved from 0.14353 to 0.13967, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 0.1599 - accuracy: 0.9517 - val_loss: 0.1397 - val_accuracy: 0.9567\n",
            "Epoch 79/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9450\n",
            "Epoch 79: val_loss did not improve from 0.13967\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1498 - accuracy: 0.9450 - val_loss: 0.1444 - val_accuracy: 0.9633\n",
            "Epoch 80/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.9417\n",
            "Epoch 80: val_loss did not improve from 0.13967\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1646 - accuracy: 0.9417 - val_loss: 0.1461 - val_accuracy: 0.9500\n",
            "Epoch 81/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9502\n",
            "Epoch 81: val_loss did not improve from 0.13967\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.1554 - accuracy: 0.9500 - val_loss: 0.1410 - val_accuracy: 0.9600\n",
            "Epoch 82/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9426\n",
            "Epoch 82: val_loss improved from 0.13967 to 0.13293, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.1604 - accuracy: 0.9433 - val_loss: 0.1329 - val_accuracy: 0.9600\n",
            "Epoch 83/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1408 - accuracy: 0.9519\n",
            "Epoch 83: val_loss did not improve from 0.13293\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1431 - accuracy: 0.9500 - val_loss: 0.1370 - val_accuracy: 0.9567\n",
            "Epoch 84/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1510 - accuracy: 0.9434\n",
            "Epoch 84: val_loss did not improve from 0.13293\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1493 - accuracy: 0.9442 - val_loss: 0.1410 - val_accuracy: 0.9533\n",
            "Epoch 85/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1442 - accuracy: 0.9510\n",
            "Epoch 85: val_loss improved from 0.13293 to 0.13124, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 0.1429 - accuracy: 0.9517 - val_loss: 0.1312 - val_accuracy: 0.9600\n",
            "Epoch 86/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9625\n",
            "Epoch 86: val_loss did not improve from 0.13124\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.1277 - accuracy: 0.9625 - val_loss: 0.1343 - val_accuracy: 0.9567\n",
            "Epoch 87/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1340 - accuracy: 0.9531\n",
            "Epoch 87: val_loss did not improve from 0.13124\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.1372 - accuracy: 0.9517 - val_loss: 0.1339 - val_accuracy: 0.9600\n",
            "Epoch 88/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.9550\n",
            "Epoch 88: val_loss did not improve from 0.13124\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.1437 - accuracy: 0.9550 - val_loss: 0.1326 - val_accuracy: 0.9633\n",
            "Epoch 89/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9561\n",
            "Epoch 89: val_loss improved from 0.13124 to 0.13072, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1350 - accuracy: 0.9567 - val_loss: 0.1307 - val_accuracy: 0.9567\n",
            "Epoch 90/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9567\n",
            "Epoch 90: val_loss did not improve from 0.13072\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.1368 - accuracy: 0.9567 - val_loss: 0.1314 - val_accuracy: 0.9567\n",
            "Epoch 91/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9675\n",
            "Epoch 91: val_loss improved from 0.13072 to 0.12470, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.1210 - accuracy: 0.9675 - val_loss: 0.1247 - val_accuracy: 0.9600\n",
            "Epoch 92/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1199 - accuracy: 0.9611\n",
            "Epoch 92: val_loss did not improve from 0.12470\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.1207 - accuracy: 0.9600 - val_loss: 0.1303 - val_accuracy: 0.9567\n",
            "Epoch 93/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 0.9527\n",
            "Epoch 93: val_loss did not improve from 0.12470\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.1252 - accuracy: 0.9533 - val_loss: 0.1257 - val_accuracy: 0.9600\n",
            "Epoch 94/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9544\n",
            "Epoch 94: val_loss did not improve from 0.12470\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1382 - accuracy: 0.9542 - val_loss: 0.1255 - val_accuracy: 0.9600\n",
            "Epoch 95/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1252 - accuracy: 0.9620\n",
            "Epoch 95: val_loss improved from 0.12470 to 0.12274, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.1291 - accuracy: 0.9592 - val_loss: 0.1227 - val_accuracy: 0.9633\n",
            "Epoch 96/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9645\n",
            "Epoch 96: val_loss did not improve from 0.12274\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1209 - accuracy: 0.9642 - val_loss: 0.1313 - val_accuracy: 0.9633\n",
            "Epoch 97/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9611\n",
            "Epoch 97: val_loss improved from 0.12274 to 0.12066, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.1147 - accuracy: 0.9617 - val_loss: 0.1207 - val_accuracy: 0.9667\n",
            "Epoch 98/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9586\n",
            "Epoch 98: val_loss did not improve from 0.12066\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1248 - accuracy: 0.9592 - val_loss: 0.1239 - val_accuracy: 0.9633\n",
            "Epoch 99/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9608\n",
            "Epoch 99: val_loss did not improve from 0.12066\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1151 - accuracy: 0.9608 - val_loss: 0.1222 - val_accuracy: 0.9633\n",
            "Epoch 100/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1097 - accuracy: 0.9696\n",
            "Epoch 100: val_loss did not improve from 0.12066\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1116 - accuracy: 0.9683 - val_loss: 0.1214 - val_accuracy: 0.9633\n",
            "Epoch 101/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9592\n",
            "Epoch 101: val_loss improved from 0.12066 to 0.12035, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 137ms/step - loss: 0.1146 - accuracy: 0.9592 - val_loss: 0.1204 - val_accuracy: 0.9600\n",
            "Epoch 102/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9650\n",
            "Epoch 102: val_loss improved from 0.12035 to 0.12002, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.1012 - accuracy: 0.9650 - val_loss: 0.1200 - val_accuracy: 0.9667\n",
            "Epoch 103/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9675\n",
            "Epoch 103: val_loss improved from 0.12002 to 0.11510, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1094 - accuracy: 0.9675 - val_loss: 0.1151 - val_accuracy: 0.9667\n",
            "Epoch 104/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9654\n",
            "Epoch 104: val_loss did not improve from 0.11510\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1080 - accuracy: 0.9650 - val_loss: 0.1177 - val_accuracy: 0.9633\n",
            "Epoch 105/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9721\n",
            "Epoch 105: val_loss did not improve from 0.11510\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1008 - accuracy: 0.9700 - val_loss: 0.1189 - val_accuracy: 0.9700\n",
            "Epoch 106/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9683\n",
            "Epoch 106: val_loss did not improve from 0.11510\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.1036 - accuracy: 0.9683 - val_loss: 0.1168 - val_accuracy: 0.9700\n",
            "Epoch 107/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0856 - accuracy: 0.9679\n",
            "Epoch 107: val_loss improved from 0.11510 to 0.11369, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.0859 - accuracy: 0.9675 - val_loss: 0.1137 - val_accuracy: 0.9700\n",
            "Epoch 108/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9654\n",
            "Epoch 108: val_loss did not improve from 0.11369\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0985 - accuracy: 0.9650 - val_loss: 0.1178 - val_accuracy: 0.9667\n",
            "Epoch 109/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9645\n",
            "Epoch 109: val_loss improved from 0.11369 to 0.11242, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.1033 - accuracy: 0.9633 - val_loss: 0.1124 - val_accuracy: 0.9700\n",
            "Epoch 110/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9592\n",
            "Epoch 110: val_loss improved from 0.11242 to 0.11216, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.1121 - accuracy: 0.9592 - val_loss: 0.1122 - val_accuracy: 0.9700\n",
            "Epoch 111/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.9586\n",
            "Epoch 111: val_loss did not improve from 0.11216\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.1089 - accuracy: 0.9592 - val_loss: 0.1132 - val_accuracy: 0.9700\n",
            "Epoch 112/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0928 - accuracy: 0.9662\n",
            "Epoch 112: val_loss improved from 0.11216 to 0.11097, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0917 - accuracy: 0.9667 - val_loss: 0.1110 - val_accuracy: 0.9700\n",
            "Epoch 113/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.9683\n",
            "Epoch 113: val_loss improved from 0.11097 to 0.10743, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0936 - accuracy: 0.9683 - val_loss: 0.1074 - val_accuracy: 0.9700\n",
            "Epoch 114/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9667\n",
            "Epoch 114: val_loss did not improve from 0.10743\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0934 - accuracy: 0.9667 - val_loss: 0.1174 - val_accuracy: 0.9600\n",
            "Epoch 115/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9642\n",
            "Epoch 115: val_loss did not improve from 0.10743\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.1006 - accuracy: 0.9642 - val_loss: 0.1120 - val_accuracy: 0.9667\n",
            "Epoch 116/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9700\n",
            "Epoch 116: val_loss did not improve from 0.10743\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0868 - accuracy: 0.9700 - val_loss: 0.1107 - val_accuracy: 0.9700\n",
            "Epoch 117/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9679\n",
            "Epoch 117: val_loss did not improve from 0.10743\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0929 - accuracy: 0.9683 - val_loss: 0.1106 - val_accuracy: 0.9700\n",
            "Epoch 118/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9650\n",
            "Epoch 118: val_loss did not improve from 0.10743\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0955 - accuracy: 0.9650 - val_loss: 0.1095 - val_accuracy: 0.9700\n",
            "Epoch 119/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1073 - accuracy: 0.9620\n",
            "Epoch 119: val_loss did not improve from 0.10743\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1095 - accuracy: 0.9617 - val_loss: 0.1101 - val_accuracy: 0.9700\n",
            "Epoch 120/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 0.9730\n",
            "Epoch 120: val_loss improved from 0.10743 to 0.10471, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 148ms/step - loss: 0.0879 - accuracy: 0.9733 - val_loss: 0.1047 - val_accuracy: 0.9700\n",
            "Epoch 121/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9671\n",
            "Epoch 121: val_loss did not improve from 0.10471\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0943 - accuracy: 0.9675 - val_loss: 0.1049 - val_accuracy: 0.9700\n",
            "Epoch 122/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9783\n",
            "Epoch 122: val_loss improved from 0.10471 to 0.10405, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0786 - accuracy: 0.9783 - val_loss: 0.1040 - val_accuracy: 0.9733\n",
            "Epoch 123/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 0.9637\n",
            "Epoch 123: val_loss improved from 0.10405 to 0.10225, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.0972 - accuracy: 0.9625 - val_loss: 0.1022 - val_accuracy: 0.9733\n",
            "Epoch 124/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9767\n",
            "Epoch 124: val_loss did not improve from 0.10225\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.0773 - accuracy: 0.9767 - val_loss: 0.1123 - val_accuracy: 0.9700\n",
            "Epoch 125/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 0.9747\n",
            "Epoch 125: val_loss did not improve from 0.10225\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0812 - accuracy: 0.9750 - val_loss: 0.1065 - val_accuracy: 0.9700\n",
            "Epoch 126/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9758\n",
            "Epoch 126: val_loss did not improve from 0.10225\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0736 - accuracy: 0.9758 - val_loss: 0.1133 - val_accuracy: 0.9633\n",
            "Epoch 127/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9692\n",
            "Epoch 127: val_loss did not improve from 0.10225\n",
            "38/38 [==============================] - 2s 66ms/step - loss: 0.0817 - accuracy: 0.9692 - val_loss: 0.1093 - val_accuracy: 0.9700\n",
            "Epoch 128/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9721\n",
            "Epoch 128: val_loss did not improve from 0.10225\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0816 - accuracy: 0.9717 - val_loss: 0.1072 - val_accuracy: 0.9633\n",
            "Epoch 129/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9667\n",
            "Epoch 129: val_loss did not improve from 0.10225\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0871 - accuracy: 0.9667 - val_loss: 0.1054 - val_accuracy: 0.9667\n",
            "Epoch 130/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9750\n",
            "Epoch 130: val_loss improved from 0.10225 to 0.10111, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 145ms/step - loss: 0.0784 - accuracy: 0.9750 - val_loss: 0.1011 - val_accuracy: 0.9700\n",
            "Epoch 131/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9620\n",
            "Epoch 131: val_loss did not improve from 0.10111\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0961 - accuracy: 0.9625 - val_loss: 0.1012 - val_accuracy: 0.9700\n",
            "Epoch 132/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9713\n",
            "Epoch 132: val_loss improved from 0.10111 to 0.10084, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 0.0746 - accuracy: 0.9717 - val_loss: 0.1008 - val_accuracy: 0.9700\n",
            "Epoch 133/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9692\n",
            "Epoch 133: val_loss did not improve from 0.10084\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0823 - accuracy: 0.9692 - val_loss: 0.1021 - val_accuracy: 0.9700\n",
            "Epoch 134/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9730\n",
            "Epoch 134: val_loss improved from 0.10084 to 0.09122, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0818 - accuracy: 0.9708 - val_loss: 0.0912 - val_accuracy: 0.9700\n",
            "Epoch 135/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9747\n",
            "Epoch 135: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0766 - accuracy: 0.9750 - val_loss: 0.1033 - val_accuracy: 0.9700\n",
            "Epoch 136/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9738\n",
            "Epoch 136: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0715 - accuracy: 0.9733 - val_loss: 0.0960 - val_accuracy: 0.9700\n",
            "Epoch 137/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9721\n",
            "Epoch 137: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0747 - accuracy: 0.9725 - val_loss: 0.0982 - val_accuracy: 0.9667\n",
            "Epoch 138/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.9733\n",
            "Epoch 138: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0792 - accuracy: 0.9733 - val_loss: 0.0916 - val_accuracy: 0.9700\n",
            "Epoch 139/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9817\n",
            "Epoch 139: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 3s 78ms/step - loss: 0.0667 - accuracy: 0.9817 - val_loss: 0.0912 - val_accuracy: 0.9700\n",
            "Epoch 140/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9742\n",
            "Epoch 140: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0682 - accuracy: 0.9742 - val_loss: 0.0984 - val_accuracy: 0.9667\n",
            "Epoch 141/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9806\n",
            "Epoch 141: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0655 - accuracy: 0.9808 - val_loss: 0.0968 - val_accuracy: 0.9700\n",
            "Epoch 142/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9814\n",
            "Epoch 142: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0651 - accuracy: 0.9817 - val_loss: 0.0951 - val_accuracy: 0.9667\n",
            "Epoch 143/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9783\n",
            "Epoch 143: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.1037 - val_accuracy: 0.9700\n",
            "Epoch 144/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9755\n",
            "Epoch 144: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.0965 - val_accuracy: 0.9667\n",
            "Epoch 145/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9873\n",
            "Epoch 145: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0517 - accuracy: 0.9875 - val_loss: 0.0955 - val_accuracy: 0.9700\n",
            "Epoch 146/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9814\n",
            "Epoch 146: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0739 - accuracy: 0.9808 - val_loss: 0.1019 - val_accuracy: 0.9700\n",
            "Epoch 147/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9856\n",
            "Epoch 147: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0556 - accuracy: 0.9850 - val_loss: 0.1005 - val_accuracy: 0.9700\n",
            "Epoch 148/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0668 - accuracy: 0.9747\n",
            "Epoch 148: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0683 - accuracy: 0.9742 - val_loss: 0.1022 - val_accuracy: 0.9600\n",
            "Epoch 149/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9800\n",
            "Epoch 149: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0625 - accuracy: 0.9800 - val_loss: 0.0942 - val_accuracy: 0.9667\n",
            "Epoch 150/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9867\n",
            "Epoch 150: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 3s 70ms/step - loss: 0.0548 - accuracy: 0.9867 - val_loss: 0.0999 - val_accuracy: 0.9667\n",
            "Epoch 151/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9783\n",
            "Epoch 151: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0631 - accuracy: 0.9783 - val_loss: 0.0958 - val_accuracy: 0.9667\n",
            "Epoch 152/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9842\n",
            "Epoch 152: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0505 - accuracy: 0.9842 - val_loss: 0.1029 - val_accuracy: 0.9633\n",
            "Epoch 153/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9789\n",
            "Epoch 153: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0688 - accuracy: 0.9783 - val_loss: 0.0955 - val_accuracy: 0.9667\n",
            "Epoch 154/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9806\n",
            "Epoch 154: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.0980 - val_accuracy: 0.9667\n",
            "Epoch 155/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0636 - accuracy: 0.9792\n",
            "Epoch 155: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0612 - accuracy: 0.9800 - val_loss: 0.0998 - val_accuracy: 0.9667\n",
            "Epoch 156/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9797\n",
            "Epoch 156: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.0983 - val_accuracy: 0.9667\n",
            "Epoch 157/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9758\n",
            "Epoch 157: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0666 - accuracy: 0.9758 - val_loss: 0.0968 - val_accuracy: 0.9667\n",
            "Epoch 158/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9840\n",
            "Epoch 158: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0536 - accuracy: 0.9842 - val_loss: 0.0935 - val_accuracy: 0.9667\n",
            "Epoch 159/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9772\n",
            "Epoch 159: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0585 - accuracy: 0.9775 - val_loss: 0.0926 - val_accuracy: 0.9667\n",
            "Epoch 160/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9800\n",
            "Epoch 160: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0546 - accuracy: 0.9800 - val_loss: 0.0946 - val_accuracy: 0.9667\n",
            "Epoch 161/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9848\n",
            "Epoch 161: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0532 - accuracy: 0.9850 - val_loss: 0.0937 - val_accuracy: 0.9667\n",
            "Epoch 162/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9789\n",
            "Epoch 162: val_loss did not improve from 0.09122\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0601 - accuracy: 0.9792 - val_loss: 0.0992 - val_accuracy: 0.9633\n",
            "Epoch 163/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0508 - accuracy: 0.9852\n",
            "Epoch 163: val_loss improved from 0.09122 to 0.08875, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 153ms/step - loss: 0.0493 - accuracy: 0.9858 - val_loss: 0.0888 - val_accuracy: 0.9667\n",
            "Epoch 164/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9865\n",
            "Epoch 164: val_loss did not improve from 0.08875\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0421 - accuracy: 0.9858 - val_loss: 0.0922 - val_accuracy: 0.9667\n",
            "Epoch 165/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9772\n",
            "Epoch 165: val_loss did not improve from 0.08875\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0618 - accuracy: 0.9767 - val_loss: 0.0970 - val_accuracy: 0.9667\n",
            "Epoch 166/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9831\n",
            "Epoch 166: val_loss improved from 0.08875 to 0.08865, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0445 - accuracy: 0.9833 - val_loss: 0.0886 - val_accuracy: 0.9667\n",
            "Epoch 167/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9873\n",
            "Epoch 167: val_loss did not improve from 0.08865\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0510 - accuracy: 0.9875 - val_loss: 0.0978 - val_accuracy: 0.9633\n",
            "Epoch 168/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9800\n",
            "Epoch 168: val_loss improved from 0.08865 to 0.08836, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.0605 - accuracy: 0.9800 - val_loss: 0.0884 - val_accuracy: 0.9700\n",
            "Epoch 169/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9842\n",
            "Epoch 169: val_loss did not improve from 0.08836\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0475 - accuracy: 0.9842 - val_loss: 0.0932 - val_accuracy: 0.9667\n",
            "Epoch 170/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9873\n",
            "Epoch 170: val_loss did not improve from 0.08836\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0430 - accuracy: 0.9867 - val_loss: 0.0901 - val_accuracy: 0.9667\n",
            "Epoch 171/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9823\n",
            "Epoch 171: val_loss did not improve from 0.08836\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.0919 - val_accuracy: 0.9700\n",
            "Epoch 172/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9823\n",
            "Epoch 172: val_loss improved from 0.08836 to 0.08257, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.0547 - accuracy: 0.9825 - val_loss: 0.0826 - val_accuracy: 0.9767\n",
            "Epoch 173/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9856\n",
            "Epoch 173: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0466 - accuracy: 0.9858 - val_loss: 0.0879 - val_accuracy: 0.9733\n",
            "Epoch 174/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9892\n",
            "Epoch 174: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0389 - accuracy: 0.9892 - val_loss: 0.0843 - val_accuracy: 0.9700\n",
            "Epoch 175/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9840\n",
            "Epoch 175: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0477 - accuracy: 0.9842 - val_loss: 0.0927 - val_accuracy: 0.9700\n",
            "Epoch 176/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9831\n",
            "Epoch 176: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0514 - accuracy: 0.9833 - val_loss: 0.0948 - val_accuracy: 0.9667\n",
            "Epoch 177/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9840\n",
            "Epoch 177: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0421 - accuracy: 0.9842 - val_loss: 0.0919 - val_accuracy: 0.9700\n",
            "Epoch 178/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9823\n",
            "Epoch 178: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 3s 74ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.0876 - val_accuracy: 0.9700\n",
            "Epoch 179/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0443 - accuracy: 0.9844\n",
            "Epoch 179: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 0.0868 - val_accuracy: 0.9700\n",
            "Epoch 180/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9873\n",
            "Epoch 180: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 3s 67ms/step - loss: 0.0439 - accuracy: 0.9875 - val_loss: 0.0862 - val_accuracy: 0.9733\n",
            "Epoch 181/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9806\n",
            "Epoch 181: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0552 - accuracy: 0.9808 - val_loss: 0.0882 - val_accuracy: 0.9700\n",
            "Epoch 182/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0486 - accuracy: 0.9856\n",
            "Epoch 182: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0484 - accuracy: 0.9858 - val_loss: 0.0883 - val_accuracy: 0.9700\n",
            "Epoch 183/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9890\n",
            "Epoch 183: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0393 - accuracy: 0.9892 - val_loss: 0.0893 - val_accuracy: 0.9700\n",
            "Epoch 184/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9848\n",
            "Epoch 184: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 0.0830 - val_accuracy: 0.9767\n",
            "Epoch 185/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9833\n",
            "Epoch 185: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.0398 - accuracy: 0.9833 - val_loss: 0.0833 - val_accuracy: 0.9800\n",
            "Epoch 186/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9856\n",
            "Epoch 186: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0385 - accuracy: 0.9858 - val_loss: 0.0852 - val_accuracy: 0.9733\n",
            "Epoch 187/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9865\n",
            "Epoch 187: val_loss did not improve from 0.08257\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0481 - accuracy: 0.9867 - val_loss: 0.0895 - val_accuracy: 0.9733\n",
            "Epoch 188/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9858\n",
            "Epoch 188: val_loss improved from 0.08257 to 0.08231, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 137ms/step - loss: 0.0411 - accuracy: 0.9858 - val_loss: 0.0823 - val_accuracy: 0.9767\n",
            "Epoch 189/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9831\n",
            "Epoch 189: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.0884 - val_accuracy: 0.9700\n",
            "Epoch 190/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9916\n",
            "Epoch 190: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 0.0860 - val_accuracy: 0.9767\n",
            "Epoch 191/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9890\n",
            "Epoch 191: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.0846 - val_accuracy: 0.9767\n",
            "Epoch 192/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9890\n",
            "Epoch 192: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0879 - val_accuracy: 0.9733\n",
            "Epoch 193/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9867\n",
            "Epoch 193: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 3s 70ms/step - loss: 0.0397 - accuracy: 0.9867 - val_loss: 0.0849 - val_accuracy: 0.9733\n",
            "Epoch 194/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9883\n",
            "Epoch 194: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.0901 - val_accuracy: 0.9767\n",
            "Epoch 195/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9883\n",
            "Epoch 195: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0307 - accuracy: 0.9883 - val_loss: 0.0913 - val_accuracy: 0.9733\n",
            "Epoch 196/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 0.9831\n",
            "Epoch 196: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0446 - accuracy: 0.9833 - val_loss: 0.0874 - val_accuracy: 0.9733\n",
            "Epoch 197/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9865\n",
            "Epoch 197: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0496 - accuracy: 0.9867 - val_loss: 0.0930 - val_accuracy: 0.9667\n",
            "Epoch 198/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9908\n",
            "Epoch 198: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 0.0908 - val_accuracy: 0.9700\n",
            "Epoch 199/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9883\n",
            "Epoch 199: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.0907 - val_accuracy: 0.9700\n",
            "Epoch 200/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9842\n",
            "Epoch 200: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.0930 - val_accuracy: 0.9633\n",
            "Epoch 201/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9865\n",
            "Epoch 201: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0391 - accuracy: 0.9867 - val_loss: 0.0832 - val_accuracy: 0.9700\n",
            "Epoch 202/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9882\n",
            "Epoch 202: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0331 - accuracy: 0.9883 - val_loss: 0.0885 - val_accuracy: 0.9733\n",
            "Epoch 203/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9873\n",
            "Epoch 203: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0330 - accuracy: 0.9875 - val_loss: 0.0920 - val_accuracy: 0.9700\n",
            "Epoch 204/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9908\n",
            "Epoch 204: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0351 - accuracy: 0.9908 - val_loss: 0.0876 - val_accuracy: 0.9700\n",
            "Epoch 205/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9882\n",
            "Epoch 205: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.0839 - val_accuracy: 0.9733\n",
            "Epoch 206/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9873\n",
            "Epoch 206: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0319 - accuracy: 0.9875 - val_loss: 0.0835 - val_accuracy: 0.9767\n",
            "Epoch 207/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0290 - accuracy: 0.9905\n",
            "Epoch 207: val_loss did not improve from 0.08231\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.0929 - val_accuracy: 0.9700\n",
            "Epoch 208/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0374 - accuracy: 0.9887\n",
            "Epoch 208: val_loss improved from 0.08231 to 0.08065, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 140ms/step - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.0806 - val_accuracy: 0.9767\n",
            "Epoch 209/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9858\n",
            "Epoch 209: val_loss improved from 0.08065 to 0.08040, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 119ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.0804 - val_accuracy: 0.9800\n",
            "Epoch 210/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9949\n",
            "Epoch 210: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0231 - accuracy: 0.9950 - val_loss: 0.0893 - val_accuracy: 0.9733\n",
            "Epoch 211/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9941\n",
            "Epoch 211: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0300 - accuracy: 0.9942 - val_loss: 0.0876 - val_accuracy: 0.9733\n",
            "Epoch 212/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9856\n",
            "Epoch 212: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0417 - accuracy: 0.9858 - val_loss: 0.0939 - val_accuracy: 0.9667\n",
            "Epoch 213/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9916\n",
            "Epoch 213: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0307 - accuracy: 0.9917 - val_loss: 0.0841 - val_accuracy: 0.9700\n",
            "Epoch 214/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9900\n",
            "Epoch 214: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0361 - accuracy: 0.9900 - val_loss: 0.0840 - val_accuracy: 0.9800\n",
            "Epoch 215/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9916\n",
            "Epoch 215: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 62ms/step - loss: 0.0306 - accuracy: 0.9917 - val_loss: 0.0942 - val_accuracy: 0.9700\n",
            "Epoch 216/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9899\n",
            "Epoch 216: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0823 - val_accuracy: 0.9800\n",
            "Epoch 217/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9932\n",
            "Epoch 217: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
            "Epoch 218/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9882\n",
            "Epoch 218: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0322 - accuracy: 0.9883 - val_loss: 0.0825 - val_accuracy: 0.9800\n",
            "Epoch 219/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9900\n",
            "Epoch 219: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.0857 - val_accuracy: 0.9767\n",
            "Epoch 220/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9867\n",
            "Epoch 220: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 3s 70ms/step - loss: 0.0366 - accuracy: 0.9867 - val_loss: 0.0832 - val_accuracy: 0.9733\n",
            "Epoch 221/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9949\n",
            "Epoch 221: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.0849 - val_accuracy: 0.9800\n",
            "Epoch 222/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9916\n",
            "Epoch 222: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0295 - accuracy: 0.9917 - val_loss: 0.0889 - val_accuracy: 0.9667\n",
            "Epoch 223/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0327 - accuracy: 0.9905\n",
            "Epoch 223: val_loss did not improve from 0.08040\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.0866 - val_accuracy: 0.9733\n",
            "Epoch 224/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9907\n",
            "Epoch 224: val_loss improved from 0.08040 to 0.08026, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 147ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.0803 - val_accuracy: 0.9800\n",
            "Epoch 225/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9924\n",
            "Epoch 225: val_loss improved from 0.08026 to 0.08018, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.0802 - val_accuracy: 0.9833\n",
            "Epoch 226/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9907\n",
            "Epoch 226: val_loss did not improve from 0.08018\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 0.0812 - val_accuracy: 0.9800\n",
            "Epoch 227/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9890\n",
            "Epoch 227: val_loss improved from 0.08018 to 0.07716, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.0772 - val_accuracy: 0.9833\n",
            "Epoch 228/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9941\n",
            "Epoch 228: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0807 - val_accuracy: 0.9800\n",
            "Epoch 229/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9883\n",
            "Epoch 229: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0370 - accuracy: 0.9883 - val_loss: 0.0814 - val_accuracy: 0.9767\n",
            "Epoch 230/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9917\n",
            "Epoch 230: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0319 - accuracy: 0.9917 - val_loss: 0.0860 - val_accuracy: 0.9767\n",
            "Epoch 231/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9924\n",
            "Epoch 231: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.0829 - val_accuracy: 0.9800\n",
            "Epoch 232/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9890\n",
            "Epoch 232: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 64ms/step - loss: 0.0331 - accuracy: 0.9892 - val_loss: 0.0900 - val_accuracy: 0.9733\n",
            "Epoch 233/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9924\n",
            "Epoch 233: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.0886 - val_accuracy: 0.9700\n",
            "Epoch 234/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9908\n",
            "Epoch 234: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 0.0856 - val_accuracy: 0.9700\n",
            "Epoch 235/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9865\n",
            "Epoch 235: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0340 - accuracy: 0.9867 - val_loss: 0.0894 - val_accuracy: 0.9667\n",
            "Epoch 236/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9892\n",
            "Epoch 236: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0318 - accuracy: 0.9892 - val_loss: 0.0826 - val_accuracy: 0.9700\n",
            "Epoch 237/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9975\n",
            "Epoch 237: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0193 - accuracy: 0.9975 - val_loss: 0.0821 - val_accuracy: 0.9767\n",
            "Epoch 238/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9950\n",
            "Epoch 238: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.0830 - val_accuracy: 0.9767\n",
            "Epoch 239/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9916\n",
            "Epoch 239: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 0.0889 - val_accuracy: 0.9700\n",
            "Epoch 240/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9975\n",
            "Epoch 240: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 52ms/step - loss: 0.0183 - accuracy: 0.9975 - val_loss: 0.0878 - val_accuracy: 0.9733\n",
            "Epoch 241/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9907\n",
            "Epoch 241: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0231 - accuracy: 0.9908 - val_loss: 0.0890 - val_accuracy: 0.9700\n",
            "Epoch 242/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9949\n",
            "Epoch 242: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.0258 - accuracy: 0.9950 - val_loss: 0.0955 - val_accuracy: 0.9667\n",
            "Epoch 243/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9900\n",
            "Epoch 243: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.0948 - val_accuracy: 0.9667\n",
            "Epoch 244/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9924\n",
            "Epoch 244: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.1011 - val_accuracy: 0.9567\n",
            "Epoch 245/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9917\n",
            "Epoch 245: val_loss did not improve from 0.07716\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0844 - val_accuracy: 0.9800\n",
            "Epoch 246/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9882\n",
            "Epoch 246: val_loss improved from 0.07716 to 0.07542, saving model to /content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 147ms/step - loss: 0.0268 - accuracy: 0.9883 - val_loss: 0.0754 - val_accuracy: 0.9800\n",
            "Epoch 247/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9882\n",
            "Epoch 247: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 60ms/step - loss: 0.0281 - accuracy: 0.9883 - val_loss: 0.0847 - val_accuracy: 0.9767\n",
            "Epoch 248/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9916\n",
            "Epoch 248: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 3s 69ms/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.0851 - val_accuracy: 0.9733\n",
            "Epoch 249/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9856\n",
            "Epoch 249: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0294 - accuracy: 0.9858 - val_loss: 0.0833 - val_accuracy: 0.9733\n",
            "Epoch 250/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9958\n",
            "Epoch 250: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 61ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0783 - val_accuracy: 0.9800\n",
            "Epoch 251/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9975\n",
            "Epoch 251: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0155 - accuracy: 0.9975 - val_loss: 0.0862 - val_accuracy: 0.9700\n",
            "Epoch 252/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9925\n",
            "Epoch 252: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0844 - val_accuracy: 0.9700\n",
            "Epoch 253/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0246 - accuracy: 0.9931\n",
            "Epoch 253: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 59ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0823 - val_accuracy: 0.9733\n",
            "Epoch 254/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9941\n",
            "Epoch 254: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 58ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0784 - val_accuracy: 0.9800\n",
            "Epoch 255/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9916\n",
            "Epoch 255: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.0871 - val_accuracy: 0.9733\n",
            "Epoch 256/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0161 - accuracy: 0.9957\n",
            "Epoch 256: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.0874 - val_accuracy: 0.9733\n",
            "Epoch 257/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9908\n",
            "Epoch 257: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 0.0786 - val_accuracy: 0.9767\n",
            "Epoch 258/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9958\n",
            "Epoch 258: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 0.0860 - val_accuracy: 0.9733\n",
            "Epoch 259/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9873\n",
            "Epoch 259: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0283 - accuracy: 0.9875 - val_loss: 0.0762 - val_accuracy: 0.9733\n",
            "Epoch 260/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9907\n",
            "Epoch 260: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0245 - accuracy: 0.9908 - val_loss: 0.0797 - val_accuracy: 0.9667\n",
            "Epoch 261/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9942\n",
            "Epoch 261: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 57ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0872 - val_accuracy: 0.9733\n",
            "Epoch 262/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9875\n",
            "Epoch 262: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.0271 - accuracy: 0.9875 - val_loss: 0.0858 - val_accuracy: 0.9733\n",
            "Epoch 263/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9890\n",
            "Epoch 263: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0253 - accuracy: 0.9892 - val_loss: 0.0859 - val_accuracy: 0.9767\n",
            "Epoch 264/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9917\n",
            "Epoch 264: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0230 - accuracy: 0.9917 - val_loss: 0.0817 - val_accuracy: 0.9733\n",
            "Epoch 265/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9925\n",
            "Epoch 265: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 46ms/step - loss: 0.0201 - accuracy: 0.9925 - val_loss: 0.0772 - val_accuracy: 0.9800\n",
            "Epoch 266/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9933\n",
            "Epoch 266: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0843 - val_accuracy: 0.9733\n",
            "Epoch 267/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9933\n",
            "Epoch 267: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 51ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.0802 - val_accuracy: 0.9733\n",
            "Epoch 268/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9925\n",
            "Epoch 268: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.0197 - accuracy: 0.9925 - val_loss: 0.0803 - val_accuracy: 0.9733\n",
            "Epoch 269/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9916\n",
            "Epoch 269: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 0.0979 - val_accuracy: 0.9667\n",
            "Epoch 270/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0203 - accuracy: 0.9939\n",
            "Epoch 270: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.0923 - val_accuracy: 0.9700\n",
            "Epoch 271/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9958\n",
            "Epoch 271: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0864 - val_accuracy: 0.9767\n",
            "Epoch 272/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9941\n",
            "Epoch 272: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.0879 - val_accuracy: 0.9700\n",
            "Epoch 273/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9932\n",
            "Epoch 273: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0907 - val_accuracy: 0.9733\n",
            "Epoch 274/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.0147 - accuracy: 0.9965\n",
            "Epoch 274: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.0837 - val_accuracy: 0.9733\n",
            "Epoch 275/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9950\n",
            "Epoch 275: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 54ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.0866 - val_accuracy: 0.9733\n",
            "Epoch 276/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9958\n",
            "Epoch 276: val_loss did not improve from 0.07542\n",
            "38/38 [==============================] - 2s 56ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.0897 - val_accuracy: 0.9667\n",
            "47/47 [==============================] - 2s 19ms/step - loss: 0.6608 - accuracy: 0.8613\n",
            "Test accuracy, 15 run, after finetuning: 0.8613333106040955\n",
            "Epoch 1/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 2.9286 - accuracy: 0.5475\n",
            "Epoch 1: val_loss improved from inf to 2.05983, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 45s 576ms/step - loss: 2.9286 - accuracy: 0.5475 - val_loss: 2.0598 - val_accuracy: 0.6067\n",
            "Epoch 2/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.9729 - accuracy: 0.6367\n",
            "Epoch 2: val_loss improved from 2.05983 to 1.44210, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 1.9729 - accuracy: 0.6367 - val_loss: 1.4421 - val_accuracy: 0.6600\n",
            "Epoch 3/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.4750 - accuracy: 0.6683\n",
            "Epoch 3: val_loss improved from 1.44210 to 1.09799, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 130ms/step - loss: 1.4750 - accuracy: 0.6683 - val_loss: 1.0980 - val_accuracy: 0.6933\n",
            "Epoch 4/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.2298 - accuracy: 0.6992\n",
            "Epoch 4: val_loss improved from 1.09799 to 0.89315, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 1.2298 - accuracy: 0.6992 - val_loss: 0.8931 - val_accuracy: 0.7333\n",
            "Epoch 5/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 1.0131 - accuracy: 0.7179\n",
            "Epoch 5: val_loss improved from 0.89315 to 0.77064, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 1.0128 - accuracy: 0.7158 - val_loss: 0.7706 - val_accuracy: 0.7500\n",
            "Epoch 6/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.8902 - accuracy: 0.7297\n",
            "Epoch 6: val_loss improved from 0.77064 to 0.69124, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 131ms/step - loss: 0.8866 - accuracy: 0.7308 - val_loss: 0.6912 - val_accuracy: 0.7667\n",
            "Epoch 7/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.8676 - accuracy: 0.7382\n",
            "Epoch 7: val_loss improved from 0.69124 to 0.63666, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.8624 - accuracy: 0.7392 - val_loss: 0.6367 - val_accuracy: 0.7800\n",
            "Epoch 8/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7690 - accuracy: 0.7517\n",
            "Epoch 8: val_loss improved from 0.63666 to 0.59494, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.7706 - accuracy: 0.7525 - val_loss: 0.5949 - val_accuracy: 0.7933\n",
            "Epoch 9/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7753 - accuracy: 0.7576\n",
            "Epoch 9: val_loss improved from 0.59494 to 0.55657, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.7754 - accuracy: 0.7583 - val_loss: 0.5566 - val_accuracy: 0.8000\n",
            "Epoch 10/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.7494 - accuracy: 0.7517\n",
            "Epoch 10: val_loss improved from 0.55657 to 0.53044, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 0.7494 - accuracy: 0.7517 - val_loss: 0.5304 - val_accuracy: 0.8133\n",
            "Epoch 11/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.7792\n",
            "Epoch 11: val_loss improved from 0.53044 to 0.50447, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 0.6738 - accuracy: 0.7792 - val_loss: 0.5045 - val_accuracy: 0.8333\n",
            "Epoch 12/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.7618\n",
            "Epoch 12: val_loss improved from 0.50447 to 0.48168, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.6984 - accuracy: 0.7625 - val_loss: 0.4817 - val_accuracy: 0.8367\n",
            "Epoch 13/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.7842\n",
            "Epoch 13: val_loss improved from 0.48168 to 0.46226, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.6602 - accuracy: 0.7842 - val_loss: 0.4623 - val_accuracy: 0.8467\n",
            "Epoch 14/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5958 - accuracy: 0.7965\n",
            "Epoch 14: val_loss improved from 0.46226 to 0.44106, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.6008 - accuracy: 0.7958 - val_loss: 0.4411 - val_accuracy: 0.8567\n",
            "Epoch 15/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5718 - accuracy: 0.8066\n",
            "Epoch 15: val_loss improved from 0.44106 to 0.42354, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.5678 - accuracy: 0.8075 - val_loss: 0.4235 - val_accuracy: 0.8633\n",
            "Epoch 16/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5954 - accuracy: 0.7956\n",
            "Epoch 16: val_loss improved from 0.42354 to 0.40818, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.5918 - accuracy: 0.7967 - val_loss: 0.4082 - val_accuracy: 0.8633\n",
            "Epoch 17/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.5524 - accuracy: 0.8117\n",
            "Epoch 17: val_loss improved from 0.40818 to 0.39397, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.5552 - accuracy: 0.8117 - val_loss: 0.3940 - val_accuracy: 0.8767\n",
            "Epoch 18/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.8100\n",
            "Epoch 18: val_loss improved from 0.39397 to 0.37782, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.5364 - accuracy: 0.8100 - val_loss: 0.3778 - val_accuracy: 0.8867\n",
            "Epoch 19/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.8250\n",
            "Epoch 19: val_loss improved from 0.37782 to 0.36450, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.5196 - accuracy: 0.8250 - val_loss: 0.3645 - val_accuracy: 0.8867\n",
            "Epoch 20/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.8242\n",
            "Epoch 20: val_loss improved from 0.36450 to 0.35273, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.5194 - accuracy: 0.8242 - val_loss: 0.3527 - val_accuracy: 0.8867\n",
            "Epoch 21/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.8375\n",
            "Epoch 21: val_loss improved from 0.35273 to 0.34210, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.5115 - accuracy: 0.8375 - val_loss: 0.3421 - val_accuracy: 0.8867\n",
            "Epoch 22/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4839 - accuracy: 0.8242\n",
            "Epoch 22: val_loss improved from 0.34210 to 0.33222, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.4839 - accuracy: 0.8242 - val_loss: 0.3322 - val_accuracy: 0.8900\n",
            "Epoch 23/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.8417\n",
            "Epoch 23: val_loss improved from 0.33222 to 0.32170, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.4683 - accuracy: 0.8417 - val_loss: 0.3217 - val_accuracy: 0.8900\n",
            "Epoch 24/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4540 - accuracy: 0.8497\n",
            "Epoch 24: val_loss improved from 0.32170 to 0.31154, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.4505 - accuracy: 0.8500 - val_loss: 0.3115 - val_accuracy: 0.8967\n",
            "Epoch 25/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.8508\n",
            "Epoch 25: val_loss improved from 0.31154 to 0.30212, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.4198 - accuracy: 0.8508 - val_loss: 0.3021 - val_accuracy: 0.9000\n",
            "Epoch 26/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4230 - accuracy: 0.8471\n",
            "Epoch 26: val_loss improved from 0.30212 to 0.29363, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 143ms/step - loss: 0.4222 - accuracy: 0.8483 - val_loss: 0.2936 - val_accuracy: 0.9100\n",
            "Epoch 27/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4043 - accuracy: 0.8573\n",
            "Epoch 27: val_loss improved from 0.29363 to 0.28420, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 0.4051 - accuracy: 0.8583 - val_loss: 0.2842 - val_accuracy: 0.9100\n",
            "Epoch 28/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4108 - accuracy: 0.8505\n",
            "Epoch 28: val_loss improved from 0.28420 to 0.27544, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 151ms/step - loss: 0.4108 - accuracy: 0.8508 - val_loss: 0.2754 - val_accuracy: 0.9167\n",
            "Epoch 29/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4099 - accuracy: 0.8514\n",
            "Epoch 29: val_loss improved from 0.27544 to 0.26868, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.4126 - accuracy: 0.8508 - val_loss: 0.2687 - val_accuracy: 0.9200\n",
            "Epoch 30/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4015 - accuracy: 0.8689\n",
            "Epoch 30: val_loss improved from 0.26868 to 0.26213, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 0.3984 - accuracy: 0.8692 - val_loss: 0.2621 - val_accuracy: 0.9200\n",
            "Epoch 31/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3748 - accuracy: 0.8742\n",
            "Epoch 31: val_loss improved from 0.26213 to 0.25586, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.3725 - accuracy: 0.8750 - val_loss: 0.2559 - val_accuracy: 0.9167\n",
            "Epoch 32/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.8767\n",
            "Epoch 32: val_loss improved from 0.25586 to 0.25021, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 109ms/step - loss: 0.3828 - accuracy: 0.8767 - val_loss: 0.2502 - val_accuracy: 0.9200\n",
            "Epoch 33/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3730 - accuracy: 0.8700\n",
            "Epoch 33: val_loss improved from 0.25021 to 0.24153, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 108ms/step - loss: 0.3730 - accuracy: 0.8700 - val_loss: 0.2415 - val_accuracy: 0.9233\n",
            "Epoch 34/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3590 - accuracy: 0.8725\n",
            "Epoch 34: val_loss improved from 0.24153 to 0.23713, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.3590 - accuracy: 0.8725 - val_loss: 0.2371 - val_accuracy: 0.9233\n",
            "Epoch 35/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.8868\n",
            "Epoch 35: val_loss improved from 0.23713 to 0.22981, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.3559 - accuracy: 0.8858 - val_loss: 0.2298 - val_accuracy: 0.9267\n",
            "Epoch 36/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8825\n",
            "Epoch 36: val_loss improved from 0.22981 to 0.22513, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.3438 - accuracy: 0.8825 - val_loss: 0.2251 - val_accuracy: 0.9300\n",
            "Epoch 37/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.8851\n",
            "Epoch 37: val_loss improved from 0.22513 to 0.21958, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 121ms/step - loss: 0.3106 - accuracy: 0.8867 - val_loss: 0.2196 - val_accuracy: 0.9333\n",
            "Epoch 38/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3178 - accuracy: 0.8854\n",
            "Epoch 38: val_loss improved from 0.21958 to 0.21445, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.3182 - accuracy: 0.8867 - val_loss: 0.2145 - val_accuracy: 0.9300\n",
            "Epoch 39/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3291 - accuracy: 0.8851\n",
            "Epoch 39: val_loss improved from 0.21445 to 0.21180, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.3267 - accuracy: 0.8858 - val_loss: 0.2118 - val_accuracy: 0.9333\n",
            "Epoch 40/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.8942\n",
            "Epoch 40: val_loss improved from 0.21180 to 0.20697, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2945 - accuracy: 0.8942 - val_loss: 0.2070 - val_accuracy: 0.9333\n",
            "Epoch 41/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.8842\n",
            "Epoch 41: val_loss improved from 0.20697 to 0.20185, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.3313 - accuracy: 0.8842 - val_loss: 0.2019 - val_accuracy: 0.9300\n",
            "Epoch 42/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.9008\n",
            "Epoch 42: val_loss improved from 0.20185 to 0.19774, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.3019 - accuracy: 0.9008 - val_loss: 0.1977 - val_accuracy: 0.9267\n",
            "Epoch 43/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.8967\n",
            "Epoch 43: val_loss improved from 0.19774 to 0.19327, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.2950 - accuracy: 0.8967 - val_loss: 0.1933 - val_accuracy: 0.9333\n",
            "Epoch 44/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2836 - accuracy: 0.9033\n",
            "Epoch 44: val_loss improved from 0.19327 to 0.18936, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 142ms/step - loss: 0.2836 - accuracy: 0.9033 - val_loss: 0.1894 - val_accuracy: 0.9333\n",
            "Epoch 45/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.9130\n",
            "Epoch 45: val_loss improved from 0.18936 to 0.18583, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2830 - accuracy: 0.9133 - val_loss: 0.1858 - val_accuracy: 0.9367\n",
            "Epoch 46/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2725 - accuracy: 0.8992\n",
            "Epoch 46: val_loss improved from 0.18583 to 0.18277, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.2725 - accuracy: 0.8992 - val_loss: 0.1828 - val_accuracy: 0.9333\n",
            "Epoch 47/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.9142\n",
            "Epoch 47: val_loss improved from 0.18277 to 0.17864, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.2728 - accuracy: 0.9142 - val_loss: 0.1786 - val_accuracy: 0.9367\n",
            "Epoch 48/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.9147\n",
            "Epoch 48: val_loss improved from 0.17864 to 0.17596, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.2580 - accuracy: 0.9133 - val_loss: 0.1760 - val_accuracy: 0.9400\n",
            "Epoch 49/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2701 - accuracy: 0.9029\n",
            "Epoch 49: val_loss improved from 0.17596 to 0.17365, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2703 - accuracy: 0.9025 - val_loss: 0.1736 - val_accuracy: 0.9367\n",
            "Epoch 50/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.9105\n",
            "Epoch 50: val_loss improved from 0.17365 to 0.16907, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 132ms/step - loss: 0.2523 - accuracy: 0.9108 - val_loss: 0.1691 - val_accuracy: 0.9400\n",
            "Epoch 51/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.9105\n",
            "Epoch 51: val_loss improved from 0.16907 to 0.16686, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2567 - accuracy: 0.9100 - val_loss: 0.1669 - val_accuracy: 0.9433\n",
            "Epoch 52/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9108\n",
            "Epoch 52: val_loss improved from 0.16686 to 0.16473, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 6s 162ms/step - loss: 0.2552 - accuracy: 0.9108 - val_loss: 0.1647 - val_accuracy: 0.9567\n",
            "Epoch 53/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.9092\n",
            "Epoch 53: val_loss improved from 0.16473 to 0.16184, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 9s 233ms/step - loss: 0.2708 - accuracy: 0.9092 - val_loss: 0.1618 - val_accuracy: 0.9467\n",
            "Epoch 54/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.9079\n",
            "Epoch 54: val_loss improved from 0.16184 to 0.15835, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.2449 - accuracy: 0.9092 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
            "Epoch 55/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2092 - accuracy: 0.9248\n",
            "Epoch 55: val_loss improved from 0.15835 to 0.15470, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.2098 - accuracy: 0.9250 - val_loss: 0.1547 - val_accuracy: 0.9567\n",
            "Epoch 56/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.9150\n",
            "Epoch 56: val_loss improved from 0.15470 to 0.14835, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 127ms/step - loss: 0.2464 - accuracy: 0.9150 - val_loss: 0.1484 - val_accuracy: 0.9567\n",
            "Epoch 57/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2220 - accuracy: 0.9257\n",
            "Epoch 57: val_loss improved from 0.14835 to 0.14529, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.2220 - accuracy: 0.9250 - val_loss: 0.1453 - val_accuracy: 0.9667\n",
            "Epoch 58/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9155\n",
            "Epoch 58: val_loss improved from 0.14529 to 0.14221, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 138ms/step - loss: 0.2284 - accuracy: 0.9158 - val_loss: 0.1422 - val_accuracy: 0.9633\n",
            "Epoch 59/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.9139\n",
            "Epoch 59: val_loss improved from 0.14221 to 0.14065, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 133ms/step - loss: 0.2253 - accuracy: 0.9150 - val_loss: 0.1406 - val_accuracy: 0.9667\n",
            "Epoch 60/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9233\n",
            "Epoch 60: val_loss improved from 0.14065 to 0.13996, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.2094 - accuracy: 0.9233 - val_loss: 0.1400 - val_accuracy: 0.9667\n",
            "Epoch 61/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2114 - accuracy: 0.9299\n",
            "Epoch 61: val_loss improved from 0.13996 to 0.13805, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.2167 - accuracy: 0.9267 - val_loss: 0.1381 - val_accuracy: 0.9633\n",
            "Epoch 62/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9292\n",
            "Epoch 62: val_loss improved from 0.13805 to 0.13610, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.2057 - accuracy: 0.9292 - val_loss: 0.1361 - val_accuracy: 0.9633\n",
            "Epoch 63/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9341\n",
            "Epoch 63: val_loss improved from 0.13610 to 0.13380, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.2070 - accuracy: 0.9342 - val_loss: 0.1338 - val_accuracy: 0.9667\n",
            "Epoch 64/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9258\n",
            "Epoch 64: val_loss improved from 0.13380 to 0.13216, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1954 - accuracy: 0.9258 - val_loss: 0.1322 - val_accuracy: 0.9700\n",
            "Epoch 65/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.9342\n",
            "Epoch 65: val_loss improved from 0.13216 to 0.12803, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 123ms/step - loss: 0.2040 - accuracy: 0.9342 - val_loss: 0.1280 - val_accuracy: 0.9667\n",
            "Epoch 66/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1934 - accuracy: 0.9332\n",
            "Epoch 66: val_loss improved from 0.12803 to 0.12556, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.1924 - accuracy: 0.9333 - val_loss: 0.1256 - val_accuracy: 0.9700\n",
            "Epoch 67/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9375\n",
            "Epoch 67: val_loss improved from 0.12556 to 0.12485, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1864 - accuracy: 0.9375 - val_loss: 0.1248 - val_accuracy: 0.9700\n",
            "Epoch 68/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.9324\n",
            "Epoch 68: val_loss did not improve from 0.12485\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.2072 - accuracy: 0.9308 - val_loss: 0.1251 - val_accuracy: 0.9667\n",
            "Epoch 69/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.9350\n",
            "Epoch 69: val_loss improved from 0.12485 to 0.12175, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.1868 - accuracy: 0.9350 - val_loss: 0.1217 - val_accuracy: 0.9733\n",
            "Epoch 70/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9408\n",
            "Epoch 70: val_loss improved from 0.12175 to 0.12072, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.1739 - accuracy: 0.9408 - val_loss: 0.1207 - val_accuracy: 0.9733\n",
            "Epoch 71/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.9433\n",
            "Epoch 71: val_loss improved from 0.12072 to 0.11871, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1642 - accuracy: 0.9433 - val_loss: 0.1187 - val_accuracy: 0.9700\n",
            "Epoch 72/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9425\n",
            "Epoch 72: val_loss improved from 0.11871 to 0.11684, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.1679 - accuracy: 0.9425 - val_loss: 0.1168 - val_accuracy: 0.9700\n",
            "Epoch 73/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1770 - accuracy: 0.9299\n",
            "Epoch 73: val_loss improved from 0.11684 to 0.11532, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1833 - accuracy: 0.9275 - val_loss: 0.1153 - val_accuracy: 0.9667\n",
            "Epoch 74/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1841 - accuracy: 0.9367\n",
            "Epoch 74: val_loss improved from 0.11532 to 0.11261, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1821 - accuracy: 0.9375 - val_loss: 0.1126 - val_accuracy: 0.9700\n",
            "Epoch 75/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9500\n",
            "Epoch 75: val_loss improved from 0.11261 to 0.11002, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 120ms/step - loss: 0.1639 - accuracy: 0.9500 - val_loss: 0.1100 - val_accuracy: 0.9733\n",
            "Epoch 76/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.9434\n",
            "Epoch 76: val_loss did not improve from 0.11002\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.1731 - accuracy: 0.9442 - val_loss: 0.1101 - val_accuracy: 0.9700\n",
            "Epoch 77/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1775 - accuracy: 0.9358\n",
            "Epoch 77: val_loss did not improve from 0.11002\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1751 - accuracy: 0.9358 - val_loss: 0.1101 - val_accuracy: 0.9733\n",
            "Epoch 78/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9467\n",
            "Epoch 78: val_loss improved from 0.11002 to 0.10673, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.1522 - accuracy: 0.9467 - val_loss: 0.1067 - val_accuracy: 0.9700\n",
            "Epoch 79/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9434\n",
            "Epoch 79: val_loss improved from 0.10673 to 0.10600, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.1608 - accuracy: 0.9442 - val_loss: 0.1060 - val_accuracy: 0.9767\n",
            "Epoch 80/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9324\n",
            "Epoch 80: val_loss improved from 0.10600 to 0.10500, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.1736 - accuracy: 0.9333 - val_loss: 0.1050 - val_accuracy: 0.9733\n",
            "Epoch 81/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9458\n",
            "Epoch 81: val_loss improved from 0.10500 to 0.10402, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.1422 - accuracy: 0.9458 - val_loss: 0.1040 - val_accuracy: 0.9767\n",
            "Epoch 82/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9483\n",
            "Epoch 82: val_loss improved from 0.10402 to 0.10386, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.1430 - accuracy: 0.9483 - val_loss: 0.1039 - val_accuracy: 0.9733\n",
            "Epoch 83/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9592\n",
            "Epoch 83: val_loss improved from 0.10386 to 0.10142, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1296 - accuracy: 0.9592 - val_loss: 0.1014 - val_accuracy: 0.9733\n",
            "Epoch 84/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9426\n",
            "Epoch 84: val_loss improved from 0.10142 to 0.09862, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1603 - accuracy: 0.9425 - val_loss: 0.0986 - val_accuracy: 0.9767\n",
            "Epoch 85/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1409 - accuracy: 0.9527\n",
            "Epoch 85: val_loss improved from 0.09862 to 0.09734, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.1400 - accuracy: 0.9533 - val_loss: 0.0973 - val_accuracy: 0.9733\n",
            "Epoch 86/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.9525\n",
            "Epoch 86: val_loss did not improve from 0.09734\n",
            "38/38 [==============================] - 2s 55ms/step - loss: 0.1451 - accuracy: 0.9525 - val_loss: 0.0979 - val_accuracy: 0.9700\n",
            "Epoch 87/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1476 - accuracy: 0.9493\n",
            "Epoch 87: val_loss improved from 0.09734 to 0.09648, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 125ms/step - loss: 0.1481 - accuracy: 0.9483 - val_loss: 0.0965 - val_accuracy: 0.9733\n",
            "Epoch 88/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1443 - accuracy: 0.9443\n",
            "Epoch 88: val_loss improved from 0.09648 to 0.09574, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 110ms/step - loss: 0.1463 - accuracy: 0.9425 - val_loss: 0.0957 - val_accuracy: 0.9733\n",
            "Epoch 89/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9508\n",
            "Epoch 89: val_loss did not improve from 0.09574\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.1417 - accuracy: 0.9508 - val_loss: 0.0968 - val_accuracy: 0.9733\n",
            "Epoch 90/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1393 - accuracy: 0.9527\n",
            "Epoch 90: val_loss improved from 0.09574 to 0.09321, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 145ms/step - loss: 0.1398 - accuracy: 0.9525 - val_loss: 0.0932 - val_accuracy: 0.9767\n",
            "Epoch 91/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9519\n",
            "Epoch 91: val_loss improved from 0.09321 to 0.09180, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.1322 - accuracy: 0.9525 - val_loss: 0.0918 - val_accuracy: 0.9733\n",
            "Epoch 92/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1356 - accuracy: 0.9519\n",
            "Epoch 92: val_loss improved from 0.09180 to 0.09155, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.1348 - accuracy: 0.9525 - val_loss: 0.0915 - val_accuracy: 0.9733\n",
            "Epoch 93/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.9535\n",
            "Epoch 93: val_loss improved from 0.09155 to 0.08770, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 124ms/step - loss: 0.1416 - accuracy: 0.9542 - val_loss: 0.0877 - val_accuracy: 0.9767\n",
            "Epoch 94/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1204 - accuracy: 0.9595\n",
            "Epoch 94: val_loss did not improve from 0.08770\n",
            "38/38 [==============================] - 2s 53ms/step - loss: 0.1228 - accuracy: 0.9567 - val_loss: 0.0889 - val_accuracy: 0.9733\n",
            "Epoch 95/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9502\n",
            "Epoch 95: val_loss did not improve from 0.08770\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1354 - accuracy: 0.9492 - val_loss: 0.0905 - val_accuracy: 0.9767\n",
            "Epoch 96/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9519\n",
            "Epoch 96: val_loss did not improve from 0.08770\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1311 - accuracy: 0.9525 - val_loss: 0.0904 - val_accuracy: 0.9733\n",
            "Epoch 97/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9525\n",
            "Epoch 97: val_loss did not improve from 0.08770\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1249 - accuracy: 0.9525 - val_loss: 0.0879 - val_accuracy: 0.9700\n",
            "Epoch 98/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9542\n",
            "Epoch 98: val_loss improved from 0.08770 to 0.08428, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.1297 - accuracy: 0.9542 - val_loss: 0.0843 - val_accuracy: 0.9733\n",
            "Epoch 99/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9550\n",
            "Epoch 99: val_loss improved from 0.08428 to 0.08173, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 126ms/step - loss: 0.1348 - accuracy: 0.9550 - val_loss: 0.0817 - val_accuracy: 0.9733\n",
            "Epoch 100/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9575\n",
            "Epoch 100: val_loss did not improve from 0.08173\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1198 - accuracy: 0.9575 - val_loss: 0.0848 - val_accuracy: 0.9733\n",
            "Epoch 101/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9592\n",
            "Epoch 101: val_loss did not improve from 0.08173\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1164 - accuracy: 0.9592 - val_loss: 0.0835 - val_accuracy: 0.9767\n",
            "Epoch 102/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9467\n",
            "Epoch 102: val_loss improved from 0.08173 to 0.07993, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1433 - accuracy: 0.9467 - val_loss: 0.0799 - val_accuracy: 0.9767\n",
            "Epoch 103/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9544\n",
            "Epoch 103: val_loss improved from 0.07993 to 0.07844, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1165 - accuracy: 0.9533 - val_loss: 0.0784 - val_accuracy: 0.9767\n",
            "Epoch 104/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1326 - accuracy: 0.9517\n",
            "Epoch 104: val_loss improved from 0.07844 to 0.07754, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1326 - accuracy: 0.9517 - val_loss: 0.0775 - val_accuracy: 0.9767\n",
            "Epoch 105/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.9603\n",
            "Epoch 105: val_loss did not improve from 0.07754\n",
            "38/38 [==============================] - 2s 50ms/step - loss: 0.1128 - accuracy: 0.9592 - val_loss: 0.0793 - val_accuracy: 0.9733\n",
            "Epoch 106/1500\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.1178 - accuracy: 0.9635\n",
            "Epoch 106: val_loss did not improve from 0.07754\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1165 - accuracy: 0.9650 - val_loss: 0.0778 - val_accuracy: 0.9733\n",
            "Epoch 107/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 0.9625\n",
            "Epoch 107: val_loss did not improve from 0.07754\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.1031 - accuracy: 0.9625 - val_loss: 0.0790 - val_accuracy: 0.9733\n",
            "Epoch 108/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9747\n",
            "Epoch 108: val_loss improved from 0.07754 to 0.07709, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 128ms/step - loss: 0.0944 - accuracy: 0.9742 - val_loss: 0.0771 - val_accuracy: 0.9733\n",
            "Epoch 109/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9675\n",
            "Epoch 109: val_loss improved from 0.07709 to 0.07468, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.1018 - accuracy: 0.9675 - val_loss: 0.0747 - val_accuracy: 0.9767\n",
            "Epoch 110/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9592\n",
            "Epoch 110: val_loss improved from 0.07468 to 0.07217, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 4s 111ms/step - loss: 0.1159 - accuracy: 0.9592 - val_loss: 0.0722 - val_accuracy: 0.9767\n",
            "Epoch 111/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9633\n",
            "Epoch 111: val_loss improved from 0.07217 to 0.07166, saving model to /content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3.h5\n",
            "38/38 [==============================] - 5s 129ms/step - loss: 0.1099 - accuracy: 0.9633 - val_loss: 0.0717 - val_accuracy: 0.9767\n",
            "Epoch 112/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9603\n",
            "Epoch 112: val_loss did not improve from 0.07166\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.1118 - accuracy: 0.9592 - val_loss: 0.0727 - val_accuracy: 0.9767\n",
            "Epoch 113/1500\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9671\n",
            "Epoch 113: val_loss did not improve from 0.07166\n",
            "38/38 [==============================] - 2s 49ms/step - loss: 0.0970 - accuracy: 0.9675 - val_loss: 0.0732 - val_accuracy: 0.9733\n",
            "Epoch 114/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9667\n",
            "Epoch 114: val_loss did not improve from 0.07166\n",
            "38/38 [==============================] - 2s 47ms/step - loss: 0.1096 - accuracy: 0.9667 - val_loss: 0.0733 - val_accuracy: 0.9733\n",
            "Epoch 115/1500\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9667\n",
            "Epoch 115: val_loss did not improve from 0.07166\n",
            "38/38 [==============================] - 2s 48ms/step - loss: 0.0959 - accuracy: 0.9667 - val_loss: 0.0738 - val_accuracy: 0.9733\n",
            "Epoch 116/1500\n",
            "19/38 [==============>...............] - ETA: 0s - loss: 0.1142 - accuracy: 0.9605"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  res_net = create_model()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=res_net)\n",
        "  callbacks = [EarlyStopping(monitor='val_loss', patience=30, mode='min'), ModelCheckpoint('/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p3_FTm3.h5', verbose=1, monitor='val_loss', save_best_only=True, mode='min')]\n",
        "  res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "  res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p3.h5\")\n",
        "\n",
        "  for layer in res_net.layers[:-3]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  Known_data_X_finetune, Known_data_X_finetune_label = shuffle(Known_data_X_finetune, Known_data_X_finetune_label)\n",
        "\n",
        "  history = res_net.fit(Known_data_X_finetune, Known_data_X_finetune_label, epochs=1500, batch_size=32, verbose=1, validation_split=0.2, shuffle=True, callbacks=callbacks)\n",
        "\n",
        "  res_net.save_weights('/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p3_FTm3_PP.h5')\n",
        "\n",
        "  test_loss, test_acc = res_net.evaluate(Known_data_X_test, Known_data_X_test_label)\n",
        "  print('Test accuracy, 01 run, after finetuning:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rgl6y8eYkwL",
        "outputId": "6bc6524d-667e-4429-c619-4317f43e4758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 33s 636ms/step - loss: 0.5455 - accuracy: 0.8720\n",
            "Test accuracy, 01 run: 0.871999979019165\n",
            "47/47 [==============================] - 32s 650ms/step - loss: 0.5801 - accuracy: 0.8687\n",
            "Test accuracy, 02 run: 0.8686666488647461\n",
            "47/47 [==============================] - 33s 643ms/step - loss: 0.5115 - accuracy: 0.8813\n",
            "Test accuracy, 03 run: 0.8813333511352539\n",
            "47/47 [==============================] - 33s 648ms/step - loss: 0.5512 - accuracy: 0.8700\n",
            "Test accuracy, 04 run: 0.8700000047683716\n",
            "47/47 [==============================] - 32s 646ms/step - loss: 0.5354 - accuracy: 0.8820\n",
            "Test accuracy, 05 run: 0.8820000290870667\n",
            "47/47 [==============================] - 33s 645ms/step - loss: 0.5390 - accuracy: 0.8787\n",
            "Test accuracy, 06 run: 0.8786666393280029\n",
            "47/47 [==============================] - 33s 669ms/step - loss: 0.6348 - accuracy: 0.8687\n",
            "Test accuracy, 07 run: 0.8686666488647461\n",
            "47/47 [==============================] - 33s 664ms/step - loss: 0.5219 - accuracy: 0.8887\n",
            "Test accuracy, 08 run: 0.8886666893959045\n",
            "47/47 [==============================] - 32s 639ms/step - loss: 0.5463 - accuracy: 0.8833\n",
            "Test accuracy, 09 run: 0.8833333253860474\n",
            "47/47 [==============================] - 32s 648ms/step - loss: 0.5584 - accuracy: 0.8687\n",
            "Test accuracy, 10 run: 0.8686666488647461\n",
            "47/47 [==============================] - 33s 661ms/step - loss: 0.4831 - accuracy: 0.8753\n",
            "Test accuracy, 11 run: 0.875333309173584\n",
            "47/47 [==============================] - 33s 651ms/step - loss: 0.5513 - accuracy: 0.8833\n",
            "Test accuracy, 12 run: 0.8833333253860474\n",
            "47/47 [==============================] - 33s 641ms/step - loss: 0.5137 - accuracy: 0.8753\n",
            "Test accuracy, 13 run: 0.875333309173584\n",
            "47/47 [==============================] - 33s 647ms/step - loss: 0.6039 - accuracy: 0.8667\n",
            "Test accuracy, 14 run: 0.8666666746139526\n",
            "47/47 [==============================] - 32s 640ms/step - loss: 0.6591 - accuracy: 0.8627\n",
            "Test accuracy, 15 run: 0.862666666507721\n",
            "47/47 [==============================] - 34s 657ms/step - loss: 0.6544 - accuracy: 0.8713\n",
            "Test accuracy, 16 run: 0.8713333606719971\n",
            "47/47 [==============================] - 33s 644ms/step - loss: 0.5146 - accuracy: 0.8807\n",
            "Test accuracy, 17 run: 0.8806666731834412\n",
            "47/47 [==============================] - 33s 653ms/step - loss: 0.5736 - accuracy: 0.8687\n",
            "Test accuracy, 18 run: 0.8686666488647461\n",
            "47/47 [==============================] - 32s 638ms/step - loss: 0.6056 - accuracy: 0.8787\n",
            "Test accuracy, 19 run: 0.8786666393280029\n",
            "47/47 [==============================] - 32s 638ms/step - loss: 0.6527 - accuracy: 0.8740\n",
            "Test accuracy, 20 run: 0.8740000128746033\n"
          ]
        }
      ],
      "source": [
        "# Now run and see the models with the best validation accuracy\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 01 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 02 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 03 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 04 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 05 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 06 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 07 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 08 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 09 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 10 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 11 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 12 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 13 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 14 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 15 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 16 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 17 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 18 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 19 run:', test_acc)\n",
        "\n",
        "res_net = create_model()\n",
        "res_net.load_weights(\"/content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=.00001/10),\n",
        "            metrics=['accuracy'])\n",
        "test_loss, test_acc = res_net.evaluate(Known_data_X_test,Known_data_X_test_label)\n",
        "print('Test accuracy, 20 run:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T5UV4GXiQDdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine the models into ensemble"
      ],
      "metadata": {
        "id": "qaLv5mBdF6RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res_net01 = create_model()\n",
        "res_net02 = create_model()\n",
        "res_net03 = create_model()\n",
        "res_net04 = create_model()\n",
        "res_net05 = create_model()\n",
        "res_net06 = create_model()\n",
        "res_net07 = create_model()\n",
        "res_net08 = create_model()\n",
        "res_net09 = create_model()\n",
        "res_net10 = create_model()\n",
        "res_net11 = create_model()\n",
        "res_net12 = create_model()\n",
        "res_net13 = create_model()\n",
        "res_net14 = create_model()\n",
        "res_net15 = create_model()\n",
        "res_net16 = create_model()\n",
        "res_net17 = create_model()\n",
        "res_net18 = create_model()\n",
        "res_net19 = create_model()\n",
        "res_net20 = create_model()\n",
        "\n",
        "res_net01.load_weights(\"/content/gdrive/MyDrive/Stanford_data/01_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net02.load_weights(\"/content/gdrive/MyDrive/Stanford_data/02_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net03.load_weights(\"/content/gdrive/MyDrive/Stanford_data/03_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net04.load_weights(\"/content/gdrive/MyDrive/Stanford_data/04_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net05.load_weights(\"/content/gdrive/MyDrive/Stanford_data/05_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net06.load_weights(\"/content/gdrive/MyDrive/Stanford_data/06_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net07.load_weights(\"/content/gdrive/MyDrive/Stanford_data/07_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net08.load_weights(\"/content/gdrive/MyDrive/Stanford_data/08_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net09.load_weights(\"/content/gdrive/MyDrive/Stanford_data/09_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net10.load_weights(\"/content/gdrive/MyDrive/Stanford_data/10_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net11.load_weights(\"/content/gdrive/MyDrive/Stanford_data/11_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net12.load_weights(\"/content/gdrive/MyDrive/Stanford_data/12_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net13.load_weights(\"/content/gdrive/MyDrive/Stanford_data/13_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net14.load_weights(\"/content/gdrive/MyDrive/Stanford_data/14_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net15.load_weights(\"/content/gdrive/MyDrive/Stanford_data/15_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net16.load_weights(\"/content/gdrive/MyDrive/Stanford_data/16_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net17.load_weights(\"/content/gdrive/MyDrive/Stanford_data/17_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net18.load_weights(\"/content/gdrive/MyDrive/Stanford_data/18_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net19.load_weights(\"/content/gdrive/MyDrive/Stanford_data/19_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "res_net20.load_weights(\"/content/gdrive/MyDrive/Stanford_data/20_Naive_K_p1_p3_FTm3_PP.h5\")\n",
        "\n",
        "\n",
        "\n",
        "prediction01_known = res_net01.predict(Known_data_X_test)\n",
        "prediction02_known = res_net02.predict(Known_data_X_test)\n",
        "prediction03_known = res_net03.predict(Known_data_X_test)\n",
        "prediction04_known = res_net04.predict(Known_data_X_test)\n",
        "prediction05_known = res_net05.predict(Known_data_X_test)\n",
        "prediction06_known = res_net06.predict(Known_data_X_test)\n",
        "prediction07_known = res_net07.predict(Known_data_X_test)\n",
        "prediction08_known = res_net08.predict(Known_data_X_test)\n",
        "prediction09_known = res_net09.predict(Known_data_X_test)\n",
        "prediction10_known = res_net10.predict(Known_data_X_test)\n",
        "\n",
        "prediction11_known = res_net11.predict(Known_data_X_test)\n",
        "prediction12_known = res_net12.predict(Known_data_X_test)\n",
        "prediction13_known = res_net13.predict(Known_data_X_test)\n",
        "prediction14_known = res_net14.predict(Known_data_X_test)\n",
        "prediction15_known = res_net15.predict(Known_data_X_test)\n",
        "prediction16_known = res_net16.predict(Known_data_X_test)\n",
        "prediction17_known = res_net17.predict(Known_data_X_test)\n",
        "prediction18_known = res_net18.predict(Known_data_X_test)\n",
        "prediction19_known = res_net19.predict(Known_data_X_test)\n",
        "prediction20_known = res_net20.predict(Known_data_X_test)\n",
        "\n",
        "\n",
        "prediction_known_ensemble_1 = (prediction01_known + prediction02_known + prediction03_known + prediction04_known + prediction05_known)/5\n",
        "\n",
        "true = 0\n",
        "for i in range(Known_data_X_test_label.shape[0]):\n",
        "  if prediction_known_ensemble_1.argmax(axis=1)[i] == Known_data_X_test_label_int[i]:\n",
        "    true += 1\n",
        "print(\"Accuracy of the first ensemble on the knowns\", true/(Known_data_X_test_label.shape[0]))\n",
        "\n",
        "prediction_known_ensemble_2 = (prediction06_known + prediction07_known + prediction08_known + prediction09_known + prediction10_known)/5\n",
        "\n",
        "true = 0\n",
        "for i in range(Known_data_X_test_label.shape[0]):\n",
        "  if prediction_known_ensemble_2.argmax(axis=1)[i] == Known_data_X_test_label_int[i]:\n",
        "    true += 1\n",
        "print(\"Accuracy of the second ensemble on the knowns\", true/(Known_data_X_test_label.shape[0]))\n",
        "\n",
        "prediction_known_ensemble_3 = (prediction11_known + prediction12_known + prediction13_known + prediction14_known + prediction15_known)/5\n",
        "\n",
        "true = 0\n",
        "for i in range(Known_data_X_test_label.shape[0]):\n",
        "  if prediction_known_ensemble_3.argmax(axis=1)[i] == Known_data_X_test_label_int[i]:\n",
        "    true += 1\n",
        "print(\"Accuracy of the third ensemble on the knowns\", true/(Known_data_X_test_label.shape[0]))\n",
        "\n",
        "prediction_known_ensemble_4 = (prediction16_known + prediction17_known + prediction18_known + prediction19_known + prediction20_known)/5\n",
        "\n",
        "true = 0\n",
        "for i in range(Known_data_X_test_label.shape[0]):\n",
        "  if prediction_known_ensemble_4.argmax(axis=1)[i] == Known_data_X_test_label_int[i]:\n",
        "    true += 1\n",
        "print(\"Accuracy of the fourth ensemble on the knowns\", true/(Known_data_X_test_label.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKZ11xxHQDfo",
        "outputId": "a11e0216-586f-4bac-b79e-3476b7ed62a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 10s 189ms/step\n",
            "47/47 [==============================] - 10s 183ms/step\n",
            "47/47 [==============================] - 10s 183ms/step\n",
            "47/47 [==============================] - 10s 184ms/step\n",
            "47/47 [==============================] - 10s 183ms/step\n",
            "47/47 [==============================] - 9s 179ms/step\n",
            "47/47 [==============================] - 10s 176ms/step\n",
            "47/47 [==============================] - 9s 176ms/step\n",
            "47/47 [==============================] - 9s 178ms/step\n",
            "47/47 [==============================] - 10s 182ms/step\n",
            "47/47 [==============================] - 10s 188ms/step\n",
            "47/47 [==============================] - 10s 185ms/step\n",
            "47/47 [==============================] - 9s 177ms/step\n",
            "47/47 [==============================] - 9s 179ms/step\n",
            "47/47 [==============================] - 10s 184ms/step\n",
            "47/47 [==============================] - 9s 179ms/step\n",
            "47/47 [==============================] - 10s 183ms/step\n",
            "47/47 [==============================] - 9s 179ms/step\n",
            "47/47 [==============================] - 10s 181ms/step\n",
            "47/47 [==============================] - 10s 184ms/step\n",
            "Accuracy of the first ensemble on the knowns 0.8833333333333333\n",
            "Accuracy of the second ensemble on the knowns 0.88\n",
            "Accuracy of the third ensemble on the knowns 0.8786666666666667\n",
            "Accuracy of the fourth ensemble on the knowns 0.8793333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction01_unknown = res_net01.predict(NeverSeen_data_X_test)\n",
        "prediction02_unknown = res_net02.predict(NeverSeen_data_X_test)\n",
        "prediction03_unknown = res_net03.predict(NeverSeen_data_X_test)\n",
        "prediction04_unknown = res_net04.predict(NeverSeen_data_X_test)\n",
        "prediction05_unknown = res_net05.predict(NeverSeen_data_X_test)\n",
        "prediction06_unknown = res_net06.predict(NeverSeen_data_X_test)\n",
        "prediction07_unknown = res_net07.predict(NeverSeen_data_X_test)\n",
        "prediction08_unknown = res_net08.predict(NeverSeen_data_X_test)\n",
        "prediction09_unknown = res_net09.predict(NeverSeen_data_X_test)\n",
        "prediction10_unknown = res_net10.predict(NeverSeen_data_X_test)\n",
        "prediction11_unknown = res_net11.predict(NeverSeen_data_X_test)\n",
        "prediction12_unknown = res_net12.predict(NeverSeen_data_X_test)\n",
        "prediction13_unknown = res_net13.predict(NeverSeen_data_X_test)\n",
        "prediction14_unknown = res_net14.predict(NeverSeen_data_X_test)\n",
        "prediction15_unknown = res_net15.predict(NeverSeen_data_X_test)\n",
        "prediction16_unknown = res_net16.predict(NeverSeen_data_X_test)\n",
        "prediction17_unknown = res_net17.predict(NeverSeen_data_X_test)\n",
        "prediction18_unknown = res_net18.predict(NeverSeen_data_X_test)\n",
        "prediction19_unknown = res_net19.predict(NeverSeen_data_X_test)\n",
        "prediction20_unknown = res_net20.predict(NeverSeen_data_X_test)\n",
        "\n",
        "\n",
        "prediction_unknown_ensemble_1 = (prediction01_unknown + prediction02_unknown + prediction03_unknown + prediction04_unknown + prediction05_unknown)/5\n",
        "prediction_unknown_ensemble_2 = (prediction06_unknown + prediction07_unknown + prediction08_unknown + prediction09_unknown + prediction10_unknown)/5\n",
        "prediction_unknown_ensemble_3 = (prediction11_unknown + prediction12_unknown + prediction13_unknown + prediction14_unknown + prediction15_unknown)/5\n",
        "prediction_unknown_ensemble_4 = (prediction16_unknown + prediction17_unknown + prediction18_unknown + prediction19_unknown + prediction20_unknown)/5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzhmPYCEQZph",
        "outputId": "db3108db-123d-46b2-d20f-fccea80308c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 6s 174ms/step\n",
            "32/32 [==============================] - 6s 175ms/step\n",
            "32/32 [==============================] - 6s 184ms/step\n",
            "32/32 [==============================] - 6s 175ms/step\n",
            "32/32 [==============================] - 6s 185ms/step\n",
            "32/32 [==============================] - 6s 182ms/step\n",
            "32/32 [==============================] - 6s 177ms/step\n",
            "32/32 [==============================] - 6s 184ms/step\n",
            "32/32 [==============================] - 6s 176ms/step\n",
            "32/32 [==============================] - 6s 183ms/step\n",
            "32/32 [==============================] - 6s 180ms/step\n",
            "32/32 [==============================] - 6s 175ms/step\n",
            "32/32 [==============================] - 6s 182ms/step\n",
            "32/32 [==============================] - 6s 174ms/step\n",
            "32/32 [==============================] - 6s 173ms/step\n",
            "32/32 [==============================] - 6s 173ms/step\n",
            "32/32 [==============================] - 6s 179ms/step\n",
            "32/32 [==============================] - 6s 181ms/step\n",
            "32/32 [==============================] - 6s 178ms/step\n",
            "32/32 [==============================] - 6s 172ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOGl1nPiQZrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ODIN scores"
      ],
      "metadata": {
        "id": "IRj7e66EGBbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temperature = 1000\n",
        "magnitude = 0.001\n",
        "batch_size = 32\n",
        "threshold = 0.1\n",
        "\n",
        "loaded_models = [res_net01, res_net02, res_net03, res_net04, res_net05, res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "                 res_net11, res_net12, res_net13, res_net14, res_net15, res_net16, res_net17, res_net18, res_net19, res_net20]\n",
        "\n",
        "UN_Known_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "odin_scores_for_models = [np.array([]) for _ in loaded_models]\n",
        "\n",
        "def compute_odin_scores_for_model(model, images, threshold):\n",
        "    logits_layer = model.layers[-2].output\n",
        "    logits_model = tf.keras.Model(inputs=model.input, outputs=logits_layer)\n",
        "\n",
        "    odin_scores_UN_KNOWN = []\n",
        "\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch = images[i:i + batch_size]\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            logits = logits_model(batch)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(batch)\n",
        "            output = logits_model(batch)\n",
        "        grads = tape.gradient(output, batch)\n",
        "\n",
        "        signed_grads = tf.sign(grads)\n",
        "\n",
        "        perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "        scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "        perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "        max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "        max_logits = tf.reduce_max(tf.nn.softmax(logits), axis=1)\n",
        "        odin_scores_batch = max_logits - max_perturbed_softmax_scores\n",
        "\n",
        "        odin_scores_UN_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "    return np.array(odin_scores_UN_KNOWN)\n",
        "\n",
        "for model_index, model in enumerate(loaded_models):\n",
        "    odin_scores = compute_odin_scores_for_model(model, UN_Known_data_X_test_as_tensor, threshold)\n",
        "    odin_scores_for_models[model_index] = odin_scores"
      ],
      "metadata": {
        "id": "2GRnV883FiFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "all_odin_scores = []\n",
        "for scores in odin_scores_for_models:\n",
        "    all_odin_scores.extend(scores)\n",
        "\n",
        "folder_path = \"/content/gdrive/MyDrive/Stanford_data\"\n",
        "\n",
        "file_name = \"all_odin_scores_NAIVEKp1p3.txt\"\n",
        "\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    for score in all_odin_scores:\n",
        "        file.write(f\"{score}\\n\")"
      ],
      "metadata": {
        "id": "vZTsgbocCke2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temperature = 1000\n",
        "magnitude = 0.001\n",
        "batch_size = 32\n",
        "threshold = 0.1\n",
        "\n",
        "loaded_models = [res_net01, res_net02, res_net03, res_net04, res_net05, res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "                 res_net11, res_net12, res_net13, res_net14, res_net15, res_net16, res_net17, res_net18, res_net19, res_net20]\n",
        "\n",
        "Known_data_X_test_as_tensor = tf.convert_to_tensor(Known_data_X_test)\n",
        "\n",
        "odin_scores_for_models = [np.array([]) for _ in loaded_models]\n",
        "\n",
        "def compute_odin_scores_for_model(model, images, threshold):\n",
        "    logits_layer = model.layers[-2].output\n",
        "    logits_model = tf.keras.Model(inputs=model.input, outputs=logits_layer)\n",
        "\n",
        "    odin_scores_KNOWN = []\n",
        "\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch = images[i:i + batch_size]\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            logits = logits_model(batch)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(batch)\n",
        "            output = logits_model(batch)\n",
        "        grads = tape.gradient(output, batch)\n",
        "\n",
        "        signed_grads = tf.sign(grads)\n",
        "\n",
        "        perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "        scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "        perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "        max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "        max_logits = tf.reduce_max(tf.nn.softmax(logits), axis=1)\n",
        "        odin_scores_batch = max_logits - max_perturbed_softmax_scores\n",
        "\n",
        "        odin_scores_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "    return np.array(odin_scores_KNOWN)\n",
        "\n",
        "for model_index, model in enumerate(loaded_models):\n",
        "    odin_scores = compute_odin_scores_for_model(model, Known_data_X_test_as_tensor, threshold)\n",
        "    odin_scores_for_models[model_index] = odin_scores\n"
      ],
      "metadata": {
        "id": "FCW1K-UwCkiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "all_odin_scores = []\n",
        "for scores in odin_scores_for_models:\n",
        "    all_odin_scores.extend(scores)\n",
        "\n",
        "folder_path = \"/content/gdrive/MyDrive/Stanford_data\"\n",
        "\n",
        "file_name = \"KNOWN_all_odin_scores_NAIVEKp1p3.txt\"\n",
        "\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    for score in all_odin_scores:\n",
        "        file.write(f\"{score}\\n\")"
      ],
      "metadata": {
        "id": "CnM_MpuCi9yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wGVzfgDjNZM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temperature = 1000\n",
        "magnitude = 0.001\n",
        "\n",
        "UN_Known_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "logits_layer = res_net01.layers[-2].output\n",
        "logits_model = tf.keras.Model(inputs=res_net01.input, outputs=logits_layer)\n",
        "\n",
        "odin_scores_UN_KNOWN = []\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "for i in range(0, len(NeverSeen_data_X_test), batch_size):\n",
        "    batch = UN_Known_data_X_test_as_tensor[i:i+batch_size]\n",
        "\n",
        "    with tf.device(\"/CPU:0\"):\n",
        "        logits = logits_model(batch)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(batch)\n",
        "        output = logits_model(batch)\n",
        "    grads = tape.gradient(output, batch)\n",
        "\n",
        "    signed_grads = tf.sign(grads)\n",
        "\n",
        "    perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "    with tf.device(\"/CPU:0\"):\n",
        "        perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "    scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "    perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "    max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "    max_logits = tf.reduce_max(tf.nn.softmax(logits), axis=1)\n",
        "    odin_scores_batch = max_logits - max_perturbed_softmax_scores\n",
        "\n",
        "    odin_scores_UN_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "odin_scores_UN_KNOWN = np.array(odin_scores_UN_KNOWN)\n",
        "\n",
        "plt.hist(odin_scores_UN_KNOWN, bins=10)\n",
        "\n",
        "plt.xlabel('ODIN Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of ODIN UNKNOWN Scores')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "sYCaEow6TjZX",
        "outputId": "2b8e8378-7c29-407a-cb4f-ce7d291b68e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(odin_scores_UN_KNOWN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILGfFvuNTjcG",
        "outputId": "5b47cd5f-149c-4ffa-db1c-888b302b01e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.027058257"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "magnitude = 0.001\n",
        "temperature = 1000\n",
        "num_models = 20\n",
        "\n",
        "loaded_models = [\n",
        "    res_net01, res_net02, res_net03, res_net04, res_net05,\n",
        "    res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "    res_net11, res_net12, res_net13, res_net14, res_net15,\n",
        "    res_net16, res_net17, res_net18, res_net19, res_net20\n",
        "]\n",
        "\n",
        "odin_scores_all_models = []\n",
        "\n",
        "for i in range(num_models):\n",
        "    logits_layer = loaded_models[i].layers[-2].output\n",
        "\n",
        "    logits_model = tf.keras.Model(inputs=loaded_models[i].input, outputs=logits_layer)\n",
        "\n",
        "    Known_data_X_test_as_tensor = tf.convert_to_tensor(Known_data_X_test)\n",
        "\n",
        "    odin_scores_KNOWN = []\n",
        "\n",
        "    for j in range(0, len(Known_data_X_test), batch_size):\n",
        "        batch = Known_data_X_test_as_tensor[j:j+batch_size]\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            logits = logits_model(batch)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(batch)\n",
        "            logits = logits_model(batch)\n",
        "        grads = tape.gradient(logits, batch)\n",
        "\n",
        "        signed_grads = tf.sign(grads)\n",
        "\n",
        "        perturbed_spectra = batch + magnitude * signed_grads\n",
        "\n",
        "        with tf.device(\"/CPU:0\"):\n",
        "            perturbed_logits = logits_model(perturbed_spectra)\n",
        "\n",
        "        scaled_perturbed_logits = perturbed_logits / temperature\n",
        "\n",
        "        perturbed_softmax_output = tf.nn.softmax(scaled_perturbed_logits)\n",
        "\n",
        "        max_perturbed_softmax_scores = tf.reduce_max(perturbed_softmax_output, axis=1)\n",
        "\n",
        "        original_softmax_output = tf.nn.softmax(logits / temperature)\n",
        "        max_softmax_scores = tf.reduce_max(original_softmax_output, axis=1)\n",
        "\n",
        "        odin_scores_batch = max_softmax_scores - max_perturbed_softmax_scores\n",
        "\n",
        "        odin_scores_KNOWN.extend(odin_scores_batch)\n",
        "\n",
        "    odin_scores_KNOWN = np.array(odin_scores_KNOWN)\n",
        "    odin_scores_all_models.append(odin_scores_KNOWN)\n",
        "\n",
        "combined_odin_scores = np.concatenate(odin_scores_all_models)\n",
        "\n",
        "plt.hist(combined_odin_scores, bins=10)\n",
        "\n",
        "plt.xlabel('ODIN Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of ODIN Scores for Known Data (All Models)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "q_TY7dM1TjeZ",
        "outputId": "64a1e3c6-9401-43af-c8d9-0a36520d6f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/gdrive/MyDrive/Stanford_data\"\n",
        "file_name = \"KNOWN_all_odin_scores_NAIVEKp1p3.txt\"\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "np.savetxt(file_path, combined_odin_scores, delimiter=',')\n"
      ],
      "metadata": {
        "id": "JALwLcdUNZPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFMUQqj33p1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBTm9C9NABqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# All loaded models\n",
        "loaded_models = [res_net01, res_net02, res_net03, res_net04, res_net05, res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "                 res_net11, res_net12, res_net13, res_net14, res_net15, res_net16, res_net17, res_net18, res_net19, res_net20]\n",
        "\n",
        "deep_features_known_all = []\n",
        "mahalanobis_distances_known_all = []\n",
        "deep_features_unknown_all = []\n",
        "mahalanobis_distances_unknown_all = []\n",
        "\n",
        "# Number of PCA components to regularize the Mahalanobis matrix\n",
        "n_components = 100\n",
        "\n",
        "for model in loaded_models:\n",
        "    deep_features_known = extract_deep_features(model, Known_data_X_test)\n",
        "    deep_features_unknown = extract_deep_features(model, NeverSeen_data_X_test)\n",
        "\n",
        "    # PCA for dimensionality reduction\n",
        "    pca = PCA(n_components=n_components)\n",
        "    deep_features_known_pca = pca.fit_transform(deep_features_known)\n",
        "    deep_features_unknown_pca = pca.transform(deep_features_unknown)\n",
        "\n",
        "    mean_known = np.mean(deep_features_known_pca, axis=0)\n",
        "    cov_known = np.cov(deep_features_known_pca, rowvar=False)\n",
        "\n",
        "    cond_number = np.linalg.cond(cov_known)\n",
        "    print(\"Condition Number of Covariance Matrix (Known Data):\", cond_number)\n",
        "\n",
        "    # Regularization parameter\n",
        "    epsilon = 1e-5\n",
        "\n",
        "    if cond_number > 1 / epsilon:\n",
        "        cov_known_reg = cov_known + epsilon * np.eye(cov_known.shape[0])\n",
        "    else:\n",
        "        cov_known_reg = cov_known\n",
        "\n",
        "    # Compute Mahalanobis distances for known and unknown deep features\n",
        "    mahalanobis_distances_known = []\n",
        "    for feature in deep_features_known_pca:\n",
        "        mahalanobis_distance = distance.mahalanobis(feature, mean_known, np.linalg.inv(cov_known_reg))\n",
        "        mahalanobis_distances_known.append(mahalanobis_distance)\n",
        "\n",
        "    mahalanobis_distances_unknown = []\n",
        "    for feature in deep_features_unknown_pca:\n",
        "        mahalanobis_distance = distance.mahalanobis(feature, mean_known, np.linalg.inv(cov_known_reg))\n",
        "        mahalanobis_distances_unknown.append(mahalanobis_distance)\n",
        "\n",
        "    deep_features_known_all.append(deep_features_known_pca)\n",
        "    mahalanobis_distances_known_all.append(mahalanobis_distances_known)\n",
        "    deep_features_unknown_all.append(deep_features_unknown_pca)\n",
        "    mahalanobis_distances_unknown_all.append(mahalanobis_distances_unknown)\n",
        "\n",
        "deep_features_known_combined = np.concatenate(deep_features_known_all, axis=-1)\n",
        "mahalanobis_distances_known_combined = np.mean(mahalanobis_distances_known_all, axis=0)\n",
        "\n",
        "deep_features_unknown_combined = np.concatenate(deep_features_unknown_all, axis=-1)\n",
        "mahalanobis_distances_unknown_combined = np.mean(mahalanobis_distances_unknown_all, axis=0)\n",
        "\n",
        "threshold_known = 3.0\n",
        "threshold_unknown = 4.0\n",
        "\n",
        "ood_samples_known = [i for i, distance in enumerate(mahalanobis_distances_known_combined) if distance > threshold_known]\n",
        "ood_samples_unknown = [i for i, distance in enumerate(mahalanobis_distances_unknown_combined) if distance > threshold_unknown]\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(mahalanobis_distances_known_combined, bins=10)\n",
        "plt.xlabel('Mahalanobis Distance')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Mahalanobis Scores for Known Data (Combined)')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(mahalanobis_distances_unknown_combined, bins=10)\n",
        "plt.xlabel('Mahalanobis Distance')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Mahalanobis Scores for Unknown Data (Combined)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FmT4CO1zABsf",
        "outputId": "577c77bf-1f42-486f-a3ec-66c54410c056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 11s 202ms/step\n",
            "32/32 [==============================] - 7s 193ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 253.25168256197594\n",
            "47/47 [==============================] - 10s 185ms/step\n",
            "32/32 [==============================] - 7s 176ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 228.70166800074475\n",
            "47/47 [==============================] - 9s 179ms/step\n",
            "32/32 [==============================] - 7s 186ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 241.09720677004123\n",
            "47/47 [==============================] - 10s 184ms/step\n",
            "32/32 [==============================] - 7s 172ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 242.7929371321592\n",
            "47/47 [==============================] - 10s 180ms/step\n",
            "32/32 [==============================] - 7s 177ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 211.6374411275592\n",
            "47/47 [==============================] - 10s 183ms/step\n",
            "32/32 [==============================] - 7s 173ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 238.8628260430703\n",
            "47/47 [==============================] - 9s 180ms/step\n",
            "32/32 [==============================] - 8s 184ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 227.21824548298287\n",
            "47/47 [==============================] - 10s 183ms/step\n",
            "32/32 [==============================] - 7s 179ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 245.72828010982155\n",
            "47/47 [==============================] - 10s 189ms/step\n",
            "32/32 [==============================] - 7s 179ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 226.0599349810238\n",
            "47/47 [==============================] - 9s 178ms/step\n",
            "32/32 [==============================] - 7s 185ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 240.8933024380566\n",
            "47/47 [==============================] - 10s 185ms/step\n",
            "32/32 [==============================] - 7s 172ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 244.9736563957353\n",
            "47/47 [==============================] - 10s 185ms/step\n",
            "32/32 [==============================] - 7s 175ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 230.68705318774946\n",
            "47/47 [==============================] - 10s 185ms/step\n",
            "32/32 [==============================] - 7s 178ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 250.41307613273776\n",
            "47/47 [==============================] - 9s 177ms/step\n",
            "32/32 [==============================] - 7s 178ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 219.82698586124084\n",
            "47/47 [==============================] - 10s 183ms/step\n",
            "32/32 [==============================] - 7s 174ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 219.78684848860362\n",
            "47/47 [==============================] - 9s 178ms/step\n",
            "32/32 [==============================] - 7s 179ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 209.9862133711543\n",
            "47/47 [==============================] - 10s 185ms/step\n",
            "32/32 [==============================] - 7s 177ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 211.89634069558076\n",
            "47/47 [==============================] - 10s 184ms/step\n",
            "32/32 [==============================] - 7s 177ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 214.23427385020517\n",
            "47/47 [==============================] - 9s 176ms/step\n",
            "32/32 [==============================] - 7s 175ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 206.1650291744095\n",
            "47/47 [==============================] - 10s 179ms/step\n",
            "32/32 [==============================] - 7s 191ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 222.913724424494\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt(f'{folder_path}/mahalanobis_distances_known_combined_Naivep1p3.txt', mahalanobis_distances_known_combined)\n",
        "np.savetxt(f'{folder_path}/mahalanobis_distances_unknown_combined_Naivep1p3.txt', mahalanobis_distances_unknown_combined)"
      ],
      "metadata": {
        "id": "UhiPV5qLABv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v2Qd-gzRAByY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([odin_scores_KNOWN, odin_scores_UN_KNOWN], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])  # Specify the number of bins and labels\n",
        "\n",
        "plt.xlabel('Value of the ODIN score')\n",
        "plt.ylabel('Frequency of occurrence')\n",
        "plt.title('Comparison of ODIN scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "UAEfN6DoNZRv",
        "outputId": "e35eab05-cd52-4525-8861-95afeaedfcee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of 1 model"
      ],
      "metadata": {
        "id": "iK-ron4-IeD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logits_layer = res_net01.layers[-2].output\n",
        "\n",
        "logits_model = tf.keras.Model(inputs=res_net01.input, outputs=logits_layer)\n",
        "\n",
        "Known_data_X_test_as_tensor = tf.convert_to_tensor(Known_data_X_test)\n",
        "NeverSeen_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "known_logits = logits_model(Known_data_X_test_as_tensor)\n",
        "unknown_logits = logits_model(NeverSeen_data_X_test_as_tensor)\n",
        "\n",
        "max_known_logits = tf.reduce_max(known_logits, axis=1)\n",
        "max_unknown_logits = tf.reduce_max(unknown_logits, axis=1)\n",
        "\n",
        "def compute_openmax_scores_known(max_known_logits, alpha=1.0):\n",
        "    scores_known = tf.exp(alpha * max_known_logits) / tf.reduce_sum(tf.exp(alpha * max_known_logits))\n",
        "    return scores_known\n",
        "\n",
        "openmax_scores_known = compute_openmax_scores_known(max_known_logits)\n",
        "\n",
        "def compute_openmax_scores_unknown(max_known_logits, max_unknown_logits, alpha=1.0):\n",
        "    scores_unknown = []\n",
        "    for max_known, max_unknown in zip(max_known_logits, max_unknown_logits):\n",
        "        unknown_score = tf.exp(alpha * max_known) / (tf.exp(alpha * max_known) + tf.exp(alpha * max_unknown))\n",
        "        scores_unknown.append(unknown_score)\n",
        "    return tf.stack(scores_unknown)\n",
        "\n",
        "openmax_scores_unknown = compute_openmax_scores_unknown(max_known_logits, max_unknown_logits)\n",
        "\n",
        "openmax_scores_known = openmax_scores_known.numpy()\n",
        "openmax_scores_unknown = openmax_scores_unknown.numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(openmax_scores_known, bins=10)\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Known Data')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(openmax_scores_unknown, bins=10)\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Unknown Data')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "jN6kNhDByVtq",
        "outputId": "07887560-0484-4830-f528-3276e9a3450a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "alpha = 1.0\n",
        "num_models = 20\n",
        "\n",
        "loaded_models = [res_net01, res_net02, res_net03, res_net04, res_net05, res_net06, res_net07, res_net08, res_net09, res_net10,\n",
        "                 res_net11, res_net12, res_net13, res_net14, res_net15, res_net16, res_net17, res_net18, res_net19, res_net20]\n",
        "\n",
        "openmax_scores_known = []\n",
        "openmax_scores_unknown = []\n",
        "\n",
        "Known_data_X_test_as_tensor = tf.convert_to_tensor(Known_data_X_test)\n",
        "NeverSeen_data_X_test_as_tensor = tf.convert_to_tensor(NeverSeen_data_X_test)\n",
        "\n",
        "for model in loaded_models:\n",
        "    logits_layer = model.layers[-2].output\n",
        "\n",
        "    logits_model = tf.keras.Model(inputs=model.input, outputs=logits_layer)\n",
        "\n",
        "    known_logits = logits_model(Known_data_X_test_as_tensor)\n",
        "    unknown_logits = logits_model(NeverSeen_data_X_test_as_tensor)\n",
        "\n",
        "    max_known_logits = tf.reduce_max(known_logits, axis=1)\n",
        "    max_unknown_logits = tf.reduce_max(unknown_logits, axis=1)\n",
        "\n",
        "    scores_known = tf.exp(alpha * max_known_logits) / tf.reduce_sum(tf.exp(alpha * max_known_logits))\n",
        "\n",
        "    scores_unknown = []\n",
        "    for max_known, max_unknown in zip(max_known_logits, max_unknown_logits):\n",
        "        unknown_score = tf.exp(alpha * max_known) / (tf.exp(alpha * max_known) + tf.exp(alpha * max_unknown))\n",
        "        scores_unknown.append(unknown_score)\n",
        "\n",
        "    openmax_scores_known.append(scores_known.numpy())\n",
        "    openmax_scores_unknown.append(scores_unknown)\n",
        "\n",
        "merged_openmax_scores_known = np.stack(openmax_scores_known, axis=1)\n",
        "merged_openmax_scores_unknown = np.stack(openmax_scores_unknown, axis=1)\n",
        "\n",
        "combined_openmax_scores_known = merged_openmax_scores_known.flatten()\n",
        "combined_openmax_scores_unknown = merged_openmax_scores_unknown.flatten()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(combined_openmax_scores_known, bins=10, alpha=0.5, label=[f'Model {i+1}' for i in range(num_models)])\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Known Data')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(combined_openmax_scores_unknown, bins=10, alpha=0.5, label=[f'Model {i+1}' for i in range(num_models)])\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Unknown Data')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "rlg6yEIOsv-W",
        "outputId": "c2dc8d50-885a-4fad-f1a8-80fb8eb0cc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt('/content/gdrive/MyDrive/Stanford_data/NaiveKp1p3_combined_openmax_scores_known.txt', combined_openmax_scores_known)\n",
        "np.savetxt('/content/gdrive/MyDrive/Stanford_data/NaiveKp1p3_combined_openmax_scores_unknown.txt', combined_openmax_scores_unknown)\n"
      ],
      "metadata": {
        "id": "kw6IcLHmswBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SsrGbueaswDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([openmax_scores_known, openmax_scores_unknown], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "\n",
        "plt.xlabel('Value of the OpenMax score')\n",
        "plt.ylabel('Frequency of occurrence')\n",
        "plt.title('Comparison of OpenMax scores, Naive, $\\mathcal{K} = p_1 + p_3$, $\\mathcal{I} = \\emptyset$')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "mfIQKwId0zIA",
        "outputId": "4d609580-fe70-4ec6-b7d8-8fb97c150ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(openmax_scores_known)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-nBrEfbyVwY",
        "outputId": "0bfde404-c497-4a00-baed-185ea15b62f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6427326"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(openmax_scores_unknown)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l10GGVozyVzh",
        "outputId": "4a97cc27-2713-4ea2-85c8-9c57395a852c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8391194e-05"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "openmax_scores_known_sorted = np.sort(openmax_scores_known)\n",
        "openmax_scores_unknown_sorted = np.sort(openmax_scores_unknown)\n",
        "\n",
        "min_known_score = openmax_scores_known_sorted.min()\n",
        "max_known_score = openmax_scores_known_sorted.max()\n",
        "min_unknown_score = openmax_scores_unknown_sorted.min()\n",
        "max_unknown_score = openmax_scores_unknown_sorted.max()\n",
        "\n",
        "bins = np.linspace(min(min_known_score, min_unknown_score), max(max_known_score, max_unknown_score), 1000)\n",
        "\n",
        "hist_known, _ = np.histogram(openmax_scores_known_sorted, bins)\n",
        "hist_unknown, _ = np.histogram(openmax_scores_unknown_sorted, bins)\n",
        "\n",
        "intersection = np.minimum(hist_known, hist_unknown)\n",
        "union = np.maximum(hist_known, hist_unknown)\n",
        "\n",
        "iou = np.sum(intersection) / np.sum(union) * 100\n",
        "\n",
        "print(f\"Overlap (IoU): {iou:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5WsoePtyV2O",
        "outputId": "02f95676-3ac2-4ef2-f6b4-f5a5986c96a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap (IoU): 1.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "import tensorflow as tf\n",
        "\n",
        "def preprocess_data(data):\n",
        "    preprocessed_data = data\n",
        "    return preprocessed_data\n",
        "\n",
        "def extract_deep_features(model, data):\n",
        "    preprocessed_data = preprocess_data(data)\n",
        "\n",
        "    deep_features = model.layers[-2].output\n",
        "    deep_feature_model = tf.keras.Model(inputs=model.input, outputs=deep_features)\n",
        "    extracted_features = deep_feature_model.predict(preprocessed_data)\n",
        "\n",
        "    return extracted_features\n",
        "\n",
        "deep_features_known = extract_deep_features(res_net01, Known_data_X_test)\n",
        "deep_features_unknown = extract_deep_features(res_net01, NeverSeen_data_X_test)\n",
        "\n",
        "mean_known = np.mean(deep_features_known, axis=0)\n",
        "cov_known = np.cov(deep_features_known, rowvar=False)\n",
        "\n",
        "cond_number = np.linalg.cond(cov_known)\n",
        "print(\"Condition Number of Covariance Matrix (Known Data):\", cond_number)\n",
        "\n",
        "epsilon = 1e-6\n",
        "\n",
        "if cond_number > 1 / epsilon:\n",
        "    cov_known_reg = cov_known + epsilon * np.eye(cov_known.shape[0])\n",
        "else:\n",
        "    cov_known_reg = cov_known\n",
        "\n",
        "mahalanobis_distances_known = []\n",
        "for feature in deep_features_known:\n",
        "    mahalanobis_distance = distance.mahalanobis(feature, mean_known, np.linalg.inv(cov_known_reg))\n",
        "    mahalanobis_distances_known.append(mahalanobis_distance)\n",
        "\n",
        "mahalanobis_distances_unknown = []\n",
        "for feature in deep_features_unknown:\n",
        "    mahalanobis_distance = distance.mahalanobis(feature, mean_known, np.linalg.inv(cov_known_reg))\n",
        "    mahalanobis_distances_unknown.append(mahalanobis_distance)\n",
        "\n",
        "threshold_known = 3.0\n",
        "threshold_unknown = 4.0\n",
        "\n",
        "ood_samples_known = [i for i, distance in enumerate(mahalanobis_distances_known) if distance > threshold_known]\n",
        "ood_samples_unknown = [i for i, distance in enumerate(mahalanobis_distances_unknown) if distance > threshold_unknown]\n",
        "\n",
        "print(\"Out-of-Distribution Sample Indices (Known Data):\", ood_samples_known)\n",
        "print(\"Out-of-Distribution Sample Indices (Unknown Data):\", ood_samples_unknown)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSYqyZCS5PMH",
        "outputId": "38794514-23d2-4add-a0a1-f5daa1d1c227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 33s 680ms/step\n",
            "32/32 [==============================] - 21s 590ms/step\n",
            "Condition Number of Covariance Matrix (Known Data): 4.439165158466121e+21\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-288ca2bca1c9>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mmahalanobis_distances_known\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeep_features_known\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mmahalanobis_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmahalanobis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_known\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_known_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mmahalanobis_distances_known\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmahalanobis_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(mahalanobis_distances_known, bins=10)\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Known Data')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(mahalanobis_distances_unknown, bins=10)\n",
        "plt.xlabel('OpenMax Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of OpenMax Scores for Unknown Data')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ml0THzer5PPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([mahalanobis_distances_known, mahalanobis_distances_unknown], bins=25, label=['Samples belonging to the knowns', 'Never seen before samples'])  # Specify the number of bins and labels\n",
        "plt.xlim(2.5, 15)\n",
        "\n",
        "plt.xlabel('Value of the Mahalanobis score')\n",
        "plt.ylabel('Frequency of occurrence')\n",
        "plt.title('Comparison of Mahalanobis scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RlgL09fo5PRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "mahalanobis_scores_known_sorted = np.sort(mahalanobis_distances_known)\n",
        "mahalanobis_scores_unknown_sorted = np.sort(mahalanobis_distances_unknown)\n",
        "\n",
        "min_known_score = mahalanobis_scores_known_sorted.min()\n",
        "max_known_score = mahalanobis_scores_known_sorted.max()\n",
        "min_unknown_score = mahalanobis_scores_unknown_sorted.min()\n",
        "max_unknown_score = mahalanobis_scores_unknown_sorted.max()\n",
        "\n",
        "bins = np.linspace(min(min_known_score, min_unknown_score), max(max_known_score, max_unknown_score), 1000)\n",
        "\n",
        "hist_known, _ = np.histogram(mahalanobis_scores_known_sorted, bins)\n",
        "hist_unknown, _ = np.histogram(mahalanobis_scores_unknown_sorted, bins)\n",
        "\n",
        "intersection = np.minimum(hist_known, hist_unknown)\n",
        "union = np.maximum(hist_known, hist_unknown)\n",
        "\n",
        "iou = np.sum(intersection) / np.sum(union) * 100\n",
        "\n",
        "print(f\"Overlap (IoU): {iou:.2f}%\")"
      ],
      "metadata": {
        "id": "I8Xxqpvr5PUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCiMJfcc5PW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(3, 1, figsize=(8, 12))  # 3 rows, 1 column\n",
        "\n",
        "axs[0].hist([odin_scores_KNOWN, odin_scores_UN_KNOWN], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[0].set_xlabel('Value of the ODIN score')\n",
        "axs[0].set_ylabel('Frequency of occurrence')\n",
        "axs[0].set_title('Comparison of ODIN scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].hist([openmax_scores_known, openmax_scores_unknown], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[1].set_xlabel('Value of the OpenMax score')\n",
        "axs[1].set_ylabel('Frequency of occurrence')\n",
        "axs[1].set_title('Comparison of OpenMax scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[2].hist([mahalanobis_distances_known, mahalanobis_distances_unknown], bins=25, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[2].set_xlabel('Value of the Mahalanobis score')\n",
        "axs[2].set_ylabel('Frequency of occurrence')\n",
        "axs[2].set_title('Comparison of Mahalanobis scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OuSPZIJdF49F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "axs[0].hist([odin_scores_KNOWN, odin_scores_UN_KNOWN], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[0].set_xlabel('Value of the ODIN score')\n",
        "axs[0].set_ylabel('Frequency of occurrence')\n",
        "axs[0].set_title('Comparison of ODIN scores, Obj.class, $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].hist([openmax_scores_known, openmax_scores_unknown], bins=10, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[1].set_xlabel('Value of the OpenMax score')\n",
        "axs[1].set_ylabel('Frequency of occurrence')\n",
        "axs[1].set_title('Comparison of OpenMax scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[2].hist([mahalanobis_distances_known, mahalanobis_distances_unknown], bins=25, label=['Samples belonging to the knowns', 'Never seen before samples'])\n",
        "axs[2].set_xlabel('Value of the Mahalanobis score')\n",
        "axs[2].set_ylabel('Frequency of occurrence')\n",
        "axs[2].set_title('Comparison of Mahalanobis scores, Obj., $\\mathcal{K} = p_1$, $\\mathcal{I} = p_3$')\n",
        "axs[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zGqgXKZVF5AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUiyR6MKF5Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pebv8wScFiK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "18E12wUJFiM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5b8ExRFJFiPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMXsmbFbFiRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kU6SdJV9FiUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QW7PifIAFiWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bOdG05nkFiYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uvLNft8RFia2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E248mikiFidM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VhxkerZ7FifO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkIDZmeWFihP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separating $\\mathcal{K}$ and $\\mathcal{N}$ by a fixed (class-independendent) threshold"
      ],
      "metadata": {
        "id": "E3Pq2KqHYYgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_known = prediction_known_ensemble_1\n",
        "prediction_unknown = prediction_unknown_ensemble_1"
      ],
      "metadata": {
        "id": "yZfHJkznZ4Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def thresholding(threshold):\n",
        "  true = 0\n",
        "  for i in range(prediction_known.shape[0]):\n",
        "    if prediction_known.argmax(axis=1)[i] == Known_data_X_test_label_int[i] and max(prediction_known[i]) > threshold:\n",
        "      true += 1\n",
        "  return true/(prediction_known.shape[0])"
      ],
      "metadata": {
        "id": "HA75xLuUGNca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW6PGNX72bky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09238a32-4fe9-4dfd-a129-1ee19bced6ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.1, 88.33333333333333],\n",
              " [0.11, 88.33333333333333],\n",
              " [0.12000000000000001, 88.33333333333333],\n",
              " [0.13, 88.33333333333333],\n",
              " [0.14, 88.33333333333333],\n",
              " [0.15000000000000002, 88.33333333333333],\n",
              " [0.16, 88.33333333333333],\n",
              " [0.17, 88.33333333333333],\n",
              " [0.18, 88.33333333333333],\n",
              " [0.19, 88.33333333333333],\n",
              " [0.2, 88.33333333333333],\n",
              " [0.21000000000000002, 88.33333333333333],\n",
              " [0.22, 88.33333333333333],\n",
              " [0.23, 88.33333333333333],\n",
              " [0.24000000000000002, 88.33333333333333],\n",
              " [0.25, 88.33333333333333],\n",
              " [0.26, 88.33333333333333],\n",
              " [0.27, 88.33333333333333],\n",
              " [0.28, 88.33333333333333],\n",
              " [0.29000000000000004, 88.33333333333333],\n",
              " [0.30000000000000004, 88.33333333333333],\n",
              " [0.31, 88.33333333333333],\n",
              " [0.32, 88.33333333333333],\n",
              " [0.33, 88.33333333333333],\n",
              " [0.33999999999999997, 88.33333333333333],\n",
              " [0.35, 88.26666666666667],\n",
              " [0.36, 88.26666666666667],\n",
              " [0.37, 88.26666666666667],\n",
              " [0.38, 88.26666666666667],\n",
              " [0.39, 88.2],\n",
              " [0.4, 88.13333333333333],\n",
              " [0.41000000000000003, 88.06666666666668],\n",
              " [0.42000000000000004, 88.06666666666668],\n",
              " [0.43000000000000005, 88.06666666666668],\n",
              " [0.44000000000000006, 87.86666666666667],\n",
              " [0.45000000000000007, 87.86666666666667],\n",
              " [0.45999999999999996, 87.73333333333333],\n",
              " [0.47, 87.66666666666667],\n",
              " [0.48, 87.6],\n",
              " [0.49, 87.6],\n",
              " [0.5, 87.53333333333333],\n",
              " [0.51, 87.33333333333333],\n",
              " [0.52, 87.0],\n",
              " [0.53, 86.86666666666667],\n",
              " [0.54, 86.86666666666667],\n",
              " [0.55, 86.8],\n",
              " [0.56, 86.6],\n",
              " [0.5700000000000001, 86.46666666666667],\n",
              " [0.58, 86.33333333333333],\n",
              " [0.59, 86.26666666666667],\n",
              " [0.6, 86.13333333333333],\n",
              " [0.61, 85.73333333333333],\n",
              " [0.62, 85.46666666666667],\n",
              " [0.63, 85.39999999999999],\n",
              " [0.64, 85.06666666666666],\n",
              " [0.65, 84.93333333333334],\n",
              " [0.66, 84.8],\n",
              " [0.67, 84.53333333333333],\n",
              " [0.6799999999999999, 84.33333333333334],\n",
              " [0.69, 83.86666666666667],\n",
              " [0.7, 83.73333333333333],\n",
              " [0.71, 83.46666666666667],\n",
              " [0.72, 83.26666666666667],\n",
              " [0.73, 83.13333333333334],\n",
              " [0.74, 82.8],\n",
              " [0.75, 82.66666666666667],\n",
              " [0.76, 82.33333333333334],\n",
              " [0.77, 82.26666666666667],\n",
              " [0.78, 82.19999999999999],\n",
              " [0.79, 82.06666666666666],\n",
              " [0.8, 81.73333333333333],\n",
              " [0.8099999999999999, 81.46666666666667],\n",
              " [0.82, 81.2],\n",
              " [0.83, 80.66666666666666],\n",
              " [0.84, 80.33333333333333],\n",
              " [0.85, 80.06666666666666],\n",
              " [0.86, 79.73333333333333],\n",
              " [0.87, 79.46666666666667],\n",
              " [0.88, 79.26666666666667],\n",
              " [0.89, 78.93333333333334],\n",
              " [0.9, 78.0],\n",
              " [0.91, 77.60000000000001],\n",
              " [0.92, 76.93333333333334],\n",
              " [0.93, 76.13333333333333],\n",
              " [0.94, 75.13333333333333],\n",
              " [0.95, 74.2],\n",
              " [0.96, 73.0],\n",
              " [0.97, 71.26666666666667],\n",
              " [0.98, 68.13333333333334],\n",
              " [0.99, 64.2],\n",
              " [0.99, 64.2],\n",
              " [0.991, 63.53333333333333],\n",
              " [0.992, 62.26666666666667],\n",
              " [0.993, 61.266666666666666],\n",
              " [0.994, 60.13333333333334],\n",
              " [0.995, 59.0],\n",
              " [0.996, 57.46666666666667],\n",
              " [0.997, 55.60000000000001],\n",
              " [0.998, 53.0],\n",
              " [0.999, 47.66666666666667]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "CorrectThresholding = []\n",
        "for i in range(90):\n",
        "  CorrectThresholding.append([0.1 + 0.01*i,100*thresholding(0.1 + 0.01*i)])\n",
        "for i in range(10):\n",
        "  CorrectThresholding.append([0.99 + 0.001*i,100*thresholding(0.99 + 0.001*i)])\n",
        "CorrectThresholding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def false_identify(threshold):\n",
        "  false_identify = 0\n",
        "  for i in range(prediction_known.shape[0]):\n",
        "    if prediction_known.argmax(axis=1)[i] != Known_data_X_test_label_int[i] and max(prediction_known[i]) > threshold:\n",
        "      false_identify += 1\n",
        "  return false_identify/(prediction_known.shape[0])"
      ],
      "metadata": {
        "id": "Vn2lRWxDM4G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FalseIdentify = []\n",
        "for i in range(90):\n",
        "  FalseIdentify.append([0.1 + 0.01*i,100*false_identify(0.1 + 0.01*i)])\n",
        "for i in range(10):\n",
        "  FalseIdentify.append([0.99 + 0.001*i,100*false_identify(0.99 + 0.001*i)])\n",
        "FalseIdentify"
      ],
      "metadata": {
        "id": "M753dWrlM4Km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee78d0be-cdf2-4ce6-fbf7-f91d9f56dedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.1, 11.666666666666666],\n",
              " [0.11, 11.666666666666666],\n",
              " [0.12000000000000001, 11.666666666666666],\n",
              " [0.13, 11.666666666666666],\n",
              " [0.14, 11.666666666666666],\n",
              " [0.15000000000000002, 11.666666666666666],\n",
              " [0.16, 11.666666666666666],\n",
              " [0.17, 11.666666666666666],\n",
              " [0.18, 11.666666666666666],\n",
              " [0.19, 11.666666666666666],\n",
              " [0.2, 11.666666666666666],\n",
              " [0.21000000000000002, 11.666666666666666],\n",
              " [0.22, 11.666666666666666],\n",
              " [0.23, 11.666666666666666],\n",
              " [0.24000000000000002, 11.666666666666666],\n",
              " [0.25, 11.666666666666666],\n",
              " [0.26, 11.666666666666666],\n",
              " [0.27, 11.600000000000001],\n",
              " [0.28, 11.600000000000001],\n",
              " [0.29000000000000004, 11.600000000000001],\n",
              " [0.30000000000000004, 11.600000000000001],\n",
              " [0.31, 11.533333333333333],\n",
              " [0.32, 11.533333333333333],\n",
              " [0.33, 11.466666666666667],\n",
              " [0.33999999999999997, 11.333333333333332],\n",
              " [0.35, 11.333333333333332],\n",
              " [0.36, 11.266666666666666],\n",
              " [0.37, 11.200000000000001],\n",
              " [0.38, 11.200000000000001],\n",
              " [0.39, 11.200000000000001],\n",
              " [0.4, 11.200000000000001],\n",
              " [0.41000000000000003, 11.200000000000001],\n",
              " [0.42000000000000004, 11.133333333333335],\n",
              " [0.43000000000000005, 11.133333333333335],\n",
              " [0.44000000000000006, 10.933333333333334],\n",
              " [0.45000000000000007, 10.933333333333334],\n",
              " [0.45999999999999996, 10.866666666666665],\n",
              " [0.47, 10.8],\n",
              " [0.48, 10.666666666666668],\n",
              " [0.49, 10.6],\n",
              " [0.5, 10.533333333333333],\n",
              " [0.51, 10.133333333333333],\n",
              " [0.52, 10.066666666666666],\n",
              " [0.53, 9.933333333333334],\n",
              " [0.54, 9.8],\n",
              " [0.55, 9.733333333333333],\n",
              " [0.56, 9.533333333333333],\n",
              " [0.5700000000000001, 9.466666666666667],\n",
              " [0.58, 9.2],\n",
              " [0.59, 9.2],\n",
              " [0.6, 8.933333333333334],\n",
              " [0.61, 8.799999999999999],\n",
              " [0.62, 8.533333333333333],\n",
              " [0.63, 8.4],\n",
              " [0.64, 8.266666666666666],\n",
              " [0.65, 8.066666666666666],\n",
              " [0.66, 8.0],\n",
              " [0.67, 7.866666666666666],\n",
              " [0.6799999999999999, 7.866666666666666],\n",
              " [0.69, 7.6],\n",
              " [0.7, 7.533333333333333],\n",
              " [0.71, 7.199999999999999],\n",
              " [0.72, 7.133333333333333],\n",
              " [0.73, 7.133333333333333],\n",
              " [0.74, 6.933333333333333],\n",
              " [0.75, 6.800000000000001],\n",
              " [0.76, 6.7333333333333325],\n",
              " [0.77, 6.466666666666667],\n",
              " [0.78, 6.133333333333333],\n",
              " [0.79, 6.0],\n",
              " [0.8, 5.933333333333334],\n",
              " [0.8099999999999999, 5.6000000000000005],\n",
              " [0.82, 5.333333333333334],\n",
              " [0.83, 5.266666666666667],\n",
              " [0.84, 5.066666666666666],\n",
              " [0.85, 4.8],\n",
              " [0.86, 4.6],\n",
              " [0.87, 4.533333333333333],\n",
              " [0.88, 4.533333333333333],\n",
              " [0.89, 4.266666666666667],\n",
              " [0.9, 4.133333333333333],\n",
              " [0.91, 4.133333333333333],\n",
              " [0.92, 4.0],\n",
              " [0.93, 3.8666666666666667],\n",
              " [0.94, 3.5999999999999996],\n",
              " [0.95, 3.2],\n",
              " [0.96, 2.8000000000000003],\n",
              " [0.97, 2.533333333333333],\n",
              " [0.98, 2.0666666666666664],\n",
              " [0.99, 1.4666666666666666],\n",
              " [0.99, 1.4666666666666666],\n",
              " [0.991, 1.4000000000000001],\n",
              " [0.992, 1.3333333333333335],\n",
              " [0.993, 1.1333333333333333],\n",
              " [0.994, 1.0666666666666667],\n",
              " [0.995, 1.0666666666666667],\n",
              " [0.996, 1.0],\n",
              " [0.997, 0.8],\n",
              " [0.998, 0.5333333333333333],\n",
              " [0.999, 0.4]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def misclassifyunknown(threshold):\n",
        "  misclassifyunknown = 0\n",
        "  for i in range(prediction_unknown.shape[0]):\n",
        "    if max(prediction_unknown[i]) > threshold:\n",
        "      misclassifyunknown += 1\n",
        "  return misclassifyunknown/(prediction_unknown.shape[0])"
      ],
      "metadata": {
        "id": "InSYYnV1M4Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UnknownMisclassify = []\n",
        "for i in range(90):\n",
        "  UnknownMisclassify.append([0.1 + 0.01*i,100*misclassifyunknown(0.1 + 0.01*i)])\n",
        "for i in range(10):\n",
        "  UnknownMisclassify.append([0.99 + 0.001*i,100*misclassifyunknown(0.99 + 0.001*i)])\n",
        "UnknownMisclassify"
      ],
      "metadata": {
        "id": "jKdfbnzZM4ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d811dd-371f-4272-8af6-fb1c59882966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.1, 100.0],\n",
              " [0.11, 100.0],\n",
              " [0.12000000000000001, 100.0],\n",
              " [0.13, 100.0],\n",
              " [0.14, 100.0],\n",
              " [0.15000000000000002, 100.0],\n",
              " [0.16, 100.0],\n",
              " [0.17, 100.0],\n",
              " [0.18, 100.0],\n",
              " [0.19, 100.0],\n",
              " [0.2, 100.0],\n",
              " [0.21000000000000002, 100.0],\n",
              " [0.22, 100.0],\n",
              " [0.23, 100.0],\n",
              " [0.24000000000000002, 100.0],\n",
              " [0.25, 100.0],\n",
              " [0.26, 100.0],\n",
              " [0.27, 100.0],\n",
              " [0.28, 100.0],\n",
              " [0.29000000000000004, 100.0],\n",
              " [0.30000000000000004, 100.0],\n",
              " [0.31, 99.9],\n",
              " [0.32, 99.6],\n",
              " [0.33, 99.6],\n",
              " [0.33999999999999997, 99.6],\n",
              " [0.35, 99.6],\n",
              " [0.36, 99.3],\n",
              " [0.37, 99.2],\n",
              " [0.38, 99.1],\n",
              " [0.39, 99.0],\n",
              " [0.4, 98.8],\n",
              " [0.41000000000000003, 98.6],\n",
              " [0.42000000000000004, 98.6],\n",
              " [0.43000000000000005, 98.3],\n",
              " [0.44000000000000006, 98.2],\n",
              " [0.45000000000000007, 98.0],\n",
              " [0.45999999999999996, 97.8],\n",
              " [0.47, 97.6],\n",
              " [0.48, 97.39999999999999],\n",
              " [0.49, 96.89999999999999],\n",
              " [0.5, 95.89999999999999],\n",
              " [0.51, 95.19999999999999],\n",
              " [0.52, 94.19999999999999],\n",
              " [0.53, 93.4],\n",
              " [0.54, 92.30000000000001],\n",
              " [0.55, 91.5],\n",
              " [0.56, 90.5],\n",
              " [0.5700000000000001, 89.9],\n",
              " [0.58, 89.0],\n",
              " [0.59, 88.3],\n",
              " [0.6, 87.0],\n",
              " [0.61, 86.7],\n",
              " [0.62, 86.1],\n",
              " [0.63, 85.5],\n",
              " [0.64, 84.89999999999999],\n",
              " [0.65, 84.5],\n",
              " [0.66, 83.7],\n",
              " [0.67, 83.1],\n",
              " [0.6799999999999999, 82.1],\n",
              " [0.69, 80.9],\n",
              " [0.7, 80.2],\n",
              " [0.71, 79.60000000000001],\n",
              " [0.72, 79.0],\n",
              " [0.73, 77.8],\n",
              " [0.74, 77.0],\n",
              " [0.75, 75.8],\n",
              " [0.76, 75.5],\n",
              " [0.77, 74.8],\n",
              " [0.78, 74.0],\n",
              " [0.79, 73.6],\n",
              " [0.8, 72.7],\n",
              " [0.8099999999999999, 72.0],\n",
              " [0.82, 71.39999999999999],\n",
              " [0.83, 70.39999999999999],\n",
              " [0.84, 69.69999999999999],\n",
              " [0.85, 68.7],\n",
              " [0.86, 67.7],\n",
              " [0.87, 66.5],\n",
              " [0.88, 65.8],\n",
              " [0.89, 64.0],\n",
              " [0.9, 63.0],\n",
              " [0.91, 61.4],\n",
              " [0.92, 60.099999999999994],\n",
              " [0.93, 58.4],\n",
              " [0.94, 55.800000000000004],\n",
              " [0.95, 52.6],\n",
              " [0.96, 50.7],\n",
              " [0.97, 47.599999999999994],\n",
              " [0.98, 43.5],\n",
              " [0.99, 35.6],\n",
              " [0.99, 35.6],\n",
              " [0.991, 34.8],\n",
              " [0.992, 33.2],\n",
              " [0.993, 32.4],\n",
              " [0.994, 31.3],\n",
              " [0.995, 29.799999999999997],\n",
              " [0.996, 27.800000000000004],\n",
              " [0.997, 25.5],\n",
              " [0.998, 22.3],\n",
              " [0.999, 18.7]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dontknow(threshold):\n",
        "  notknown = 0\n",
        "  for i in range(prediction_known.shape[0]):\n",
        "    if max(prediction_known[i]) <= threshold:\n",
        "      notknown += 1\n",
        "  return notknown/(prediction_known.shape[0])"
      ],
      "metadata": {
        "id": "RXvKcD4fM4VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWInVYNk2bml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d89049-380a-47aa-e266-092fd8c5a5d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.1, 0.0],\n",
              " [0.11, 0.0],\n",
              " [0.12000000000000001, 0.0],\n",
              " [0.13, 0.0],\n",
              " [0.14, 0.0],\n",
              " [0.15000000000000002, 0.0],\n",
              " [0.16, 0.0],\n",
              " [0.17, 0.0],\n",
              " [0.18, 0.0],\n",
              " [0.19, 0.0],\n",
              " [0.2, 0.0],\n",
              " [0.21000000000000002, 0.0],\n",
              " [0.22, 0.0],\n",
              " [0.23, 0.0],\n",
              " [0.24000000000000002, 0.0],\n",
              " [0.25, 0.0],\n",
              " [0.26, 0.0],\n",
              " [0.27, 0.06666666666666667],\n",
              " [0.28, 0.06666666666666667],\n",
              " [0.29000000000000004, 0.06666666666666667],\n",
              " [0.30000000000000004, 0.06666666666666667],\n",
              " [0.31, 0.13333333333333333],\n",
              " [0.32, 0.13333333333333333],\n",
              " [0.33, 0.2],\n",
              " [0.33999999999999997, 0.33333333333333337],\n",
              " [0.35, 0.4],\n",
              " [0.36, 0.46666666666666673],\n",
              " [0.37, 0.5333333333333333],\n",
              " [0.38, 0.5333333333333333],\n",
              " [0.39, 0.6],\n",
              " [0.4, 0.6666666666666667],\n",
              " [0.41000000000000003, 0.7333333333333333],\n",
              " [0.42000000000000004, 0.8],\n",
              " [0.43000000000000005, 0.8],\n",
              " [0.44000000000000006, 1.2],\n",
              " [0.45000000000000007, 1.2],\n",
              " [0.45999999999999996, 1.4000000000000001],\n",
              " [0.47, 1.5333333333333332],\n",
              " [0.48, 1.7333333333333332],\n",
              " [0.49, 1.7999999999999998],\n",
              " [0.5, 1.9333333333333333],\n",
              " [0.51, 2.533333333333333],\n",
              " [0.52, 2.933333333333333],\n",
              " [0.53, 3.2],\n",
              " [0.54, 3.3333333333333335],\n",
              " [0.55, 3.4666666666666663],\n",
              " [0.56, 3.8666666666666667],\n",
              " [0.5700000000000001, 4.066666666666666],\n",
              " [0.58, 4.466666666666667],\n",
              " [0.59, 4.533333333333333],\n",
              " [0.6, 4.933333333333334],\n",
              " [0.61, 5.466666666666667],\n",
              " [0.62, 6.0],\n",
              " [0.63, 6.2],\n",
              " [0.64, 6.666666666666667],\n",
              " [0.65, 7.000000000000001],\n",
              " [0.66, 7.199999999999999],\n",
              " [0.67, 7.6],\n",
              " [0.6799999999999999, 7.8],\n",
              " [0.69, 8.533333333333333],\n",
              " [0.7, 8.733333333333333],\n",
              " [0.71, 9.333333333333334],\n",
              " [0.72, 9.6],\n",
              " [0.73, 9.733333333333333],\n",
              " [0.74, 10.266666666666667],\n",
              " [0.75, 10.533333333333333],\n",
              " [0.76, 10.933333333333334],\n",
              " [0.77, 11.266666666666666],\n",
              " [0.78, 11.666666666666666],\n",
              " [0.79, 11.933333333333334],\n",
              " [0.8, 12.333333333333334],\n",
              " [0.8099999999999999, 12.933333333333334],\n",
              " [0.82, 13.466666666666665],\n",
              " [0.83, 14.066666666666666],\n",
              " [0.84, 14.6],\n",
              " [0.85, 15.133333333333333],\n",
              " [0.86, 15.666666666666668],\n",
              " [0.87, 16.0],\n",
              " [0.88, 16.2],\n",
              " [0.89, 16.8],\n",
              " [0.9, 17.866666666666667],\n",
              " [0.91, 18.266666666666666],\n",
              " [0.92, 19.066666666666666],\n",
              " [0.93, 20.0],\n",
              " [0.94, 21.266666666666666],\n",
              " [0.95, 22.6],\n",
              " [0.96, 24.2],\n",
              " [0.97, 26.200000000000003],\n",
              " [0.98, 29.799999999999997],\n",
              " [0.99, 34.333333333333336],\n",
              " [0.99, 34.333333333333336],\n",
              " [0.991, 35.06666666666667],\n",
              " [0.992, 36.4],\n",
              " [0.993, 37.6],\n",
              " [0.994, 38.800000000000004],\n",
              " [0.995, 39.93333333333333],\n",
              " [0.996, 41.53333333333333],\n",
              " [0.997, 43.6],\n",
              " [0.998, 46.46666666666667],\n",
              " [0.999, 51.93333333333333]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "DontKnowThresholding = []\n",
        "for i in range(90):\n",
        "  DontKnowThresholding.append([0.1 + 0.01*i,100*dontknow(0.1 + 0.01*i)])\n",
        "for i in range(10):\n",
        "  DontKnowThresholding.append([0.99 + 0.001*i,100*dontknow(0.99 + 0.001*i)])\n",
        "DontKnowThresholding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aligned_array = [element for row in prediction_unknown for element in row]\n",
        "# Find the maximum value in the aligned array\n",
        "max_value = max(aligned_array)\n",
        "\n",
        "# The max_value variable now contains the maximum value in the aligned array\n",
        "print(\"The maximum value in the aligned array is:\", max_value)\n"
      ],
      "metadata": {
        "id": "whvlD7tVNOew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fb84bc3-c767-429e-e919-724ec4133743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum value in the aligned array is: 0.9999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thresholding(max_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQT16bp2f4xV",
        "outputId": "7267a0ed-4ba7-4548-bd93-bbe1c688ef15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0006666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dontknow(max_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb8_5G4-hP8l",
        "outputId": "468eab91-e0e1-46fe-c278-5907a2044419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9993333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "misclassifyunknown(max_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjStdK4hhS8K",
        "outputId": "a17844e4-4ac6-4834-a505-3b27ad7a80eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "false_identify(max_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ihRU5ZxhbjN",
        "outputId": "bc9f2a09-fbb2-4a8c-c14b-10a332663fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DontKnowThresholdingANOTHER = []\n",
        "\n",
        "for i in range(89):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.1 + 0.01*i),100*dontknow(0.1 + 0.01*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.99 + 0.001*i),100*dontknow(0.99 + 0.001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.999 + 0.0001*i),100*dontknow(0.999 + 0.0001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.9999 + 0.00001*i),100*dontknow(0.9999 + 0.00001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.99999 + 0.000001*i),100*dontknow(0.99999 + 0.000001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.999999 + 0.0000001*i),100*dontknow(0.999999 + 0.0000001*i),])\n",
        "\n",
        "for i in range(9):\n",
        "  DontKnowThresholdingANOTHER.append([100*thresholding(0.9999999 + 0.00000001*i),100*dontknow(0.9999999 + 0.00000001*i),])\n",
        "\n",
        "DontKnowThresholdingANOTHER.append([100*thresholding(max_value),100*dontknow(max_value)])\n",
        "\n",
        "DontKnowThresholdingANOTHER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRKbUDYDNOSp",
        "outputId": "9d2fbfac-40e5-408f-ffde-9453b98a7acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.0],\n",
              " [88.33333333333333, 0.06666666666666667],\n",
              " [88.33333333333333, 0.06666666666666667],\n",
              " [88.33333333333333, 0.06666666666666667],\n",
              " [88.33333333333333, 0.06666666666666667],\n",
              " [88.33333333333333, 0.13333333333333333],\n",
              " [88.33333333333333, 0.13333333333333333],\n",
              " [88.33333333333333, 0.2],\n",
              " [88.33333333333333, 0.33333333333333337],\n",
              " [88.26666666666667, 0.4],\n",
              " [88.26666666666667, 0.46666666666666673],\n",
              " [88.26666666666667, 0.5333333333333333],\n",
              " [88.26666666666667, 0.5333333333333333],\n",
              " [88.2, 0.6],\n",
              " [88.13333333333333, 0.6666666666666667],\n",
              " [88.06666666666668, 0.7333333333333333],\n",
              " [88.06666666666668, 0.8],\n",
              " [88.06666666666668, 0.8],\n",
              " [87.86666666666667, 1.2],\n",
              " [87.86666666666667, 1.2],\n",
              " [87.73333333333333, 1.4000000000000001],\n",
              " [87.66666666666667, 1.5333333333333332],\n",
              " [87.6, 1.7333333333333332],\n",
              " [87.6, 1.7999999999999998],\n",
              " [87.53333333333333, 1.9333333333333333],\n",
              " [87.33333333333333, 2.533333333333333],\n",
              " [87.0, 2.933333333333333],\n",
              " [86.86666666666667, 3.2],\n",
              " [86.86666666666667, 3.3333333333333335],\n",
              " [86.8, 3.4666666666666663],\n",
              " [86.6, 3.8666666666666667],\n",
              " [86.46666666666667, 4.066666666666666],\n",
              " [86.33333333333333, 4.466666666666667],\n",
              " [86.26666666666667, 4.533333333333333],\n",
              " [86.13333333333333, 4.933333333333334],\n",
              " [85.73333333333333, 5.466666666666667],\n",
              " [85.46666666666667, 6.0],\n",
              " [85.39999999999999, 6.2],\n",
              " [85.06666666666666, 6.666666666666667],\n",
              " [84.93333333333334, 7.000000000000001],\n",
              " [84.8, 7.199999999999999],\n",
              " [84.53333333333333, 7.6],\n",
              " [84.33333333333334, 7.8],\n",
              " [83.86666666666667, 8.533333333333333],\n",
              " [83.73333333333333, 8.733333333333333],\n",
              " [83.46666666666667, 9.333333333333334],\n",
              " [83.26666666666667, 9.6],\n",
              " [83.13333333333334, 9.733333333333333],\n",
              " [82.8, 10.266666666666667],\n",
              " [82.66666666666667, 10.533333333333333],\n",
              " [82.33333333333334, 10.933333333333334],\n",
              " [82.26666666666667, 11.266666666666666],\n",
              " [82.19999999999999, 11.666666666666666],\n",
              " [82.06666666666666, 11.933333333333334],\n",
              " [81.73333333333333, 12.333333333333334],\n",
              " [81.46666666666667, 12.933333333333334],\n",
              " [81.2, 13.466666666666665],\n",
              " [80.66666666666666, 14.066666666666666],\n",
              " [80.33333333333333, 14.6],\n",
              " [80.06666666666666, 15.133333333333333],\n",
              " [79.73333333333333, 15.666666666666668],\n",
              " [79.46666666666667, 16.0],\n",
              " [79.26666666666667, 16.2],\n",
              " [78.93333333333334, 16.8],\n",
              " [78.0, 17.866666666666667],\n",
              " [77.60000000000001, 18.266666666666666],\n",
              " [76.93333333333334, 19.066666666666666],\n",
              " [76.13333333333333, 20.0],\n",
              " [75.13333333333333, 21.266666666666666],\n",
              " [74.2, 22.6],\n",
              " [73.0, 24.2],\n",
              " [71.26666666666667, 26.200000000000003],\n",
              " [68.13333333333334, 29.799999999999997],\n",
              " [64.2, 34.333333333333336],\n",
              " [63.53333333333333, 35.06666666666667],\n",
              " [62.26666666666667, 36.4],\n",
              " [61.266666666666666, 37.6],\n",
              " [60.13333333333334, 38.800000000000004],\n",
              " [59.0, 39.93333333333333],\n",
              " [57.46666666666667, 41.53333333333333],\n",
              " [55.60000000000001, 43.6],\n",
              " [53.0, 46.46666666666667],\n",
              " [47.66666666666667, 51.93333333333333],\n",
              " [47.66666666666667, 51.93333333333333],\n",
              " [47.199999999999996, 52.46666666666666],\n",
              " [46.06666666666667, 53.6],\n",
              " [45.06666666666666, 54.666666666666664],\n",
              " [44.2, 55.60000000000001],\n",
              " [43.06666666666666, 56.733333333333334],\n",
              " [41.53333333333333, 58.333333333333336],\n",
              " [40.2, 59.66666666666667],\n",
              " [38.6, 61.266666666666666],\n",
              " [34.86666666666667, 65.06666666666666],\n",
              " [34.86666666666667, 65.06666666666666],\n",
              " [34.13333333333333, 65.8],\n",
              " [33.666666666666664, 66.26666666666667],\n",
              " [32.733333333333334, 67.2],\n",
              " [31.866666666666667, 68.06666666666666],\n",
              " [31.266666666666666, 68.66666666666667],\n",
              " [29.933333333333334, 70.0],\n",
              " [28.799999999999997, 71.13333333333334],\n",
              " [27.200000000000003, 72.73333333333333],\n",
              " [24.46666666666667, 75.53333333333333],\n",
              " [24.46666666666667, 75.53333333333333],\n",
              " [24.333333333333336, 75.66666666666667],\n",
              " [23.733333333333334, 76.26666666666667],\n",
              " [23.133333333333333, 76.86666666666667],\n",
              " [22.066666666666666, 77.93333333333334],\n",
              " [21.266666666666666, 78.73333333333333],\n",
              " [20.733333333333334, 79.26666666666667],\n",
              " [20.266666666666666, 79.73333333333333],\n",
              " [19.066666666666666, 80.93333333333334],\n",
              " [17.066666666666666, 82.93333333333334],\n",
              " [17.066666666666666, 82.93333333333334],\n",
              " [16.866666666666667, 83.13333333333334],\n",
              " [16.8, 83.2],\n",
              " [16.53333333333333, 83.46666666666667],\n",
              " [16.333333333333332, 83.66666666666667],\n",
              " [15.8, 84.2],\n",
              " [15.4, 84.6],\n",
              " [14.666666666666666, 85.33333333333334],\n",
              " [13.533333333333333, 86.46666666666667],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332],\n",
              " [0.06666666666666667, 99.93333333333332]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UnknownMisclassifyANOTHER = []\n",
        "for i in range(89):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.1 + 0.01*i),100*misclassifyunknown(0.1 + 0.01*i),])\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.99 + 0.001*i),100*misclassifyunknown(0.99 + 0.001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.999 + 0.0001*i),100*misclassifyunknown(0.999 + 0.0001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.9999 + 0.00001*i),100*misclassifyunknown(0.9999 + 0.00001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.99999 + 0.000001*i),100*misclassifyunknown(0.99999 + 0.000001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.999999 + 0.0000001*i),100*misclassifyunknown(0.999999 + 0.0000001*i),])\n",
        "\n",
        "for i in range(9):\n",
        "  UnknownMisclassifyANOTHER.append([100*thresholding(0.9999999 + 0.00000001*i),100*misclassifyunknown(0.9999999 + 0.00000001*i),])\n",
        "\n",
        "UnknownMisclassifyANOTHER.append([100*thresholding(max_value),100*misclassifyunknown(max_value),])\n",
        "\n",
        "UnknownMisclassifyANOTHER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkK7Pwx6b9vA",
        "outputId": "a925339a-03b5-4a0e-c70e-5e899a6e52e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 100.0],\n",
              " [88.33333333333333, 99.9],\n",
              " [88.33333333333333, 99.6],\n",
              " [88.33333333333333, 99.6],\n",
              " [88.33333333333333, 99.6],\n",
              " [88.26666666666667, 99.6],\n",
              " [88.26666666666667, 99.3],\n",
              " [88.26666666666667, 99.2],\n",
              " [88.26666666666667, 99.1],\n",
              " [88.2, 99.0],\n",
              " [88.13333333333333, 98.8],\n",
              " [88.06666666666668, 98.6],\n",
              " [88.06666666666668, 98.6],\n",
              " [88.06666666666668, 98.3],\n",
              " [87.86666666666667, 98.2],\n",
              " [87.86666666666667, 98.0],\n",
              " [87.73333333333333, 97.8],\n",
              " [87.66666666666667, 97.6],\n",
              " [87.6, 97.39999999999999],\n",
              " [87.6, 96.89999999999999],\n",
              " [87.53333333333333, 95.89999999999999],\n",
              " [87.33333333333333, 95.19999999999999],\n",
              " [87.0, 94.19999999999999],\n",
              " [86.86666666666667, 93.4],\n",
              " [86.86666666666667, 92.30000000000001],\n",
              " [86.8, 91.5],\n",
              " [86.6, 90.5],\n",
              " [86.46666666666667, 89.9],\n",
              " [86.33333333333333, 89.0],\n",
              " [86.26666666666667, 88.3],\n",
              " [86.13333333333333, 87.0],\n",
              " [85.73333333333333, 86.7],\n",
              " [85.46666666666667, 86.1],\n",
              " [85.39999999999999, 85.5],\n",
              " [85.06666666666666, 84.89999999999999],\n",
              " [84.93333333333334, 84.5],\n",
              " [84.8, 83.7],\n",
              " [84.53333333333333, 83.1],\n",
              " [84.33333333333334, 82.1],\n",
              " [83.86666666666667, 80.9],\n",
              " [83.73333333333333, 80.2],\n",
              " [83.46666666666667, 79.60000000000001],\n",
              " [83.26666666666667, 79.0],\n",
              " [83.13333333333334, 77.8],\n",
              " [82.8, 77.0],\n",
              " [82.66666666666667, 75.8],\n",
              " [82.33333333333334, 75.5],\n",
              " [82.26666666666667, 74.8],\n",
              " [82.19999999999999, 74.0],\n",
              " [82.06666666666666, 73.6],\n",
              " [81.73333333333333, 72.7],\n",
              " [81.46666666666667, 72.0],\n",
              " [81.2, 71.39999999999999],\n",
              " [80.66666666666666, 70.39999999999999],\n",
              " [80.33333333333333, 69.69999999999999],\n",
              " [80.06666666666666, 68.7],\n",
              " [79.73333333333333, 67.7],\n",
              " [79.46666666666667, 66.5],\n",
              " [79.26666666666667, 65.8],\n",
              " [78.93333333333334, 64.0],\n",
              " [78.0, 63.0],\n",
              " [77.60000000000001, 61.4],\n",
              " [76.93333333333334, 60.099999999999994],\n",
              " [76.13333333333333, 58.4],\n",
              " [75.13333333333333, 55.800000000000004],\n",
              " [74.2, 52.6],\n",
              " [73.0, 50.7],\n",
              " [71.26666666666667, 47.599999999999994],\n",
              " [68.13333333333334, 43.5],\n",
              " [64.2, 35.6],\n",
              " [63.53333333333333, 34.8],\n",
              " [62.26666666666667, 33.2],\n",
              " [61.266666666666666, 32.4],\n",
              " [60.13333333333334, 31.3],\n",
              " [59.0, 29.799999999999997],\n",
              " [57.46666666666667, 27.800000000000004],\n",
              " [55.60000000000001, 25.5],\n",
              " [53.0, 22.3],\n",
              " [47.66666666666667, 18.7],\n",
              " [47.66666666666667, 18.7],\n",
              " [47.199999999999996, 18.3],\n",
              " [46.06666666666667, 17.7],\n",
              " [45.06666666666666, 16.6],\n",
              " [44.2, 15.8],\n",
              " [43.06666666666666, 15.0],\n",
              " [41.53333333333333, 13.600000000000001],\n",
              " [40.2, 12.5],\n",
              " [38.6, 11.0],\n",
              " [34.86666666666667, 9.1],\n",
              " [34.86666666666667, 9.1],\n",
              " [34.13333333333333, 9.1],\n",
              " [33.666666666666664, 8.6],\n",
              " [32.733333333333334, 8.3],\n",
              " [31.866666666666667, 8.1],\n",
              " [31.266666666666666, 8.0],\n",
              " [29.933333333333334, 7.6],\n",
              " [28.799999999999997, 7.1],\n",
              " [27.200000000000003, 6.5],\n",
              " [24.46666666666667, 5.6000000000000005],\n",
              " [24.46666666666667, 5.6000000000000005],\n",
              " [24.333333333333336, 5.6000000000000005],\n",
              " [23.733333333333334, 5.4],\n",
              " [23.133333333333333, 5.2],\n",
              " [22.066666666666666, 5.0],\n",
              " [21.266666666666666, 4.8],\n",
              " [20.733333333333334, 4.6],\n",
              " [20.266666666666666, 3.8],\n",
              " [19.066666666666666, 3.3000000000000003],\n",
              " [17.066666666666666, 2.1999999999999997],\n",
              " [17.066666666666666, 2.1999999999999997],\n",
              " [16.866666666666667, 2.0],\n",
              " [16.8, 1.7999999999999998],\n",
              " [16.53333333333333, 1.7000000000000002],\n",
              " [16.333333333333332, 1.6],\n",
              " [15.8, 1.6],\n",
              " [15.4, 1.4000000000000001],\n",
              " [14.666666666666666, 1.2],\n",
              " [13.533333333333333, 0.8],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FalseIdentifyANOTHER = []\n",
        "for i in range(89):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.1 + 0.01*i),100*false_identify(0.1 + 0.01*i),])\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.99 + 0.001*i),100*false_identify(0.99 + 0.001*i)])\n",
        "\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.999 + 0.0001*i),100*false_identify(0.999 + 0.0001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.9999 + 0.00001*i),100*false_identify(0.9999 + 0.00001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.99999 + 0.000001*i),100*false_identify(0.99999 + 0.000001*i),])\n",
        "\n",
        "for i in range(10):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.999999 + 0.0000001*i),100*false_identify(0.999999 + 0.0000001*i),])\n",
        "\n",
        "for i in range(9):\n",
        "  FalseIdentifyANOTHER.append([100*thresholding(0.9999999 + 0.00000001*i),100*false_identify(0.9999999 + 0.00000001*i),])\n",
        "\n",
        "FalseIdentifyANOTHER.append([100*thresholding(max_value),100*false_identify(max_value),])\n",
        "FalseIdentifyANOTHER"
      ],
      "metadata": {
        "id": "oe9DmTAKNOXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62dc5db5-2085-4120-b852-cc506e68464d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.666666666666666],\n",
              " [88.33333333333333, 11.600000000000001],\n",
              " [88.33333333333333, 11.600000000000001],\n",
              " [88.33333333333333, 11.600000000000001],\n",
              " [88.33333333333333, 11.600000000000001],\n",
              " [88.33333333333333, 11.533333333333333],\n",
              " [88.33333333333333, 11.533333333333333],\n",
              " [88.33333333333333, 11.466666666666667],\n",
              " [88.33333333333333, 11.333333333333332],\n",
              " [88.26666666666667, 11.333333333333332],\n",
              " [88.26666666666667, 11.266666666666666],\n",
              " [88.26666666666667, 11.200000000000001],\n",
              " [88.26666666666667, 11.200000000000001],\n",
              " [88.2, 11.200000000000001],\n",
              " [88.13333333333333, 11.200000000000001],\n",
              " [88.06666666666668, 11.200000000000001],\n",
              " [88.06666666666668, 11.133333333333335],\n",
              " [88.06666666666668, 11.133333333333335],\n",
              " [87.86666666666667, 10.933333333333334],\n",
              " [87.86666666666667, 10.933333333333334],\n",
              " [87.73333333333333, 10.866666666666665],\n",
              " [87.66666666666667, 10.8],\n",
              " [87.6, 10.666666666666668],\n",
              " [87.6, 10.6],\n",
              " [87.53333333333333, 10.533333333333333],\n",
              " [87.33333333333333, 10.133333333333333],\n",
              " [87.0, 10.066666666666666],\n",
              " [86.86666666666667, 9.933333333333334],\n",
              " [86.86666666666667, 9.8],\n",
              " [86.8, 9.733333333333333],\n",
              " [86.6, 9.533333333333333],\n",
              " [86.46666666666667, 9.466666666666667],\n",
              " [86.33333333333333, 9.2],\n",
              " [86.26666666666667, 9.2],\n",
              " [86.13333333333333, 8.933333333333334],\n",
              " [85.73333333333333, 8.799999999999999],\n",
              " [85.46666666666667, 8.533333333333333],\n",
              " [85.39999999999999, 8.4],\n",
              " [85.06666666666666, 8.266666666666666],\n",
              " [84.93333333333334, 8.066666666666666],\n",
              " [84.8, 8.0],\n",
              " [84.53333333333333, 7.866666666666666],\n",
              " [84.33333333333334, 7.866666666666666],\n",
              " [83.86666666666667, 7.6],\n",
              " [83.73333333333333, 7.533333333333333],\n",
              " [83.46666666666667, 7.199999999999999],\n",
              " [83.26666666666667, 7.133333333333333],\n",
              " [83.13333333333334, 7.133333333333333],\n",
              " [82.8, 6.933333333333333],\n",
              " [82.66666666666667, 6.800000000000001],\n",
              " [82.33333333333334, 6.7333333333333325],\n",
              " [82.26666666666667, 6.466666666666667],\n",
              " [82.19999999999999, 6.133333333333333],\n",
              " [82.06666666666666, 6.0],\n",
              " [81.73333333333333, 5.933333333333334],\n",
              " [81.46666666666667, 5.6000000000000005],\n",
              " [81.2, 5.333333333333334],\n",
              " [80.66666666666666, 5.266666666666667],\n",
              " [80.33333333333333, 5.066666666666666],\n",
              " [80.06666666666666, 4.8],\n",
              " [79.73333333333333, 4.6],\n",
              " [79.46666666666667, 4.533333333333333],\n",
              " [79.26666666666667, 4.533333333333333],\n",
              " [78.93333333333334, 4.266666666666667],\n",
              " [78.0, 4.133333333333333],\n",
              " [77.60000000000001, 4.133333333333333],\n",
              " [76.93333333333334, 4.0],\n",
              " [76.13333333333333, 3.8666666666666667],\n",
              " [75.13333333333333, 3.5999999999999996],\n",
              " [74.2, 3.2],\n",
              " [73.0, 2.8000000000000003],\n",
              " [71.26666666666667, 2.533333333333333],\n",
              " [68.13333333333334, 2.0666666666666664],\n",
              " [64.2, 1.4666666666666666],\n",
              " [63.53333333333333, 1.4000000000000001],\n",
              " [62.26666666666667, 1.3333333333333335],\n",
              " [61.266666666666666, 1.1333333333333333],\n",
              " [60.13333333333334, 1.0666666666666667],\n",
              " [59.0, 1.0666666666666667],\n",
              " [57.46666666666667, 1.0],\n",
              " [55.60000000000001, 0.8],\n",
              " [53.0, 0.5333333333333333],\n",
              " [47.66666666666667, 0.4],\n",
              " [47.66666666666667, 0.4],\n",
              " [47.199999999999996, 0.33333333333333337],\n",
              " [46.06666666666667, 0.33333333333333337],\n",
              " [45.06666666666666, 0.26666666666666666],\n",
              " [44.2, 0.2],\n",
              " [43.06666666666666, 0.2],\n",
              " [41.53333333333333, 0.13333333333333333],\n",
              " [40.2, 0.13333333333333333],\n",
              " [38.6, 0.13333333333333333],\n",
              " [34.86666666666667, 0.06666666666666667],\n",
              " [34.86666666666667, 0.06666666666666667],\n",
              " [34.13333333333333, 0.06666666666666667],\n",
              " [33.666666666666664, 0.06666666666666667],\n",
              " [32.733333333333334, 0.06666666666666667],\n",
              " [31.866666666666667, 0.06666666666666667],\n",
              " [31.266666666666666, 0.06666666666666667],\n",
              " [29.933333333333334, 0.06666666666666667],\n",
              " [28.799999999999997, 0.06666666666666667],\n",
              " [27.200000000000003, 0.06666666666666667],\n",
              " [24.46666666666667, 0.0],\n",
              " [24.46666666666667, 0.0],\n",
              " [24.333333333333336, 0.0],\n",
              " [23.733333333333334, 0.0],\n",
              " [23.133333333333333, 0.0],\n",
              " [22.066666666666666, 0.0],\n",
              " [21.266666666666666, 0.0],\n",
              " [20.733333333333334, 0.0],\n",
              " [20.266666666666666, 0.0],\n",
              " [19.066666666666666, 0.0],\n",
              " [17.066666666666666, 0.0],\n",
              " [17.066666666666666, 0.0],\n",
              " [16.866666666666667, 0.0],\n",
              " [16.8, 0.0],\n",
              " [16.53333333333333, 0.0],\n",
              " [16.333333333333332, 0.0],\n",
              " [15.8, 0.0],\n",
              " [15.4, 0.0],\n",
              " [14.666666666666666, 0.0],\n",
              " [13.533333333333333, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0],\n",
              " [0.06666666666666667, 0.0]]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6Vf4U_EQDh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class-adaptive threshold"
      ],
      "metadata": {
        "id": "astEHCwEWNFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run #1"
      ],
      "metadata": {
        "id": "mgZEtA56usFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_known = prediction_known_ensemble_1\n",
        "prediction_unknown = prediction_unknown_ensemble_1"
      ],
      "metadata": {
        "id": "EEg9x6-vurgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores = []\n",
        "for i in range(15):\n",
        "  ThresholdNeverSeenBefores.append(np.max(prediction_unknown[:,i]))"
      ],
      "metadata": {
        "id": "8Tyc8FzcWUk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "C_count0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp_hvYS9WP6J",
        "outputId": "31bbeece-e4e3-48b4-b7a8-e75401e1577c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "mistake0\n",
        "print(\"Number of mistakes in this class:\",mistake0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAu3K9nEWP8P",
        "outputId": "d2523bb2-ce72-4870-8cb4-d5946b80147e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "C_count1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHzot9WdXkC7",
        "outputId": "32361923-d275-4bf6-b5e2-e3ca258747fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4RVufLtXkAR",
        "outputId": "4419e3a8-d6e6-4af8-f7a9-f80310401dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184\n",
            "Number of mistakes in this class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[184])] = max(prediction_known[184])"
      ],
      "metadata": {
        "id": "9xZ6sVoHNNI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG9PHsHdNQdK",
        "outputId": "ef2c5652-4c39-4a47-8c07-d0f5fc3005df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "C_count2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmmpoficmsIo",
        "outputId": "7c54d38a-2ded-4f4a-8591-bb41878192e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "mistake2\n",
        "print(\"Number of mistakes in this class:\",mistake2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTiQq-WKmsMB",
        "outputId": "197ff2e1-cea2-4798-bc94-cd1ed80f4b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "C_count3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsNwlMBAmsN3",
        "outputId": "5fd2d4b4-926a-4670-d570-e0460925683a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP9oRkpvmsPv",
        "outputId": "7f9133cd-c416-4929-9436-0294bd97a40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "344\n",
            "Number of mistakes in this class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[344])] = max(prediction_known[344])"
      ],
      "metadata": {
        "id": "NoSkKXrjNXtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ootm-oO6Na0k",
        "outputId": "762904c5-fa55-413f-eda5-58d4d389c1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "C_count4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGdmlHmUmsSi",
        "outputId": "52ac89f0-b262-4f39-9e61-cf79090bc640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTXAEphBmsU_",
        "outputId": "6c524516-cff4-4576-e614-021688fe981d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "416\n",
            "418\n",
            "Number of mistakes in this class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[416])] = max(prediction_known[416])"
      ],
      "metadata": {
        "id": "bHbI6AuvpouI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ya9wY9iNjmW",
        "outputId": "90586deb-f77a-4a11-8096-c1abef746516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "C_count5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwuWW0SkqIB_",
        "outputId": "312be9d3-10ed-4dc1-f777-c042e0bc12ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMRqQVgIqKWx",
        "outputId": "2ad52401-0f49-439c-a30b-de483d5f1ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "C_count6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJt2-_RjqhZM",
        "outputId": "e4e9752b-853d-431c-cee5-a7d7503ede92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ0sklVOqhbU",
        "outputId": "7dde95f8-2d18-4c2a-ee5b-766f9a499dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "602\n",
            "603\n",
            "604\n",
            "607\n",
            "608\n",
            "616\n",
            "618\n",
            "619\n",
            "623\n",
            "624\n",
            "628\n",
            "630\n",
            "651\n",
            "699\n",
            "Number of mistakes in this class: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[699])] = max(prediction_known[699])"
      ],
      "metadata": {
        "id": "46R_9FV_Nv0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRmK5EjkN0bY",
        "outputId": "9a3d109d-cde6-45b6-df1e-936854bce86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "C_count7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMsrIQt1qhe2",
        "outputId": "0ef54842-64dc-48ab-dd83-1f0dc67a48bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gau4TuhUqhiG",
        "outputId": "e25ada5d-2783-472e-ca16-c9e2d2ff8111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "C_count8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyufo5sUqhkP",
        "outputId": "5999b9a4-8b66-4ede-b3a6-70158e6eff66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqBpRvSWqhnj",
        "outputId": "af77a494-6f54-48d8-d51c-b7d73e92a1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "C_count9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbQcIVdBqhpv",
        "outputId": "4cfb5625-d56a-467d-d76d-8239387e3276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6TeE6FjrOKT",
        "outputId": "5cc49c78-cce6-4a05-fb51-e8b308ccce58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "923\n",
            "944\n",
            "982\n",
            "985\n",
            "Number of mistakes in this class: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[985])] = max(prediction_known[985])"
      ],
      "metadata": {
        "id": "UFjElWxVOGwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rmu0fy2ONYK",
        "outputId": "38547e9b-cdd0-4c4f-cafc-4d4f45a43fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 10*100,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[i + 10*100]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "C_count10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfyOeyVNONgV",
        "outputId": "444ff00f-bde3-459f-bb04-81635192a321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekt_bBxvONcA",
        "outputId": "e518b4d3-719e-430d-a700-d17116e28ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 11*100,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[i + 11*100]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "C_count11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6byw4L6ONjQ",
        "outputId": "65846544-1606-451c-8eb9-4ca64c17c78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTo9fjq0ONn7",
        "outputId": "1227973c-401b-40da-8acb-9695b2f9ee43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 12*100,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[i + 12*100]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "C_count12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZEkgZKTQHnK",
        "outputId": "aab216cb-7116-4d1e-9b34-77db9262535c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B0SAhUMQHpb",
        "outputId": "ef5d4c44-4002-49d4-ad1e-6e7f86a69e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 13*100,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[i + 13*100]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "C_count13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIpPnc7NQHtA",
        "outputId": "99dd2db6-7180-4f7e-abd3-580989d50cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-6dJoSlQHvl",
        "outputId": "08970118-bb79-4f1b-e717-af3f8d3d2c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 14*100,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[i + 14*100]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0\n",
        "C_count14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulMey8s2QHy6",
        "outputId": "58fba400-2c00-478a-cd43-56234c4844e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3rfjenwQH37",
        "outputId": "c38bb8e0-2e82-4ada-8d1b-931bc77e5927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "\n",
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "\n",
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "\n",
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "\n",
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "\n",
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "\n",
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "\n",
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "\n",
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "\n",
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "\n",
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "\n",
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "\n",
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "\n",
        "\n",
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "\n",
        "\n",
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "\n",
        "NumberOfMistakesAfterThrAdj = [mistake0, mistake1, mistake2, mistake3, mistake4, mistake5, mistake6, mistake7,mistake8,mistake9,mistake10,mistake11,mistake12,mistake13,mistake14]\n",
        "NumberOfMistakesAfterThrAdj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFTqb2dlQH-K",
        "outputId": "907f6122-74a8-45af-9979-ac5c4c473de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "\n",
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "\n",
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "\n",
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "\n",
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "\n",
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "\n",
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "\n",
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "\n",
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "\n",
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "\n",
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1000 + i,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[1000 + i]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "\n",
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1100 + i,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[1100 + i]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "\n",
        "\n",
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1200 + i,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[1200 + i]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "\n",
        "\n",
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1300 + i,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[1300 + i]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "\n",
        "\n",
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1400 + i,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[1400 + i]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0"
      ],
      "metadata": {
        "id": "jXF3VkIGQIA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FinalDistributionOver10ClassesRun1 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9]]\n",
        "FinalDistributionOver10ClassesRun1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tCq14c7KIKZ",
        "outputId": "6edda0e8-245a-42d3-9983-14f9d39194b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 2],\n",
              " [3, 15],\n",
              " [4, 46],\n",
              " [5, 5],\n",
              " [6, 45],\n",
              " [7, 72],\n",
              " [8, 28],\n",
              " [9, 99],\n",
              " [10, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FinalDistributionOver15ClassesRun1 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9],[11,C_count10],[12,C_count11],[13,C_count12],[14,C_count13],[15,C_count14]]\n",
        "FinalDistributionOver15ClassesRun1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDX1bRdiKKii",
        "outputId": "ae12ffa8-7f0a-4761-a37c-26f2ea495bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 2],\n",
              " [3, 15],\n",
              " [4, 46],\n",
              " [5, 5],\n",
              " [6, 45],\n",
              " [7, 72],\n",
              " [8, 28],\n",
              " [9, 99],\n",
              " [10, 7],\n",
              " [11, 7],\n",
              " [12, 32],\n",
              " [13, 22],\n",
              " [14, 89],\n",
              " [15, 60]]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9)/1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8xTrLFWLVPX",
        "outputId": "8521fef5-e0fe-476f-fb6d-eb9777f3c239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.319"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9 + C_count10 + C_count11 + C_count12 + C_count13 + C_count14)/1500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t0rgKFRLij_",
        "outputId": "94b608e0-5cd4-41d5-8af7-692d68e4e6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3526666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QuanBGbMVzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run #2"
      ],
      "metadata": {
        "id": "yXZDKhZ0MWKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_known = prediction_known_ensemble_2\n",
        "prediction_unknown = prediction_unknown_ensemble_2"
      ],
      "metadata": {
        "id": "4LS8rdLNMWKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores = []\n",
        "for i in range(15):\n",
        "  ThresholdNeverSeenBefores.append(np.max(prediction_unknown[:,i]))"
      ],
      "metadata": {
        "id": "C_abGbZfMWKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "C_count0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9906c550-699d-4343-b1d6-0f7a24f9c129",
        "id": "jzjmM1NDMWKs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "mistake0\n",
        "print(\"Number of mistakes in this class:\",mistake0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d142fadb-5029-438b-8f44-2bc9ab0ffc1d",
        "id": "sO6Irab4MWKs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "C_count1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7cac2eb-82ee-4569-9d88-b2c00760fc02",
        "id": "RErY8WZwMWKs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6280fe91-f55f-48fc-abc1-22187005a21b",
        "id": "zFPtjUgRMWKs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184\n",
            "Number of mistakes in this class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[184])] = max(prediction_known[184])"
      ],
      "metadata": {
        "id": "VFNOocaEMWKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811ee4a8-412a-4c8c-9f13-314e6a297a30",
        "id": "8xrQo0pmMWKs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "C_count2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4331e9f8-e05a-4b98-9ef4-c975047fee87",
        "id": "VX38Qjz4MWKs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "mistake2\n",
        "print(\"Number of mistakes in this class:\",mistake2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a736b5-261d-482f-cbcf-372acffef865",
        "id": "hEq5osTYMWKt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "C_count3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec983fdd-eb2b-4aef-ecbc-c831e39ba07c",
        "id": "eqgVOTUdMWKt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87bb195-dbf0-4010-a2f0-deeabe37b4bf",
        "id": "bAJu8iPQMWKt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "306\n",
            "344\n",
            "Number of mistakes in this class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[344])] = max(prediction_known[344])"
      ],
      "metadata": {
        "id": "vN2xDtC2MWKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a354b86-a32e-45c4-ca28-c8950d7dd6aa",
        "id": "wQtuTTt5MWKt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "C_count4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df07cf35-0edf-4501-d623-7879c6643415",
        "id": "2j-pl4rdMWKt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296d7c11-db3a-42b9-eca3-2748819de244",
        "id": "oY4UIXLWMWKt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "416\n",
            "418\n",
            "Number of mistakes in this class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[418])] = max(prediction_known[418])"
      ],
      "metadata": {
        "id": "CO92AfLMMWKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec3dc8f-09e8-4ab6-cfc6-2e40f636277c",
        "id": "jirVTvIXMWKu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "C_count5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2376d26-c6e2-4fdb-8418-ff85a76381d0",
        "id": "Cp8ZhMNSMWKu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79951077-3ee8-4115-d025-0d84a6b92728",
        "id": "stTW_WiGMWKu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "C_count6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8560c32-c70e-445a-ccd9-82ba3718a695",
        "id": "GZpVhqsPMWKu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af8bc50-c41c-4d14-c7e9-5047eeaa6cf3",
        "id": "70RfuL9ZMWKu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "602\n",
            "603\n",
            "604\n",
            "607\n",
            "608\n",
            "616\n",
            "618\n",
            "619\n",
            "623\n",
            "624\n",
            "628\n",
            "630\n",
            "651\n",
            "657\n",
            "661\n",
            "665\n",
            "681\n",
            "697\n",
            "699\n",
            "Number of mistakes in this class: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[699])] = max(prediction_known[699])"
      ],
      "metadata": {
        "id": "ogfeBvgAMWKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc4126b0-f595-4e31-b4e2-64c9895e919f",
        "id": "YPmYxRpwMWKu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "C_count7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1063db4-c092-4c49-8a35-8a9258366031",
        "id": "qqjv_hlrMWKv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd96861-8c48-4161-fa64-24ef1ac59a67",
        "id": "43gz7-HGMWKv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "C_count8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab6dc6d-d60d-4b12-dda1-1957b4907144",
        "id": "xpQxjo_tMWKv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679c78d0-377c-4c3f-d74f-a26ba70f77cc",
        "id": "KGo4JbBvMWKv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "C_count9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc27019-50bc-4120-efc4-744810880944",
        "id": "OLxLg7SQMWKv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d009b1a6-b87e-45dd-f8f4-1b47f28008c7",
        "id": "XMqLpSXyMWKv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "918\n",
            "923\n",
            "944\n",
            "982\n",
            "985\n",
            "Number of mistakes in this class: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[985])] = max(prediction_known[985])"
      ],
      "metadata": {
        "id": "YQ50lS6iMWKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2f5a18-a55b-4235-e0f1-2f1a4a6d48c7",
        "id": "_-RDG_6LMWKw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 10*100,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[i + 10*100]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "C_count10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612099f9-40d8-46b4-fbfb-5dbf81a0adb2",
        "id": "Nt56ls57MWKw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9958e35e-120f-41b7-fc96-e97e45ac53a5",
        "id": "UPh-SEtoMWKw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 11*100,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[i + 11*100]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "C_count11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd915cc-9429-4dca-d632-6821a117e2d7",
        "id": "f3MCRzgTMWKw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b1f146-94e4-40ed-ca1d-acc7f6e74557",
        "id": "k1I6W5iKMWKw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 12*100,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[i + 12*100]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "C_count12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a22707a-c93d-406f-a898-028df7e3e5c1",
        "id": "Euoqkd1mMWKw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192eabbb-7c2e-452b-e690-10c0506f3a71",
        "id": "ZNKf7L2NMWKw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 13*100,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[i + 13*100]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "C_count13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2967f0de-f932-4cb3-9e67-2ffa9943b4f7",
        "id": "D7xHjAdcMWKw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e48c6b4-d762-45ef-b043-a19ad0a16f73",
        "id": "Vu0ZrL5DMWKx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 14*100,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[i + 14*100]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0\n",
        "C_count14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9c7121-d0a5-42be-8f48-62738f4eaa35",
        "id": "0PEEKg4cMWKx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfa9b59-bbe2-4cf9-badf-2bd479db023e",
        "id": "w4DZFCoxMWKx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "\n",
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "\n",
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "\n",
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "\n",
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "\n",
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "\n",
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "\n",
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "\n",
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "\n",
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "\n",
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "\n",
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "\n",
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "\n",
        "\n",
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "\n",
        "\n",
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "\n",
        "NumberOfMistakesAfterThrAdj = [mistake0, mistake1, mistake2, mistake3, mistake4, mistake5, mistake6, mistake7,mistake8,mistake9,mistake10,mistake11,mistake12,mistake13,mistake14]\n",
        "NumberOfMistakesAfterThrAdj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea2a3f9-1c99-4348-f1f0-f319fc5f6a0f",
        "id": "hfL7oFo7MWKx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "\n",
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "\n",
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "\n",
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "\n",
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "\n",
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "\n",
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "\n",
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "\n",
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "\n",
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "\n",
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1000 + i,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[1000 + i]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "\n",
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1100 + i,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[1100 + i]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "\n",
        "\n",
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1200 + i,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[1200 + i]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "\n",
        "\n",
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1300 + i,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[1300 + i]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "\n",
        "\n",
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1400 + i,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[1400 + i]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0"
      ],
      "metadata": {
        "id": "4EgFCpY7MWKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FinalDistributionOver10ClassesRun2 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9]]\n",
        "FinalDistributionOver10ClassesRun2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e352572-09bb-46a5-a184-0960a643b912",
        "id": "rxurRTj0MWKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 2],\n",
              " [3, 11],\n",
              " [4, 42],\n",
              " [5, 4],\n",
              " [6, 41],\n",
              " [7, 65],\n",
              " [8, 28],\n",
              " [9, 99],\n",
              " [10, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FinalDistributionOver15ClassesRun2 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9],[11,C_count10],[12,C_count11],[13,C_count12],[14,C_count13],[15,C_count14]]\n",
        "FinalDistributionOver15ClassesRun2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d706c9ec-59f5-4f54-9718-5c0101ea5497",
        "id": "SiTc1ijEMWKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 2],\n",
              " [3, 11],\n",
              " [4, 42],\n",
              " [5, 4],\n",
              " [6, 41],\n",
              " [7, 65],\n",
              " [8, 28],\n",
              " [9, 99],\n",
              " [10, 1],\n",
              " [11, 6],\n",
              " [12, 31],\n",
              " [13, 10],\n",
              " [14, 90],\n",
              " [15, 73]]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9)/1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd5a2de-f3cf-4126-9f5e-a8f86c01d79e",
        "id": "SVEKPNh-MWKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.293"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9 + C_count10 + C_count11 + C_count12 + C_count13 + C_count14)/1500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4823ec1-2b1a-4a2f-e2d8-fa05066c1733",
        "id": "pFlZ1ZDbMWKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3353333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4s4y_3vRMdV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run #3"
      ],
      "metadata": {
        "id": "osHoz6PKMdpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_known = prediction_known_ensemble_3\n",
        "prediction_unknown = prediction_unknown_ensemble_3"
      ],
      "metadata": {
        "id": "F9zBJgNfMdpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores = []\n",
        "for i in range(15):\n",
        "  ThresholdNeverSeenBefores.append(np.max(prediction_unknown[:,i]))"
      ],
      "metadata": {
        "id": "zTSyIrtpMdpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "C_count0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3163210d-7304-4569-d62d-0dbf5a2ed616",
        "id": "pQ8W5pQzMdpk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "mistake0\n",
        "print(\"Number of mistakes in this class:\",mistake0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c40c2ce-d25c-42dd-c6e9-6dc13d1a8713",
        "id": "KGalO8N0Mdpk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "C_count1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f782a8f2-e181-42fc-a58f-de7722edb6c8",
        "id": "J8Oteaf8Mdpk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd908fc0-9372-4038-b99b-f9c8dcad484f",
        "id": "0moELJC5Mdpk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184\n",
            "Number of mistakes in this class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[184])] = max(prediction_known[184])"
      ],
      "metadata": {
        "id": "KRgXmPOuMdpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4858f3-7856-4d98-dd7f-728f70282c8f",
        "id": "O8JzXFACMdpk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "C_count2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6230ab-d6b3-4694-87a8-96a65427c4a7",
        "id": "IKWD9ppnMdpl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "mistake2\n",
        "print(\"Number of mistakes in this class:\",mistake2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c35536-4147-4d69-98dc-c28d2048dcd2",
        "id": "G-p6wXKrMdpl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "C_count3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec5b601-5495-4979-aa2d-f27f487dce01",
        "id": "Rslm__lyMdpl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9f0f60-25eb-46ed-ccf5-8aa19ef3daf8",
        "id": "XRGXPEJRMdpl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "344\n",
            "Number of mistakes in this class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[344])] = max(prediction_known[344])"
      ],
      "metadata": {
        "id": "rSxnqHosMdpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75aba8d1-6f35-4535-9111-9dfa4b68b182",
        "id": "8tvdQPckMdpl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "C_count4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4444081-8b12-44f7-812b-2aad0920e57f",
        "id": "L-h6LSptMdpl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6b96b5-7cbc-4289-e094-3e7e7dcf859f",
        "id": "lGcHtimjMdpl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "416\n",
            "418\n",
            "Number of mistakes in this class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[418])] = max(prediction_known[418])"
      ],
      "metadata": {
        "id": "314O7lGrMdpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee853221-9547-4a84-c2d4-2b0779a84cca",
        "id": "wRDNppIJMdpm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "C_count5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434b31e8-dff5-4396-f9da-a534d2c47a8e",
        "id": "90028L4OMdpm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86879918-8593-41bf-acc9-118e35327c4d",
        "id": "TofzDE5YMdpm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "C_count6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6c10ff-fcc1-4244-d1db-6584455d03d3",
        "id": "tnRrwairMdpm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd61186-7ccb-4738-a2b1-ac294d6d17e9",
        "id": "YiKXlIoUMdpm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "602\n",
            "603\n",
            "604\n",
            "607\n",
            "608\n",
            "616\n",
            "618\n",
            "619\n",
            "623\n",
            "624\n",
            "628\n",
            "630\n",
            "651\n",
            "657\n",
            "699\n",
            "Number of mistakes in this class: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[699])] = max(prediction_known[699])"
      ],
      "metadata": {
        "id": "coG4Vi6cMdpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef7ef37-c909-4bce-b936-773d0ca7eacc",
        "id": "47sP1rQiMdpm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "C_count7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9ab6cf-7be1-4092-ff8b-d7160dfd7a10",
        "id": "oTD1xWGHMdpm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892c7522-b6d5-4b4c-8e86-26206faec1c5",
        "id": "VG-JWua9Mdpn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "C_count8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8fa9afb-d880-4e01-c8d2-e58aed628cd1",
        "id": "pipZSxW7Mdpn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9824cf4e-4875-413f-f0a1-da39670cfab5",
        "id": "dlE0myxLMdpn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "C_count9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf881d4-f78c-48b9-85ca-c4556cc22eda",
        "id": "75iBBOxyMdpn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6343ef88-49d5-4e76-863b-06ad38a66e31",
        "id": "-iYgHNE6Mdpn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "923\n",
            "944\n",
            "982\n",
            "985\n",
            "Number of mistakes in this class: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[985])] = max(prediction_known[985])"
      ],
      "metadata": {
        "id": "FhxFacSYMdpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205dbf14-431a-4f6a-facd-0b73226ebe34",
        "id": "SFtqLz6dMdpn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 10*100,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[i + 10*100]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "C_count10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e228638-5595-444e-ee91-5fda0157af55",
        "id": "v4MVZWvKMdpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acb6e6a-f0f9-496b-8e1f-6da8606ae67a",
        "id": "nCn8gDRcMdpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 11*100,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[i + 11*100]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "C_count11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107fe8f6-1907-45a3-88ee-f1b8b008d7ea",
        "id": "x8KYf4Y0Mdpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba2381e-b5f6-4dce-9ed3-9e68993dd83a",
        "id": "EG2NejdtMdpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 12*100,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[i + 12*100]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "C_count12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cee443-f09c-4959-baa2-7577d0d69ec8",
        "id": "5s_FTaDyMdpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b04083f-de99-4f08-98f6-6e5bd3f0addc",
        "id": "iUQ4CgL2Mdpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 13*100,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[i + 13*100]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "C_count13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b73360e-6623-4f36-d8fc-8ff0d253de85",
        "id": "8GVB51_JMdpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557f3e62-a5a2-4c6b-a08b-5fe8d89381ce",
        "id": "bqYRwxZgMdpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 14*100,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[i + 14*100]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0\n",
        "C_count14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460dea59-7489-47b3-85cc-0945d9289f97",
        "id": "v6p4AyFNMdpp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6acf28e-a816-4259-ab27-f8a95300e4be",
        "id": "4z11UyB9Mdpp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "\n",
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "\n",
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "\n",
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "\n",
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "\n",
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "\n",
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "\n",
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "\n",
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "\n",
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "\n",
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "\n",
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "\n",
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "\n",
        "\n",
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "\n",
        "\n",
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "\n",
        "NumberOfMistakesAfterThrAdj = [mistake0, mistake1, mistake2, mistake3, mistake4, mistake5, mistake6, mistake7,mistake8,mistake9,mistake10,mistake11,mistake12,mistake13,mistake14]\n",
        "NumberOfMistakesAfterThrAdj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1329b07a-13ea-4517-d185-9abe170076af",
        "id": "XyR8LQy5Mdpp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "\n",
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "\n",
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "\n",
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "\n",
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "\n",
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "\n",
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "\n",
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "\n",
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "\n",
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "\n",
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1000 + i,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[1000 + i]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "\n",
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1100 + i,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[1100 + i]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "\n",
        "\n",
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1200 + i,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[1200 + i]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "\n",
        "\n",
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1300 + i,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[1300 + i]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "\n",
        "\n",
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1400 + i,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[1400 + i]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0"
      ],
      "metadata": {
        "id": "W3Ox_CGRMdpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FinalDistributionOver10ClassesRun3 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9]]\n",
        "FinalDistributionOver10ClassesRun3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d380928-2adc-4037-b0f8-10c448f3bd14",
        "id": "6QVx6GaeMdpp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 2],\n",
              " [3, 10],\n",
              " [4, 43],\n",
              " [5, 5],\n",
              " [6, 50],\n",
              " [7, 66],\n",
              " [8, 25],\n",
              " [9, 99],\n",
              " [10, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FinalDistributionOver15ClassesRun3 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9],[11,C_count10],[12,C_count11],[13,C_count12],[14,C_count13],[15,C_count14]]\n",
        "FinalDistributionOver15ClassesRun3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3baff78-a834-4a3a-fc05-465eefe7a298",
        "id": "SsDAyUJEMdpq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 2],\n",
              " [3, 10],\n",
              " [4, 43],\n",
              " [5, 5],\n",
              " [6, 50],\n",
              " [7, 66],\n",
              " [8, 25],\n",
              " [9, 99],\n",
              " [10, 4],\n",
              " [11, 9],\n",
              " [12, 39],\n",
              " [13, 6],\n",
              " [14, 93],\n",
              " [15, 67]]"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9)/1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c8add0-9b6a-435a-cdb6-457e79fbaa01",
        "id": "IHCQcsFYMdpq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.304"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9 + C_count10 + C_count11 + C_count12 + C_count13 + C_count14)/1500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbff0656-e28b-4f6e-eff5-db670ed71986",
        "id": "1XbNU4tpMdpq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3453333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6usFl3A6MnYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run #4"
      ],
      "metadata": {
        "id": "GXb76J4wMnxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_known = prediction_known_ensemble_4\n",
        "prediction_unknown = prediction_unknown_ensemble_4"
      ],
      "metadata": {
        "id": "9csHSJOsMnxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores = []\n",
        "for i in range(15):\n",
        "  ThresholdNeverSeenBefores.append(np.max(prediction_unknown[:,i]))"
      ],
      "metadata": {
        "id": "OKvgeZioMnxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "C_count0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77cd3e8-bbfc-44c1-c116-db62218a6d3e",
        "id": "bGhq8VKxMnxh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "mistake0\n",
        "print(\"Number of mistakes in this class:\",mistake0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b2dce8-99b8-418a-e9de-9a91c7e1eadf",
        "id": "_qealqdLMnxh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "C_count1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1315bce-8b51-43af-9efa-b558507c61e6",
        "id": "L5s3SI2AMnxh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851709c1-8751-4550-c850-c6694391c1c1",
        "id": "txOdGBxcMnxi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184\n",
            "Number of mistakes in this class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[184])] = max(prediction_known[184])"
      ],
      "metadata": {
        "id": "eM_15lZIMnxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "mistake1\n",
        "print(\"Number of mistakes in this class:\",mistake1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d376d0-8f7c-4930-ec1d-c204d4b75c4c",
        "id": "hlMycJ8DMnxi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "C_count2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b9e778-95d4-4f3a-9cab-bff2ffbea86d",
        "id": "Etj3mhKxMnxi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "mistake2\n",
        "print(\"Number of mistakes in this class:\",mistake2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8c9127-72ea-4b9a-e8b4-61d486078baa",
        "id": "TCXs7ptGMnxi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "C_count3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0056af-3082-47b3-ae6e-ad2b11f1a212",
        "id": "ZXdIQc8_Mnxi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62889f85-2867-46f4-fb34-6bd9e52b5a8c",
        "id": "whNho1a0Mnxj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "306\n",
            "344\n",
            "Number of mistakes in this class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[344])] = max(prediction_known[344])"
      ],
      "metadata": {
        "id": "ov259UzhMnxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "mistake3\n",
        "print(\"Number of mistakes in this class:\",mistake3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18ac090-e67d-437c-f8bf-4ce409c61a2a",
        "id": "qEHLb3scMnxj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "C_count4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396f24f0-6f04-4681-9900-fd2706aaacc4",
        "id": "wcS9OWfyMnxj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5ed52c-2ad2-4183-c0ee-24ed925e6aa6",
        "id": "xLnqOkRiMnxj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "416\n",
            "418\n",
            "Number of mistakes in this class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[418])] = max(prediction_known[418])"
      ],
      "metadata": {
        "id": "HyE3oJSzMnxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1306d4-1dbc-466e-ccf9-b21e7a0c1d27",
        "id": "U6_wvRNUMnxj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "C_count5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5be0d3e-b3b6-4fc7-b2ee-4369a5fcb3ea",
        "id": "GSIL0j9YMnxk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948149dd-a57a-4e07-c370-579fe4b4fb5a",
        "id": "tcIiXZJPMnxk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "C_count6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18140f7d-5af0-4d63-c6f1-ac3b97108f50",
        "id": "SZq68-D-Mnxk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de0e484-9c91-4b19-be09-9a9ea85899e8",
        "id": "kNhwlVmDMnxk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "602\n",
            "603\n",
            "604\n",
            "607\n",
            "608\n",
            "616\n",
            "618\n",
            "619\n",
            "623\n",
            "624\n",
            "628\n",
            "630\n",
            "651\n",
            "657\n",
            "699\n",
            "Number of mistakes in this class: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[651])] = max(prediction_known[651])"
      ],
      "metadata": {
        "id": "NrPFgOL9Mnxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07f0791-59d9-4d72-daf7-b2a99fc13cb6",
        "id": "2nZSpTtKMnxk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "C_count7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2b4ecb-c3f5-4689-90e2-1a1128b4ea19",
        "id": "Diu-4pVaMnxk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8fa9de-77aa-412a-b9cc-c5370b967d4c",
        "id": "-PfKkp4QMnxl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "C_count8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7512c1-132c-4b47-c893-34ce64cf98cf",
        "id": "y-7_mtrfMnxl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f18023-81c0-4aba-af63-39c34e49557e",
        "id": "DRZQ_Kn_Mnxl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "C_count9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f1b436-3d08-453a-ec79-ad04a6ed88b6",
        "id": "zFa44efoMnxl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba82ede9-fd1e-4e6b-9e9e-b08d17b6fb18",
        "id": "hHS705iAMnxl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "918\n",
            "923\n",
            "944\n",
            "985\n",
            "Number of mistakes in this class: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ThresholdNeverSeenBefores[np.argmax(prediction_known[985])] = max(prediction_known[985])"
      ],
      "metadata": {
        "id": "Ro_W_5TOMnxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131a6cf6-c2ae-4d8b-eb02-31f71087f559",
        "id": "ifocjRy3Mnxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 10*100,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[i + 10*100]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "C_count10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec314db-251b-456e-afd8-41b89bb7ef0f",
        "id": "8JPnA3sxMnxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c9bc42-3f74-439d-e544-21d0649cc4f5",
        "id": "_T2bZaXHMnxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 11*100,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[i + 11*100]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "C_count11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b884424-8dad-496b-ac60-28451f33f201",
        "id": "tEdaDr9qMnxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64031d87-47d1-4b8e-f33f-df59e4e936d8",
        "id": "Vqt86YjxMnxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 12*100,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[i + 12*100]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "C_count12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "007c4c68-7aac-417a-9348-118a4713a416",
        "id": "MmyEm-k-Mnxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36cb0113-6c7c-413f-a87a-c675cfd2a201",
        "id": "VU8hAzcDMnxm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 13*100,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[i + 13*100]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "C_count13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e22f31-b967-43d1-bc72-2b4cef152cde",
        "id": "oWAsZtvGMnxn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake13)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507b8bdf-07fb-44a9-84ec-3aee5f5a02c4",
        "id": "EJ8qGT2IMnxn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i + 14*100,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[i + 14*100]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0\n",
        "C_count14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e931dd-8b29-4977-9fac-712b224834f7",
        "id": "RXb_ZE2qMnxn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "print(\"Number of mistakes in this class:\",mistake14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0f3326-ac4f-4a46-c16c-f735ae7b1983",
        "id": "_dwrCk7EMnxn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mistakes in this class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistake0 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[i]) != 0 and max(prediction_known[i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[i])]:\n",
        "    mistake0 += 1\n",
        "    print(i)\n",
        "  else:\n",
        "    mistake0 += 0\n",
        "\n",
        "mistake1 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[100 + i]) != 1 and max(prediction_known[100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[100 + i])]:\n",
        "    mistake1 += 1\n",
        "    print(100 + i)\n",
        "  else:\n",
        "    mistake1 += 0\n",
        "\n",
        "mistake2 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[200 + i]) != 2 and max(prediction_known[200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[200 + i])]:\n",
        "    mistake2 += 1\n",
        "    print(200 + i)\n",
        "  else:\n",
        "    mistake2 += 0\n",
        "\n",
        "mistake3 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[300 + i]) != 3 and max(prediction_known[300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[300 + i])]:\n",
        "    mistake3 += 1\n",
        "    print(300 + i)\n",
        "  else:\n",
        "    mistake3 += 0\n",
        "\n",
        "mistake4 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[400 + i]) != 4 and max(prediction_known[400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[400 + i])]:\n",
        "    mistake4 += 1\n",
        "    print(400 + i)\n",
        "  else:\n",
        "    mistake4 += 0\n",
        "\n",
        "mistake5 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[500 + i]) != 5 and max(prediction_known[500 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[500 + i])]:\n",
        "    mistake5 += 1\n",
        "    print(500 + i)\n",
        "  else:\n",
        "    mistake5 += 0\n",
        "\n",
        "mistake6 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[600 + i]) != 6 and max(prediction_known[600 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[600 + i])]:\n",
        "    mistake6 += 1\n",
        "    print(600 + i)\n",
        "  else:\n",
        "    mistake6 += 0\n",
        "\n",
        "mistake7 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[700 + i]) != 7 and max(prediction_known[700 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[700 + i])]:\n",
        "    mistake7 += 1\n",
        "    print(700 + i)\n",
        "  else:\n",
        "    mistake7 += 0\n",
        "\n",
        "mistake8 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[800 + i]) != 8 and max(prediction_known[800 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[800 + i])]:\n",
        "    mistake8 += 1\n",
        "    print(800 + i)\n",
        "  else:\n",
        "    mistake8 += 0\n",
        "\n",
        "mistake9 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[900 + i]) != 9 and max(prediction_known[900 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[900 + i])]:\n",
        "    mistake9 += 1\n",
        "    print(900 + i)\n",
        "  else:\n",
        "    mistake9 += 0\n",
        "\n",
        "mistake10 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1000 + i]) != 10 and max(prediction_known[1000 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1000 + i])]:\n",
        "    mistake10 += 1\n",
        "    print(1000 + i)\n",
        "  else:\n",
        "    mistake10 += 0\n",
        "\n",
        "mistake11 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1100 + i]) != 11 and max(prediction_known[1100 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1100 + i])]:\n",
        "    mistake11 += 1\n",
        "    print(1100 + i)\n",
        "  else:\n",
        "    mistake11 += 0\n",
        "\n",
        "mistake12 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1200 + i]) != 12 and max(prediction_known[1200 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1200 + i])]:\n",
        "    mistake12 += 1\n",
        "    print(1200 + i)\n",
        "  else:\n",
        "    mistake12 += 0\n",
        "\n",
        "\n",
        "mistake13 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1300 + i]) != 13 and max(prediction_known[1300 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1300 + i])]:\n",
        "    mistake13 += 1\n",
        "    print(1300 + i)\n",
        "  else:\n",
        "    mistake13 += 0\n",
        "\n",
        "\n",
        "mistake14 = 0\n",
        "for i in range(100):\n",
        "  if np.argmax(prediction_known[1400 + i]) != 14 and max(prediction_known[1400 + i]) > ThresholdNeverSeenBefores[np.argmax(prediction_known[1400 + i])]:\n",
        "    mistake14 += 1\n",
        "    print(1400 + i)\n",
        "  else:\n",
        "    mistake14 += 0\n",
        "\n",
        "NumberOfMistakesAfterThrAdj = [mistake0, mistake1, mistake2, mistake3, mistake4, mistake5, mistake6, mistake7,mistake8,mistake9,mistake10,mistake11,mistake12,mistake13,mistake14]\n",
        "NumberOfMistakesAfterThrAdj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9abe8d-c52e-447c-c5d0-dbe58e932a0c",
        "id": "1U32BtNEMnxn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_count0 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[i,0] > ThresholdNeverSeenBefores[0] and np.argmax(prediction_known[i]) == 0:\n",
        "    C_count0 += 1\n",
        "  else:\n",
        "    C_count0 += 0\n",
        "\n",
        "C_count1 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[100 + i,1] > ThresholdNeverSeenBefores[1] and np.argmax(prediction_known[100 + i]) == 1:\n",
        "    C_count1 += 1\n",
        "  else:\n",
        "    C_count1 += 0\n",
        "\n",
        "C_count2 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[200 + i,2] > ThresholdNeverSeenBefores[2] and np.argmax(prediction_known[200 + i]) == 2:\n",
        "    C_count2 += 1\n",
        "  else:\n",
        "    C_count2 += 0\n",
        "\n",
        "C_count3 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[300 + i,3] > ThresholdNeverSeenBefores[3] and np.argmax(prediction_known[300 + i]) == 3:\n",
        "    C_count3 += 1\n",
        "  else:\n",
        "    C_count3 += 0\n",
        "\n",
        "C_count4 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[400 + i,4] > ThresholdNeverSeenBefores[4] and np.argmax(prediction_known[400 + i]) == 4:\n",
        "    C_count4 += 1\n",
        "  else:\n",
        "    C_count4 += 0\n",
        "\n",
        "C_count5 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[500 + i,5] > ThresholdNeverSeenBefores[5] and np.argmax(prediction_known[500 + i]) == 5:\n",
        "    C_count5 += 1\n",
        "  else:\n",
        "    C_count5 += 0\n",
        "\n",
        "C_count6 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[600 + i,6] > ThresholdNeverSeenBefores[6] and np.argmax(prediction_known[600 + i]) == 6:\n",
        "    C_count6 += 1\n",
        "  else:\n",
        "    C_count6 += 0\n",
        "\n",
        "C_count7 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[700 + i,7] > ThresholdNeverSeenBefores[7]  and np.argmax(prediction_known[700 + i]) == 7:\n",
        "    C_count7 += 1\n",
        "  else:\n",
        "    C_count7 += 0\n",
        "\n",
        "C_count8 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[800 + i,8] > ThresholdNeverSeenBefores[8] and np.argmax(prediction_known[800 + i]) == 8:\n",
        "    C_count8 += 1\n",
        "  else:\n",
        "    C_count8 += 0\n",
        "\n",
        "C_count9 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[900 + i,9] > ThresholdNeverSeenBefores[9] and np.argmax(prediction_known[900 + i]) == 9:\n",
        "    C_count9 += 1\n",
        "  else:\n",
        "    C_count9 += 0\n",
        "\n",
        "C_count10 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1000 + i,10] > ThresholdNeverSeenBefores[10] and np.argmax(prediction_known[1000 + i]) == 10:\n",
        "    C_count10 += 1\n",
        "  else:\n",
        "    C_count10 += 0\n",
        "\n",
        "C_count11 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1100 + i,11] > ThresholdNeverSeenBefores[11] and np.argmax(prediction_known[1100 + i]) == 11:\n",
        "    C_count11 += 1\n",
        "  else:\n",
        "    C_count11 += 0\n",
        "\n",
        "\n",
        "C_count12 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1200 + i,12] > ThresholdNeverSeenBefores[12] and np.argmax(prediction_known[1200 + i]) == 12:\n",
        "    C_count12 += 1\n",
        "  else:\n",
        "    C_count12 += 0\n",
        "\n",
        "\n",
        "C_count13 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1300 + i,13] > ThresholdNeverSeenBefores[13] and np.argmax(prediction_known[1300 + i]) == 13:\n",
        "    C_count13 += 1\n",
        "  else:\n",
        "    C_count13 += 0\n",
        "\n",
        "\n",
        "C_count14 = 0\n",
        "for i in range(100):\n",
        "  if prediction_known[1400 + i,14] > ThresholdNeverSeenBefores[14] and np.argmax(prediction_known[1400 + i]) == 14:\n",
        "    C_count14 += 1\n",
        "  else:\n",
        "    C_count14 += 0"
      ],
      "metadata": {
        "id": "G5ja4_sLMnxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FinalDistributionOver10ClassesRun4 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9]]\n",
        "FinalDistributionOver10ClassesRun4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9ea8ef-d99a-438d-e090-c3860fb49124",
        "id": "_mjJW4tbMnxo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 1],\n",
              " [3, 15],\n",
              " [4, 48],\n",
              " [5, 4],\n",
              " [6, 50],\n",
              " [7, 72],\n",
              " [8, 27],\n",
              " [9, 99],\n",
              " [10, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FinalDistributionOver15ClassesRun4 = [[1,C_count0],[2,C_count1],[3,C_count2],[4,C_count3],[5,C_count4],[6,C_count5],[7,C_count6],[8,C_count7],[9,C_count8],[10,C_count9],[11,C_count10],[12,C_count11],[13,C_count12],[14,C_count13],[15,C_count14]]\n",
        "FinalDistributionOver15ClassesRun4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188141e1-2e5d-4829-edbd-c98c5cef4029",
        "id": "EbjxsAc_Mnxo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0],\n",
              " [2, 1],\n",
              " [3, 15],\n",
              " [4, 48],\n",
              " [5, 4],\n",
              " [6, 50],\n",
              " [7, 72],\n",
              " [8, 27],\n",
              " [9, 99],\n",
              " [10, 2],\n",
              " [11, 7],\n",
              " [12, 48],\n",
              " [13, 11],\n",
              " [14, 92],\n",
              " [15, 56]]"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9)/1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce37b7e-252f-49f7-c0a1-ab7c3d35d437",
        "id": "Q4LHiIRfMnxo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.318"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(C_count0 + C_count1 + C_count2 + C_count3 + C_count4 + C_count5 + C_count6 + C_count7 + C_count8 + C_count9 + C_count10 + C_count11 + C_count12 + C_count13 + C_count14)/1500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa70ce74-d8cd-4f14-8b90-146cd3103c99",
        "id": "CxP5sG68Mnxp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3546666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Combine the datasets into one list of lists\n",
        "all_datasets = [FinalDistributionOver10ClassesRun1, FinalDistributionOver10ClassesRun2, FinalDistributionOver10ClassesRun3, FinalDistributionOver10ClassesRun4]\n",
        "\n",
        "# Initialize an empty list to store the new dataset\n",
        "new_dataset = []\n",
        "\n",
        "# Loop through x values from 1 to 10\n",
        "for x_value in range(1, 11):\n",
        "    y_values = []\n",
        "\n",
        "    # Extract y values for each dataset corresponding to the current x_value\n",
        "    for dataset in all_datasets:\n",
        "        for data_point in dataset:\n",
        "            if data_point[0] == x_value:\n",
        "                y_values.append(data_point[1])\n",
        "\n",
        "    # Calculate the average y value and standard deviation\n",
        "    avg_y = np.mean(y_values)\n",
        "    std_y = np.std(y_values)\n",
        "\n",
        "    # Append the new data point to the new dataset\n",
        "    new_dataset.append([x_value, avg_y, std_y])\n",
        "\n",
        "# Print the new dataset\n",
        "for data_point in new_dataset:\n",
        "    print(data_point)"
      ],
      "metadata": {
        "id": "5LxQwEOhUQCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a481eb5-6837-4296-d49b-eb860b2ad360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0.0, 0.0]\n",
            "[2, 1.75, 0.4330127018922193]\n",
            "[3, 12.75, 2.277608394786075]\n",
            "[4, 44.75, 2.384848003542364]\n",
            "[5, 4.5, 0.5]\n",
            "[6, 46.5, 3.774917217635375]\n",
            "[7, 68.75, 3.2691742076555053]\n",
            "[8, 27.0, 1.224744871391589]\n",
            "[9, 99.0, 0.0]\n",
            "[10, 3.5, 2.29128784747792]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiOAa6olqnym",
        "outputId": "5733c16b-ef8a-45a8-c534-818c1248cdb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0.0, 0.0],\n",
              " [2, 1.75, 0.4330127018922193],\n",
              " [3, 12.75, 2.277608394786075],\n",
              " [4, 44.75, 2.384848003542364],\n",
              " [5, 4.5, 0.5],\n",
              " [6, 46.5, 3.774917217635375],\n",
              " [7, 68.75, 3.2691742076555053],\n",
              " [8, 27.0, 1.224744871391589],\n",
              " [9, 99.0, 0.0],\n",
              " [10, 3.5, 2.29128784747792]]"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Combine the datasets into one list of lists\n",
        "all_datasets = [FinalDistributionOver15ClassesRun1, FinalDistributionOver15ClassesRun2, FinalDistributionOver15ClassesRun3, FinalDistributionOver15ClassesRun4]\n",
        "\n",
        "# Initialize an empty list to store the new dataset\n",
        "new_dataset = []\n",
        "\n",
        "# Loop through x values from 1 to 10\n",
        "for x_value in range(1, 16):\n",
        "    y_values = []\n",
        "\n",
        "    # Extract y values for each dataset corresponding to the current x_value\n",
        "    for dataset in all_datasets:\n",
        "        for data_point in dataset:\n",
        "            if data_point[0] == x_value:\n",
        "                y_values.append(data_point[1])\n",
        "\n",
        "    # Calculate the average y value and standard deviation\n",
        "    avg_y = np.mean(y_values)\n",
        "    std_y = np.std(y_values)\n",
        "\n",
        "    # Append the new data point to the new dataset\n",
        "    new_dataset.append([x_value, avg_y, std_y])\n",
        "\n",
        "# Print the new dataset\n",
        "for data_point in new_dataset:\n",
        "    print(data_point)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WihmOq4ts158",
        "outputId": "54c2f54e-4c47-4b45-c853-8bd566e4cb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0.0, 0.0]\n",
            "[2, 1.75, 0.4330127018922193]\n",
            "[3, 12.75, 2.277608394786075]\n",
            "[4, 44.75, 2.384848003542364]\n",
            "[5, 4.5, 0.5]\n",
            "[6, 46.5, 3.774917217635375]\n",
            "[7, 68.75, 3.2691742076555053]\n",
            "[8, 27.0, 1.224744871391589]\n",
            "[9, 99.0, 0.0]\n",
            "[10, 3.5, 2.29128784747792]\n",
            "[11, 7.25, 1.0897247358851685]\n",
            "[12, 37.5, 6.800735254367722]\n",
            "[13, 12.25, 5.931905258852336]\n",
            "[14, 91.0, 1.5811388300841898]\n",
            "[15, 64.0, 6.519202405202649]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset"
      ],
      "metadata": {
        "id": "jH760zIIs9m-",
        "outputId": "4612e88b-6b49-42e5-f757-d6e6ad1c5545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0.0, 0.0],\n",
              " [2, 1.75, 0.4330127018922193],\n",
              " [3, 12.75, 2.277608394786075],\n",
              " [4, 44.75, 2.384848003542364],\n",
              " [5, 4.5, 0.5],\n",
              " [6, 46.5, 3.774917217635375],\n",
              " [7, 68.75, 3.2691742076555053],\n",
              " [8, 27.0, 1.224744871391589],\n",
              " [9, 99.0, 0.0],\n",
              " [10, 3.5, 2.29128784747792],\n",
              " [11, 7.25, 1.0897247358851685],\n",
              " [12, 37.5, 6.800735254367722],\n",
              " [13, 12.25, 5.931905258852336],\n",
              " [14, 91.0, 1.5811388300841898],\n",
              " [15, 64.0, 6.519202405202649]]"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNvKgK2aqLoWn05i/xe0wi7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}